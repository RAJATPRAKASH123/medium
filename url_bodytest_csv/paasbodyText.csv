story_url,bodyText
https://medium.com/@nnilesh7756/what-are-cloud-computing-services-iaas-caas-paas-faas-saas-ac0f6022d36e?source=search_post---------0,"Sign in
There are currently no responses for this story.
Be the first to respond.
Nilesh Suryavanshi
Nov 8, 2017¬∑2 min read
Today, everyone are moving towards Cloud World (AWS/GCP/Azure/PCF/VMC). It might be a public cloud, a private cloud or a hybrid cloud.
But are you aware of what are Services Cloud Computing provides to us ????
Majorly there are three categories of Cloud Computing Services:
a) Infrastructure as a Service (IaaS) : It provides only a base infrastructure (Virtual machine, Software Define Network, Storage attached). End user have to configure and manage platform and environment, deploy applications on it.
AWS (EC2), GCP (CE), Microsoft Azure (VM) are examples of Iaas.
b) Software as a Service (SaaS) : It is sometimes called to as ‚Äúon-demand software‚Äù. Typically accessed by users using a thin client via a web browser. In SaaS everything can be managed by vendors: applications, runtime, data, middleware, OSes, virtualization, servers, storage and networking, End users have to use it.
GMAIL is Best example of SaaS. Google team managing everything just we have to use the application through any of client or in browsers. Other examples SAP, Salesforce .
c) Platform as a Service (PaaS): It provides a platform allowing end user to develop, run, and manage applications without the complexity of building and maintaining the infrastructure.
Google App Engine, CloudFoundry, Heroku, AWS (Beanstalk) are some examples of PaaS.
Below fig 1.0 while give you more idea on it.
d) Container as a Service (CaaS): Is a form of container-based virtualization in which container engines, orchestration and the underlying compute resources are delivered to users as a service from a cloud provider.
Google Container Engine(GKE), AWS (ECS), Azure (ACS) and Pivotal (PKS) are some examples of CaaS.
e) Function as a Service (FaaS): It provides a platform allowing customers to develop, run, and manage application functionalities without the complexity of building and maintaining the infrastructure.
AWS (Lamda), Google Cloud Function are some examples of Faas
Hope this gives you clear idea on what are Cloud Computing Services provided in market!!!!!!
@nilesh7756 | VMware NSX-T | Kubernetes | Openshift | PCF/PKS | Docker | AWS | GCE/GKE | DevOps
See all (25)
935 
7
935¬†claps
935 
7
@nilesh7756 | VMware NSX-T | Kubernetes | Openshift | PCF/PKS | Docker | AWS | GCE/GKE | DevOps
About
Write
Help
Legal
Get the Medium app
"
https://m.oursky.com/saas-paas-and-iaas-explained-in-one-graphic-d56c3e6f4606?source=search_post---------1,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
The Pizza-as-a-Service metaphor was firstly introduced by Albert Barron in 2014 as a visualization of the differences between Infrastructure-as-a-service (IaaS), Platform-as-a-service (PaaS) and Software-as-a-service (SaaS). At first sight it looks brilliant ‚Äî but if you look in depth, it falls apart. This diagram wants to illustrate that you need to do less and less, but the items that are listed and increasingly ‚Äúoutsourced‚Äù don‚Äôt fit the comparison. I‚Äôll look at the services in the original diagram and suggest a better comparison for people who want to choose which services to use.
The basic concept is in each case you get a pizza, though in some cases, you do all of the work; in other cases you have other people do the work for you.
In the diagram, the amount of work you do is in the following order:
Made at home > Take and bake > Pizza delivery > Dining out
Let‚Äôs focus on two stages first: if ‚ÄúTraditional On-Premises Deployment = Made at home‚Äù, why does ‚ÄúInfrastructure-as-a-Service = Take and bake‚Äù? At first glance, it means that the service provider gives you a pre-made pizza, so you can bake it in your own kitchen without making a mess. However, this is not how Infrastructure-as-a-Service differs from Traditional On-Premises Deployment.
Rather than thinking of the consumer doing less and less, let‚Äôs think about a product that is increasingly customizable because less is pre-made by the service provider.
By adopting an X-aaS, you don‚Äôt need to worry about a certain ‚ÄúX‚Äù ‚Äî be it infrastructure, platform, software or pizza. Instead of forcing the X-aaS model into existing pizza services, I will be dissecting the steps to making an increasingly customized pizza.
Pizza-as-a-Service means you can enjoy a pizza (a fully finished product) upon order. You call the pizza delivery so the pizza is already designed, prepared and baked by somebody else and arrives hot and ready to eat.
In the world of SaaS, we only need to sign up to use the service. We can customize some features, layouts, or users (pizza toppings), but we never need to worry about the deployment and framework the project is used (just like how the service providers put our orders together for us). It also means we can‚Äôt choose this brand of cheese over that, or how long they choose to bake it for. If you don‚Äôt like their crust, you‚Äôll have to choose another company. So what should be the service layer right below Pizza-as-a-Sevice?
The idea of ‚Äútake-and-bake‚Äù in the original diagram was close, but it misses a few key ideas. The take-and-bake doesn‚Äôt allow customization, which is what IaaS and PaaS offer. IaaS and PaaS take care of some backend things you don‚Äôt want to deal with, and probably come with API‚Äôs, but you choose what you can add.
Instead of a ‚Äútake-and-bake‚Äù, the next level down is more like walking into a kitchen with a ready-to-cook package of ingredients. IaaS and PaaS are when you want to make your own pizza, but you don‚Äôt need to worry about buying ingredients, prep work, or having the right tools. You can focus on rolling out the dough, assembling the pre-washed ingredients to your taste and factors like size and thickness before sticking it into someone‚Äôs provided oven.
If you use IaaS or PaaS, you can focus on your own business logic and implement your user interface on a reliable platform. The service provider manages the hosting and hardware technologies for you.
This option might not be suitable for every end-user. At least you need some pizza-making skills to turn the dough into a pizza.
Kitchen equipment is infrastructural investment. For engineers, this is where your code runs. It also includes all the infrastructure you need (such as runtime, storage, networking). Without it, your product doesn‚Äôt go anywhere, but on the other hand, it doesn‚Äôt affect the nature of the product itself.
For a pizza, the next layer below is buying your own ingredients to prepare exactly the pizza you want, with the specific brands you like. But you don‚Äôt have to worry about the oven, rolling pin, whether you counter is big enough, or the pizza cutter. Now, you have absolute control on what pizza you are going to make, but maybe the rental kitchen doesn‚Äôt have every type of tool you want.
For hard core pizza makers ‚Äî not only will you want to choose all your pizza ingredients and make it from scratch, you will also want complete control of all the tools in your kitchen: the oven that has the exact settings and capabilities you want, the pizza stone many places don‚Äôt have, or let your dough sit overnight at the most optimal corner of your fridge. And finally, you can drizzle that homemade chilli oil on top and savor it fresh out of the oven.
You may think that‚Äôs overkill ‚Äî but in real world, sometimes the effort is necessary if you can‚Äôt find a service that will let you customize for that one essential deployment setting, such as a firewall configuration or that specific network setting requirements.
SaaS (Software-as-a-Service)
PaaS (Platform-as-a-Service)
IaaS (Infrastructure-as-a-Service)
On-Premises Deployment
IaaS and PaaS save us a huge amount of preparation work, so we can customize our ‚Äúpizza‚Äú and bake it fast. The best type of service is whatever suits your product best.
Hope these examples clear up these concepts.
If you found this piece helpful, follow Oursky Publication for more startup/entrepreneurship/project management/app dev hacks! üíö
üòª At Oursky we‚Äôre all about helping brands and entrepreneurs make their ideas happen. Get in touch if you‚Äôre looking for a partner to help build your next digital product.
We Develop for Developers.
365 
1
365¬†claps
365 
1
Written by
Software Engineer | Previously Growth @ SCMP | davidng.hk | Love hiking and camping.
We Develop for Developers. We open source best practices for product development for web and mobile. Visit us at oursky.com
Written by
Software Engineer | Previously Growth @ SCMP | davidng.hk | Love hiking and camping.
We Develop for Developers. We open source best practices for product development for web and mobile. Visit us at oursky.com
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/capital-one-tech/serverless-is-the-paas-i-always-wanted-9e9c7d925539?source=search_post---------2,"There are currently no responses for this story.
Be the first to respond.
Top highlight
In the early days of Cloud computing, there was a really simple picture we would share to explain the Cloud Service Model, sometimes with a diagram like the pyramid above. I‚Äôm sure you‚Äôve seen a version of it ‚Äî a way of showing the different service types as a stack, highlighting the relationships between each. When I gave training for new associates beginning to use Cloud, the instruction would cover the different service layers, and the definition of each one would be spelled out.
Infrastructure as a Service ‚Äî the foundation to the new Cloud computing model. I‚Äôd articulate how using this model differed from owning your own datacenter, including no longer having to focus on managing facilities, and the per unit cost benefits that these major providers have in scale for racking commodity servers and top of rack switches.
Platform as a Service was well ‚Äî a work-in-progress. There were some real world examples, but much of it was still describing what was possible vs. what was being used in the marketplace. The advantages were clear as we needed more than just a provider providing compute capacity, and I would cite this reference from NIST that carried great appeal.
Cloud Platform as a Service (PaaS). The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations. ‚Äî source: National Institute of Standards and Technology, ca 2009.
Software as a Service ‚Äî is where speed and agility would really be unlocked. There were great examples to highlight the success and growth of Office365 and Workday, as well as many industry specific services. The model and benefits were easy to articulate given the time to market savings, and it fit nicely into the microservices discussions that were also being introduced at the same time.
Given the need to build custom servicing systems and leverage standard engineering patterns, the concept was great, but of the three service types, the PaaS market was slowest to develop, and without great success stories, harder to explain the value proposition to others.
Okay, fast forward to today, and let‚Äôs check in on our options for building infrastructure in the Cloud. How are they similar and how are they different from when I first gave my training?
Given that it‚Äôs 2017, let‚Äôs use a common contemporary investment project as an example ‚Äî building a voice chat-bot. This hypothetical chat-bot will be a friendly voice-driven assistant that can operate on the Amazon Alexa platform and help walk individuals through finding and booking their ideal vacation getaway. Marketing says it will be a big hit this winter as people seek to escape the cold weather. Therefore, we should assume it can handle thousands of requests per second; and when running our ad campaigns, potentially service millions of prospects each day. Let‚Äôs also assume we‚Äôre looking to push the envelope for Amazon Alexa development so the returned content will not just be spoken words but will also include the ability to play sounds from exotic locales and use the card feature to show pictures of possible destinations.
The first alternative is to use the foundational parts that a Cloud provider like AWS offers, similar to a traditional on-premise datacenter. We will benefit by having all of this infrastructure pre-provisioned for us, but will need to automate the provisioning of the different parts, as well as the assembly. The solution might end up looking like this.
Within the new platform are a series of stacks:
Each stack will have an ELB in each region, it‚Äôs own cluster of EC2 instances (complete with auto-scaling groups), as well as requisite EBS volumes, subnets, and security groups. We will automate it all via CloudFormation.
How much infrastructure is needed? Well it depends on what our non-functional requirements, but assuming extensive use of auto-scaling, running workloads across zones and regions to provide a HA solution, blue-green deployments for code rollouts, and non-production environments, around 60‚Äì80 EC2 instances. Let‚Äôs say half of those are on-demand, and the others we can convert to Reserved Instances. Throw in a dozen or so ELB‚Äôs, 120‚Äì150 EBS volumes, some with high IOPS for the analytics. Sizing matters, and while the web layer we might be able to get down to small general purpose instances, the analytic and content management components may be specialty types with large capacity.
The first option has many pieces and parts, and is going to take multiple engineers familiar with the domains to go off and provision each stack. One of the aspirations we had in going to the Cloud was that we were getting out of the complexity in managing infrastructure, so how else can we accomplish this? Let‚Äôs try and use the new serverless approach, and see how it compares.
Rather than building ‚Äústacks‚Äù like in the first option, we‚Äôre using different services in the AWS catalog (numbers match stacks for option #1 above).
Now let‚Äôs go further in comparing the two options.
One key concept to understand between the options is what the pricing model is, and if we‚Äôre paying for capacity (option #1) or consumption (option #2). For example, the chart below describes the typical utilization of a servicing application that peaks during the day. In option#1, we‚Äôre paying for everything in the box, but in option #2, we‚Äôre just paying for what is consumed ‚Äî the ‚Äúblue area‚Äù. There are features available with IaaS like autoscaling where capacity can be dropped during off hours (see dark line), but even with this done really well, there still will be some amount of excess capacity being paid for that‚Äôs not used. If it‚Äôs not done well or the workload isn‚Äôt a great fit for auto-scaling, the delta between the two areas is huge ‚Äî potentially 3‚Äì5x.
As long as we have AWS experts, it‚Äôs far quicker to provision infrastructure in option #2. It‚Äôs getting us out of managing the low level components that can be time consuming to orchestrate, and each service exposes the key parts for us to tune. Also there‚Äôs a labor impact with option #1 when we focus cycles to configure and test the auto-scaling rules. While this might be time well-spent, it drives up the labor effort (thus isn‚Äôt free). In option #2, this complexity is taken on by the cloud provider and included into the price of the service.
Now after reading this, you might be inclined to improve on these design options using containers and swarm/kubernetes/mesos, etc. to orchestrate. They are a good fit for stack #1, a moderate fit for stacks #4 & #5, and a poor fit for stacks #2 & #3. Containers are a great technology as they can simplify application provisioning and deployment, and drive up the utilization of our infrastructure ‚Äî narrowing the gap between what‚Äôs been provisioned and what‚Äôs being consumed in the chart above.
First, let‚Äôs clarify our assumptions that if we use ECS, it‚Äôs just a variation of option #2 as the Cloud provider is taking on the base infrastructure and tooling. As a customer, if I build containers on top of the base infrastructure, that is a new approach with merits over option #1, but let‚Äôs ask ourselves a clarifying question on what our broader goals are as an organization.
Where do you want your engineering talent to spend time on? Do you want them to become experts at building infrastructure abstraction layers, or do you want them to be creating product features?
For me, I don‚Äôt work for a Cloud hosting company, and building tools and infrastructure abstraction layers isn‚Äôt our core competency. I do want my engineers to spend time focusing on customers, and building features to improve their financial lives. While my team could be building tools to manage containers, this effort takes away from features/cycles that could be dedicated to product development. From my perspective, abstractions on top of infrastructure are great works of engineering, but isn‚Äôt that what the Cloud provider is supposed to be doing for me?
Serverless patterns are still maturing, and while products are evolving quickly, they still have limitations which can require workarounds to mimic the features that can be built with frameworks from scratch on top of IaaS. Over time, I‚Äôm assuming these limitations will go away as these services become more mature. There are also some significant shifts in infrastructure approaches that groups must adopt for this new model to be a success. These include:
One of the biggest mindset shifts when deploying the serverless model is in how the network is managed, as well as how different components communicate. Most current security models assume a private network namespace that mimics a traditional datacenter. Small blocks of address space are allocated up-front into subnets based on size estimations for the applications. Modeling tools for managing the software defined network are robust, facilitating the complexity built up in legacy firewalls, but there still is an assumption of doing a local network design for the application where IP address ranges are king.
The serverless model assumes role-based access as the authentication model between components, with a network space that is largely hidden from the application. Whomever is provisioning the infrastructure will need to understand the relationships between the components (i.e. which components can talk to others), and be able to author policies that enable this communication. For example, in Option #2, the execution role for the Lambda function will need a policy enabling it to write and read only to relevant S3 buckets and DDB tables. This is how we get to the principal of ‚Äúleast privilege‚Äù in information security.
When building highly redundant platforms that can deploy applications across regions, we need to engineer how the persisted data will be replicated in support of any RTO/RPO service levels. While S3 can easily be configured to transport data across regions, products like DynamoDB & RDS are designed to provide capability across zones (datacenters) and require extra tools and patterns to replicate across regions. When building applications using IaaS, the assumption is that you‚Äôre doing it all yourself, and in some cases there are frameworks or tools to install that enable this to be done. Long-term I believe that these features will get built into the services as features by the Cloud providers, and new features are being released every day.
Building efficient infrastructure using a Cloud provider requires good engineering skills and a training plan for associates when they‚Äôre getting started. Building robust platforms with just the IaaS services does get complex, requiring an in-depth understanding of proper EC2 instance types, security groups, EBS options, autoscaling, and configuration of ELB‚Äôs. It may be easier to convert a legacy sysadmin over to IaaS given that many of the patterns are the same (although most that I‚Äôve met are gapped on the required networking skills).
In the serverless model, the level of detail needed to get started with an individual service is less as the provisioning tooling provides the framework for how to get started, and defaults are provided to simplify the model. It‚Äôs only when we start combining many services do catch-up to the level of complexity needed to learn the IaaS model that assumes significant depth on how to assemble a very fungible set of tools to support a specific pattern.
If I were to update the training dialogue from my Cloud Computing class to reflect the state of Cloud Service Models in 2017, the examples I would cite in the PaaS section offerings from AWS including Lambda, DynamoDB, and RedShift. They are an excellent model ‚Äúusing programming languages and tools supported by the provider‚Äù while not requiring me to ‚Äúmanage or control the underlying cloud infrastructure including network, servers, operating systems, or storage‚Äù that the NIST definition laid out to define PaaS years ago. Getting out of managing the underlying infrastructure enables engineers to focus on the most important part of solution building ‚Äî being responsive to the customer‚Äôs needs.
For more on APIs, open source, community events, and developer culture at Capital One, visit DevExchange, our one-stop developer portal. https://developer.capitalone.com/
The low down on our high tech from the engineering experts‚Ä¶
118 
2
The low down on our high tech from the engineering experts at Capital One. Learn about the solutions, ideas and stories driving our tech transformation.¬†Take a look.

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
118¬†claps
118 
2
Written by
Technology enthusiast, Amazon Alexa Champion, EV enthusiast. Always learning how to make new things with the latest tech.
The low down on our high tech from the engineering experts at Capital One. Learn about the solutions, ideas and stories driving our tech transformation.
Written by
Technology enthusiast, Amazon Alexa Champion, EV enthusiast. Always learning how to make new things with the latest tech.
The low down on our high tech from the engineering experts at Capital One. Learn about the solutions, ideas and stories driving our tech transformation.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/cloud-and-servers/bulut-hizmetlerinde-iaas-paas-saas-nedir-3bb5620fd357?source=search_post---------3,"There are currently no responses for this story.
Be the first to respond.
Amazon(AWS), Google(Cloud Platform), Microsoft(Azure), IBM(SoftLayer, Bluemix) gibi b√ºy√ºk firmalarƒ±n bulut hizmetlerindeki servis katmanlarƒ± birbirleriyle aynƒ± mantƒ±ktadƒ±r.
Ama√ß katman katman olan bu yapƒ±larƒ±n geli≈ütiriciden soyutlanarak herkesin rahat√ßa kullanabileceƒüi ortamlar olu≈üturmaktƒ±r. A≈üaƒüƒ±da bu sorumluluklarƒ±n kimin sorumluluƒüunda olduƒüunu anlatan bir resim g√∂rmektesiniz.
On-Premises: Yazƒ±lƒ±mlarƒ±nƒ±n sizin veya firmanƒ±n bilgisayarlarƒ±na y√ºklendiƒüi kƒ±sƒ±mda t√ºm katmanlarƒ±n sorumluluƒüu sizin ekibinizin √ºzerindedir. Bir sistem ekibiniz olmasƒ± gerekir. Bu sistem ekibi sunucularƒ±, veritabanlarƒ±nƒ±, g√ºvenliƒüi, network‚Äô√º bilmesi ve kurmasƒ± gerekmektedir. Veritabanƒ±nƒ±n yedeklerinin alƒ±nmasƒ±nƒ± saƒülamasƒ±, i≈ületim sisteminin g√ºncel s√ºr√ºmlerinin y√ºklenmesini saƒülamasƒ± gerekmektedir. Ayrƒ±ca sistem ekibinin JVM, dll, plugin gibi yazƒ±lƒ±mƒ±n ihtiyacƒ± olan Run-Time sisteme kurmalarƒ± gerekmektedir.
Infrastructure As A Service: Size bulut √ºzerinden sanal Compute, Storage, Networking satƒ±ldƒ±ƒüƒ±, kiralandƒ±ƒüƒ± bulut hizmeti olarak d√º≈ü√ºnebilirsiniz. Bilgisayar, Disk ve Network kartlarƒ± almak yerine bunlarƒ± Sanal olarak bulut‚Äôtan kiralayƒ±p √ºzerine istediƒüiz i≈ületim sistemini kurup yolunuza devam edebilirsiniz.
Platform As A Service: Bulut √ºzerinde direk bir java, ruby, node uygulamasƒ± geli≈ütirmek istiyorsunuz ve i≈ületim sistemi, network, sunucu gibi sistemler ile uƒüra≈ümak istemiyorsunuz, Sadece uygulamanƒ±zƒ± geli≈ütirmek ile uƒüra≈üƒ±yorsunuz sonrada uygulamanƒ±zƒ±n run-time dosyalarƒ±nƒ± ilgili platforma atƒ±p √ßalƒ±≈ümasƒ±nƒ± saƒülƒ±yorsunuz.
Software As A Service: Uygulamalarƒ±n bulut‚Äôtan hizmet vermesine SaaS denir. Kullanƒ±cƒ±lar sadece uygulama aray√ºzlerine eri≈üebilir. Kendilerine ait bilgileri bu yazƒ±lƒ±mlara girerek, bilgilerini bulut √ºzerinde saklar ve buradan kullanƒ±rlar.
√ñrneƒüin: GoogleDocs, Evernote uygulamalar SaaS olarak d√º≈ü√ºnebiliriz.
Uzun s√ºredir farklƒ± sekt√∂rlerde (Askeri, Telekom√ºnikasyon, Devlet, Bankacƒ±lƒ±k, Sigortacƒ±lƒ±k, T√ºbitak, SaaS) yazƒ±lƒ±mlar geli≈ütiriyorum. Bu s√ºre√ßte Havelsan, Milsoft, T2, Cybersoft ve Thundra firmalarƒ±nda y√∂netici ve yazƒ±lƒ±m m√ºhendisi olarak √ßalƒ±≈ütƒ±m. Deneyimlerimi ve teknolojik bilgi birikimi mi olabildiƒüince OnurDayibasi.com adresinde toplamaya √ßalƒ±≈üƒ±yorum. T√ºm yazƒ±larƒ±ma ve daha fazlasƒ±nƒ± bu site √ºzerinden eri≈üebilirsiniz.
AWS, Azure, OpenStack
104 
1
104¬†claps
104 
1
AWS, Azure, OpenStack
Written by
Senior Frontend Developer at Thundra
AWS, Azure, OpenStack
"
https://serverless.zone/serverless-vs-paas-and-docker-three-legged-hairless-yaks-f2c4191b1ed6?source=search_post---------4,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Top highlight
A tweet today from Eberhard Wolff posited that serverless architecture will not be as broadly applicable as PaaS and Docker. I had some thoughts, and I‚Äôm putting them down as an article.
To start with, PaaS and Docker have a major headstart that serverless architecture lacks: you can lift-and-shift an existing system into it without substantially rearchitecting. The many quirks and tradeoffs in serverless offerings mean that assumptions you made in your traditionally-architected system may not be possible to guarantee with serverless.
However, if you‚Äôre starting from scratch, or already rearchitecting anyway, you can use serverless architecture to drop a huge amount of overhead from your development and operations. It‚Äôs hard to overstate this benefit. With a fully serverless system, with computation entirely through FaaS and all other infrastructure in SaaS, you essentially only write business logic.
This is the core advantage to serverless. You stop shaving yaks, and start buying hairless yaks. But it doesn‚Äôt come free. There are a host of consequences.
To start, you have to architect differently. With Functions as a Service (FaaS), your component graph becomes your call graph. This means that your system is distributed by nature. Distributed systems thinking moves from the boundaries of your system to permeate every decision (Chaos Monkey serves to force this on traditional architectures). This is more work! But at the same time, you‚Äôre going to build a more robust system because of it.
This distributed-by-nature aspect is part of a paradigm shift in architecture. To get the benefits of serverless, you have to think of the components of system not only as less reliable, but potentially as less functional as well. You have to be more flexible in the products that you accept. That hairless yak? It may only have three legs. Does Kafka have more features than Kinesis? Yes. Kong vs. API Gateway? Same. But I can build a system faster and use fewer people to operate it if I go with the serverless options. So it requires more thinking about total cost of ownership.
Sometimes the term ‚ÄúNoOps‚Äù gets thrown around when talking about serverless, but nobody in their right mind believes that. It‚Äôs LessOps at best, but also kind of DifferentOps. Charity Majors points out that it doesn‚Äôt matter if a fully-managed service you rely on goes down: it‚Äôs you that is responsible to your users for the outage. So you start having to architect and monitor around the services you‚Äôre using. Do you need HA with your Lambda-backed service? You‚Äôre going to need to implement a multi-region system, with all the attendant complexity that involves. You have to plan for less observability. Gather all the provided metrics, instrument for new ones, ferret out details of service implementation when you can. Pester the hairless yak breeder about what yak food they buy.
So that‚Äôs is an argument for why, in the aggregate, serverless has substantial benefits over PaaS and Docker. But to address Eberhard‚Äôs assertion, will it replace PaaS/Docker?
First, serverless can‚Äôt fully replace PaaS or Docker. Serverless architectures are great at event-based logic and efficiently handling unpredictable or rapidly-changing load. Long-running jobs are not a good fit for FaaS, and for mature systems, the higher per-compute-cycle cost of FaaS is going to make traditional architecture more attractive for predictable loads. ETL and map-reduce jobs are a question mark for me; they tend to be large-scale (i.e. cost sensitive) and relatively predictable, but also consist of a lot of small pieces of work.
I think any system with sufficiently complex requirements will probably dictate a hybrid architecture, using FaaS for event-based compute, PaaS or Docker for other compute, and SaaS for as much of the infrastructure as possible. There are a lot of pain points with current serverless offerings, especially for enterprise applications, but once they are solved (and progress is being made), I think serverless is going to be the standard first approach to architecture.
A community publication all about serverless architectures
112 
2
112¬†claps
112 
2
Written by
Cloud Robotics Research Scientist at @iRobot
A community publication all about serverless architectures
Written by
Cloud Robotics Research Scientist at @iRobot
A community publication all about serverless architectures
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@ariya114/mengenal-iaas-vs-paas-vs-saas-menghindari-salah-kaprah-teknologi-cloud-5358dd843312?source=search_post---------5,"Sign in
There are currently no responses for this story.
Be the first to respond.
Ariya Hidayat
Jan 13, 2020¬∑7 min read
Karena dangkalnya pemahaman sesungguhnya soal teknologi komputasi di awan, atau yang lazim dikenal sebagai Cloud Computing, banyak pengamat dan pengguna teknologi yang malah terjerumus ke beragam kesalahpahaman tentang pemakaian Cloud. Mana yang lebih murah? Apa yang lebih aman? Harus pakai cloud yang mana? Dan rentetan kepeningan lainnya.
Hampir 99% kejadian, kalau ada tim/organisasi/perusahaan yang mengklaim telah ‚Äúhijrah ke cloud‚Äù, yang dimaksud adalah sudah menggunakan Infrastructure-as-a-Service, disingkat IaaS. Namun demikian, masih banyak dan luas lagi ranah pemanfaatan cloud, termasuk juga Platform-as-a-Service (PaaS) dan Software-as-a-Service (SaaS). Bagaimana kesamaan dan perbedaan ketiganya?
Yang jelas, karena terhimpun dalam keluarga ‚Äúcloud‚Äù, ketiganya punya karakteristik yang sama: yakni menjadi cara untuk menghantarkan sebuah layanan (service) melalui Internet publik (yang dikonotasikan dengan ‚Äúcloud‚Äù). Contohnya, dulu tatkala kita mesti menulis laporan, meramu lembar kerja, atau menyusun slide untuk presentasi, andalannya adalah Microsoft Word, Excel, and PowerPoint (dipaket sebagai Microsoft Office) yang diinstal di komputer masing-masing. Akan tetapi, di zaman now, sebagian besar dari kita lebih memilih untuk menuangkan kreatifitas kita melalui Google Docs/Sheets/Slides yang semuanya notabene diakses secara online melalui layanan Google. Bisa dikatakan Google Docs ini adalah manifestasi dari paket Office ala Cloud. Tidak perlu lagi memburu dan memasang aplikasi secara lokal.
Dalam konteks IaaS/PaaS/SaaS, kesamaannya adalah tidak adanya infrastruktur fisik yang mesti dikelola oleh kita sendiri. Lawannya adalah ‚Äúon-premises‚Äù, ditandai dengan aplikasi yang jalan di server fisik, biasanya diletakkan di ruang khusus (server room) atau pusat data (data center), dan disambungkan ke Internet. Di jaman sebelum ada teknologi cloud, inilah yang harus kita kerjakan: beli CPU dan disk, pasang sistem operasi, koneksikan ke Internet, dan konfigurasi aplikasinya.
Pun dalam keseharian, ada pekerjaan untuk memantau server tersebut, baik untuk memastikan bahwa perangkat keras sehat wal afiat (tidak kepanasan, kabel masih tertancap baik, dll) sampai sistem operasinya juga terus lancar (terus dimutakhirkan, tidak kekurangan swap, dll). Bila terjadi masalah, dari RAM yang jahil atau hard disk yang jebol, mesti diluangkan juga waktu dan tenaga untuk membenahinya.
Apakah bedanya IaaS dengan PaaS ataupun SaaS? Paling mudah kita lihat ilustrasi analoginya, Pizza as a Service, buah karya Albert Barron yang bekerja untuk IBM.
Dalam proses perjalanan sepotong pizza, dari awal hingga masuk ke lahapan kita, maka ‚Äúon-premises‚Äù dapat digambarkan sebagai kegiatan yang dikerjakan sendiri, dan benar-benar dari awal. Kita mesti membuat adonan dan menambahkan saos tomat, keju, serta topping lain yang dikehendaki. Terus kita harus panggang sendiri juga (perlu oven dan api). Baru akhirnya menghidangkannya (lagi-lagi sendiri), barangkali juga bersama air limun segar sebagai pelengkapnya.
Sementara itu, IaaS, bisa dilukiskan sebagai modifikasi besar-besaran dari mekanisme on-premises, yaitu dengan pizza mentah yang sudah disiapkan oleh sang vendor (atau yang bisa dibeli di swalayan, seringnya masih beku). Memang potongan pizza tersebut belum matang. Adalah masih menjadi kewajiban kita untuk memanggangnya (masih perlu oven dan api/gas) serta menghidangkannya (meja, minuman pelengkap). Akan tetapi, bisa dilihat di sini bahwa kerja kita sendiri sudah sangat berkurang karena keribetan mengolah adonan pizza sudah bukan tanggung jawab kita.
Bagaimana bila pizza lezat ini dihantarkan dengan model PaaS? Dalam kasus ini, artinya pizzanya sudah jadi, alias tinggal dimakan. Entah caranya bagaimana, bisa nelpon pizzeria lalu minta diantar, atau ala PhD (Pizza Hut Delivery), ataupun dengan GO-FOOD, Grab Food, dan sebangsanya. Kerjaan kita minim sekali, hanya tinggal menghidangkan pizza tersebut sesuai selera dan langsung melahapnya (dan bersih-bersih, begitu sudah kelar). Tidak ada kerepotan bikin adonan dari nol. Tidak perlu punya oven, microwave, kompor, ataupun alat masak lainnya.
Akan halnya dengan SaaS, ini diibaratkan dengan makan di luar. Tidak perlu ada pengantaran. Kita cukup pilih kedai makan favorit, pesan dari menunya (misalnya pizza tersebut, bersama minuman pelengkap), lalu nikmati sajiannya. Sebagai bonus, kadang juga ada live music, baik dalam bentuk pengamen jalanan ataupun musisi serius, sebagai penghidup suasana. Selesai makan? Bayar tunai atau gesek kartu. Beres dah!
Di sisi lain, ada juga kombinasi lain yang juga ajib, seperti misalnya hybrid cloud atau malah multicloud (kita akan ulas di lain kesempatan).
Jawabannya: tergantung situasi. Tidak bisa dipukul rata.
Contohnya begini. Kalau Anda ingin makan nasi goreng (kearifan lokal: beralih dari contoh pizza di atas), murah mana antara bikin sendiri di dapur atau beli dari tukang nasgor. Dilihat dari harga bahan-bahannya, jelas lebih menghemat kala masak sendiri dong. Tapi terkadang, masak sendiri tidak memungkinkan. Barangkali Anda tinggal di kamar kost tanpa dapur. Atau juga, belum punya keahlian memasak nasi, apalagi meracik bumbu maupun menggorengnya hingga sedap. Atau malah, sedang buru-buru sehingga tidak bakal sempat untuk masak sendiri. Karena berbagai alasannya ini mungkin Anda lebih memilih pesan nasgor dari tukang nasgor di depan jalan atau lewat pengantaran GO-FOOD/Grab Food.
Apalagi untuk Anda yang sibuk sekali dan senantiasa dikejar waktu. Waktu Anda mungkin jauh lebih berharga untuk difokuskan ke pekerjaan, bercengkrama dengan keluarga, ataupun kegiatan yang lain. Walaupun perlu merogoh saku untuk membeli nasgor, dari perhitungan TCO (Total Cost of Ownership), masih lebih menguntungkan.
Makanya, kalau memikirkan soal harga murah atau nggak, tidak melulu hanya masalah harga beli. Ada juga ongkos waktu, pemeliharaan, dan komponen lainnya. Perhatikan TCO itu tadi.
Di sisi lain, walaupun masak sendiri itu menghabiskan ongkos lebih murah, belum kita dengar ada pasangan pengantin yang menyiapkan sendiri seribu porsi makan untuk tamu kondangannya. Selain sibuk dengan persiapan tetek bengek, tentu ada faktor scaling yang menyebabkan kemustahilan pasangan pengantin tersebut memasak untuk ribuan tamu kehormatan (gimana, kebayang capeknya nggak?). Di sini, lagi-lagi ada peran catering, sejalan dengan konsep SaaS, sehingga si mempelai (atau panitia yang didelegasikan) cukup membayar vendor untuk meramu selusin rupa-rupa hidangan, bahkan lengkap dengan alat makan, pelayanan, urusan kebersihan, dll. Tidak perlu pusing. Lebih mahal daripada masak sendiri? Sudah pasti. Mau mengerjakan sendiri? Jangan harap.
Orang yang benci on-premises tapi punya kendaraan sendiri itu berarti nggak konsisten (lho kenapa nggak selalu pakai ojol dan taksi, transportasi-as-a-Service?). Sama juga, mereka yang 100% bermusuhan dengan SaaS tapi masih suka beli kopi/Indomie/nasgor juga nggak taat doktrinnya sendiri (harusnya senantiasa masak sendiri dong!).
Jadi kalau ada pihak yang secara absolut sangat benci on-premises atau ada kubu lain yang 100% bermusuhan dengan cloud, jangan didengar. Pendapat seperti itu amat berbahaya dan menjerumuskan.
Jawabannya pun serupa: tergantung situasi. Tidak bisa dipukul rata.
Contohnya begini. Anda bernasib mujur dan memperoleh uang selembar 20 ribu. Bakal disimpan di dompet saja atau langsung disetor ke bank? Sebagian besar dari kita akan menyimpan lembaran tersebut di dompet saja. Ribet amat kalau hanya uang segitu terus harus repot ke bank segala. Nggak worth it, cetus anak millennial.
Lain halnya, kalau tiba-tiba ada yang menyetorkan uang kepada Anda, 100 juta rupiah, tunai. Wuih, mana berani disembunyikan di ransel lama-lama (apalagi di saku atau di dompet atau di bawah bantal). Pastinya lekas kita bergerak mencari cara untuk menjebloskan rejeki nomplok ini ke rekening bank. Gercep dong. Itupun sambil was was, siapa tahu ada penyamun di siang bolong manakala kita lagi beranjak ke kantor cabang bank tersebut.
Menyimpan data di sistem on-premises atau IaaS memberikan beberapa kelebihan, dari kontrol akses fisiknya hingga kesempatan kita menggunakan berbagai macam teknologi keamanan (kriptografi, penyandian data dari hulu ke hilir, dan lain sebagainya). Tetapi tidak selalu mutlak seperti itu, karena semua pekerjaan ini perlu ditangani ahlinya. Salah menggunakan algoritma kriptografi bisa berakibat fatal. Tidak melakukan analisis pemodelan ancaman (threat modeling) dapat menghasilkan ilusi keamanan. Ada mekanisme key rotation? Lantas, adakah review secara berkala untuk memastikan kalau semua personil yang terlibat tidak mudah ditipu oleh kampanye phishing atau social engineering lainnya? Dan selusin detil-detil lain yang mesti diperhatikan.
Sementara itu, kalau kita delegasikan urusan keamanan tersebut ke tim Google/Amazon/Microsoft karena kita menggunakan IaaS/Paas/SaaS yang mereka tawarkan, ada sejumlah hal yang berkaitan dengan kriptografi yang tidak lagi bisa kita kerjakan sendiri. Walaupun semua provider di atas menawarkan fitur untuk enkripsi (misalnya via KMS, Key Management System), tidak selalu semuanya bisa dimutlakkan. Di sisi lain, kita hendak mendapatkan manfaat dari keseriusan tim mereka untuk mengurusi keamanan fisik (triple biometrics), backup via redundancy, threat modeling, review berkala, dan beragam pekerjaan SecOps lainnya.
Ini namanya trade-off. Menimbun 100 juta rupiah di bank itu berarti kita nggak akan selalu bisa pakai kapan saja. Tetapi gila dong kalau kita pikir mengamankan 100 juta rupiah itu gampang. Bank dijaga beberapa satpam. Ada brankas lapis baja juga di dalamnya. Di rumah kita sendiri? Kadang ikan asin aja raib digondol kucing tetangga tanpa ketahuan!
Makanya, kalau berkaitan dengan isu keamanan dan ada pihak yang secara absolut sangat benci on-premises atau ada kubu lain yang 100% bermusuhan dengan cloud, juga jangan didengar. Sama-sama berbahaya dan menjerumuskan.
Mau naik sepeda atau naik mobil? Nah, tergantung ke mana dong. Tidak masuk akal kalau kita pilih moda transportasinya dulu sebelum jelas arah tujuannya. Menggenjot sepeda untuk pulkam dari Jakarta ke Semarang akan menghasilkan kepenatan tiada tara. Menyetir mobil untuk ke Indomaret depan gang juga buang-buang bensin/emosi/waktu.
Mau pakai on-premises, IaaS, PaaS, atau Saas? Cermati dari apa yang mau dibangun. Jabarkan kebutuhan dan calon-calon solusinya, lalu hitung TCO (jangan cuman harga beli), dan tinggal tentukan mana yang cocok. Tidak ada satu pilihan yang cocok untuk semuanya. Jauhi fanatisme dan jangan main pukul rata. Solusi yang manjur untuk startup kecil yang baru punya ribuan user akan sangat beda dengan apa yang bakal dipilih oleh Unicorn dengan jutaan pemakai.
Yang jelas, ketika membahas tajuk cloud, selalu gunakan kesempatan tersebut untuk menguraikan dengan rinci. Jangan hanya sebut cloud, tapi arahkan ke IaaS, atau PaaS, atau SaaS. Dengan lebih detil seperti itu, segala macam kesalahpahaman dan kerancuan dapat dihindari dan diskusinya bisa mengalir lebih cerdas.
Nah, siapa yang mau tinggal di Negeri di Awan?
Nggak bisa move on dari open-source.
283 
283¬†
283 
Nggak bisa move on dari open-source.
"
https://medium.com/swlh/iaas-vs-paas-vs-saas-dfece8fd6ca?source=search_post---------6,"There are currently no responses for this story.
Be the first to respond.
You have 2 free member-only stories left this month. Sign up for Medium and get an extra one
If your ecommerce business is progressing to the Cloud, you need to be familiar with these three main types of cloud computing:
These are all experiencing a surge in popularity as more businesses move to the Cloud. Gartner forecasts worldwide public cloud revenue to grow 17% in 2020. With growth rates like these, cloud computing will soon be the industry norm, and many businesses are phasing out on-prem software altogether.
Utilizing cloud computing is a great way to future-proof your business.
It was actually not so long ago, that every company‚Äôs IT systems were on-prem (located at the company‚Äôs premises), and clouds were only those white fluffy stuff in the sky.
Today, you can utilize the Cloud platform for nearly all your systems and processes. SaaS, PaaS, and IaaS are simply three ways to describe how you can use the cloud for your business.
Here is a visual breakdown of these cloud services:
Most businesses use a combination of SaaS and IaaS cloud computing services, and many engage developers to create applications using PaaS, too.
IaaS examples: Amazon Web Services (AWS) EC2, Rackspace, Google Compute Engine (GCE), Digital Ocean, Magento 1 Enterprise Edition.
PaaS examples: AWS Elastic Beanstalk, Heroku, Windows Azure (mostly used as PaaS), Force.com, OpenShift, Apache Stratos, Magento Commerce Cloud.
SaaS examples: Novade Solutions, BigCommerce, Google Apps, Salesforce, Dropbox, MailChimp, ZenDesk, DocuSign, Slack, Hubspot.
IaaS businesses offer services such as pay-as-you-go storage, networking, and virtualization. IaaS gives users cloud-based alternatives to on-prem infrastructure, so businesses can avoid investing in expensive on-site resources.
Maintaining on-prem IT infrastructure is costly and labor-intensive. It often requires a significant initial investment in physical hardware, and then you will probably need to engage external IT contractors to maintain the hardware and keep everything working and up-to-date.
A PaaS vendor provides hardware and software tools over the internet, and people use these tools to develop applications.
PaaS is primarily used by developers who are building software or applications. A PaaS solution provides the platform for developers to create unique, customizable software. This means developers do not need to start from scratch when creating applications, saving them a lot of time (and money) on writing extensive code.
SaaS platforms make software available to users over the internet, usually for a monthly subscription fee.
With SaaS, you do not need to install and run software applications on your computer (or any computer). Everything is available over the internet when you log in to your account online. You can usually access the software from any device, anytime and anywhere (as long as there is an internet connection).
A SaaS salesman would tell you, ‚ÄúIt is all taken care of in the Cloud.‚Äù
Each of these cloud computing service gives users choice, flexibility, and options that on-prem hosting simply cannot provide. The level of system administration knowledge decreases in this order: On-prem > IaaS > PaaS > SaaS.
Using pizza as an example to breakdown each type of service:
You might choose to start with one or any combination of these cloud computing services, depending on the size and complexity of your business.
I hope you have enjoyed reading my stories. To get unlimited access to quality content on Medium, join as a Medium member!
Get smarter at building your thing. Join The Startup‚Äôs +750K followers.
257 

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
257¬†claps
257 
Written by
perpetual student, fitness enthusiast, passionate explorer https://www.linkedin.com/in/jnyh/
Get smarter at building your thing. Follow to join The Startup‚Äôs +8 million monthly readers & +750K followers.
Written by
perpetual student, fitness enthusiast, passionate explorer https://www.linkedin.com/in/jnyh/
Get smarter at building your thing. Follow to join The Startup‚Äôs +8 million monthly readers & +750K followers.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://netflixtechblog.com/prana-a-sidecar-for-your-netflix-paas-based-applications-and-services-258a5790a015?source=search_post---------7,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
‚ÄúThe Right Tool for the Right Job‚Äù
It‚Äôs hard to argue against this time tested mantra. At Netflix, an overwhelming part of our applications and services have traditionally been implemented in Java. As our services and products evolved, we asked ourselves if Java was still the right choice for implementing these services/applications. While it‚Äôs still true that for most of our microservices Java is the right choice, there were a growing set that begged for a closer look at alternatives.
For example, Javascript is a natural fit for Web Applications and we fully embraced Reactive Extensions pattern via RxJS for our UI layer. While Javascript has traditionally ruled the roost on the Web UI front, the advent of Node.js made Javascript and Event based models a force to reckon with on the server side as well.
Python, for example, is a popular choice for many machine learning and recommendation systems.
Over the years, we have evolved and rapidly augmented our stable of libraries that constitute the Netflix PaaS ecosystem. For the most part these libraries were traditionally implemented in Java. While we wanted to embrace Python and Node.js and other non-java based tools and frameworks for the right reasons, we also wanted to be able to leverage our existing Java libraries and services and continue evolving them. Duplicating the functionalities of these libraries in different languages was undesirable as it would lead to duplication of effort and increased cost in terms of maintenance and developer resources to say nothing of the bug fixes that may need to be ported across these languages.
How could we leverage our Java libraries and services infrastructure while aiding and supporting our increasingly Polyglot ecosystem?
A Sidecar was the solution we naturally evolved into.
A sidecar by definition is ‚ÄúA one-wheeled device attached to the side of a motorcycle, scooter, or bicycle,[1] producing a three-wheeled vehicle.‚Äù.
Sidecar as a solution for providing applications with ‚Äúnon-intrusive platform capabilities‚Äù has gained popularity outside of Netflix as well, especially in the NetflixOSS ecosystem where many users have used this concept. Andrew‚Äôs earlier blog post while he was championing NetflixOSS within IBM addresses some of the motivations and philosophies.
Prana is the Sidecar we use at Netflix.
We are happy to add Prana to the collection of open source components under the NetflixOSS banner. Prana is available on Github at http://github.com/netflix/Prana.
Prana is conceptually ‚Äúattached‚Äù to the main (aka Parent) application and complements it by providing ‚Äúplatform features‚Äù that are otherwise available as libraries within a JVM-based application.
The diagram above shows a typical application/service implemented in a non JVM language (Python, RoR, Node.js etc.) accessing various Platform Services via Prana the sidecar which is hosted alongside the main application in the same host/vm.
The motivation for creating Prana is to provide Netflix platform functionality for the following two broad application categories:
The usage of Prana inside Netflix is mainly in applications where we can‚Äôt plug in our JVM based client libraries. We use Prana with non JVM applications and also with any application which is not developed on the Netflix stack. For example, we run Prana alongside Memcached, Spark, Mesos servers to make them discoverable.
Functions such as Hystrix, Eureka registration and health check, when integrated within a JVM based application via the respective java libraries will work better operationally given the internal knowledge the application has of itself as opposed to being accessed via a Sidecar. Also, functions such as dynamic properties and metrics are more efficiently queried and updated within the application process as compared to calling cross process.
You can take Prana for a quick run by following the instructions at https://github.com/Netflix/Prana/wiki/Getting-Started.
Homogeneity is a great asset while operating and managing a heavily microservices based ecosystem. An effective way to provide such homogeneity in terms of platform-infrastructure is by leveraging the concept of a Sidecar. Prana fulfils this functionality and provides us the ability to employ the best suitable language/framework for our increasingly complex and heterogeneous Cloud ecosystem.
We hope that Prana will be a welcome addition to our already growing NetflixOSS ecosystem. We welcome contributions in terms of code, documentation or ideas to Prana or any of our other NetflixOSS projects.
If building innovative infrastructural components is your passion, we are looking for great engineers to join us and further augment our PaaS infrastructure.
Contributors: Diptanu Gon Choudhury, Sudhir Tonse, Andrew Spyker, and Raju Uppalapati
ispyker.blogspot.com
techblog.netflix.com
Originally published at techblog.netflix.com on November 5, 2014.
Learn about Netflix‚Äôs world class engineering efforts‚Ä¶
54 
1
54¬†claps
54 
1
Written by
Learn more about how Netflix designs, builds, and operates our systems and engineering organizations
Learn about Netflix‚Äôs world class engineering efforts, company culture, product developments and more.
Written by
Learn more about how Netflix designs, builds, and operates our systems and engineering organizations
Learn about Netflix‚Äôs world class engineering efforts, company culture, product developments and more.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/gomix/gomix-and-the-evolution-of-paas-3624fed131b9?source=search_post---------8,"There are currently no responses for this story.
Be the first to respond.
Once upon a time, a long time ago, like all the way back in the 90s‚Ä¶ the internet as we know it began to emerge. Back then we didn‚Äôt just visit a few sites or apps every day ‚Äî there used to be tons of new, interesting and weird things made by people, companies, and communities.
If you found a website that you liked, you could just ‚Äòview source‚Äô and see the code used to build it. Creating your own site, however, was harder.
You had to run a web server on your own hardware and open it up to the internet. This could be expensive, and if you didn‚Äôt know what you were doing your server could end up being the target of spammers and ne‚Äôer do wells. So some smart folks began to offer web hosting services where you could rent space on a server that they ran instead.
Now all you had to do to run your own site was upload your files with FTP, make changes, and save them back to the server while refreshing your browser to see them. It wasn‚Äôt pretty, but it worked.
This was the start of ‚ÄúInfrastructure as a Service‚Äù offerings. The model was: click, get server, configure, deploy and scale. And that worked better‚Ä¶ until it didn‚Äôt. When it broke you had to play Sys Admin, and if it suddenly got popular then your site would go down or you‚Äôd get a huge hosting bill. So some other smart folks began to offer to manage and scale the services on top of providing servers, and ‚ÄúPlatform as a Service‚Äù (PaaS) was born.
Fotango is widely credited with launching the world‚Äôs first PaaS back in 2005, but soon everyone from Amazon to Google, IBM and Microsoft had all launched their own services. Nowadays these are powerful platforms aimed at professional developers with a model of: click, get server, configure, deploy. But have you seen the AWS dashboard lately? It‚Äôs acronym soup. There‚Äôs S3, SNS, RDS, and of course DynamoDB, SES, SQS, EC2, and it goes on. But while it‚Äôs great that these services are available, most of us won‚Äôt ever need to use many of them.
So that has been how PaaS has evolved to date ‚Äî almost entirely along a technological axis. They‚Äôve become increasingly powerful but at the cost of alienating all but power users.
The problem with that is, it‚Äôs not just professional developers who have ideas and want to use code to solve problems and create stuff. In fact, there are only an estimated 12M professional developers in the world, yet 45M people hit Stack Overflow each month looking to solve their coding problems.
And our modern view of who a coder is has proven to be just as alienating. The makeup of coders has rapidly changed over the last 30 to 40 years, the result of which has left whole groups of people underrepresented in tech.
This is where Gomix can make a difference.
Gomix exists to make coding ‚Äî creating apps, bots and sites ‚Äî more human and accessible. We‚Äôre proud of the underlying tech, but you don‚Äôt have to know it to use and enjoy the platform. We think of it as being a bit like IRC ‚Äî it‚Äôs a great technology, but what it needed was a Slack type offering to drive that type of thing into the hands of a much wider audience.
So Gomix provides almost all the core benefits professional devs get from AWS et al. just without complex configuration and the overhead of keeping track of lots of moving pieces. It frees professional developers to focus on their unique talents and welcomes a whole new group of users ‚Äî perhaps an order of magnitude more users ‚Äî to join in. While both groups are still able to leverage the full power and flexibility of code, just in a more usable manner.
The creation of Gomix is another stage in the evolution of PaaS, and one that differentiates us from other PaaS offerings, like Heroku, Engine Yard, etc. They do a good job of hosting apps that are already built with a model that‚Äôs more like: click, get server, deploy. But unlike Gomix, they don‚Äôt provide the ability to discover new toolkits, to remix working apps, or to collaborate in a live environment with other developers.
The Gomix model is: just click. And in that respect, we have much in common with developer playgrounds like CodePen and JSFiddle. They too are fun for trying things out, and a nice way for developers to share ideas. But they don‚Äôt provide any ability to run back-end code, which greatly limits the types of things that you can build with them. What‚Äôs more, key features like realtime collaboration between multiple users are often limited to only paying users, putting up a barrier for educational use or simple pair-programming scenarios.
By providing working example apps to remix, a code editor to modify them, instant hosting and deployment ‚Äî anybody can build a web app on Gomix, for free. We are breaking down the barriers that have hitherto restricted coding to just code monkeys, and we‚Äôre opening coding up to a wider audience by making coding itself more human. If that has the effect of helping to change our idea of who a coder is, or can be, then that will be an evolutionary step in the right direction.
Gomix is the easiest way to build the app or bot of your‚Ä¶
23 
23¬†claps
23 
Gomix is the easiest way to build the app or bot of your dreams
Written by
1x developer turned evil marketer.
Gomix is the easiest way to build the app or bot of your dreams
"
https://medium.com/@tiwari_nitish/storage-in-paas-minio-and-deis-7f9f604dedf2?source=search_post---------9,"Sign in
There are currently no responses for this story.
Be the first to respond.
Nitish Tiwari
Jun 9, 2016¬∑5 min read
Whether you notice it or not, as an end user, storage is an important component of almost all the software we use today. As a developer however, it is important is to be able retrieve stuff in an easy yet secure and fast way. As I mentioned earlier, Object storage is a great way to achieve this. We also saw how to create a reliable data store, taking WordPress as an example. In this post, we‚Äôll see how Deis, an open source PaaS based on Kubernetes uses Minio for almost all of its storage requirements. But first, introductions.
Simply put, Deis is a platform that lets developers easily deploy and manage their applications. By easily, I mean developers can deploy their code with a simple git push ‚Äî Deis handles all the building, packaging and deployment processes. We‚Äôll see how it does that in a while. With Deis, developers can also manage the application configuration, create or roll-back releases, get extensive logging and more. Deis is available via command line or REST APIs. Read more on Deis website.
Right now, there are two Deis flavors available. First is Deis Workflow (Deis v2.0) based on Kubernetes. Deis Workflow is in beta, so expect a few things to change in due course of time. Second is Deis v1.13.0, based on CoreOS. It is a long term support release and there are no further features planned for this line. Deis Workflow is supposed to be the successor of Deis, and hence, we‚Äôll limit our discussions to Deis Workflow.
Minio is a minimalistic object storage server written in Golang. Minio server, client and SDK are API compatible with Amazon S3 cloud storage service. If you‚Äôre wondering what all these elements are for ‚Äî Minio server lets you store unstructured data files in a safe, reliable and easy to retrive way. Minio client is S3 compatible implementation of common file handling commands like ls, cp, mkdir, diff and more. Minio SDK lets you embed Minio APIs in your own applications.
For any queries about Minio, head to our Gitter channel. We‚Äôre pretty active there and will love to help you out!
To understand better, think of Deis as a group of self-contained components that communicate using both the Kubernetes system and an object storage server. There are three deployment methods available in Deis
All of the three deployment methods, as well as Deis Workflow internals like postgres, registry and builder components use Minio extensively behind the scenes:
To see Minio in action while using Deis Workflow, you‚Äôll need to have Deis Workflow installed. When the Deis Workflow has all its pods running, you can see Minio pod among them. This pod is responsible for backup of critical user and application data. You can install Deis Workflow by following these steps:
Check if it‚Äôs working fine by:
Next you‚Äôll need to install Helm Classic. Helm is a package manager for Kubernetes. We‚Äôll use it to manage software in our Kubernetes cluster. Install it by:
Again, check if install is successful.
Once you are done, type
and add the Key ID, Secret Access Key, default region name & the output format. You can now interact with your AWS account via the CLI. Now create a folder at a suitable place, that will serve as the home to your Kubernetes installation. Then download and unzip Kubernetes
Now configure the Kubernetes environment
Now that you‚Äôre ready, boot up the cluster using
You should get a detailed list like this
This confirms that Helm can talk to your Kubernetes cluster (that we booted in the previous step). Next step is to add Deis charts repo to Helm.
Then install Deis Workflow
This will complete the installation process. But you‚Äôll have to wait some more for the pods to be ready. You can check the progress using the command
Once all the pods show a ready status, you can be assured that Deis Workflow is up and running. Here is how the status looks like.
You can see the deis-minio pod running, confirming that Minio is the default object storage used by Deis. As I said in the beginning, Deis Workflow can be thought of as a collection several pods ‚Äî with each doing a predefined activity. Here you can see various pods in action.
If you‚Äôre interested in deploying your application using Deis Workflow, follow this link.
While you‚Äôre at it, help us understand your use case and how we can help you better! Fill out our best of Minio deployment form (takes less than a minute), and get a chance to be featured on the Minio website and showcase your Minio private cloud design to Minio community.
Minio.io
17 
17¬†
17 
Minio.io
"
https://betterprogramming.pub/how-to-build-an-asp-net-web-api-with-entity-framework-and-retrieve-data-from-an-sql-server-43b57677a14a?source=search_post---------10,"Sign in
You have 1 free member-only story left this month. Sign up for Medium and get an extra one
Michael Bogan
Jul 14, 2019¬∑4 min read
Choosing between PaaS and IaaS is critical. The wrong choice can not only slow down your team from the start, but it can cause a spiral into long-term costs as you release more code, build more features, and become more and more embedded in your decision. However, if you take the time upfront to consider your project‚Äôs needs, you can make the right choice. This will save your team both time and money.
At Ohana, a startup focused on increasing employee engagement, we were under pressure to release a functioning app quickly and on-budget. We carefully considered the benefits of both PaaS and IaaS. In the end, we built and deployed our app with a PaaS provider ‚Äî Heroku.
Let‚Äôs look at why we chose PaaS and some cases when you might choose IaaS instead.
At Ohana, we had several constraints with our app. First, we didn‚Äôt have the ability, or desire, to host our own infrastructure on-prem, so we knew we wanted to choose either PaaS or IaaS. But which one?
One of our more senior developers pushed strongly for IaaS. He was extremely technical and loved to be creative in his architectural decisions. He wanted to own as much of the code and architecture as possible. He loved diving into the nitty-gritty of protocols and databases, and he valued control over everything else.
A different developer felt the opposite and pushed for PaaS. He believed that as a startup, we should be focusing on our business logic ‚Äî the ideas that made our startup unique. In our case, these were features that only our app offered that would increase employee engagement for our customers. This developer had no interest in configuring environments, managing middleware, or in building basic functionality such as security, user administration, and so on. He valued time and resources over control.
We had several meetings examining when teams should use PaaS, when they should use IaaS, and which one was right for us. Here are the benefits of each that we took into account as we made our decision:
We found that PaaS projects tend to value speed, reduced complexity, and business logic over technical control. PaaS typically offers teams:
On the other hand, we found that IaaS works well for very technical teams that value control and technical details over convenience. IaaS works well for teams with:
In the end, we decided on PaaS. Although it was difficult for our more technical developer to give up control, our final decision came down to several PaaS benefits that outweighed his preference. PaaS gave us:
While there was a bit of a learning curve (since we were new to the Heroku platform), our decision to go with PaaS worked out well. In just six weeks, we deployed an impressive MVP that supported our initial customers‚Äô needs and showcased our differentiators.
We were able to focus on creating a product that our customers loved, and one where the ancillary tech (such as user management, environments, database connectivity, and so on) just worked. We didn‚Äôt spend our spare time ‚Äúreinventing the wheel.‚Äù Heroku also filled in our need for dev-ops, giving us easy builds, deploys, continuous deliveries, app management, scaling, and more.
Developers love to learn. Their job is to understand, build, and create. But they often get caught up in the building, underestimating the value of their time. They are biased towards creating custom solutions, even when those solutions might already exist. Sometimes this is the correct choice, but sometimes a PaaS can help increase efficiency. Understanding your team‚Äôs biases, moving past them, and choosing the correct technology is critical. It‚Äôs an upfront decision with long-term effects on your costs, performance, hiring decisions, and more.
At Ohana, PaaS was the right choice for our app, but it may not be for yours. Take the time to carefully consider your needs and the benefits of both technologies.
25 years of startups, products, and software architecture. Currently run DevSpotlight ‚Äî tech content for tech companies. michael@devspotlight.com.
141 
141¬†claps
141 
Advice for programmers. Here‚Äôs why you should subscribe: https://bit.ly/bp-subscribe
"
https://medium.com/@jrodthoughts/which-paas-is-winning-the-machine-learning-and-artificial-intelligence-race-2640e1e96eed?source=search_post---------11,"Sign in
There are currently no responses for this story.
Be the first to respond.
Top highlight
Jesus Rodriguez
Jul 26, 2016¬∑2 min read
Machine learning(ML) and artificial intelligence(AI) are becoming pivotal elements on the next wave of innovation in the platform as a service space. PaaS incumbents like AWS, Azure, Bluemix or Google Cloud are constantly trying to out innovate each other with new ML and AI capabilities. While the first wave of PaaS innovation was focused on core infrastructure and application platform services, this new wave is driven by data insights and knowledge. In the near future, ML and AI services will be as common as data and infrastructure in PaaS applications.
If we think about AI and ML as general categories, we will conclude that PaaS AI and ML capabilities are still in its infancy. The current race in the PaaS space has been focused on a very specific types of AI and ML capabilities and it seems to remain very consistent across all PaaS leaders. A few months after a PaaS platform announces a new AI-ML service, we can expect some of its competitors to release similar features.
What are the current AI-ML areas of focus in PaaS technologies. The following list is a good starting point:
¬∑ Machine learning platforms: Native cloud services that enable authoring, executing and managing traditional machine learning models (ex: classification ,clustering, regression, etc)
¬∑ Natural language processing service: Services that enable the syntactical and sematic analysis of natural language sentences. Some of the common disciplinice in this category include sentiment analysis, intend analysis, conversation modeling, etc.
¬∑ Vision analytic services: Services that provide understanding the content of images. Some of the common techniques in this category include automatic image classication, emotion analysis etc.
¬∑ Speech processing services: Services that enable speech analytic capabilities such as translation, conversion to text, etc
¬∑ Knowledge services: Services that complement data with knowledge performing operations such as concept extraction, entity linking etc.
¬∑ Data insights services: Services that provide insights about target data sources. Some of the common techniques in this category include tradeoff analysis, news analysis, etc
How are the top PaaS incumbents compared in these different areas. The following matrix provides an initial analysis:
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
See all (604)
22 
2
22¬†claps
22 
2
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
About
Write
Help
Legal
Get the Medium app
"
https://articles.microservices.com/how-we-built-dovecote-a-revolutionary-microservices-paas-for-the-masses-for-the-koding-global-5764e7cff958?source=search_post---------12,"This is the story of how we built DoveCote, a PaaS for creating and managing microservices in 48 hours for the Koding Global Hackathon in Feb 2016.
Initially, given the aim of koding for introducing programming to masses, we wanted to create a platform where everyone could code. So we thought about building a visual editor for programming. However, this had already been tried several times to no avail, our analysis showed that current visual programming dumbed down the programming aspect too much. Building a system for non-programmers, visually was a task that seemed to require more than two days of programming, so we wanted to find another, but similar idea. Finally, since Armagan was already the author of cote.js which is a library for building and orchestrating microservices easily, we settled on the idea of a PaaS that uses cote.js behind the scene to revolutionize microservices for the masses.
Since we were already targeting programmers, but also believed in the virtues of visual programming, we imagined an environment that mixes visual programming and textual programming. We believe the answer is neither visual programmer alone that a programmer drags and drops visual code blocks for basic language level functionality like control flow: blocks for if, for etc. only serve to muddy the waters. As an analogy for the discovery of scripture, visual programming tools aim to code using hieroglyphs, while we as coders have already discovered the virtues of text. However, the answer is not 100% code either, especially with microservices, programmers need a visual aid to discover which service is attached to which.
So, two days before the hackathon, we finally decided to build such a tool: Visual blocks for each microservice, where one can visually connect each, however the code for each service has to be written by the programmer in order to give the programmer the flexibility of a real language.
There were a few problems though: some members of the our original team from December were unavailable for the hackathon this time, some were ill, including me the week before, and we had to find new members. Things looked a bit grim. Luckily, Fatih Erikli accepted our offer at the last minute, and we are grateful to him for that.
We had a plan. We had a team of 5, all talented in JavaScript. We did some mockups in Balsamiq for the user interface and waited until the hackathon started.
We first split into two groups: frontend and backend. 3 members of the backend team, Armagan, Deniz and Mert had previously worked before and since Armagan was the author of the microservices library cote.js, they devised a plan to build the backend easily. node.js, due to its async nature by default was the perfect fit.
Fatih and me on the other hand had not worked together before, and had no previous experience working with the backend team too. Luckily, two of us are big believers in the React ecosystem, so choosing the stack and tooling on the frontend was straightforward. Interestingly, Armagan is pretty opinionated about React and thought that it is a bad idea, but luckily he trusted us that choosing React would work, as long as we just consumed their backend API properly.
Although 4 members of the team were in Istanbul and Armagan was in Berlin, we decided to work all remotely. Now, this was quite ambitiuous for a team that had not worked together before, but I have to say it worked pretty well and we never ran into major conflicts while working.
We started the hackathon with a Google Hangouts session, where we settled on the final strategy and work distribution, the two teams settled on a data format for the project, which involves multiple services. We also prepared a trello board for the project and assigned tasks to each member. Then backend and frontend teams started working independently, since we had a common data format now.
On the frontend, we knew we had to be as fast as possible, and nothing beats faster development than immediate feedback. We used Dan Abramov‚Äôs excellent boilerplate for hot code reloading, which also automatically sets up webpack, babel etc. So much for the JavaScript fatigue. The solution is a clone away!
Once we had auto reload working, we first paired with Fatih over ScreenHero, which is amazing for this kind of interaction.
We as the whole team also had Google Hangouts working in the backend, where each member muted himself, and only talked when he had a question. We also set up a Slack room for easier collaboration and set up Trello and Github integrations for the room.
On the frontend, we first settled on the final data structure on how we are going to store the data of the frontend application. This is one major strength of React, since f(data) = view in general, it forces you to focus on the data first. As long as you have the data and the relevant state transitions, the view will work out fine.
Once we finalized the application object (a JavaScript associative array ) which acts as the database of the frontend application, Fatih moved on to making the visual designer, while I worked on making frontend application production ready by setting up proper builds and cache busting. In a hackathon, this might seem strange that we were thinking about production at the first minute, but it paid off greatly. We never had to deal with issues in production, our build scripts for the front and backend were clearly defined, and the backend team did not have to know much about frontend other than running the single build script that sets up everything automatically. This made it very easy to collaborate without needlesly having to explain how to set up the project for each team members.
Similarly, on the backend, we had a proper build script and the frontend team basically just ran one command to make everything running.
Note that we used JavaScript on both sides, so actually it was as simple as npm install on both sides and an npm script for each side. This is one of the major advantages of using a single stack for your application. Since we all knew JavaScript at the expert level, we were easily able to contribute to other section‚Äôs code for some trivial things without bothering the other team too much. For example, at one point, I had to make a modification for the backend data to sort it by update date: although I had not used express or mongo before, it was trivial to add this support without bothering the backend team. They were working on the real stuff: Code generation and service orchestration.
In the meantime, Fatih made great progress on the visual designer. In my opinion, Fatih is both a coder and an artist. This manifests itself in his previous projects like arguman.org and dbpatterns.org, which made use of similar visual aids for end users. He quickly built up the visual designer, and proceeded to implement the drag and drop interface.
Now, drag and drop is not something every frontend programmer is knowledgable about. In fact, before Fatih joined the project, I was thinking of just using React DnD by Dan Abramov, since I had not used the drag and drop API before. But lucky for us, due to his previous experiences, Fatih is an expert in this arena, and he suggested that he would build it himself before we had time to go over the React DnD docs. You should not try this at home, but with Fatih, we were confident it would work at.
A few hours passed during which I spent my time on optimizing the data we use on the frontend and implementing undo. But before I implemented undo, I knew mutability was our enemy there. Initially, we had used mutable data to give us some speed. In hackathon settings, you are trying to solve a problem in a limited time, so you have to throw away the best practcies sometimes.
I was at a crossroads. I knew immutability is the right solution most of the time. But would we lose time while I converted the mutable data to immutable? I first joked on the hangout that we should try immutablejs and we all laughed. Then, I decided to give it a try: Just an experiment for 15‚Äì20 minutes.
At the end of that experiment, I had managed to convert the application to use immutable data structures and within an hour, we had undo and redo functionality. Trivially. React‚Äôs one way data flow and immutable data structures made this almost too easy.
During this time, Fatih had finished the drag and drop interface and we merged the results, giving us a visual editor with undo and redo functionality. Things were working out very well.
In the meantime, backend team had been steadily working on their goal, and were making great progress. They showed initial results, deploying to individual node processes using pm2. I usually use Python on the backend and supervisor, but I have to say that pm2 is amazing at what it does. It gives you auto reload, streaming logs out of the box with very little effort, and I was sold.
However, the backend team quickly ran into issues with having every user process handled by pm2: Since each user process was running in a trusted environment where they had access to node, it would be a huge security issue since anyone could access the host using the file system api of the host.
So, they quickly changed direction, deciding to contain each process via docker. Now, this would be a huge problem if we did not have Mert and Deniz who are Docker experts. At work, they are dealing with Docker and Kubernetes on a daily basis, so they started porting the infrastructure to Docker. Meanwhile, Armagan was making sure that the whole architecture was working and the code generation worked as expected. And it was working as expected. Architecture is key to building such an ambitious project in two days, and luckily our architect knew his stuff. Being the author of cote.js, he had been building and using cote.js in production for the last four years and we were on a mission to bring this expertise to the masses.
It was not all smooth though. At one point, I accidentally blew off my git repository. Since we were using dovecote inside node_modules, at one point, the npm install script stopped working for some reason. Armagan told me to delete the symlink inside the node_modules to dovecote using rm -f node_modules/dovecote. Out ouf habit, I typed rm -rf node_modules/dovecote/. n ls later, I quickly discovered that this had deleted the whole folder I was in. I quickly warned the other team member to not run rm -rf. Their response was: We did not ask you to run rm -rf, but rm -f. Oh. Well. My work in the last 2 hours were gone and time was running out. I felt dispair, but then decided to move on. There was no time for despair.
When Sunday came, I had to be at another place for about 6 hours. I had forgotten that the hackathon was postponed to this week and had promised to be a jury at another hackathon. I had to go there and judge other projects, while our team was trying to win a hackathon at another place. Similarly, Armagan hosts a radio programme on Sundays, and he had to go for a few hours for his session. This was a bummer, but luckily the rest of the team continued implementing great stuff while we were away.
Towards the end of Sunday in Turkey time, we managed to get basic functionality working end to end. There was much cheering in the whole team. This thing was getting real. We just had to persist a few more hours and we would win.
Or would we? My experience at the hackathon where I was a jury was good, but with even only 15 entrants, we had a hard time choosing the winner. With more than thousands of entrants, would we really win? This made me somewhat nervous. Here we were, building a great project, but my fear was that some of the judges would not even see the project since there are thousands. Given I was ill the previous week, and being tired with the hackathon, and with only about 10 hours remaining, my brain stopped working. I had to go to sleep.
This is when you need a dedicated team. Amazingly, when one of us fell, the others lifted the others. You can be a great programmer, but being in a great team is a completely different experience. I decided to take a break, told them I would wake up in three hours, at which point Fatih, completely exhausted after two days, could go to sleep. I woke up to the call from the team at about 4 AM, with 6 hours to go. We sent Fatih to sleep, and I took over implementing the final bits.
Two hours had remained and we were almost done, but at this point, we were so exhausted we were working very slowly. The functionality was there, we just had to pretty it, add some visual tour, do the final polishes and we would be done. Armagan finished up the code generation for the examples in the last hour, and with one hour to go, we were ready.
We just had to make a video showcasing the demo. Armagan did an amazing job here. After not sleeping for two days, he made an excellent presentation with such energy that you would think he had just woken up full of energy. The demo had worked while he was presenting, no major hiccups, the video was edited and uploaded to vimeo and about 10 minutes remaining, we added intercom at the final minute so that we could at least be able to communicate with our users and the jury, demonstrating the features of our project.
When it was 10AM in the morning Turkey time, which is when the hackathon ended in California time, we were exhausted but extremely proud of what we had built. We had built an ambitious, working project in just 48 hours that we believe is the first proof of concept that will revolutionize how we build microservices and backends.
This is the story of how we built DoveCote in two days, and I am proud to be a member of the DoveCote hackathon team. Great software requires more than indivdiually great programmers, it needs a great team, and we managed to form a great team in just two days, producing an awesome piece of technology in two days. The jury is out there, it will take a couple of weeks before we get the results, but I can say that we have already accomplished a lot by implementing a real, revolutionary product and team.
I would like to thank and congratulate every member of the team. Final thanks goes to koding, with whom we share their passion of bringing programming to the masses. We believe in a future where being able to read and write code is a skill that most human beings will possess, just like most people can read and write today. But programming is more than just reading and writing code, and we will be among the frontiers making programming simpler, easier, more fun for the masses.
Check out DoveCote , watch the demo to see how it works in production and have fun building microservices!
Ustun
Technical posts about adopting microservices architectures
29 
29¬†claps
29 
Written by
Software Engineer. Founder of Rugila Technology Sofware Consultancy. Previously built SellerCrowd.
Technical posts about adopting microservices architectures
Written by
Software Engineer. Founder of Rugila Technology Sofware Consultancy. Previously built SellerCrowd.
Technical posts about adopting microservices architectures
"
https://towardsdatascience.com/paas-to-accelerate-data-science-dc-os-data-science-engine-656842dd7ba8?source=search_post---------13,"Sign in
What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
This is your last free member-only story this month. Sign up for Medium and get an extra one
Russell Jurney
Oct 7, 2019¬∑26 min read
As a full-stack machine learning engineer that focuses on delivering new products to market, I‚Äôve often found myself at the intersection of data science, data engineering and dev ops. So it has been with great interest that I‚Äôve followed the rise of data science Platforms as a Service (PaaS). In this series of posts, I‚Äôll be evaluating different Platforms as a Service (PaaS) and their potential to automate data science operations. I‚Äôm going to explore their capabilities and then automate the setup and execution of code from my forthcoming book Weakly Supervised Learning (O‚ÄôReilly, 2020) to find the best way for the book‚Äôs readers to work through the book.
In my last book, Agile Data Science 2.0 (4.5 stars :D), I built my own platform for readers to run the code using bash scripts, the AWS CLI, jq, Vagrant and EC2. While this made the book much more valuable for beginners who would otherwise have trouble running the code, it has been extremely difficult to maintain and keep running. Older software falls off the internet and the platform rots. There have been 85 issues on the project, and while many of those have been fixed by reader contributions, it has still taken up much of the time I have to devote to open source software. This time is going to be different.
Note: code for this post is available at github.com/rjurney/paas_blog
The first PaaS for data science I‚Äôm evaluating is the newly launched DC/OS Data Science Engine. In this post I‚Äôll walk you through my initial experiment with DC/OS (caveat: I‚Äôve used it in the past) and its Data Science Engine using the GUI and then we‚Äôll cover how to automate that same process in a few lines of code. It turns out this is actually simpler than creating the equivalent resources using the AWS CLI, which impressed me. We‚Äôll set up our environment and software prerequisites, initialize a DC/OS cluster using Terraform and the Universal Installer, install the Data Science Engine package and then the evaluate the environment by running a model that tags Stack Overflow posts.
A few caveats: we‚Äôll go through how to boot a DC/OS cluster with JupyterLab installed step-by-step, but if you run into trouble you can always refer to the Universal Installer documentation for DC/OS Terraform problems or the Data Science Engine documentation for problems deploying that service.
It has become fairly easy to setup a Jupyter Notebook in any given cloud environment like Amazon Web Services (AWS), Google Cloud Platform (GCP) and Azure for an individual data scientist to work. For startups and small data science teams, this is a good solution. Nothing stays up to be maintained and notebooks can be saved in Github for persistence and sharing.
For large enterprises, things are not so simple. At this scale, temporary environments on transitory assets across multiple clouds can create chaos rather than order, as environments and modeling become irreproducible. Enterprises work across multiple clouds and on premises, have particular access control and authentication requirements, and need to provide access to internal resources for data, source control, streaming and other services.
For these organizations the DC/OS Data Science Engine offers a unified system offering the Python ML stack, Spark, Tensorflow and other DL frameworks, including TensorFlowOnSpark to enable distributed multi-node, multi-GPU model training. Its a pretty compelling setup that works out of the box and can end much frustration and complexity for larger data science teams and companies.
The DC/OS Universal Installer can run from Linux, Mac OS X and Windows. For all platforms you will need Python, pip, the AWS Command Line Interface (CLI) and Terraform. You probably have Python installed if you‚Äôre testing out the Data Science Engine, but if not we‚Äôll install Anaconda Python.
You will also need to authorize 5 GPU instances in the region in which you will run DC/OS Data Science Engine (in this post we use `us-west-2`). Let‚Äôs take it step by step.
If you already have Python installed on your machine, there is no need to install Anaconda Python. If you don‚Äôt, I recommend Anaconda Python as it is easy to install, sits in your home directory, and has the excellent conda package manager.
Download Anaconda Python 3.X for your platform here, then follow the instructions for installation for Linux, Mac OS X and Windows.
There are two ways of setting up AWS access for the Terraform AWS provider: via the AWS CLI or by editing (path from the Github project root) paas_blog/dcos/terraform/terraform.tf.
First we‚Äôll setup our AWS credentials for Terraform to use. To , use the PyPI awscli package:
Now setup your AWS credentials, using your Access Key ID and Secret Access Key, which you can find in the IAM console. You can alter the region to your own default. Terraform‚Äôs AWS module will use these credentials by default. They‚Äôre stored in the ~/.aws/ directory.
Now verify the setup worked:
You should see something like this:
You can explicitly setup AWS authentication by editing (from the project root) paas_blog/dcos/terraform/terraform.tf to include your credentials where the AWS provider is called. Simply add your access key/secret key and default region.
Terraform enables users to define and provision a datacenter infrastructure using a high-level configuration language known as Hashicorp Configuration Language (HCL).  ‚Äî Wikipedia, Terraform (software)
The DC/OS Universal Installer requiresds Terraform 11.x. Ubuntu users can install Terraform 11.x like so:
On a Mac, use Homebrew:
Windows users can use Chocolatey:
Verify that terraform works:
You should see:
Now we‚Äôre good to go! Ignore any message about upgrading. Now that Terraform is installed, we‚Äôre ready to configure and launch our DC/OS cluster on AWS.
AWS Service Limits define how many AWS resources you can use in any given region. We‚Äôll be booting 5 p3.2xlarge GPU instances as private agents for our DC/OS cluster where notebooks will run. The default service quota for the p3.2xlarge instance type is 0. In order to run this tutorial, you will need to request that AWS increase this to 5 or more.
You can do so by logging into the AWS Web Console and visiting the Service Quotas console here: https://us-west-2.console.aws.amazon.com/servicequotas/home?region=us-west-2#!/services/ec2/quotas (you can substitute your preferred AWS region in the url, just be sure to substitute it in _both_ places it appears in the url). Search for p3.2xlarge in the search box and click the orange Request quota increase button to the right.
Enter 5 into the Change quota value field. Then click the orange Request button at bottom right.
Now you will have to wait 12‚Äì48 hours for the request to be approved. I have a basic AWS account and when I request an increase in the afternoon and it is approved the next morning. If you need to speed things up, you can go to the AWS Support Center and request a call with an agent. They can usually accelerate things quite a bit.
There is good documentation for the DC/OS Universal Installer on d2iq.com, but I‚Äôll provide code that ‚Äòjust works‚Äô as part of this post. We‚Äôll be using Terraform to configure and launch our cluster, then we‚Äôll install the Data Science Engine package and get down to work with JupyterLab!
Note: change directory to the Github project subdirectory paas_blog/dcos/terraform for the remainder of the tutorial.
The first step in configuring out DC/OS cluster is to create a cluster-specific ssh key. We‚Äôll call this key my_key.pub.
Hit enter twice to create the key without a password.
We need to change the permissions of my_key to be readable only to our user, 0600, or later ssh will complain.
Now run ssh-agent if it isn‚Äôt running and add the key to the agent.
Note: without this step, you will get ssh errors when you create the cluster. See section Common Errors below.
Now verify the key has been added:
Which should show:
Now we‚Äôll create a superuser password hash file for the cluster using Python‚Äôs hashlib module. We‚Äôll call ours dcos_superuser_password_hash.
I‚Äôve created a command line script that will generate, print and write a password hash to disk called paas_blog/dcos/terraform/generate_password_hash.py.
To run it, simply run:
You should see output something like this:
Verify the write to the file dcos_superuser_password_hash was successful:
Creating a Superuser Password Hash in Python
To create the hash manually, open a Python shell (consider using ipython):
Now run the following code:
Change the password hash‚Äôs permissions to be readable only to your user, 0600, or the DC/OS CLI will complain:
Verify the password has saved successfully:
You should see something like this:
As we‚Äôll be using the open version of DC/OS, I created an empty license.txt file via touch license.txt. It needs to exist, but it can be empty. It is already committed to Github, so for the open version of DC/OS, you don‚Äôt need to create it once you check out the GitHub project. If you‚Äôre using the Enterprise Edition, you‚Äôll need to put your actual license in license.txt.
I‚Äôve edited the file paas_blog/dcos/terraform/desired_cluster_profile.tfvars to personalize the superuser account name, load the superuser password hash from the password hash file we created above, to specify an empty license string and point at an empty license.txt file. The DC/OS variant is set to open, the DC/OS version to 1.13.3, we‚Äôll use an m5.xlarge for our bootstrap instance type and we‚Äôll use p3.2xlarge instances to run JupyterLab. We set the number of GPU agents to 5, which is enough to run Spark and JupyterLab. Finally, we specify the public key we generated earlier, my_key.pub. Remember to use the public and not private key.
Note: you can find the latest version of DC/OS on the releases page, and you can find the latest version of the Universal Installer by clicking on tags on its Github repo. If you run into problems, use the highest 0.2.x tag available by editing the version key in terraform.tf.
Note: If you‚Äôre using the enterprise edition of DC/OS, you‚Äôll need to fill in dcos_license_key_contents, which we‚Äôll leave blank for the open variant. You‚Äôll also want to change the configuration such that dcos_variant = ‚Äúee‚Äù.
First we need to initialize Terraform with all the modules we‚Äôll be using:
You should see:
Now we need to use the variables we defined in paas_blog/dcos/terraform/desired_cluster_profile.tfvars to generate a plan of action for Terraform to carry out. We‚Äôll save the plan to paas_blog/dcos/terraform/plan.out.
You should see a lot of output with no errors, ending with:
Now we have a plan for Terraform to create our DC/OS cluster in plan.out, which is binary and can‚Äôt be inspected very easily.
Now that we have a plan that includes our custom variables, we don‚Äôt need to include them again in the apply command. We can just follow the directions at the end of the output of the *plan* command. Note that we don‚Äôt use --var-file with apply, because plan has inserted our variables into the plan.
This command can take as long as 15 minutes to execute as there is a delay in initializing a sequence of AWS resources and then executing commands to initialize the services on EC2 instances. You should see a lot of output, beginning with:
If you see any errors, the best thing is to destroy the cluster and try again. Occasionally timing issues in delayed initialization of AWS resources can cause boot problems.
When you‚Äôre done with the cluster, if there is an error, or if you need to recreate it, you can destroy all associated resources with the following command. Note that we do need to use--var-file with destroy.
This may take a second, as there are many resources to remove. Once the destroy is complete you are free to plan and apply again.
The final output of the `terraform apply` command gives us the address of the master node to connect to and should look something like this:
Open the master ip address in a browser and you should see a login window. Note that the only IP authorized to connect to this machine is your source IP.
Select your authentication method ‚Äî I use Google. Once you authenticate, it will return you to the home page.
On the left hand menu, fourth down from the top and circled in orange in this image, is the *Catalog* item. Click it and the DC/OS Service Menu will come up. When I did so, the *data-science-engine* service was visible in the second row from the top, but if it isn‚Äôt use the search box at top left to find it.
Click on the data-science-engine service and its service page will come up. Click Review & Run to install the service.
This will bring up a window where you can edit the configuration of the Data Science Engine. You need to name the cluster using letters and dashes, but it doesn‚Äôt matter what you name it, except that names are unique. Since we‚Äôre using p3.2xlarge instances, configure the service to use 58GB of RAM and 8 CPUs. Check the Nvidia GPU Allocation Configuration Enabled checkbox and type 1 for the number of GPUs.
Click the purple Review & Run button at top right. This will take you to the final review screen. Click the purple Run Service button at top right.
Note that you can download the service configuration as JSON to run later with the DC/OS CLI, enabling you to automate the deployment of the service, for example as part of your continuous integration system. To do so click Download Config.
You should see a popup announcing the successful launch of the system. Click Open Service.
This will take you to the Data Science Engine service page. At first the page‚Äôs status will say the service is loading, but soon the Health swatch will become green and the Status will say Running.
Now click on the text Services where it says Services > data-science-engine at the top of the white area of the screen. This will take you to the service listing. You should see data-science-engine listed. Click on the launch icon circled in orange in the image below. This will open a connection with JupyterLab. The default Jupyter password is jupyter, but you can set it using the service configuration window we used to launch the service.
Once you enter the default Jupyter password of jupyter (you can change it in desired_cluster_profile.tfvars), you will see the homepage of JupyterLab. The first page load can take a little while. Tada!
Now that we‚Äôve booted the cluster and service, let‚Äôs exercise it by training a neural network to tag Stack Overflow questions. We treat this as a multi-class, multi-label problem. The training data has been balanced by upsampling the complete dump of questions that have at least one answer, one vote and have at least one tag occurring more than 2,000 times. It is about 600MB. This dataset was previously computed and the files can be found in the paas_blog/data directory of the Github repo.
You can view the Jupyter Notebook with the code we‚Äôll be running from Github at github.com/rjurney/paas_blog/DCOS_Data_Science_Engine.ipynb. We‚Äôll be opening it using the JupyterLab Github interface, but if you like you can paste its content block-by-block into a new Python 3 notebook.
JupyterLab‚Äôs Github module is super awesome and makes loading the tutorial notebook easy. Click on the Github icon on the far left of the screen, between the file and running man icons. Enter rjurney where it says <Edit User>.
My public Github projects will come up. Select paas_blog and then double click on the DCOS_Data_Science_Engine.ipynb Jupyter notebook to open it. It uses data on S3, so you shouldn‚Äôt have to download any data.
The first thing to do is to verify that our JupyterLab Python environment on our Data Science Engine EC2 instance is properly configured to work with its onboard GPU. We use tensorflow.test.is_gpu_available and tensorflow.compat.v2.config.experimental.list_physical_devices to verify the GPUs are working with Tensorflow.
You should see something like:
You can load the data for this tutorial using pandas.read_parquet.
Now we load the indexes to convert back and forth between label indexes and text tags. We‚Äôll use these to view the actual resulting tags predicted at the end of the tutorial.
Then we verify the number of records loaded:
You should see:
We need to join the previously tokenized text back into a string for use in a Tokenizer, which provides useful properties. In addition, making the number of documents a multiple of batch size is a requirement for Tensorflow/Keras to split work among multiple GPUs and to use certain models such as Elmo.
You should see:
The data has already been truncated to 200 words per post but the tokenization using the top 10K words reduces this to below 200 in some documents. If any documents vary from 200 words, the data won‚Äôt convert properly into a numpy matrix below.
In addition to converting the text to numeric sequences with a key, Keras‚Äô Tokenizer class is handy for producing the final results of the model via the keras.preprocessing.text.Tokenizer.sequences_to_textsmethod. Then we use Keras‚Äô keras.preprocessing.sequence.pad_sequences method and check the output to ensure the sequences are all 200 items long or they won‚Äôt convert properly into a matrix. The string __PAD__ has been used previously to pad the documents, so we reuse it here.
We need one dataset to train with and one separate dataset to test and validate our model with. The oft used sklearn.model_selection.train_test_split makes it so.
Although there has already been filtering and up-sampling of the data to restrict it to a sample of questions with at least one tag that occurs more than 2,000 times, there are still uneven ratios between common and uncommon labels. Without class weights, the most common label will be much more likely to be predicted than the least common. Class weights will make the loss function consider uncommon classes more than frequent ones.
Now we‚Äôre ready to train a model to classify/label questions with tag categories. The model is based on Kim-CNN, a commonly used convolutional neural network for sentence and document classification. We use the functional API and we‚Äôve heavily parametrized the code so as to facilitate experimentation.
In Kim-CNN, we start by encoding the sequences using an Embedding, followed by a Dropout layer to reduce overfitting. Next we split the graph into multiple Conv1D layers with different widths, each followed by MaxPool1D. These are joined by concatenation and are intended to characterize patterns of different size sequence lengths in the documents. There follows another Conv1D/GlobalMaxPool1D layer to summarize the most important of these patterns. This is followed by flattening into a Dense layer and then on to the final sigmoid output layer. Otherwise we use selu throughout.
Next we compile our model. We use a variety of metrics, because no one metric summarizes model performance, and we need to drill down into the true and false positives and negatives. We also use the ReduceLROnPlateau, EarlyStopping and ModelCheckpoint callbacks to improve performance once we hit a plateau, then to stop early, and to persist only the very best model in terms of the validation categorical accuracy.
Categorical accuracy is the best fit for gauging our model‚Äôs performance because it gives points for each row separately for each class we‚Äôre classifying. This means that if we miss one, but get the others right, this is a great result. With binary accuracy, the entire row is scored as incorrect.
Then it is time to fit the model. We give it the class weights we computed earlier.
Because we used ModelCheckpoint(save_only_best-True), the best epoch in terms of CategoricalAccuracy is what was saved. We want to use that instead of the last epoch‚Äôs model, which is what is stored in model above. So we load the file before evaluating our model.
Metrics include names like precision_66 which aren‚Äôt consistent between runs. We fix these to cleanup our report on training the model. We also add an f1 score, then make a DataFrame to display the log. This could be extended in repeat experiments.
We want to know the performance at each epoch so that we don‚Äôt train needlessly large numbers of epochs.
It is not enough to know theoretical performance. We need to see the actual output of the tagger at different confidence thresholds.
Lets look at the sentences with the actual labels and the predicted labels in a DataFrame:
We can see from these three records that the model is doing fairly well. This tells a different story than performance metrics alone. It is so strange that most machine learning examples just compute performance and don‚Äôt actually employ the `predict()` method! At the end of the day statistical performance is irrelevant and what matters is the real world performance ‚Äî which is not contained in simple summary statistics!
That covers how you use the platform manually, but this is about PaaS automation. So how do we speed things up?
DC/OS‚Äôs graphical user interface and CLI together enable easy access to JupyterLab via the Data Science Engine for all kinds of users: non-technical managers trying to view a report in a notebook and dev ops/data engineers looking to automate a process. If the manual GUI process seems involved, we can automate it in a few lines once we have the service configuration as a JSON file by launching the DC/OS cluster via Terraform commands, getting the cluster address from Terraform,then using the DC/OS CLI to authenticate with the cluster and run the service.
Note: check out the Github page for the DC/OS CLI for more information on how it works.
The DC/OS CLI is not required to boot a cluster with Terraform and install the Data Science Engine manually in the UI, but it is required to automate the process. If you run into trouble, check out the CLI install documentation. You will need curl.
Note that you can also download the CLI using the commands that print when you click on the top right dropdown titled jupyter-gpu-xxxx (or whatever you named your cluster) and then click on the Install CLI button inside the orange box below.
A popup will appear with installation code for Windows, OS X and Linux. Copy/paste that code into a terminal to complete the install.
Now, if you run dcos you should see the following:
To automatically install the Data Science Engine package, we first need to get its configuration as a JSON file. This can be done in two ways: via the GUI or via the DC/OS CLI or via the Terraform CLI. We‚Äôll cover both methods.
Using the GUI, we can get the JSON for the package configuration by downloading it from the Configuration tab of the data-science-engine service page. Click Download Config in purple at the top right under the line.
By the way, you can edit the Data Science Engine service by clicking the purple Edit button at top right. You can use the menu or JSON editor to change the service ‚Äî increase RAM or GPUs for example ‚Äî and it will automatically re-deploy with that configuration.
To use the CLI, we need to authenticate with the cluster. This can be done via Google, or via a username or other method that suits your organization. To do so, first we need the server address from Terraform. We can extract the cluster master IP address(es) via terraform output -json and the jq json utility. Once we have that, we can use whatever method we prefer, including Google, to authenticate. This could also be a username to facilitate automation.
Check the documentation for dcos cluster setup for information on different methods of authentication.
Once we‚Äôve authenticated, we can use the CLI to generate the package configuration file for later reuse.
For Mac OS X the flag for the command base64 is a capital -D:
For Linux the flag for base64 is a lowercase -d:
Note that the exported options cover every single option, which isn‚Äôt ideal because options can change across different versions of the platform and it is better to rely on the system defaults if you don‚Äôt change a value. For example, I‚Äôve edited this export down to:
You can edit this file to fit your needs or use the GUI to do so and download and edit the config.
Now we can install the Data Science Engine package using the CLI:
All together, that makes the entire process using the exported JSON package configuration:
In this post we booted a DC/OS cluster and deployed the Data Science Engine in a repeatable manner, then executed a test notebook to create a Stack Overflow tagger. This shows how PaaS can be used to enhance the productivity of a data science team. Stay tuned for the next PaaS in the series!
Note: every step in the tutorial was rigorously tested, so please let me know in the comments if you run into any problems.
There are some errors I ran into while writing this post that you may run into while working through the example in this post, so I‚Äôve included what those are and how to fix them! :)
If you forget to run the ssh-agent via eval ""$(ssh-agent -s)"" and then ssh-add your key, you will see the error below. This is especially easy to do if you open a new shell and run terraform commands from it.
The solution is ssh-add ./my_key from the paas_blog/dcos/terraform directory. To avoid this in the future, you can edit the key field in desired_cluster_profile.tfvars to use a public key in your ~ /.ssh/ directory that you automatically add to the ssh-agent when the shell starts, using ~/.profile, ~/.bash_profile or ~/.bashrc.
Now verify the key has been added:
Which should show:
Occasionally things don‚Äôt synchronize properly when DC/OS boots up and you‚Äôll get an error about Ansible bootstrap or the load balancer timing out. The thing to do is to destroy and then plan/apply to recreate. It will work the second time.
If you see either of the following errors, this is what is going on.
Or:
My name is Russell Jurney. I am Principal Data Scientist at Data Syndrome, where I build end-to-end machine learning and visualization products, recommender systems, lead generation systems, data engineering and specialize in weakly supervised learning, or doing more with less data. I blog at http://blog.datasyndrome.com
I am working on a new book due out next year called Weakly Supervised Learning. Stay tuned for more!
I am CTO at Deep Discovery where I fight global corruption with networks and AI
See all (286)
111 
2
Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.¬†Take a look.
111¬†claps
111 
2
Your home for data science. A Medium publication sharing concepts, ideas and codes.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/turkce/giri%C5%9Fim-olarak-siyasi-parti-political-party-as-a-startup-paas-67ea59eca2db?source=search_post---------14,"There are currently no responses for this story.
Be the first to respond.
Startup mantƒ±ƒüƒ±yla parti kurulur mu?
Bu d√º≈ü√ºnce aklƒ±ma yakƒ±n zamanda d√º≈üt√º, bu kadar geni≈ü a√ßƒ±dan bakmak i√ßin ger√ßekten zamana ihtiyacƒ±m oldu.
Hep partilerin yetersizliƒüinden, politikanƒ±n kalitesizliƒüinden bahsediyoruz. Bir taraftan da startup k√ºlt√ºr√ºnden √∂ƒürendiƒüimiz ger√ßek bir sorun bulup √ß√∂zmenin ba≈üarƒ±lƒ± bir giri≈üim i√ßin ilk kademe olduƒüunu biliyoruz.
Bu ikisini e≈üle≈ütirmek nasƒ±l olduysa yeni aklƒ±ma geliyor. ≈ûu anda √ßok teorik bir kesi≈üim olarak g√∂r√ºlebilir ama bu konuyla ilgili daha √ßok d√º≈ü√ºnmek istiyorum ve startup ekosistemi i√ßerisindeki az insanƒ±n da bununla ilgili d√º≈ü√ºnmeye ba≈ülamasƒ±nƒ±n faydalƒ± olabileceƒüini d√º≈ü√ºn√ºyorum.
Bazƒ± belli ba≈ülƒ± sorunlarƒ± hemen farketmek gerekiyor, T√ºrkiye gibi bir yerde, inanƒ±lmaz b√ºrokrasi ve formalite varken politikayƒ± ‚Äúdisrupt‚Äù etmek hi√ß kolay deƒüil ama bir taraftan da en √ßok ‚Äúdisrupt‚Äù edilebilir alan olarak duruyor.
D√º≈ü√ºnsenize,
T√ºm bunlar i√ßin, her yerde internet olmasƒ± gerekir, herkesin interneti kullanabilir olmasƒ± gerekir olduƒüunun farkƒ±ndayƒ±m. Bu durumun ≈üu anda mevcut olmadƒ±ƒüƒ±nƒ±n da farkƒ±ndayƒ±m fakat eƒüer bilmemne vergisinden %x bu i≈üe aktarƒ±labilirse, herkese eƒüitim verilebilir, t√ºm yerle≈üim yerlerinde bedava wifi ve herkese bilgisayar saƒülanabilir.
Ben a√ßƒ±k√ßa bunu yapƒ±labilir ama zor olduƒüunu d√º≈ü√ºn√ºyorum. Herhangi politik g√∂r√º≈üten baƒüƒ±msƒ±z olarak bu ≈üekilde bir yapƒ±, √ºretmeye ve eƒüitime odaklƒ±, ba≈üarƒ±lƒ± olabilir.
Bu konu ile ilgili daha yoƒüun d√º≈ü√ºnmeye ba≈ülayacaƒüƒ±m. Giri≈üim fikirlerinin nereden geleceƒüi belli olmuyor.
L√ºtfen bana bu fikirle ilgili g√∂r√º≈ülerinizi bildirin, bu konu √ºzerine d√º≈ü√ºnmesi zevkli bir konu.
Resmi T√ºrk√ße Yayƒ±n
16 
1
16¬†claps
16 
1
Resmi T√ºrk√ße Yayƒ±n
Written by
Podcast host at http://girisimcimuhabbeti.com, Idealist http://linkedin.com/in/bkocdur, talk to me https://superpeer.com/kocdur
Resmi T√ºrk√ße Yayƒ±n
"
https://medium.com/t-t-software-solution/%E0%B8%AA%E0%B8%B2%E0%B8%98%E0%B8%B4%E0%B8%95%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%95%E0%B8%B4%E0%B8%94%E0%B8%95%E0%B8%B1%E0%B9%89%E0%B8%87-azure-paas-%E0%B8%AA%E0%B8%B3%E0%B8%AB%E0%B8%A3%E0%B8%B1%E0%B8%9A-%E0%B8%81%E0%B8%B2%E0%B8%A3-migrate-asp-net-core-2-%E0%B9%81%E0%B8%A5%E0%B8%B0-entity-framework-core-6196eaeaefec?source=search_post---------15,"There are currently no responses for this story.
Be the first to respond.
‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ ‡∏ú‡∏°‡∏à‡∏∞‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ PaaS (Platform as a Service) ‡∏Ç‡∏≠‡∏á Azure ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏á Web ‡πÅ‡∏•‡∏∞ Database ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‡∏î‡πâ‡∏ß‡∏¢ Technology Stack ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏õ‡∏•.‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞ ‡πÄ‡∏•‡∏¢‡∏à‡∏∞‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö PaaS ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Server ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏ô‡πâ‡∏ô‡∏î‡∏π‡πÅ‡∏Ñ‡πà ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ ‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏ó‡∏≤‡∏á Azure ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏î‡∏π‡πÅ‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô Windows ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≠‡∏¢ update ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏ï‡πà‡∏≤‡∏á‡πÜ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡πÄ‡∏≠‡∏á
‡∏ú‡∏°‡∏Ç‡∏≠‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
Subscription ‡∏à‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏á‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏Ñ‡∏ß‡∏£‡πÅ‡∏¢‡∏Å subscription ‡πÅ‡∏ö‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏ï‡∏≤‡∏° ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ project ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°
Resource Group ‡∏à‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á Azure Resource ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á Group Dev ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Resource ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Development ‡∏ã‡∏∂‡πà‡∏á ‡πÄ‡∏ß‡∏•‡∏≤‡∏•‡∏ö‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á Group ‡πÄ‡∏•‡∏¢‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ Storage Account ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö Database Backup File ‡∏à‡∏≤‡∏Å Server ‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤ Deploy ‡∏ï‡πà‡∏≠‡πÉ‡∏ô Azure Cloud Database ‡∏Ñ‡∏£‡∏±‡∏ö
‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ Storage Account ‡πÅ‡∏•‡πâ‡∏ß ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Container ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô (‡∏°‡∏≠‡∏á‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô Storage Account ‡πÄ‡∏õ‡πá‡∏ô Drive, Container ‡πÄ‡∏õ‡πá‡∏ô Folder)
‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ migrate database ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡πÑ‡∏ß‡πâ ‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà Azure Cloud Database ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô File ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Data-tier Applications (.bacpac) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ query ‡∏Ç‡πâ‡∏≤‡∏° database
‡πÉ‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏ó‡∏≥ ‡∏ú‡πà‡∏≤‡∏ô MSSQL Express 2016 + Microsoft SQL Server Management Studio 13 (SSMS)‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Storage Account ‡∏ú‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ download Microsoft Azure Storage Explorer ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
Azure SQL Server ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏°‡∏≠‡∏á‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° logical database links ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏Ñ‡∏∑‡∏≠ database ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Server ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏¢‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ query ‡∏Ç‡πâ‡∏≤‡∏° database ‡πÑ‡∏î‡πâ
Azure Database ‡∏à‡∏∞‡∏°‡∏µ Firewall ‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏á‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ Firewall ‡∏î‡πâ‡∏ß‡∏¢
‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ migrate database ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤ import ‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô storage account ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÑ‡∏ß‡πâ‡πÉ‡∏ô database ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏û‡∏∂‡πà‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Azure database ‡∏à‡∏∞‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ß‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô DTU ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ú‡∏π‡∏Å‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö Database ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏ã‡∏∂‡πà‡∏á ‡∏ñ‡πâ‡∏≤ DTU ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πá‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏ß‡πà‡∏≤ Database ‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
App Service Plan ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏°‡∏≠‡∏á‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Web Server ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ host web ‡∏¢‡πà‡∏≠‡∏¢‡πÜ‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö (App Service) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å package ‡πÅ‡∏ö‡∏ö standard ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ Backup web ‡πÅ‡∏•‡∏∞ database ‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á)
‡∏Ñ‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÜ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Application ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Web ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö (‡∏à‡∏£‡∏¥‡∏á‡πÜ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏≠‡∏µ‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô mobile app, function app)
‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ deploy web ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ 2 ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏∑‡∏≠
‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ ‡∏Å‡∏î ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å App Service Menu ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ download public profile
‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ configure App Service ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ backup ‡∏ó‡∏±‡πâ‡∏á web ‡πÅ‡∏•‡∏∞ database ‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ App Service Plan ‡πÉ‡∏ô package standard ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ
‡∏ó‡∏î‡∏•‡∏≠‡∏á Backup files ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Web API ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô ‡∏ö‡∏ô Azure
‡∏ú‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡∏ß‡πà‡∏≤ ‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏≠‡∏µ‡∏Å 2 ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Azure ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡∏Å‡πÜ‡∏Ñ‡∏£‡∏±‡∏ö
https://www.tt-ss.net/
15 
1

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
15¬†claps
15 
1
Written by
Development Manager, Web Developer with ASP.Net, ASP.net Core, Azure and Microsoft Technologies
Web developers with ASP.Net, MSSQL, Azure working in Remote Office 100%
Written by
Development Manager, Web Developer with ASP.Net, ASP.net Core, Azure and Microsoft Technologies
Web developers with ASP.Net, MSSQL, Azure working in Remote Office 100%
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/the-internal-startup/how-to-set-up-your-own-paas-within-hours-83356523413d?source=search_post---------16,"There are currently no responses for this story.
Be the first to respond.
There are many useful and free open-source software on the Internet, we just need to know where to look.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://blog.datasyndrome.com/open-source-software-and-paas-crisis-and-adaptation-587d07d95a92?source=search_post---------17,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Structural changes in the open source ecosystem are occurring as a result of the rise of cloud computing Platforms as a Service (PaaS) that are disrupting the cycle of investment that sustains the ecosystem. The shift to cloud computing reduces the number of companies making direct investments in open source by several orders of magnitude and concentrates control of companies‚Äô indirect investments in the hands of a few intermediaries that lack the same incentives as individual companies which ensured their ethical participation.
This constitutes a full blown crisis for the pay-it-forward soft economy of free and open source software. As a result, dramatic change is coming to the ecosystem, which is adapting in multiple ways that we‚Äôll be exploring in upcoming posts.
I see many people complaining about the symptoms of these changes, about bad actors in the ecosystem. I see virtually no one talking about the structural reasons for these symptoms and what they mean for the future, let alone outlining potential scenarios, what they might mean and how we might affect those outcomes. This is the first in a series of posts that will attempt to do those things.
Don‚Äôt kid yourself: companies, not volunteers, fund most open source software. Companies like Company A pay workers like Worker B to solve its problems using Open Source Project C. In a cycle of reciprocity, Company A allows Worker B to contribute improvements back to Open Source Project C where other companies can use them and in turn contribute their own improvements. Everyone benefits.
This is the fundamental cycle that makes open source work. This cycle has operated without interruption from the dawn of open source in the 1970s, starting with research institutions and BSD *nix and expanding into the enterprise with Linux and Apache. Until recently it has fueled the growth of open source software until the systems operating the global economy are completely dependent upon it.
Cloud computing fundamentally changes the open source cycle of reciprocity. Under the Platform as a Service (PaaS) model, Company A pays Cloud PaaS Provider D to run open source software for them. This presents a potential problem ‚Äî if you don‚Äôt run your own software, you don‚Äôt improve it and you don‚Äôt contribute those improvements back to the project. The cycle of reciprocity is broken and the economics of open source no longer work.
In a cloud based model Cloud Paas Provider D pays Worker E to improve Open Source Project C and they allow Worker E to contribute those improvements back to Open Source Project C where other cloud providers can use them and in turn contribute their own improvements.
Note that the contributor to open source software is now the cloud provider, not the original company and the cycle of reciprocity now operates among cloud providers and not individual companies across the many industries of the global economy. Cloud providers have as many as 1,000,000 customers which means that the scale of reduction in the number of companies directly funding open source software is enormous. I‚Äôm not saying it is 1,000,000:1 but it is certainly several orders of magnitude. Several zeros at minimum.
Note that because they are few in number, cloud providers have different relationships between one another than two companies that contributed to an open source project under the traditional model. An increased level of competition among direct contributors to open source may tend to decrease their allocation of investment to the overall ecosystem and instead lead them to try to undermine, fragment and own the ecosystem itself. To make what is open transparent ‚Äî but closed once again. Free as in beer but not free as in freedom. This the dystopian scenario we must try to avoid, which I‚Äôll talk about in a future post.
For now, the most important thing to note is that for open source in the PaaS model, for each cloud provider there are still as many as one million companies indirectly funding open source software, but now the cloud provider manages the allocation of those funds. Cloud computing providers have become open source investment managers, whether they like it or not.
This raises a number of important questions: are cloud providers stepping up and taking on this new responsibility as the de facto financial managers of open source investment? Does their investment in open source projects reflect their customers‚Äô investment in those projects‚Äô continued existence? Are they doing their fiduciary duty? How can we be sure cloud providers keep the cycle of reciprocal investment in open source going? These are the questions this series will explore.
Once we decide we are looking for answers, how do we go about it? How do we evaluate the free and open source software ecosystem and the citizenship of the cloud providers? Who do we listen to? The cloud providers themselves? Open source enthusiasts? Project founders? Entrepreneurs? FOSS prophets? Analysts (what analysts)? Journalists?
Over the course of the last six months, I‚Äôve spoken to or conducted interviews with all of the above parties. Each has a different perspective, each cites different examples to justify their opinion. Some see the crisis I do, others do not see it at all. Most evidence I was presented with was anecdotal. The only statistics cited by anyone come from cloud providers, and as we‚Äôll see there is reason to be skeptical of their claims.
In the end, I found the only reliable way to understand the changing situation was to look at hard data. This is why I adopted Github and Stack Overflow data as the datasets used in my forthcoming book, Weakly Supervised Learning (O‚ÄôReilly, 2020). In this series of posts, I will combine hard data with insights from the interviews I‚Äôve conducted to investigate what open source might look like in the future and what any of us can do to effect change to create the kind of future everyone involved wants: a vibrant open source ecosystem far into the future.
Fear not, there is hope! But we had better get moving‚Ä¶
Russell Jurney is an AI product consultant specializing in natural language processing, data labeling, Snorkel and weakly supervised learning. He is the author of four books on data science. His fifth book, Weakly Supervised Learning (O‚ÄôReilly, 2020) is out later this year.
Machine learning engineering for hire
106 
Some rights reserved

106¬†claps
106 
Written by
I am CTO at Deep Discovery where I fight global corruption with networks and AI
Machine learning engineering for hire
Written by
I am CTO at Deep Discovery where I fight global corruption with networks and AI
Machine learning engineering for hire
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://blog.realkinetic.com/there-and-back-again-why-paas-is-pass%C3%A9-and-why-its-not-f4f871083449?source=search_post---------18,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
In 10 years nobody will be talking about Kubernetes. Not because people stopped using it or because it fell out of favor, but because it became utility. Containers, Kubernetes, service meshes ‚Äî they‚Äôll all be there, the same way VMs, hypervisors, and switches will be. Compute is a commodity, and I don‚Äôt care how my workload runs so long as it meets my business‚Äôs SLOs and other requirements. Within AWS alone, there are now innumerable ways to run a compute workload.
This was the promise of Platform as a Service (PaaS): provide a pre-built runtime where you simply plug in your application and the rest ‚Äî compute, networking, storage ‚Äî is handled for you. Heroku (2007), Google App Engine (2008), OpenShift (2011), and Cloud Foundry (2011) all come to mind. But PaaS has, in many ways, become a sort of taboo in recent years. As a consultant working with companies either in the cloud or looking to move to the cloud, I‚Äôve found PaaS to almost be a trigger word; the wince from clients upon its utterance is almost palpable. It‚Äôs hard to pin down exactly why this is the case, but I think there are a number of reasons which range from entirely legit to outright FUD.
There is often a funny cognitive dissonance with these companies who recoil at the mention of PaaS. After unequivocally rejecting the idea for reasons like vendor lock-in and runtime restrictions (again, some of these are legitimate concerns), they will describe, in piecemeal fashion, their own half-baked idea of a PaaS. ‚ÄúWell, we‚Äôll use Kubernetes to handle compute, ELK stack for logging, Prometheus for metrics, OpenTracing for distributed tracing, Redis for caching‚Ä¶‚Äù, and so the list goes on. Not to mention there tends to be a bias on build over buy. And we need to somehow provide all of these things as a self-service platform to developers.
While there are ongoing efforts to democratize the cloud and provide reference architectures of sorts, the fact is there are no standards and the proliferation of tools and technologies continues to expand at a rapid pace. On the other hand, as certain tools emerge, such as Kubernetes, the patterns and practices around them have naturally lagged behind. The serverless movement bears this out further. Serverless is the microservice equivalent for PaaS but with a lot less tooling and operations maturity. This is an exciting time, but the cloud has become ‚Äî without a doubt ‚Äî an unnavigable wasteland. Even with all the things at your disposal today, it‚Äôs still a ton of work to build and operate what is essentially your own PaaS.
But technology is cyclical and the cloud is no different. This evolution, in some sense, parallels what happened with the NoSQL movement. Eric Brewer discusses this in his RICON 2012 talk. When you cut through the hype, NoSQL was about giving developers more control at the expense of less pre-packaged functionality, but it was not intended to be the end game or an alternative to SQL. It‚Äôs about two different, equally valid world views: top-down and bottom-up. The top-down view is looking at a model and its semantics and then figuring out what you need to do to implement it. With a relational database, this is using SQL to declaratively construct our model. The bottom-up view is about the layering of primitive components into something more complex. For example, modern databases like CockroachDB present a SQL abstraction on top of a transactional layer on top of a replication layer on top of a simple key-value-store layer. NoSQL gives us a reusable storage component with a lot of flexibility and, over time, as we add more and more pieces on top, we get something that looks more like a database. We start with low-level layers, but the end goal is still the same: nice, user-friendly semantics. I would argue the same thing is happening with PaaS.
What the major cloud providers are doing is unbundling the PaaS. We have our compute, our cluster scheduler, our databases and caches, our message queues, and other components. What‚Äôs missing is the glue ‚Äî the standards and tools that tie these things together into a coherent, manageable unit ‚Äî a PaaS. Everything old is new again. What we will see is the rebundling of these components gradually happen over time as those standards and tools emerge. Tools like AWS Fargate and Google App Engine Flexible Environment are a step in that direction (Google really screwed up by calling it App Engine Flex because of all the PaaS baggage associated with the App Engine name). The container is just the interface. However, that‚Äôs only the start.
PaaS and serverless are great because they truly accelerate application development and reduce operations overhead. However, the trade-off is: we become constrained. For example, with App Engine, we were initially constrained to certain Google Cloud APIs, such as Cloud Datastore and Task Queues, and specific language runtimes. Over time, this has improved, notably, with Cloud SQL, and now today we can use custom runtimes. Similarly, PaaS gives us service autoscaling, high availability, and critical security patches for free, but we lose a degree of control over compute characteristics and workload-processing patterns.
In a sense, what a PaaS offers is an opinionated framework for running applications. Opinionated is good if you want to be productive, but it‚Äôs limiting once you have a mature product. What we want are the benefits of PaaS with a bit more flexibility. A PaaS provides us a top-down template from which we can start, but we want to be able to tweak that to our needs. Kubernetes is a key part of that template, but it‚Äôs ultimately just a means to an end.
This is why I think no one will be talking about Kubernetes in 10 years. Hopefully by then it‚Äôs just not that interesting. If it still is, we‚Äôre not done yet.
Real Kinetic is passionate about helping companies deliver value to customers quickly and reliably. Learn more about working with us.
Our thoughts, opinions, and insights into technology and‚Ä¶
31 
31¬†claps
31 
Written by
Managing Partner at Real Kinetic. Interested in distributed systems, messaging infrastructure, and resilience engineering.
Our thoughts, opinions, and insights into technology and leadership. We blog about scalability, devops, and organizational issues.
Written by
Managing Partner at Real Kinetic. Interested in distributed systems, messaging infrastructure, and resilience engineering.
Our thoughts, opinions, and insights into technology and leadership. We blog about scalability, devops, and organizational issues.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://itnext.io/azure-explained-deep-enough-azure-paas-321a0f16bd57?source=search_post---------19,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
This is the third part of Azure mini-series Azure explained deep enough
Part1: Azure explained deep enough: learn and get certified
Part2: Azure explained deep enough: Containers
Part3: Azure explained deep enough: Azure PaaS <- this blog
Part4: Azure explained deep enough: Azure DevOps
Azure App Service is a fully managed service for building, deploying, and scaling your web apps, web APIs, and other server-side workloads. App Service is an Azure PaaS offering, PaaS stands for Platform as a Service.
There are other PaaS providers than Azure, each major Cloud Provider have their offering:
There are also interesting smaller PaaS providers
Modern software infrastructure is pretty complicated, from VMs to containers. From monolithic applications to serverless, from on-prem to hybrid modes. Everything is more connected, IoT and edge requirements push the boundaries of what is considered possible every day! Technologies like WASM, RISC-V, Kubernetes, Machine Learning & AI, Quantum Computing, and many more will completely revolutionize how software is created, delivered, and personalized.
This is all great, but how should developers keep up with all the building and deployment options? How to easily monitor and operationalizing all those various workloads? That‚Äôs where PaaS comes in.
PaaS bridges the gap between the underlying hosting platforms and running workloads, by providing a good balance between opinionated defaults and configuration options.
In other words a good PaaS offering will be flexible enough to accommodate for different needs and workloads and intelligent enough to hide infrastructure complexity by providing smart abstraction layer to work with.
Azure, like any other major cloud provider, offers a lot of services to choose from. Most often than not, the sheer number of options and services is just plain confusing. The below diagram guides you through the decision process and helps understand where PaaS offering is a good choice.
In general, if you have a workload that will be consumer-facing via HTTP(s), like a web page, web API, etc, Azure App Service is a good choice.
Other than standard hosting options, now it is possible to run App Service on Azure Arc enabled Kubernetes anywhere. This is a pretty interesting feature because it extends the Azure App Service control plane and runs it on top of Kubernetes, meaning that if you have App Services running in Azure already, you could run them for example on-prem on a Kubernetes cluster and still use Azure App Service abstraction as you would in Azure itself.
Finally, in order to run our App Service, we need to select an SKU (Stock Keeping Unit) plan that will define the capabilities of the underlying infrastructure.
Here we can decide how much CPU and RAM should our infrastructure have, what are the auto-scaling rules and other features, like support for custom certificates or custom domain names, etc.
for full list of available configuration options please refer to Azure Docs
Since there is no good graphical representation helping us choose between SKUs (similar to the one helping us choose between hosting options for our service), I have created one:
We are going to deploy Azure infrastructure and use App Service with Azure Container Registry to deploy a sample web app running in a docker container.
To set up our testing infrastructure, we will take advantage of the fact that Azure Cloud Shell comes with a pre-installed terraform.
You don‚Äôt need to be familiar with terraform, all commands will be provided, but remember always check scripts from the internet before executing. All scripts are part of the learning repository here.
Please feel free to fork the repository and make your own changes. One thing to note is that terraform state file will be generated once you start typing terraform commands. Terraform state file contains sensitive information that you do not want to commit to your repository. The .gitignore present in the terraform folder will exclude state files from being added to the repository, so please do not delete this file.
Login to the Azure portal and select Cloud Shell. Follow this tutorial to activate cloud shell if you are login for the first time on a fresh account.
Once you are in the cloud shell, make sure to select bash environment and follow the steps below.
The above commands should create our Azure infrastructure and. Go ahead and copy the URL from terraform output and you should see a sample PWA web page from my Docker Hub registry.
From here we have various options to play around with deploying a sample HTML page from the nginx-demo folder, replacing the app service container with another one, setting up CI/CD pipeline, etc. If you are interested, follow along with the instructions.
Retrieve login details to our Azure Container Registry so we can push an image with the sample web app
Since docker daemon is not running in the cloud shell VM, we have to use az acr build command to build an image and deploy it to ACR.
Now we can set the image for our App Service. Please note that all those actions are done in an ‚Äúimperative‚Äù way for educational purposes. In real-life scenarios, CI/CD pipelines would be set up to handle the flow of change and updates
Give it a moment so that Azure can refresh the image and navigate to the same address, you should see an nginx demo page.
This step is IMPORTANT so that you will avoid unnecessary charges. Let‚Äôs remove the resources, it is very easy to do this with terraform.
Azure PaaS, App Service is a very versatile and powerful service. We have learned when to use it, how to select the right SKU, finally how to deploy a sample workload following infrastructure as code practices.
ITNEXT is a platform for IT developers & software engineers‚Ä¶
84 
84¬†claps
84 
Written by
Opinions: Multi-cloud is real, Microservices are hard, Kubernetes is the future, CLIs are good. Me: Love jogging with my dog and learning new things.
ITNEXT is a platform for IT developers & software engineers to share knowledge, connect, collaborate, learn and experience next-gen technologies.
Written by
Opinions: Multi-cloud is real, Microservices are hard, Kubernetes is the future, CLIs are good. Me: Love jogging with my dog and learning new things.
ITNEXT is a platform for IT developers & software engineers to share knowledge, connect, collaborate, learn and experience next-gen technologies.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/oracledevs/quick-start-docker-ized-paas-service-manager-cli-f54eaf4ebcc7?source=search_post---------20,"There are currently no responses for this story.
Be the first to respond.
This blog will give you a quick tour of Oracle PaaS Service Manager command line interface (PSM CLI in short) which provides a command line interface (CLI) to manage the lifecycle of various services (e.g. Oracle Application Container Cloud, Oracle Big Data Cloud Compute Edition, Oracle Java Cloud, Oracle Event Hub Cloud etc.) in Oracle Public Cloud
We will explore PSM CLI capabilities for Oracle Application Container Cloud (ACCS) to be specific (for all the PSM ACCS commands, refer the documentation)
Here is the blog which served as the inspiration/trigger for this one!
Here is the Dockerfile along with a summary of what‚Äôs going on‚Ä¶
The application is available here.. to get started,
git clone https://github.com/abhirockzz/accs-psm-cli-docker.git
mvn clean install will create a target directory with accs-hello-world.zip ‚Äî this is the artifact which will be pushed to the cloud
Execute docker images ‚Äî you should see psm-cliin the list of images
docker run --rm -it psm-cli ‚Äî you will land in the shell.. now its time to execute our commands
psm --version
Response: PSM CLI Client ‚Äî version 1.1.16
We will use the Job ID (highlighted above) which was returned by the push operation
psm accs operation-status -j 14988917
psm accs app -n HelloWorldApp
The sample application uses a simple JDK based HTTPServer
curl https://helloworldapp-<identity-domain>.apaas.us2.oraclecloud.com/ will return something like Hello @ Fri Sep 01 13:37:39 UTC 2017 from 10.199.34.135
psm accs check-health -n HelloWorldApp
psm accs stop -n HelloWorldApp ‚Äî process will be triggered
Track using Job ID (same as before) and check the status after some time using psm accs app -n HelloWorldApp
psm accs delete -n HelloWorldApp ‚Äî track progress using Job ID
That‚Äôs all folks !
The views expressed in this post are my own and do not necessarily reflect the views of Oracle.
A community for developers by developers.
44 
44¬†claps
44 
Aggregation of articles from Oracle engineers, Groundbreaker Ambassadors, Oracle ACEs, and Java Champions on all things Oracle technology. The views expressed are those of  the authors and not necessarily of Oracle.
Written by
Azure Cosmos DB at Microsoft | I like Databases, Go, Kubernetes
Aggregation of articles from Oracle engineers, Groundbreaker Ambassadors, Oracle ACEs, and Java Champions on all things Oracle technology. The views expressed are those of  the authors and not necessarily of Oracle.
"
https://medium.com/@chadrodriguez/platforms-4f813ab41e69?source=search_post---------21,"Sign in
There are currently no responses for this story.
Be the first to respond.
Chad Rodriguez
Feb 17, 2015¬∑5 min read
By now, most of the world knows about Jon (Not John, flip) Stewart‚Äôs announcement to leave the Daily Show. I was sitting on my couch watching his latest episode when it showed up in my Twitter feed. To say I was bummed would be an understatement. I, like most people in this world, feel I carry a very full schedule‚Ä¶ wife, two (almost three!) kids, job, friends, all while trying to balance it in NYC. The Daily Show is one of the few things I consistently watch each day. It‚Äôs my way of decompressing from everything that the day usually throws at me.
Everyone has come out with their piece on ‚ÄúWho should replace him and why‚Äù. This is not what one of those pieces. To be honest, I‚Äôm one of those die hards who would prefer we didn‚Äôt have to wonder who could replace him. What has been great reading are all the articles around the different people he, in essence, ‚Äúlaunched‚Äù. The list is pretty fantastic.
Those are just a few of the ‚Äúbigger‚Äù names that almost anyone in the US would recognize today. The list is so much longer, and you should Google it. They are some of the funniest people in comedy today.
This got me thinking about the idea of ‚Äúplatforms‚Äù and what it means to be one, to function with this idea that my role is People As A Service (PaaS). I‚Äôve got a tech background (was just at a SaaS startup) so platforms have always been something I‚Äôve been technically obsessed with creating. To build something that better and smarter things could be built upon is what most startups aim for, and rightly so.
It might seem odd thinking that you are being built upon, but we are, whether we realize it or not. This is especially true for those of us that have many people reporting to us. Most people like to think linearly about these things, and it‚Äôs just not possible. We don‚Äôt exist on an island. We‚Äôre connected. Bottom line. People choose to build on platforms for many different reasons. Sure, some do it for solely for notoriety. I mean who wouldn‚Äôt want the gig as a correspondent on the Daily Show, or to work at Apple, Nike, Google?
I think ultimately the reason people take a certain position is because they‚Äôve seen a precedent for it being a safe place to grow, and to learn. They see it as safe, and not in a bad way.
What makes Apple, Twitter, FB or Google such popular platforms is the deeper fact that they are safe to build on (as a piece of soft/hardware). Why do you think no one builds on Microsoft (unless Microsoft begs and pays)? Sure, all the guys I mentioned first offer innovative ways to reach people, but it‚Äôs because they‚Äôre safe & have proven themselves that people are drawn to them. That didn‚Äôt happen overnight of course. As with Jon, it took time to establish that reputation in the industry. It takes a level of trust and time to be a real platform (yea sorry, it can‚Äôt happen overnight).
We have to stop thinking of ‚Äúsafe‚Äù as a bad word. That it‚Äôs indicative of doing something that doesn‚Äôt matter, or not challenging. Amazing things can happen when you feel safe.
Every interview I‚Äôve ever read with one of the new correspondents talking about making it on the show always had this phrase, ‚ÄúJon just told me to be myself, to not try to be anyone else.‚Äù I can‚Äôt imagine a safer feeling walking into a situation, especially when you know you had people like Stephen Colbert come before you. Feeling safe is something we all want and if we were all honest, it‚Äôs something we want more than we let on.
Like any good platform, the future of what comes from it depends on how solid it is at its core.
It‚Äôs hard to build a safe environment, because it means people have to have the ability to try and fail. To build and to break. Most places/individuals, unfortunately, don‚Äôt work that way. It always makes me laugh when a leader tells someone to ‚Äúrun with something‚Äù, then basically follows that with all these ‚Äúdo‚Äôs and don‚Äôts‚Äù. If we‚Äôre a solid platform, we should be okay with risk because we know we‚Äôre secure. Truth be told, most innovation doesn‚Äôt come from a lack of smart or creative people. It comes from people feeling safe enough to explore the boundaries (which means occasionally crossing them). It comes from them feeling safe enough to fail despite fear of what might come.
I have to be able to inspire trust in me as a leader so that when you break something you feel safe knowing it won‚Äôt shake me to my core. This is what most people fail to accomplish. Often as leaders, we‚Äôre terrified of people failing because we‚Äôre terrified that it could expose our weakness.
This kind of thinking stifles everything. Creativity, growth‚Ä¶ and the list could go on. I get that people need guardrails and boundaries, and I believe great creativity comes from having them. The Daily Show provides guardrails in the form of segments to cover a topic. The rest is up to the correspondent - the angle they take, the type of humor they choose to leverage, etc. Ultimately, whether the bit fails or is a hit doesn‚Äôt affect what we‚Äôre all there for- Jon. He‚Äôs a platform, and like any good one, he‚Äôs solid.
He knows that if a bit fails, the person will only get better, and that the best thing he can do is continue to do what he does best, make us laugh. By being incredible at his craft, he makes it safe for everyone else to do the same.
As a leader, being/becoming a platform leaves us with one of two challenges:
There is, after all, a reason why what Jon has created what is being referred to as a legacy, and why most of us struggle to think about how someone can replace him. I do know this: whoever it will be will have to be more than solely funny because there are a lot of people who can ‚Äúdo‚Äù funny. They just damn sure better be secure enough to consistently build the future of funny for a new generation of watchers. That‚Äôs something only someone who has a true understanding of themselves as a platform can provide.
Here‚Äôs looking forward to The Daily Show with‚Ä¶
Usually hovering around the ideas of relationship, technology, belief and our tensions between them.
59 
59¬†
59 
Usually hovering around the ideas of relationship, technology, belief and our tensions between them.
"
https://medium.com/@jaychapel/saas-vs-paas-vs-iaas-where-the-market-is-going-fcc46771731d?source=search_post---------22,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jay Chapel
Jul 24, 2019¬∑4 min read
SaaS, PaaS, IaaS ‚Äî these are the three essential models of cloud services to compare, otherwise known as Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). Each of these has its own benefits, and it‚Äôs good to understand why providers offer these different models and what implications they have for the market. While SaaS, PaaS, and IaaS are different, they are not competitive ‚Äî most software-focused companies use some form of all three. Let‚Äôs take a look at these main categories, and because I like to understand things by company name, I‚Äôll include a few of the more common SaaS, PaaS, and IaaS providers in market today.
Software as a Service, also known as cloud application services, represents the most commonly utilized option for businesses in the cloud market. SaaS utilizes the internet to deliver applications, which are managed by a third-party vendor, to its users. A majority of SaaS applications are run directly through the web browser, and do not require any downloads or installations on the client side.
Prominent providers: Salesforce, ServiceNow, Google Apps, Dropbox and Slack (and ParkMyCloud, of course).
Cloud platform services, or Platform as a Service (PaaS), provide cloud components to certain software while being used mainly for applications. PaaS delivers a framework for developers that they can build upon and use to create customized applications. All servers, storage, and networking can be managed by the enterprise or a third-party provider while the developers can maintain management of the applications.
Prominent providers and offerings: AWS Elastic Beanstalk, RedHat Openshift, IBM Bluemix, Windows Azure, and VMware Pivotal CF.
Cloud infrastructure services, known as Infrastructure as a Service (IaaS), are made of highly scalable and automated compute resources. IaaS is fully self-service for accessing and monitoring things like compute, storage, networking, and other infrastructure related services, and it allows businesses to purchase resources on-demand and as-needed instead of having to buy hardware outright.
Prominent Providers: Amazon Web Services (AWS), Microsoft Azure (Azure), Google Cloud Platform (GCP), and IBM Cloud.
SaaS, PaaS and IaaS are all under the umbrella of cloud computing (building, creating, and storing data over the cloud). Think about them in terms of out-of-the-box functionality and building from the bottom up.
IaaS helps build the infrastructure of a cloud-based technology. PaaS helps developers build custom apps via an API that can be delivered over the cloud. And SaaS is cloud-based software companies can sell and use.
Think of IaaS as the foundation of building a cloud-based service ‚Äî whether that‚Äôs content, software, or the website to sell a physical product, PaaS as the platform on which developers can build apps without having to host them, and SaaS as the software you can buy or sell to help enterprises (or others) get stuff done.
The SaaS market is by far the largest market, according to a Gartner study that reported that enterprises spent $182B+ on cloud services, with SaaS services making up 43% of that spend.
While SaaS is currently the largest cloud service in terms of spend, IaaS is currently projected to be the fastest growing market with a CAGR of 20% plus over the next 3 to 4 years. This bodes very well for the ‚Äúbig three‚Äù providers, AWS, Azure and GCP.
What‚Äôs interesting is that many pundits argue that PaaS is the future, along with FaaS, DaaS and every other X-as-a-service. However, the data shows otherwise. As evidenced by the reports from Gartner above, IaaS has a larger market share and is growing the fastest.
First of all, this is because IaaS offers all the important benefits of using the cloud such as scalability, flexibility, location independence and potentially lower costs. In comparison with PaaS and SaaS, the biggest strength of IaaS is the flexibility and customization it offers. The leading cloud computing vendors offer a wide range of different infrastructure options, allowing customers to pick the performance characteristics that most closely match their needs.
In addition, IaaS is the least likely of the three cloud delivery models to result in vendor lock-in. With SaaS and PaaS, it can be difficult to migrate to another option or simply stop using a service once it‚Äôs baked into your operations. IaaS also charges customers only for the resources they actually use, which can result in cost reductions if used strategically. While much of the growth is from existing customers, it‚Äôs also because more organizations are using IaaS across more functions than either of the other models of cloud services.
Originally published at www.parkmycloud.com on May 21, 2019.
CEO of ParkMyCloud
See all (317)
28 
2
28¬†claps
28 
2
CEO of ParkMyCloud
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@avs431/explain-it-to-me-like-i-am-a-5-year-old-cloud-delivery-models-iaas-paas-and-saas-with-use-77499c233fd3?source=search_post---------23,"Sign in
There are currently no responses for this story.
Be the first to respond.
Ameya Shanbhag
Apr 5, 2020¬∑5 min read
I always wondered what the cloud is and wanted to start exploring the cloud. When people around me used to say words like PaaS, IaaS, Microservices, Docker, I used to be so overwhelmed that I used to just nod my head so that I don‚Äôt look dumb. But soon I realized that it's not just me, but also people who talk about IaaS and all these words, have little idea about what it actually means in real-world so I thought to not only educate myself to understand the meaning but also to make sure I know when to use what given a real-world scenario.
This blog is dedicated to all who want to learn cloud concepts but in a simple and easy manner.
The best way to learn anything is to visualize it so here is something that I found, which sums up the whole topic:
Let‚Äôs say your end goal is to go from point A to point B:
You can consider IaaS as buying a car, While buying a car, you look for all the specs, the color of the car, interior design and also do a lot of research before actually buying it. Once you decide on the car, you pay for it and then you can drive the car. Here the car is the ‚Äòinfrastructure‚Äô, you driving it is ‚Äòusing it‚Äô and you pay for it is ‚Äòservice‚Äô. Another example is like going on AWS, renting an EC2 instance and spinning up Windows machine.
On the same grounds, PaaS is analogous to renting a car where you do not have to do any research on specific specs but there are few already bought cars that come with in-built specs. You just have to pay for it and then you can drive. Here the rental car is the ‚ÄòPlatform‚Äô and rest everything stays the same as the previous one. Another example is like using AWS BeanStalk where you tell what you want, and it automatically runs an instance and downloads all the software you want.
SaaS, on the other hand, can be considered as a taxi where you are not even driving the car but using someone else‚Äôs service to go from point A to point B. Here using someone else‚Äôs service is ‚ÄòSoftware‚Äô and rest everything stays the same. Another example would be to use Microsoft 365 services online.
Going into specifics and real-world use cases:
Why can‚Äôt we use PaaS instead of IaaS?
If you have existing legacy applications already running on your private servers, moving them on PaaS will be difficult because let‚Äôs say you want to use AWS as PaaS then as you can see from the above diagram, you will be using the database provided by AWS. This means you will need to change your code to use AWS SDK which can be a tough task.
Polyglot PaaS:
In simple terms, it is easy to deploy an application when written in one specific language, for example, Java application can be deployed as WAR and Fabric can be used for python application. But as we all know, each language is best in doing its own thing so if you want to develop an application that uses multiple languages(polyglot), how would you deploy it? With multiple languages involved, it becomes really difficult to deploy it hence Heroku started working on Polyglot PaaS where you can just develop the application using whichever language you want and it will deploy it for you.For more information visit: https://blog.heroku.com/polyglot_platform
That‚Äôs all for today! I will be writing future blogs where I break down Microservices, Docker, and Containers and make it explainable in very simpler terms.
I am just a beginner in this cloud journey so if there is anything that I missed out and explained in a different way, please do let me know. Also if there are any other cloud concepts that you want me to write on, let me know in the comment section below.
I can be reached via Linkedin.
Credits: LinkedIn Learning, IBM Cloud
https://www.ameyashanbhag.com/
11 
1
11¬†
11 
1
https://www.ameyashanbhag.com/
"
https://medium.com/@shijuvar/the-evolution-of-cloud-paas-to-container-ecosystem-1943a335c25b?source=search_post---------24,"Sign in
There are currently no responses for this story.
Be the first to respond.
Shiju Varghese
Nov 9, 2014¬∑8 min read
In this post, I will take a look at the evolution of Cloud PaaS with the context of building and running web apps into Cloud, and the impact which will be happen in the near future, after the arrival of container ecosystem especially with the arrival of Docker and Kubernetes. Platform as a Service (PaaS) model is the most compelling model among the different service models of Cloud computing. The real benefit of Cloud computing, is the operational agility provided by the Cloud platform in which we don‚Äôt have to worry about IT infrastructure and we can just focus on building our apps. If you really want to leverage the real power of Cloud and want to leverage the operational agility provided by Cloud, you should leverage PaaS offerings instead of setting up IaaS instances which required lot of manual intervention when comparing to corresponding PaaS offering.
AWS is the first public Cloud platform, which was initially started as an IaaS platform. On the other hand, Azure was started as a PaaS platform in which Microsoft has simplified the way for building and deploying apps into Cloud. Later, AWS started to support PaaS offerings and Azure started to support IaaS offerings. At the same time, Google Cloud came with their own PasS offering for simplifying the way for building and deploying apps into Cloud.
In Microsoft Azure, the primary PaaS offering is ‚ÄúCloud Services‚Äù which provides support for Java, Node.js, PHP, Python, .NET, and Ruby. The Cloud Services model provides two models ‚Äî Web Role and Worker Role. Web Roles lets you running Web apps and Worker Roles lets you run background processing services. Azure also provides Azure Website which is also a good option for building Web apps on Cloud. But Cloud Services is a better option for building multi-tier Cloud apps. The main disadvantages of Azure‚Äôs offerings is that it is based on Windows operating which would not be appeal for non-Windows community. For deploying non-Windows system, you must use Azure‚Äôs IaaS services. But for developers who working on .Net stack and Windows, Azure is superior option than any other Cloud platform. For .Net developers, Azure is great option comparing to similar offerings of AWS. I highly recommend Azure for .Net developer community.
The PaaS service of AWS, for deploying and managing web apps, is ‚ÄúElastic Beanstalk‚Äù. Elastic Beanstalk provides support for Java, .NET, PHP, Node.js, Python, and Ruby. The real advantage of Elastic Beanstalk is that it comes with familiar servers such as Apache, Nginx, Passenger, and IIS. Unlike Azure, it is coming with multiple OS platforms and servers, which will appeal multiple developer communities. In this context, Elastic Beanstalk is a better platform comparing to Azure. But, to be honest, Azure Cloud Services and Azure Website are better than Elastic Beanstalk from the PaaS perspective. If you worked on both AWS Elastic Beanstalk and Azure Cloud Services, you would appreciate Azure Cloud Services, at least for a .Net developer.
I observed that many AWS customers are primarily using IaaS services for deploying web apps instead of using AWS Elastic Beanstalk. As a Cloud Solutions Architect, my approach for building a Cloud solution is, if there is any possibility for leveraging PaaS offering, use it instead of leveraging IaaS instances. The reason is we can focus more on application development and we don‚Äôt have to spend time for setting-up many things on IaaS virtual machines.
Google Cloud‚Äôs PaaS offering is ‚ÄúGoogle App Engine‚Äù. Google App Engine (GAE) provides support for Python, Java, PHP, Go. It does not support for .Net, which is a major enterprise technology stack after Java stack. But I appreciate this decision, because Azure is a finest solution for a .Net developer. A good thing about Google App Engine is that it supports Go (Golang), which is an emerging technology for building next-generation apps. But at this moment, the support for Go is not much great.
In general, the current approach for PaaS is to provide a separate runtime environment for each programming language and development platform. If the PaaS platform is not providing support for your language environment, you must use their IaaS instances and need to setup the infrastructure.
Application containers are changing the way that developers build, ship and run applications. Docker is revolutionizing the application container technology with their powerful open-source platform. Docker is a application container technology platform for build, ship and run your distributed apps. The Docker ecosystem consisting of Docker Engine, a portable, lightweight runtime and packaging tool for building containerized apps, and Docker Hub, a cloud service for sharing apps and automating workflows. Docker lets the developers containerize their apps and can run these apps anywhere. Docker allows you compose your containerized apps by linking between different containers. Docker is really a powerful ecosystem where you can leverage thousands of apps available on Docker Hub. Docker is built on the top of Linux containers.
Docker is also changing the way that we build applications for Cloud. The Docker revolution transforms running server applications from virtual machines (VM) to containers. I believe that this is an evolution of distributed application development in which the current ecosystem is depends on virtual machines and mostly leveraging virtual machines of IaaS services of Cloud. When Docker is making big impact on the Cloud platforms, Kubernetes is a great enabler for managing containers on the Cloud. Kubernetes is an open source implementation of container cluster management, which was developed by Google. It was initially developed for Google Compute Engine (GCE) for managing application containers. At Google, everything is packaged and run in a Linux container, and Kubernetes is doing container cluster management. Even you are running your apps with Google App Engine, it is internally using Google Compute Engine where everything is running on Linux containers powered by Kubernetes. Now Google open-sourced Kubernetes so that other Cloud platforms can leverage the power of Kubernetes for managing Linux containers iincluding Docker containers.
Both Docker and Kubernetes are making big impact in the container technology ecosystem. The interesting thing is that both technologies were written with Go programming language. In my post, ‚ÄúWeb Development Trends For 2015 And Beyond‚Äù, I predicted Go as the emerging programming language of 2015.
Elastic Beanstalk, the PaaS platform of AWS, started to support Docker with a PaaS offering. This is a great initiative from AWS as you can work with container ecosystem through a PaaS abstraction where you don‚Äôt have to worry about the support of language runtime provided by the Cloud platform. We can package the runtime in our Docker container. This will provide great opportunity to Cloud platforms and also to developers who are working on Cloud platforms. For an example, AWS Elastic Beanstalk does not have a language runtime for Go language. But, with the Docker support of Elastic Beanstalk, we can run Go apps in AWS Elastic Beanstalk where I can add the Go image into the Docker container provided by Docker itself.
The technology term, application container, was getting attention, after the arrival Docker 1.0 released in this year. But Google has been working on containers since 2007 and the Google Compute Engine is based on container technology ecosystem. Google says that, at every week, they are launching more than 2 billion container instances across their global data centers. Everything at Google, from gmail to search, is packaged and run in a Linux container. It was a secret that Google was scaling their infrastructure with container technologies and they are already a front-runner in the container ecosystem.
Google Container Engine is a new service offering from Google Cloud platform. Google Container Engine is a fully-managed cluster manager for Docker containers, powered by Kubernetes. With Google Container Engine, you can easily package Docker containers and can quickly run the apps on Google infrastructure. The new service provided for container technologies, lets you move from managing Cloud apps running on individual virtual machines to launching portable Docker containers that are scheduled into a managed compute cluster for you. Google Container Engine is the next big evolution of Cloud PaaS. This is a transformation from running apps on individual virtual machines to portable containers where cluster management of containers will be performed by technologies such as Kubernetes. It is really awesome that Google Container Engine provides a PaaS abstraction on the top of their existing PaaS engine Google App Engine so that developers can easily work on the container technologies with greater level of operational agility.
Application container technologies are built on the top of Linux containers so that it is indeed clear that building a Docker container with Windows server is not possible. Many people believe that Docker is the one more reason to adopt Linux over Windows. But things might be change in future. Docker partners with Microsoft for bringing Docker on Windows servers and Microsoft Azure. If Docker and Microsoft could provide a better platform for Windows, it will be a big revolution. We can build containers with any platform and can running on any operating system platform. Currently Docker clients run on multiple systems, but if we could package Docker containers with multiple platforms, it would be really awesome.
Many people believe that the Cloud platform war between major Cloud platform vendor is already over where AWS won the game. It‚Äôs completely wrong assumption. I believe that the platform war is just started with container ecosystem. On the container ecosystem, Google is undoubtedly the leader as their existing IaaS services are already run on Linux containers and they have already developed and managed superior technologies such as Kubernetes. Google Cloud is already better than AWS on the IaaS space. If you compare AWS EC2 with Google Compute Engine, with an unbiased mindset, you will realize that Google Compute Engine is far superior than AWS. With the evolution of Cloud PaaS to container technologies, which is the strongest area of Google, Google Cloud is getting an edge on PaaS as well. When we are looking on the engineering excellence of Cloud platforms, Google has a real advantage among the Cloud platforms. Google Cloud platform will be the real threat to AWS platform, not from Microsoft Azure. For Microsoft Azure, they can attract their typical enterprise customers those are building apps on the Windows platform with .NET technology stack. It is indeed clear that container technologies are changing the Cloud computing platforms and the way that people deploy and manage applications.
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
9 
9¬†
9 
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
"
https://pub.towardsai.net/what-are-cloud-iaas-paas-saas-faas-and-why-we-use-them-8af979dad141?source=search_post---------25,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Click here to get to know me, my projects, and my latest articles.
Your first approach to the Cloud may be very confusing. The Cloud is gigantic, and there is not only ONE Cloud, but many viable choices in the market. Soon or late, if you decide to become a programmer, you will need to start learning how to work in ONE Cloud‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/kiwicode/insight-saas-16-paas-5ddaec89db39?source=search_post---------26,"There are currently no responses for this story.
Be the first to respond.
We covered why SaaS products require user experience in the last article ‚ÄòInsight: SaaS (15) Why does SaaS need user experience?‚Äô. Today, we‚Äôll talk about PaaS, its role, and whether or not SaaS should develop its own PaaS.
Many individuals have provided definitions of PaaS on the Internet, so you can search yourself. Simply put, the ultimate PaaS provides comprehensive development and operating environment that allows you to develop an application on it without a lot of facility deployment and environment setup. The terms PaaS, SaaS, and IaaS are frequently used interchangeably. IaaS is similar to a simple network facility rental, in that it allows clients to write and deploy any code they create. A software-as-a-service (SaaS) offering solves a customer‚Äôs specific problem and allows them to use it directly. PaaS is a form between IaaS and SaaS. It eliminates a lot of coding labor as compared to IaaS. In comparison to SaaS, it offers a degree of customization, allowing it to fulfill the individual needs of consumers in specific instances. It is, however, more of a compromise solution.
PaaS accounts for only 15% of the whole Cloud market, whereas SaaS accounts for 65%. PaaS has fatal flaws if it becomes a company‚Äôs primary product and market positioning:
PaaS is in the middle of the industry chain. It is not as good as SaaS for solving client problems and solving them clearly. The main advantage of PaaS sector entrepreneurs is that they can address different problems for different consumers because of its customizability, and the largest disadvantage is that they don‚Äôt have enough focus which is decided by the characteristics of PaaS products. PaaS, on the other hand, is not as good as IaaS in dealing with the underlying, complicated challenges, and it has significant flaws in terms of flexibility and cost. IaaS is preferred by experienced developers. PaaS is in a precarious situation.
The majority of PaaS products on the market are created by SaaS companies. Why do most SaaS businesses need to develop their own PaaS? What issues does PaaS address in SaaS businesses?
In most cases, SaaS companies must create their own PaaS to meet the unique needs of Enterprise customers. Within a specific range, PaaS can solve client customization issues.
1. Without PaaS, large-scale customized development cannot be mass-produced; otherwise, it will die outright. The difficulty for SaaS companies is custom development for Enterprises. Enterprises will leave if you refuse to build SaaS for them alone. However, development necessitates a significant amount of effort, which has an impact on the whole growth strategy and can easily lead to management misunderstanding. Demand for customized development will result in one-time income, influencing the CEO‚Äôs decision. Everyone likes revenue, but these aren‚Äôt recurring revenues and shouldn‚Äôt be the primary source of money in a SaaS model. The CEO of a SaaS company must ensure that subscription revenue accounts for a significant portion of total revenue.
2. Enterprise clients are the tier who make the most money, get the most willing to pay, and have the highest renewal rate. PaaS can also save a lot of money on maintenance costs for enterprises that use customized SaaS. The needs of big companies are constantly changing at a rapid pace. If you want to keep customers at a cheap cost, allowing customers‚Äô engineers to create and customize the software with PaaS can not only suit their needs but also reduce the SaaS company‚Äôs staff and avoid the discomfort of customization.
3. Using PaaS can broaden your consumer base. Through PaaS, more ISVs have built proper SaaS applications for various customer groups. This is a fantastic scenario; but, the prerequisites for PaaS are really high, and SaaS businesses will not be able to achieve this effect before they become giants.
We found that existing PaaS can handle a variety of difficulties, so we can define it on some levels.
1. Level-1 PaaS can customize any type, function, and authority. It requires its own DSL(Domain-specific Language) as well as comprehensive development documentation. ISVs can create apps on their own. However, it cannot break away from the scope of SaaS, and instead of writing programs line by line, there must be well-designed UI interactions that are as simple to use as feasible.
Users can be SaaS company employees, clients, or any third-party individuals who have passed registration.
2. Level-2 can add fields and key values, as well as construct autonomous business logic in a specific scenario. To help users complete part of the logic coding, low-code and no-code tools are required. However, it is unable to meet the unlimited needs of customers.
Users can be SaaS company employees, clients. Customers can design their own processes and their own data formats to make SaaS more suitable for the company‚Äôs usage habits.
3. Level-3 open API and closed development environment. Customers can design, access, and integrate open APIs into other systems, but the SaaS firm is just responsible for maintaining the API and will not have any additional functions. There is a PaaS prototype within the SaaS company that can speed up the process of customized development, but there are still many issues that prevent customers from using it themselves.
The users of the API are customers and employees of SaaS companies. Employees of SaaS organizations are the private prototype PaaS users.
Most of the SaaS companies with PaaS are at Level-3, with a few large SaaS companies having level-2 PaaS. Salesforce, Microsoft, and Oracle are among the level-1 PaaS providers. The technological level required to produce Level-3 is low, and SaaS organizations should strive for Level-3 PaaS at the very least. Level-2 PaaS necessitates a substantial investment as well as reliable architecture and new product design capabilities. And there‚Äôs a big difference between nearly getting to Level 2 and excelling at it. With the exception of a few exceptional cases, Level-1 PaaS products are frequently produced from the technical reserves of the IaaS behemoths. The complexity is really high, and it cannot be solved by money.
My response is unequivocal: They must do it. They don‚Äôt have the strength to accomplish it right now, but they must be ready to do it in the future. They must gather strength to prepare for a Level-2 PaaS before they can develop a Level-3 PaaS. Enterprise customers‚Äô value can only be maximized by SaaS firms that have implemented PaaS. Enterprise clients are the key to ensuring NDR for SaaS companies. When serving big companies, SaaS without PaaS constantly stacks up manpower. At best, it‚Äôs easy to get dragged down, and large consumers end up becoming a burden. Enterprises‚Äô needs can be largely addressed with PaaS, and the high-quality revenue for Enterprises can be shown.
PaaS construction requires a lot of labor costs. If you want to build one, think twice.
The next article ‚ÄòInsight: SaaS (17) Low Code or No Code is not the future‚Äô is published. Simply send me some claps and feedback if you enjoyed my article.
If you want to join our product ‚Äî Kiwicode (a code generation SaaS)‚Äôs waitlist, click here.
Let the computer program itself.
156 
156¬†claps
156 
Written by
Plan to build a Code Generation SaaS company in the US. Join the waitlist here ‚Äî https://www.kiwicode-service.com/waitlist
Create your app, and generate its code in Kiwicode. Kiwicode enables you to design Apps fast with our tools and turn it into a runnable code project.
Written by
Plan to build a Code Generation SaaS company in the US. Join the waitlist here ‚Äî https://www.kiwicode-service.com/waitlist
Create your app, and generate its code in Kiwicode. Kiwicode enables you to design Apps fast with our tools and turn it into a runnable code project.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/cuelogic-technologies/saas-paas-iaas-decoding-the-3-cloud-computing-service-models-25407ee1a568?source=search_post---------27,"There are currently no responses for this story.
Be the first to respond.
Over the years, this technology paradigm has evolved through multiple phases. The earlier forms of computing that preceded modern cloud computing included grid, utility, and on-demand computing. The earliest forms of modern cloud computing that include Software (SaaS), Platform (PaaS) and Infrastructure (IaaS) emerged as a technological outcome that attended the dipping costs of computer and server hardware. Users could purchase individual servers to power their computing requirements.
The cloud paradigm emerged when software makers and hardware vendors combined multiple servers in a concerted bid to harness the immense computing power generated by a grid (or network) of connected servers. Concurrently, the evolution of digital connectivity technologies that underlie the World Wide Web in recent years formally brought about the modern concept of ‚Äúcloud computing.‚Äù In recent times, the purveyors of technology have parlayed cloud-computing systems into multiple tiers of service, variously labeled as SaaS, PaaS, and IaaS.
(SaaS) is a software licensing and delivery model that has gained a significant presence in a wide range of modern corporate, business, scientific, and commercial applications.
SaaS technologies allow users to license proprietary software on a subscription basis ‚Äî monthly or annual. As providers of an ‚Äòon-demand‚Äô service, SaaS service providers host the software on the cloud to which users connect through a browser and an Internet connection. As a hugely cost-effective alternative to on-premise software installations and packages, the SaaS model seamlessly delivers a variety of applications that pertain to enterprise resource planning programs, office, and communications software, payroll and accounting packages, human resources management, mobile applications, etc.
This computing paradigm remains vulnerable to unauthorized access and malevolent hacking expeditions in online domains. Digital miscreants have targeted businesses that operate on the cloud by blocking customer access to critical online systems. This poses real risks that can translate into an erosion of market value for SaaS service providers. In response, service providers must continuously invest in improving security and authentication processes on the cloud, thereby delivering incremental assurances to their clients and customers.
Additional challenges that figure in the development of SaaS-powered products and services include custom third-party payment integration, safe and well-defined database access compliant with GDPR norms, guaranteeing zero-downtime deployment,managing the subscription lifecycle, and building a fully customizable SaaS system.
PaaS is ‚Äúa category of cloud services that provide a platform allowing customers to develop, run, and manage applications without the complexity of building and maintaining the infrastructure typically associated with developing and launching an app.‚Äù
PaaS providers host the hardware and software on their infrastructure, thereby releasing customers from any obligation to install in-house hardware and software to develop or run a new application.
PaaS technologies pose particular problems and risks for service providers. These challenges include balancing control, cost, and capacity of a PaaS-based service, providing full multi-tenancy support, designing role-based access controls, creating audit trails, and integrating third-party services into modern PaaS platforms. Additional challenges may emerge in the form of virtualization management, fine-tuning the PaaS compute architecture, designing inter-operability with other cloud services, and creating technically sound fault tolerance parameters.
IaaS operates by traditional cloud architecture. Per the IaaS cloud-computing paradigm, service providers host the infrastructure such as servers, storage units, networking hardware, virtualization or hypervisor layer, etc. This model negates the legacy business case for investing in on-premise data center infrastructure and equipment. Modern IaaS service providers also offer policy-driven services to clients and customers. These services include monitor service performance, detailed billing of customer services, log access, digital security, load balancing, backup, replication, and recovery, etc.
IaaS represents ‚Äúthe virtual delivery of computing resources in the form of hardware, networking, and storage services. It may also include the delivery of operating systems and virtualization technology to manage the resources. Rather than buying and installing the required resources in their own data center, companies rent these resources as needed,‚Äù according to popular definitions of IaaS.
A raft of business challenges have emerged to face service providers that offer IaaS services to clients and customers. These may include subscriber expectation management, defining support systems that handle different forms of payments from customers, accommodating the need for custom analytics that measures customer profitability and usage, managing the service value chain, and controlling business with multiple partners. Also, service operators must remain agile in terms of experimenting with product prices, product features, the configuration of service packages, and navigating the intricacies of customer licenses. They must also work to actively manage customer expectations and refine the concept of datacentre ‚Äòin-the-sky.‚Äô
The business case for cloud computing technologies and frameworks will continue to burnish its relevance and utility years and decades into the future. The large and incrementally enormous volumes of data generated by modern scientific, commercial, and technological enterprises will require larger data centers powered by innovative technologies. These may form the central planks of local, regional, and national economies in the future. That said, the central role of the cloud may morph into differentiated expressions, marshaled by real-time processing technologies and a deeper engagement with refined versions of civilizational requirements.
Source: Cuelogic Blog
Tech for leaders & developers
69 
69¬†claps
69 
Written by
Global organizations partner with us to leverage our engineering excellence and product thinking to build Cloud Native & Data-Driven applications.
Tech for leaders & developers
Written by
Global organizations partner with us to leverage our engineering excellence and product thinking to build Cloud Native & Data-Driven applications.
Tech for leaders & developers
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@ghaff/the-state-of-platform-as-a-service-2016-ff8f26e534e5?source=search_post---------28,"Sign in
There are currently no responses for this story.
Be the first to respond.
Gordon Haff
Nov 1, 2016¬∑6 min read
If you‚Äôre ignoring PaaS because early offerings didn‚Äôt meet your needs or because you‚Äôre more focused on operations than developers, you should look again. PaaS helps ops efficiently give developers the tools they need while also managing the underlying container infrastructure.
Circulating in drafts beginning in 2009, some variant of the NIST Cloud Computing definition used to be de rigueur in just about every cloud computing presentation. Among other terms, this document defined Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) and, even as technology has morphed and advanced, this is the taxonomy that we still largely accept and adhere to today.
That said, PaaS was never as crisply defined as IaaS and SaaS because ‚Äúplatform‚Äù was never as crisply defined as infrastructure or (end-user) software.
For example, some platforms were specific to a SaaS, such as Salesforce.
Others, specifically the online platforms that were most associated with the PaaS term early on, were tied to particular languages and frameworks. These PaaS archtypes were very opinionated. For example, the original Google App Engine only supported an environment based on a Python variant. Heroku was all about Ruby.
Heroku‚Äôs twelve-factor app manifesto was an additional type of opinion; write your apps this way or they won‚Äôt really be suitable for the platform. These platforms may not have been just for hobbyists, but they were certainly much more suited to developer prototyping and experimentation than production deployments.
At the same time, the platform moniker was used more broadly to cover the integration of a range of middleware, languages, frameworks, tools, and architectural features (such as persistent storage) that a developer might use to create both web-centric and more traditional enterprise applications. Furthermore, a PaaS such as OpenShift remained not only polyglot but also allowed for an increasing range of deployment types both on-premise and in multi-tenant and dedicated online environments. (As well as on developer laptops using the upstream open source OpenShift Origin project.)
However, the various approaches to PaaS did have a common thread. They were bundles of technology largely framed as appealing to developers.
The developer angle was never the whole story though. Back in 2013, my Red Hat colleague Gunnar Hellekson talked with me about some of the operational benefits of a PaaS in government:
One of the greatest benefits of a PaaS is its ability to create a bright line between what‚Äôs ‚Äúoperations‚Äù and what‚Äôs ‚Äúdevelopment.‚Äù In other words, what‚Äôs ‚Äúyours‚Äù and what‚Äôs ‚Äútheirs.‚Äù
Things get complicated and expensive when that line blurs: developers demand tweaks to kernel settings and specialized hardware ‚Äî customizations that fly in the face of standardization and automation efforts. At the same time, ill-defined roles lead operations to create inflexible rules for development platforms that prevent developers from doing their jobs. PaaS decouples these two, and permits each group to do what they‚Äôre good at.
If you‚Äôve outsourced your operations or development, this problem gets even worse because any idiosyncrasies on the ops or the development side create friction when sourcing work to alternate vendors.
A PaaS makes it perfectly clear who‚Äôs responsible for what: Above the PaaS line, developers can do whatever they like in the context of the PaaS platform; it will automatically comply with operations standards. Below the line, operations can implement whatever they like, choose whatever vendors they like, as long as they‚Äôre delivering a functional PaaS environment.
We spend a lot of time talking about why PaaS is great for developers. I think it‚Äôs even better for procurement, architecture, and budget.
Today, with the rise of DevOps on one hand and containers on the other, it‚Äôs increasingly clear that a PaaS can be the sum of parts that are of direct interest mostly to developers plus parts that are of direct interest mostly to operations.
In the context of PaaS, DevOps both leads to change and reflects change in a couple of major areas.
First is the number of tools that organizations are bringing into their DevOps (or DevSecOps if you prefer) software delivery workflow. Most obvious is the continuous integration/continuous delivery pipeline, most notably with Jenkins. But there are also any number of testing, source code control, collaboration, and monitoring tools that need to be integrated into the workflow. At the same time, developers still want their self-service provisioning with an overall user experience that‚Äôs tailored to how they work. A PaaS is an obvious integration and aggregation point for all this tooling.
DevOps is also changing the way in which developers and operations work with each other. Early DevOps discussions often focused on breaking down the wall between Dev and Ops. But this isn‚Äôt quite right. DevOps does indeed embody cultural elements such as collaboration and cooperation across teams ‚Äî including dev and ops. But we should also recognize that the best form of communication is sometimes eliminating the need to communicate at all.
To the degree that ops can build a self-service platform for developers and get out of the way, that can be more effective than steamlining dev and ops interactions. I don‚Äôt want to communicate more effectively with a bank teller; I want to use an ATM (or skip cash entirely).
Containers have also influenced how some organizations are thinking about PaaS. Many PaaS solutions (including OpenShift) have been based on containers from the beginning. But each platform did its own implementation of containers; in OpenShift it was Gears, in Heroku it was Dynos, in CloudFoundry it was Warden (now Garden) containers.
As the industry moved to a container standard (Docker-format with standardization through the Open Container Initiative (OCI)), OpenShift moved with it. Red Hat has helped drive that movement along with many others though not all PaaS platforms have participated in the shift to standards.
With container formats, runtimes, and orchestration increasingly standardized through the OCI and Cloud Native Computing Foundation (where kubernetes is hosted), there‚Äôs increasing interest from many ops teams in deploying a tested and integrated bundle of these technologies outside of any specific development environment initiatives within their companies.
That‚Äôs because the huge amount of technological innovation happening around containers and DevOps can be something of a double-edged sword. On the one hand it creates enormous possibilities for new types of applications running on a very dynamic and flexible platform. At the same time, channeling and packaging rapid change happening across a plethora of open source projects isn‚Äôt easy . Expending a lot of effort on customized infrastructure can also end up being a distraction from the ultimate business goals.
As a result, at Red Hat, we often talk to customers who view OpenShift primarily through the lens of a container management platform rather than the more traditional developer-centric PaaS view. There‚Äôs still a developer angle of course ‚Äî a platform isn‚Äôt much use unless you‚Äôre going to run applications on it. But sometimes there are already developer tooling and workflows in place. In this case, the pressing need is to deploy a container platform using Docker-format containers and kubernetes orchestration. Without having to assemble them from upstream community bits and support them in-house.
An integrated platform leads to real savings. For example, based on a set of interviews, IDC found that:
IT organizations that want to decouple application dependencies from the underlying infrastructure are adopting container technology as a way to migrate and deploy applications across multiple cloud environments and datacenter footprints. OpenShift provides a consistent application development and deployment platform, regardless of the underlying infrastructure, and provides operations teams with a scalable, secure, and enterprise-grade application platform and unified container and cloud management capabilities.
Among its quantitative findings was 35 percent less IT staff time required per application deployed.
In short, PaaS remains a central part of the cloud computing discussion even if the name is sometimes discarded for something more specific or descriptive such as container platform. What‚Äôs perhaps changed the most is the recognition that PaaS isn‚Äôt just a tool for developers. It‚Äôs also a way for ops to enable developers most efficiently and to manage the underlying container infrastructure.
Originally published at bitmason.blogspot.com on November 1, 2016.
Red Hat cloud guy, photographer, traveler, writer. Opinions are mine alone.
8 
8¬†
8 
Red Hat cloud guy, photographer, traveler, writer. Opinions are mine alone.
"
https://medium.com/@gabrtv/devops-and-the-future-of-paas-2e8bb5650709?source=search_post---------29,"Sign in
There are currently no responses for this story.
Be the first to respond.
Gabriel Monroy
Oct 25, 2013¬∑5 min read
These are exciting times in web and mobile development. Innovations in deployment automation and infrastructure orchestration are coming hard and fast with no sign of slowing. You might say there‚Äôs never been a better time to be a developer.
Those of us focused on making developers‚Äô lives easier have gravitated toward the ‚ÄúPlatform as a Service‚Äù model. It turns out you can keep developers happy and productive by providing them an application platform (PaaS) that neatly decouples their applications from the operating system.
Today, most automation-minded organizations are still investing in and succeeding with server-based application deployment. However, now that LXChas begun to demonstrate security and efficiency gains reminiscent of modern virtualization, the era of Open PaaS is here.
Heroku and Google App Engine have proven that application platforms based on Linux Containers can scale. Now the race is on to create open source alternatives that provide this application platform capability inside the enterprise.
The ‚ÄúNoOps‚Äù movement presumes operations teams will be made obsolete by highly automated application platforms. Hosted PaaS solutions nearly eliminate the need for DevOps skill-sets, lending credence to NoOps. However, the reality is today‚Äôs public application platforms can be shockingly expensive for even moderate workloads. Worse yet, the very abstractions they promote are often exactly what frustrate sophisticated teams.
These frustrations eventually lead to a search for a ‚Äúprivate Heroku‚Äù or ‚Äúprivate App Engine‚Äù that offers the same benefits for developers, but without the loss of operational control.
Unfortunately, the Open PaaS solutions available today (Cloud Foundry and OpenShift) introduce wholly new paradigms and components that, while ostensibly open source, are in practice difficult to install, operate and customize. This presents an opportunity for an open source application platform that can bridge the gap between the DevOps tool chains trusted by today‚Äôs sophisticated ops team and our containerized future. Deis is that platform.
Deis combines Docker‚Äôs Linux container engine with Chef‚Äôs trusted infrastructure automation, creating an open source application platform that runs on public cloud, private cloud and bare metal. By building upon Chef, which is widely deployed and proven to work at scale, Deis provides a ‚Äúprivate Heroku‚Äù experience that delights both developers and operations engineers.
Having been involved with the Docker community since their inception, we‚Äôve had a front-row seat to their meteoric rise and have great respect for the team and technology. Docker is one of those rare innovations that seem so obvious in retrospect. Portable application containers based on LXC, file system de-duplication and tooling to automate building, distributing and executing containers. Obviously! The trick is in making these ‚Äústandard containers‚Äù ubiquitous.
While the full promise of Docker has yet to be realized, the team‚Äôs ability to capture open source momentum toward Linux containers is impressive. The project is approaching 200 external contributors, featuring some large contributions including how Docker interacts with host volumes and Docker‚Äôs file system layering technology. This ability to harness open source momentum is what makes us believe Docker will succeed in its mission to standardize application containers across the modern datacenter. As a leading Docker PaaS, Deis will continue to play a role in this effort.
Prior to Deis, the OpDemand team wrote a lot of Puppet. We watched as the industry began moving toward Chef, with RightScale and AWS OpsWorks demonstrating support. Chef was quick to develop a thriving DevOps community that produced hundreds of high quality cookbooks and a first-class tool chain (knife, berkshelf). We decided to try it.
It wasn‚Äôt until we built Deis that we fully appreciated the flexibility of Chef‚Äôs Ruby DSL, the determinism of explicitly ordered resources (in contrast with Puppet‚Äôs frustratingly indirect RAL) and the reliability of Chef Data Bags as a global store for PaaS configuration. Without a Chef Server, Deis becomes significantly more complicated and brittle.
If someone can demonstrate a faster, more reliable, and more flexible approach to configuration management than Chef Server, the Deis project is open to it. Deis sports a pluggable configuration management interface, and we will gladly accept a well-designed pull request. For now, Deis is happy to be part of the healthy Chef ecosystem.
When looking for inspiration in the world of PaaS, you can‚Äôt ignore Heroku. The command line workflow they‚Äôve pioneered is second to none. By treating the developer community as artists, they‚Äôve managed to build a loyal following ‚Äî one we got to see up close at their Waza conference earlier this year. If your goal is to delight developers, emulating Heroku is a great place to start.
While Deis was designed with Heroku‚Äôs Twelve Factor methodology and command line workflow in mind, Heroku has very little to say about the guts of the application platform and runtime. This is where Deis and Heroku diverge. Deis introduces the concepts of Formations, Layers, and Nodes to help operations teams deploy a private application fabric built to their own specifications using Chef and Docker.
Although we disagree with their NoOps stance, Deis will continue to take inspiration from Heroku as we strive to become the best Open PaaS on the market.
Deis has only been available for two months. The open source community‚Äôs reaction has been exciting and humbling. We have a lot of work to do on the installation process, backing services, system hardening, access controls, load testing and more before we can make our claim as the enterprise-grade ‚Äúprivate Heroku‚Äù ‚Äî but we‚Äôre damn close. With the help and support of the open source community, we expect to announce our 1.0 release in a few months. Until then, expect a steady stream of releases featuring bug fixes, new cloud providers, enhanced Docker integration and much more.
If you‚Äôre interested in learning more about Deis or contributing to the project, come find us in IRC (#deis on Freenode) and check out the project on GitHub.
Creator of the Deis project. CTO at OpDemand. Thinks in system calls.
11 
11¬†
11 
Creator of the Deis project. CTO at OpDemand. Thinks in system calls.
"
https://medium.com/@mustwin/building-cisco-s-ioe-paas-with-mantl-94ba2ab9b204?source=search_post---------30,"Sign in
There are currently no responses for this story.
Be the first to respond.
Lovable Technology
Sep 18, 2015¬∑6 min read
Note: This is a cross post from Cisco‚Äôs cloud blog.
We blogged about the alpha launch of Shipped back in June, but today I want to talk about the service it relies on: Mantl.
Mantl‚Äôs goal is to provide a fully functional, instrumented, and portable container based PaaS for your business at the push of a button. It‚Äôs a opinionated set of services, configurations and tools that provide a standard interface for you to operate your container-based applications and infrastructure. Typically companies write a lot of unnecessarily repeated, similar-looking glue code to deploy, inspect and manage their services and the infrastructure they run on. This code is difficult to effectively version control and is seldom the same between teams. Mantl is an attempt to turn these glued together pieces into an easy to use complete solution for managing your services.
You may find Mantl useful if:
You can adopt as much or as little of it as you‚Äôd like, but before we get into those decisions, let‚Äôs look at what it provides out of the box.
Mantl is a collection of tools from a lot of great service providers, the big ones are below.
Terraform, by HashiCorp, provides an abstraction layer that allows you to provision compute resources on a large number of providers. It bootstraps the raw infrastructure that will run Mesos and all the corresponding services on top of it.
Mesos manages resources in your cluster and handles scheduling and isolating your tasks. It allows you to bin-pack your servers, efficiently running multiple tasks on each node. It‚Äôs the key to making all of this work. Mesos relies on Zookeeper for high availability, so you‚Äôll also get that for free.
Kubernetes solves similar problems as Mesos and support is planned in the near future.
Consul, another Hashicorp product, handles service discovery. It makes it easy to coordinate cluster membership and also does some other handy things like arbitrary key value storage for configuration management, etc. A lot of the coordination in Mantl uses Consul to make the magic happen.
Mantl uses the ‚ÄúELK‚Äù stack to handle logging and indexing.
This handles indexing logs and metrics from each host and each container. It‚Äôs how you‚Äôll monitor the performance of your services.
This little daemon runs on each node and basically pipes logs into elastic search for later consumption/analysis.
Kibana is basically a visualization layer for elastic search. If you annotate your logs nicely, Kibana will make pretty graphs for you (yay!).
A highly available consistent message bus. Mantl uses it for metrics monitoring data and will eventually utilize it as an event bus interested parties can subscribe to.
These are daemons that run on each node and collect information from the host or your containers so you can monitor your cluster in a standard way.
This slurps up metrics from Kafka and writes them to Influx.
Our time series database of choice. It let‚Äôs us slice and dice our data however we want.
A beautiful UI on top of Influx.
Mesos has built-in support for Docker, a very popular portable container implementation. It‚Äôs typical to build your application into a deployable docker container.
Marathon manages long running tasks, like your applications. It‚Äôs the typical deploy target for consumers of Mantl. If your servers or containers die, marathon takes care of rescheduling them so your services are always available.
Marathon allows you to scale the number of containers running your application, but once you‚Äôve done so, you have a new problem: routing traffic between instances of your application. Mantl manages this for HTTP(S) traffic by keeping the Traefik configuration up to date for each service running in Marathon.
These are the data-bridges that keep Consul up to date. Whenever Mesos or marathon runs a new task, these lets Consul know about it so the DNS entries are always current.
Handles virtual network isolation, which is useful for multi-tenant environments or maintaining strict isolation for security and compliance reasons.
Most systems have secrets, Mantl provides Vault out of the box to set you up to handle your secrets and personally identifiable information in a safe way.
Shipped is purpose built to make deploying docker applications super easy, so Mantl was built alongside it to make hosting these applications easy.
Shipped actually runs itself alongside other tenant applications on Mesos workers. Shipped allows developers to build their application into a docker image. Once you have a containerized app, you can deploy with the push of a button. Behind the scenes, this goes something like this:
Shipped wraps all this up for you in a tidy management interface:
Cisco has prepared pretty solid getting started docs in the Mantl repository. You can provision a cluster on OpenStack, Google Compute Engine, Amazon Web Services, DigitalOcean, VMware vSphere or SoftLayer without too much trouble. After that, getting to know the tools and how they all fit together is still left as a bit of an exercise to the user. I‚Äôve done my best to link to the components above, and the docs on the repo are constantly improving. The repo has been starred 1500 times, so get involved!
Updates: Just keeping the features up to date.05/23/16 ‚Äî Remove HAproxy in favor of Traefik. Add Kafka/Influx/Grafana
Looking for help managing your highly available micro-services?Reach out to Must Win!
Mike Ihbe is a founding partner of The Must Win All Star Web & Mobile Consultancy.
Mike is an expert in a dizzying array of technologies and has loads of experience managing fast-moving dev teams, designing systems, and scaling large applications. When not on the job, he can be found cooking delicious meals on ski slopes in exotic locales.
World Class Engineers and Designers Helping You Ship Lovable Web and Mobile Technology.
See all (634)
7 
Thanks to Gonzalo Maldonado and Ken Owens.¬†
7¬†claps
7 
World Class Engineers and Designers Helping You Ship Lovable Web and Mobile Technology.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@shijuvar/cloud-paas-vs-open-source-stack-in-containers-57b4e83112a2?source=search_post---------31,"Sign in
There are currently no responses for this story.
Be the first to respond.
Shiju Varghese
Jun 29, 2015¬∑3 min read
Cloud has changed the way we build and run applications. Cloud is not just a platform for hosting and running your application, but it also provides development platform as a service, which is integrated with IT infrastructure so you don‚Äôt have to worry about managing infrastructure while using these services provided by Cloud platforms. Cloud platforms provide managed services for NoSQL databases, Workflow services, Middleware messaging systems and many more.
In Cloud platforms, everything, from storage to NoSQL databases, from Pub/Sub services to massively scalable event ingestor services, available as a manged services in the flavor of PaaS. This provides lot of agility to developer communities and to IT infrastructure teams. Cloud platforms provides PaaS services as the counterpart services against the popular open-source technologies. For an example, instead of running MongoDB database on IaaS VMs, you can leverage DynamoDB on AWS, DocumentDB on Azure and Cloud Bigtable on Google Cloud. Instead of running RabbitMQ on IaaS VMs, you can leverage SNS Topic on AWS and Service Bus Topic on Azure. Instead of running Kafka clusters on IaaS VMs, you can leverage Kinesis on AWS and EventHub on Azure. When compared to running systems on Infrastructure as a Service (IaaS), Platform as a Service (PaaS) provides great operational agility when you develop applications on the Cloud. So Cloud PaaS indeed a great option when it comes to managing infrastructure. Then the next big question would be ‚ÄúIs these Cloud PaaS offerings are better than its counterpart open-source stack when it comes to technology excellence.‚Äù Is DynamoDB better than MongoDB.? Is DocumentDB better than MongoDB.? Is Kinesis better than Kafka?. Kafka is a battle-tested technology at LinkedIn and in many larger big data solutions. Can Kinesis offer similar kind of success track as a technology and for success stories in enterprises. IMHO, in many cases, open-source technologies perform better than its counterpart PaaS services provided by various Cloud platforms. But running open-source stack in IaaS VMs may leads to lot of complexities for managing infrastructure.
Open-source technologies are maintained by passionate technologists and it is getting continuous contributions from highly talented developers. Open-source technologies are getting continuous updates based on the real-world problems of developer communities. Who are maintaining the proprietary technologies of Cloud platforms.? Few salaried employees of Cloud vendors, who might be lacking passion comparing to developers working on open-source technologies. Nowadays many great technologies are coming from open-source world as a solution for real-world problems.
PaaS and IaaS services have pros and cons and it was never a perfect solution when you build larger applications. PaaS offer better agility while IaaS offer greater level of freedom to run anything on Cloud. We definitely need a more pragmatic solution for getting operational agility and technology excellence. In this context, I would like to propose a solution ‚Äî running open-source technology stack on containers. On the container ecosystem, we have great technologies such as Docker and Kubernetes. You can build your applications by composing Microservices running on Docker containers where you can leverage open-source technologies for powering your Microservices. Kubernetes, a container cluster manager can be used for scale out your containers without much management efforts. Containerized apps are easy to mange, test and run where you can use Kubernetes for clustering your containers. Google Cloud provides Kubernetes as a Service through their Managed VM service for running containers, which is a best of both PaaS and IaaS. IMHO, Cloud platforms don‚Äôt have to provide everything as a service, but they can provide a great platform for running and scaling containerized apps on the Cloud where they can offer best of both PaaS and IaaS. This will enables us to get greater level of operational agility while getting an opportunity and freedom to run proven open-source technologies on the Cloud. One of the great advantages of developing containerized apps with open-source technologies, is that you can easily run your containers in on-premises environment. This will also enables you to change one Cloud platform to another without any vendor-lock as your containers are leveraging open-source technologies instead of platform specific technologies.
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
7 
7¬†
7 
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
"
https://medium.com/@voluntas/%E3%81%AA%E3%81%9C-webrtc-sfu-paas-%E3%82%92%E3%82%84%E3%82%89%E3%81%AA%E3%81%84%E3%81%AE%E3%81%8B-312457c016dc?source=search_post---------32,"Sign in
There are currently no responses for this story.
Be the first to respond.
V
Apr 20, 2018¬∑3 min read
„Åü„Åæ„Å´ËÅû„Åã„Çå„Çã„Åì„Å®„Åå„ÅÇ„Çã„ÅÆ„Åß„Åæ„Å®„ÇÅ„Å¶„Åä„Åç„Åü„ÅÑ„ÄÇÂãòÈÅï„ÅÑ„Åó„Å¶„Åª„Åó„Åè„Å™„ÅÑ„ÅÆ„ÅØ WebRTC SFU PaaS „ÅØ„ÇÑ„Çä„Åü„ÅÑ„ÄÅ„Åü„Å†Ëá™Á§æ„ÅßÊèê‰æõ„Åô„Çã„Éá„É°„É™„ÉÉ„Éà„Åå‰ªä„ÅÆÊÆµÈöé„Åß„ÅØÂ§ö„Åô„Åé„Çã„ÅÆ„Åß„ÇÑ„Çã„Å®„ÅÑ„ÅÜÈÅ∏ÊäûËÇ¢„ÇíÁµåÂñ∂ËÄÖ„Å®„Åó„Å¶Âèñ„Çå„Å™„ÅÑ„ÄÇ
Â£≤„Çä‰∏ä„Åí„ÇãÊñπÊ≥ï„ÅåÂæìÈáèË™≤ÈáëÂà∂„Åó„Åã„Å™„Åè„ÄÅÊ≠£Á§æÂì°„ÅåÁâáÊâã„ÅßË∂≥„Çä„Å¶„Åó„Åæ„ÅÜ„Çà„ÅÜ„Å™Â∞è„Åï„Å™‰ºöÁ§æ„Åß„ÅØÈªíÂ≠ó„Å´Ëª¢Êèõ„Åß„Åç„Çã„Å®„ÅØÊÄù„Åà„Å™„ÅÑ„Åã„Çâ„ÄÇ
Ë©≥Á¥∞„ÇíÊõ∏„ÅÑ„Å¶„ÅÑ„Åè„ÄÇ
Ëá™Á§æ„ÅÆ WebRTC SFU „ÅØ„Éï„É´„Çπ„ÇØ„É©„ÉÉ„ÉÅ„ÅßÊõ∏„Åã„Çå„Å¶„Åä„Çä„ÄÅ„Åù„Çå„Çí„Éë„ÉÉ„Ç±„Éº„Ç∏Ë≤©Â£≤„Åó„Å¶„ÅÑ„Çã„ÄÇ‰ªäÊµÅË°å„Çä„ÅÆPaaS „Çí„Å™„Åú„ÇÑ„Çâ„Å™„ÅÑ„ÅÆ„ÅãÔºü„Å®ÊÄù„ÅÜ‰∫∫„ÅåÂ§ö„ÅÑ„Çà„ÅÜ„Å†„Åå„ÄÅÊ≠£Áõ¥Ëá™ÂàÜ„ÅåËÄÉ„Åà„ÇãÈôê„ÇäÁõ∏ÂΩì„Éá„É°„É™„ÉÉ„Éà„ÅåÂ§ö„ÅÑ„ÄÇ
„Åæ„ÅöÂøò„Çå„Å¶„ÅØ„ÅÑ„Åë„Å™„ÅÑ„ÅÆ„ÅØ„Éû„Éç„Éº„Ç∏„Éâ„Å™ WebRTC SFU „ÇíÊèê‰æõ„Åô„Çã„Å®„ÅÑ„ÅÜ‰æ°ÂÄ§„Åó„ÅãÁÑ°„ÅÑ„Åì„Å®„Å†„ÄÇ„Åù„Çå‰ª•Â§ñ„ÅØ„Å™„ÅÑ„ÄÇ
ÁÑ°ÊñôÊèê‰æõ„ÅØ„ÅÇ„Çä„Åà„Å™„ÅÑ„ÅÆ„Åß„ÄÅÊúâÊñôÊèê‰æõ„Å´„Å™„Çã„Å®„Åï„Åô„Åå„Å´ 24/365 „Åß„ÅÆÂØæÂøú„ÅåÂøÖË¶Å„Å´„Å™„Çã„ÄÇ„Åì„Çå„ÅØÂ£≤‰∏ä„Åå„ÅÇ„Åå„Å£„Åü„Å®„Åó„Å¶„ÇÇ‰ºöÁ§æ„Å®„Åó„Å¶ 24/365 ÂØæÂøú„ÅåÂøÖË¶Å„Å´„Å™„Çã„ÅÆ„Åß„ÄÅÂé≥„Åó„ÅÑ„ÄÇÁâπ„Å´Â∞è„Åï„Å™‰ºöÁ§æ„Å®„Åó„Å¶„ÅØÂúßÂÄíÁöÑ„Å´Âé≥„Åó„ÅÑ„ÄÇ
WebRTC SFU PaaS „ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Çã„Åô„Åπ„Å¶„ÅÆ‰ºöÁ§æ„ÅåÂæìÈáèË™≤ÈáëÂà∂„Åß„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Çã„ÄÇ„Åì„Çå„ÅØÁêÜÁî±„ÅØÂçòÁ¥î„Åß„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØËª¢ÈÄÅÈáè„Å´Ë≤ªÁî®„Åå„Åã„Åã„Çã„Åã„Çâ„ÄÇÁâπ„Å´ÂÆâÂÆö„Åó„Åü„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅßÊèê‰æõ„Åô„Çã„Å®„Å™„Çã„Å®ÂøÖÈ†à„Å´„Å™„Çã„ÄÇ
„Åì„ÅÆÊñπÂºè„ÇíÂèñ„Çä„Åü„Åè„Å™„ÅÑ„ÄÇÊ≤¢Â±±Âà©Áî®„Åó„Å¶„ÇÇ„Çâ„ÅÜ„Åì„Å®„ÅßÂÑ≤„Åë„Çã„Å®„ÅÑ„ÅÜ„ÅÆ„ÅåËá™ÂàÜ„Å´„ÅØÂêà„Çè„Å™„ÅÑ„ÄÇÂÆöÈ°ç„ÅßË≤∑„Å£„Å¶„ÇÇ„Çâ„Å£„Å¶„ÄÅ„Åù„Çå„ÅßÁµÇ„Çè„Çä„Å´„Åó„Åü„ÅÑ„ÄÇÂæìÈáèË™≤ÈáëÂà∂„Å†„Å®‰Ωø„ÅÜ„ÅÆ„Å´„Éâ„Ç≠„Éâ„Ç≠„Åô„Çã„ÄÅÂçòÁ¥î„Å´Ëá™ÂàÜ„ÅåËã¶Êâã„Å†„ÄÇ
„Çµ„Éº„Éê„ÅÆ„Ç¢„ÉÉ„Éó„Éá„Éº„Éà„ÄÅ„ÇØ„É©„Ç¶„Éâ„ÅÆË®àÁîªÂÅúÊ≠¢„ÄÅ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Ç¢„ÉÉ„Éó„Éá„Éº„Éà„ÄÅÁõ£Ë¶ñ„ÄÅ„É≠„Ç∞‰øùÂ≠ò„ÄÅ„ÇÑ„Çã„Åì„Å®„ÅØÊ≤¢Â±±„ÅÇ„Çã„ÄÇ
„Åü„Å†„ÄÅÂâçËø∞„Åó„Åü„Å®„Åä„ÇäÂæìÈáèË™≤Èáë„Åß„Åó„ÅãÁ®º„Åí„Å™„ÅÑ„ÅÆ„ÅßÊ≤¢Â±±‰Ωø„Å£„Å¶„ÇÇ„Çâ„ÅÜÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ„Åü„Åè„Åï„Çì‰Ωø„Å£„Å¶„ÇÇ„Çâ„ÅÜ„Åü„ÇÅ„Å´„ÅØ„ÅÇ„ÇãÁ®ãÂ∫¶„Çµ„Éº„Éê„ÇíÁî®ÊÑè„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ„Åì„ÅÆËæ∫„Çä„ÅØËá™ÂãïÂåñ„Åß„Åç„Çã„Å†„Çç„ÅÜ„Åå„ÄÅËá™ÂãïÂåñ„Çí„Åô„Çã„Ç≥„Çπ„Éà„ÇÇ„ÄÅ„Åù„Çå„ÇíÁ∂≠ÊåÅ„Åô„Çã„Ç≥„Çπ„Éà„ÇÇÁÑ°Ë¶ñ„ÅØ„Åß„Åç„Å™„ÅÑ„ÄÇ
„Å©„ÅÜ„Åó„Çà„ÅÜ„ÇÇ„Å™„ÅÑ„ÄÇ„ÇÑ„Çã„Å™„Çâ„Éû„É´„ÉÅ„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„ÅßÂõûÈÅø„Åô„ÇãÁ®ãÂ∫¶„Åã„ÄÇ„Åù„ÅÜ„Å™„Çã„Å®„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„Ç≥„Çπ„Éà„Åå„Åæ„Åô„Åæ„ÅôÁÑ°Ë¶ñ„Åß„Åç„Å™„Åè„Å™„Çã„ÄÇ
ÂÆü„ÅØ„Åì„Çå„ÇÇ„Åã„Å™„Çä„ÅÇ„Çã„ÄÇ„Éë„ÉÉ„Ç±„Éº„Ç∏Ë£ΩÂìÅ„Å†„Å®„ÅÇ„ÇãÁ®ãÂ∫¶ÊäÄË°ì„Çπ„Ç≠„É´„Åå„Å™„ÅÑ„Å®Êâ±„ÅÜ„ÅÆ„ÅØÈõ£„Åó„ÅÑ„ÄÇ„Å™„Åú„Å™„Çâ‰ªä„Åæ„ÅßÊõ∏„ÅÑ„Åü„Åì„Å®„ÇíËá™Ââç„ÅßÂÆüÁèæ„Åô„ÇãÊäÄË°ì„ÅåÂøÖË¶Å„Å´„Å™„Çã„Åã„Çâ„Å†„ÄÇ
„Åì„Çå„ÅØÂ∞è„Åï„Å™‰ºöÁ§æ„Å®„Åó„Å¶„ÅØÂ§ßÂ§âÈáçË¶Å„Å´„Å™„Çã„ÄÇ„Çµ„Éù„Éº„Éà„Å´ÈÅø„Åë„Çã„É™„ÇΩ„Éº„Çπ„ÅØÈôê„Çâ„Çå„Å¶„ÅÑ„Çã„Åü„ÇÅ„Å†„ÄÇ„Å®„ÅØ„ÅÑ„Åà„Çµ„Éù„Éº„Éà„ÅØÊúÄÂÑ™ÂÖà‰∫ãÈ†Ö„ÅßËá™Á§æ„ÅÆÈ°ßÂÆ¢„ÅØ„Åª„Å®„Çì„Å©„Åå„Çµ„Éù„Éº„ÉàÁõÆÁöÑ„ÅßË≥ºÂÖ•„Åó„Å¶„Åè„Çå„Çã„ÄÇ
„Åù„ÅÆ„Åü„ÇÅÈ°ßÂÆ¢„Å´„ÅØÊúÄÈ´ò„ÅÆ„Çµ„Éù„Éº„ÉàÊèê‰æõ„Åó„Åü„ÅÑ„Å®ËÄÉ„Åà„Å¶„ÅÑ„Çã„ÄÇ„Åù„ÅÆ„Åü„ÇÅ„Å´„ÅØÂ∞ë„Å™„ÅÑ„É™„ÇΩ„Éº„Çπ„Åß„ÅØ„ÅÇ„ÇãÁ®ãÂ∫¶ÊäÄË°ì„Çπ„Ç≠„É´„Åå„ÅÇ„Çã‰∫ã„ÇíÂâçÊèê„Åô„Çã„ÅÆ„Åå‰∏ÄÁï™ÂäπÁéá„ÅåËâØ„ÅÑ„ÄÇ
„Å®„Å´„Åã„ÅèÂ§ö„Åè„ÅÆ‰∫∫„Å´Ëá™Á§æ„ÅÆ WebRTC SFU „ÅÆ‰æøÂà©„Åï„ÇíÁü•„Å£„Å¶„ÇÇ„Çâ„ÅÑ‰Ωø„Å£„Å¶„Åª„Åó„ÅÑ„Åã„Çâ„ÄÇ„Åù„Åó„Å¶Ê∞óËªΩ„Å´„Çµ„Éº„Éì„Çπ„Å´Âà©Áî®„Åó„Å¶„Åª„Åó„ÅÑ„Å®ËÄÉ„Åà„Å¶„ÅÑ„Çã„Åã„Çâ„Å†„ÄÇ
„Åü„Å†„ÄÅ„Åù„ÅÆ„Åü„ÇÅ„Å´„ÅØÂ§ö„Åè„ÅÆ„É™„ÇΩ„Éº„Çπ„ÅåÂøÖË¶Å„Å´„Å™„Çã„ÄÇ‰ªä„ÅÆËá™Á§æ„ÅÆË¶èÊ®°„Åß„ÅØ„Åù„Çå„ÇíÂÆüÁèæ„Åô„Çã„ÅÆ„ÅØÈõ£„Åó„ÅÑ„ÄÇ„Åù„ÅÆ„Åü„ÇÅËá™Á§æ„ÅßÊèê‰æõ„Åô„Çã„ÅÆ„ÅØÁÑ°ÂÑü„Åß„Å°„Çá„Å£„Å®„Å†„Åë‰Ωø„Åà„Çã„Çµ„Éº„Éì„Çπ„Å´„Å®„Å©„Åæ„Å£„Å¶„ÅÑ„Çã„ÄÇ
„ÇÇ„Åó„Å©„Åì„Åã„ÅÆ‰ºöÁ§æ„ÅåËá™Á§æË£ΩÂìÅ„Çí‰Ωø„Å£„Å¶ PaaS „Çí„ÇÑ„Çä„Åü„ÅÑ„ÅÆ„Å™„ÇâÂçîÂäõ„Åó„Åü„ÅÑ„ÄÇ‰ªä„Åæ„Åß‰ΩïÁ§æ„Åã„ÅåÂ£∞„Çí„Åã„Åë„Å¶„Åç„Å¶„Åè„Çå„Åü„Åå„ÄÅ„Å©„ÅÆË©±„ÇÇÁ´ã„Å°Ê∂à„Åà„Å´„Å™„Å£„Å¶„Åó„Åæ„Å£„Åü„ÄÇÊÆãÂøµ„Å†„ÄÇ
Erlang/OTP / ÊôÇÈõ®Â†Ç / WebRTC / E2EE
14 
14¬†
14 
Erlang/OTP / ÊôÇÈõ®Â†Ç / WebRTC / E2EE
"
https://medium.com/geekculture/what-is-iaas-paas-aas-7ec315b55d93?source=search_post---------33,"There are currently no responses for this story.
Be the first to respond.
You‚Äôve probably heard of the various *aaS acronyms. IaaS, SaaS, etc. What exactly do they mean? Why are there so many?
To understand them, let‚Äôs go over the essential components that make up the core of software that runs on the Internet.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://precipitation.io/ops-devops-and-paas-2012-revisited-70bc80de9ec0?source=search_post---------34,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
In 2012, Adrian Cockroft, then at Netflix, wrote a post called Ops, DevOps and PaaS (NoOps) at Netflix, laying out how operations at Netflix worked, in response to some heated debate on Twitter about the term NoOps.
It took Adrian a year to publish his post on NoOps, and by the time it came out it sparked another round of debate, with John Allspaw at Etsy responding with this excellent gist. Which Adrian responded with ‚ÄúYour definition of DevOps seems far broader than the descriptions and definitions I can find by googling or looking on Wikipedia.‚Äù
After a year or more of debate on Twitter, the disagreement on terminology came down to differing definitions of DevOps and Twitter being an awful format for nuanced discussion. These days Adrian will tell you that what he then defined as NoOps, is just a variant of DevOps.
DevOps is such a broad term that multiple operational models seem to fall under it. The application of a DevOps approach to managing an IT platform will depend on the technology in place. The type of DevOps used in a cloud mature Netflix world would be very different to the type of DevOps used in a bank with strict compliance regimes making their first steps into cloud. In both instances you might create small self-organising multi-functional teams, that are held accountable for running the systems they are responsible for, utilising automation and abstraction. The difference is how far down or up the stack do their operational tasks start.
Netflix adopts a more developer focused approach to DevOps with developers taking on operational duties (config management, monitoring, on call rotation, etc) as part of their role. More common in most organisations it is the ‚Äúlegacy‚Äù operations teams that shift to a DevOps approach first, with sysadmins learning to script, CI/CD tooling for infrastructure deployments with automated rollback using infrastructure testing frameworks. Either way when moving to a DevOps world the need to cross skill and create multifunctional teams is clear, regardless of the background the individuals in the team come from.
The best definition, for me, of operations is in Charity Majors‚Äôs epic blog post, WTF is Operations.
a thing that every single person in an org understands as being critical to success ‚Äî Charity Majors
One of the key takeaways from Charity‚Äôs post is that operations is not the responsibility of a team labelled ‚Äúoperations‚Äù. Operations is vital to the success of the organisation, and is the individual and collective responsibility of everyone in that organisation.
As we move to Serverless and Cloud Native architectures the debate on what the operational models look like for these platforms has already been had way back in 2012. We just need to keep having it every few years to remind ourselves.
When playing with clouds, expect to get wet‚Ä¶
5 
5¬†claps
5 
Written by
Figuring it out‚Ä¶
When playing with clouds, expect to get wet‚Ä¶
Written by
Figuring it out‚Ä¶
When playing with clouds, expect to get wet‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@lopezlucas/introducci%C3%B3n-a-cloud-saas-iaas-paas-772c92c29bb1?source=search_post---------35,"Sign in
There are currently no responses for this story.
Be the first to respond.
Lucas Lopez
May 8, 2018¬∑5 min read
Hace un tiempo entramos en una √©poca donde los servicios cloud y las plataformas digitales construidas en ellos dominan casi todos los aspectos de la vida empresaria, clientes, consumidores y personas por igual. La idea de este articulo es ofrecer una corta introducci√≥n sobre algunos de los modelos m√°s importantes de los servicios cloud.
Aunque actualmente las oferta de servicios cloud ya no tiene los limites tan estrictamente definidos como antes, seguimos hablando de tres modelos principales.
Uno de los primeros modelos cloud del mercado que tuvo un √©xito rotundo fue el modelo de software como servicio. Compa√±√≠as empezaron a ofrecer servicios basados en Internet, en la nube, donde los clientes y los usuarios no ten√≠an que preocuparse de ning√∫n aspecto relacionado con donde se ejecutaba la soluci√≥n.
Todo comenz√≥ en el momento que parec√≠a menos probable, cuanto la burbuja de Internet estaba reventando. Un claro ejemplo de esto es SalesForce.com. Fundada en 1999, sale a cotizar en bolsa en 2004, juntando 110 Millones de d√≥lares. Hoy tiene una capitalizaci√≥n de mercado de m√°s de 90 mil millones de d√≥lares, siendo una de las empresas m√°s valiosas de este modelo.
Muchas m√°s la siguieron y hoy la oferta es casi ilimitada. Este modelo aceler√≥ la adopci√≥n de herramientas de IT, permitiendo que no solos los departamentos de sistemas tuvieran el control sobre estas herramientas.
Este modelo tiene dos ventajas fundamentales:
Pero estos aspectos tienen un lado negativo:
En muchos aspectos, la contra-cara de software como servicio es la infraestructura como servicio. Por? Imaginemos que somos una empresa que ofrece software como servicio. Donde vamos a ejecutar nuestra aplicaci√≥n que usan much√≠simos clientes y usuarios? Obviamente podemos ofrecer nuestro servicio desde nuestro propio datacenter pero si hacemos eso, realmente estamos cumpliendo el manifiesto cloud?
Obviamente muchas empresas, de las m√°s grandes, siguen ese modelo pero la revoluci√≥n del software como servicio est√° soportada por el modelo de Infraestructura como Servicio. En vez de ofrecer la soluci√≥n desde un datacenter propio es m√°s f√°cil usar un proveedor de infraestructura en la nube, que gestiona todos los aspectos relacionados con el hardware, energ√≠a y conectividad, permitiendo a los clientes poner foco en sus negocios. Adem√°s se reduce la inversi√≥n necesaria para comenzar a operar.
Este modelo tambi√©n tiene ventajas y desventajas:
Pero estos aspectos impactan en:
El modelo de plataforma como servicio nace de dos necesidades distintas, la de las empresas digitales que no quer√≠an tener que administrar la infraestructura en la nube y la de los proveedores que empezaron a detectar que la utilizaci√≥n de su infraestructura no era la m√°s eficiente cuando el escala de clientes iba creciendo. Por que pagar y/o mantener por hardware que realmente no se estaba utilizando?
Entonces los proveedores de servicios en la nube comenzaron a ofrecer el modelo de plataforma como servicio, donde el foco de los clientes es el desarrollo de las soluciones, pudiendo delegar el resto de las operaciones relacionadas al hardware. Las operaciones se trasforman en DevOps. En los √∫ltimos a√±os, las plataformas como servicio alcanzaron una especializaci√≥n muy importante, hay servicios de plataforma para cada necesidad, desde base de dato y tiempo de ejecuci√≥n a servicios orientados a inteligencia artificial e Internet of Things. La verdad es que el modelo PaaS engloba todo un conjunto de sub categor√≠as con sus propias caracter√≠sticas y diferencias
Este nuevo modelo ofrece como ventajas:
Aunque el lograr estos beneficios puede comprometerse por
No hay modelo perfecto ni tampoco un modelo malo. Todo depende de la arquitectura de nuestra soluci√≥n y como combinamos cada uno de los componentes de los modelos. No hay respuesta correcta, sino alternativas‚Ä¶ con la excepci√≥n de creer que un solo modelo es la respuesta a todos nuestros problemas.El tratar de migrar o adoptar modelos en la nube, como servicio, sin evaluar nuestra arquitectura y la necesidad de re-ingenier√≠a puede impactar nuestras soluciones, incluso elevando los cost√≥ de ejecutar las operaciones.
La presentaci√≥n completa est√° disponible en en Slideshare
Todas las opiniones expresadas son m√≠as y no representan opiniones de ninguna entidad con la que he estado, estoy o estar√© afiliado.
All views expressed are my own and do not represent opinions of any entity whatsoever with which I have been, am now, or will be affiliated
Avid Technologist at heart, a lifetime of projects, experience in software development and project management areas.
See all (682)
9 
Some rights reserved

9¬†claps
9 
Avid Technologist at heart, a lifetime of projects, experience in software development and project management areas.
About
Write
Help
Legal
Get the Medium app
"
https://betterprogramming.pub/how-adopting-paas-will-change-your-team-f52f587d2a0f?source=search_post---------36,"Sign in
There are currently no responses for this story.
Be the first to respond.
Michael Bogan
Jan 25, 2020¬∑6 min read
Platform as a Service (PaaS) is a cloud-based deployment and development platform. PaaS providers such as Heroku, Oracle Cloud, and Microsoft Azure allow teams to develop, deploy, and run apps without the complexity of creating and maintaining your infrastructure.
"
https://medium.com/@oleksiy/aas-saas-paas-maas-baas-taas-and-other-nonsense-trends-around-e565014b6fcf?source=search_post---------37,"Sign in
There are currently no responses for this story.
Be the first to respond.
Oleksiy Kuryliak
Mar 31, 2017¬∑1 min read
Were you ever wondering what the other *aaS stays for? Well, I was. It was totally ok to have SaaS popping out on Google back then, which was clearly explained as a software as a service, but then that PaaS (product as a service), MaaS (metal as a service) :D and other bullshit.
Why don‚Äôt you simply call the service you provide or the technology you implement as a SERVICES or PRODUCT. That‚Äôs it. Period. Way too much to handle when you are lost in all those *aaSes.
So, when you guys overthink all your marketing strategies and childish trends following with all that naming, start doing it right way.
‚Ä¶and I‚Äôm going to use a CaaS, as I have to do a lot of MaaS before we take a TaaS to go to airport where we have AaaS, and then having a BaaS on the rooftop of one of the HaaS :D
Not to be taken as a reference:
Marketing Strategist. Founder of Rioks (https://rioks.com), B2B marketing consultancy, and a digital agency. Startups Advisor.
4 
4¬†
4 
Marketing Strategist. Founder of Rioks (https://rioks.com), B2B marketing consultancy, and a digital agency. Startups Advisor.
"
https://architecht.io/googles-oren-teich-on-why-serverless-matters-and-how-we-got-here-from-paas-700cd9ae194c?source=search_post---------38,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
In this episode of the ARCHITECHT Show, Oren Teich, Google‚Äôs director of product management for serverless, discusses how we evolved to a world of functions-as-a-service and how developers should think about using this new capability. Teich, who was previously COO at Heroku and whose product responsibilities include Google App Engine, also talks about the recent history of abstractions ‚Äî from IaaS to PaaS to containers ‚Äî including mistakes that were made, and why they‚Äôre all still important tools.
architecht.io
Enterprise IT interviews and analysis: AI, cloud-native, startups, and more
12 
12¬†claps
12 
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@aramkoukia/azure-mobile-app-fully-managed-platform-as-a-service-paas-166422da1db9?source=search_post---------39,"Sign in
There are currently no responses for this story.
Be the first to respond.
Aram Koukia
Dec 9, 2016¬∑4 min read
Azure Mobile Apps is a part of new Azure App Service and it offers a highly scalable, globally available mobile application development platform for Enterprise Developers and System Integrators that brings a rich set of capabilities to mobile developers.
Now what does it mean and how it can help?
For mobile or web development you like to start building up your web page and/or your mobile app and assume there will be a back-end service that will handle the CRUD operations, so this Azure Mobile App is kind of your magic bullet that can take care of your back-end operation with minimum effort. However if you have more complex enterprise solution then there might be complicated solutions that you need to use.
As crazy as it sounds, you just need to define your Azure Mobile App service in Azure portal and create the tables/entities (no schema needed!) and once you make a POST request from your mobile application or your web application or even Postman or Fiddler, the service will create the schema and will insert the record for you!
And if you make additional POST methods to the same table with modified payload, it will update the schema accordingly and of course you can limit this dynamic schema when you think your schema is ready.
Basically it will give you a RESTful API that you can call as your application back-end.
Other Features that might be interesting for you to know:
How to create the Azure Mobile App:
First login to the Azure portal (the new one): https://portal.azure.com
Then click on the ‚Äú+‚Äù or New Resource menu and search for Mobile App on the Market Place:
Select ‚ÄúMobile App‚Äùfrom the search result and on the new tab that was opened, select ‚ÄúCreate‚Äùbutton and then enter your App Service Name,select your Subscription and the Resource Group and the App Service Plan Location and click Create again:
This will create your empty Mobile App, now you can see the properties and settings of the Mobile App you created:
Here comes the fun part. Click on the ‚ÄúEasy tables‚Äù menu in the Settings and you will see a TodoItem table created by default for you. you can try creating additional ones by clicking the Add button and giving it a name.
But for this demo I will just use the existing table. I will just open Postman and create a POST request to this endpoint : POST http://YOUROWNAPPNAME.azurewebsites.net/tables/TodoItem.
Note: Make sure you have these 2 in your request header:
ZUMO-API-VERSION = 2.0.0
Content-Type = application/json
You can see that it returned a 200OK and the entity that it created! how cool is that?
Now change the Json in the body and add another property and see what happens:
See the new column was added and returned? Magic?
Now try to do a GET on the same endpoint like:
GET http://YOUROWNAPPNAME.azurewebsites.net/tables/TodoItem and see the result:
You can make all sort of http calls to this endpoint.
Here is the documentation about all the Operations you can do on a table in Mobile Apps:
https://msdn.microsoft.com/en-us/library/azure/jj710104.aspx
Now you can go ahead and just define the entities in the Azure portal and start making POST calls to build up your back-end service!
There are a ton of features in the Mobile App like Authentication, Push Notifications, Request Interception etc that you can go and take a look in the Azure Mobile App documentation:
https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-value-prop/
Hope this helps to kick-off your new cool App/Web idea without having to worry about the back-end.
Software Engineer, Engineering Leader and Manager @ AWS. Living my dream life. http://koukia.ca/
See all (21)
3 
3¬†claps
3 
Software Engineer, Engineering Leader and Manager @ AWS. Living my dream life. http://koukia.ca/
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/codica/saas-vs-paas-vs-iaas-which-is-the-best-cloud-computing-model-for-your-startup-5dcb21e049e9?source=search_post---------40,"There are currently no responses for this story.
Be the first to respond.
Today more and more companies are moving their data to the cloud. This way, they cut corners on hardware and protect their sensitive information from internal data theft.
There are three main types of cloud computing which are software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS).
In this post, we will discuss the primary difference between these models. These insights will help you choose the right solution for your business.
Cloud computing means that on-demand computing services are delivered over the Internet on a pay-as-you-go basis. Simply put, this model allows storing and accessing data and apps on remote data centers. You no longer need to keep them on your hardware.
The global cloud computing market size is constantly growing. According to MarketsandMarkets, it may reach $623.3 billion by 2023.
The chart below by ZDNet shows forecasts for Saas, PaaS, IaaS revenue.
What creates the demand for cloud computing? Grand View Research defines the following reasons for its popularity:
There are three main cloud computing models: SaaS, PaaS, IaaS.
Let‚Äôs move to a detailed description of each delivery option.
SaaS (software-as-a-service) means ready software products that are delivered via the Internet on a subscription basis. If we compare SaaS vs PaaS vs IaaS, the first model is the simplest option to maintain.
Below you can see the growth of SaaS enterprise market size from 2009 to 2019 by Statista:
The most common examples are Google App Engine, Dropbox, JIRA, and others.
As an example of SaaS applications, here‚Äôs a screenshot of Jira ‚Äî a project management web application:
Software-as-a-service is the most suitable option in the following cases:
We have discussed the key benefits of SaaS technology. Now let‚Äôs have a look at the downsides of this option:
As it has been mentioned, SaaS solutions offer businesses ready products. PaaS (platform-as-a-service) takes it a step further and provides clients with a cloud environment that allows developing custom apps. Thus, companies no longer have to invest in building and maintaining the infrastructure that their applications require.
What are the most famous examples of this cloud computing model? First off, we should mention Windows Azure, OpenShift, Heroku, and Google App Engine.
Take a look at extensive feature set offered by Heroku, a PaaS cloud platform:
Let‚Äôs discuss in what cases platform-as-a-service solutions can bring maximum value:
IaaS (infrastructure-as-a-service) is a self-service that gives users the opportunity to access and monitor hardware. It may include specialized processors, storage space, visualization services.
The examples are Google Compute Engine, DigitalOcean, Amazon Web Services (AWS), and Cisco Metacloud.
One of the first IaaS products that comes to our mind is Amazon Web Services.
IaaS seems the best possible option for:
All mentioned types of cloud computing define how the cloud is used in your company. More specifically, they show how you host, store, manage, and process data online.
Are SaaS vs PaaS vs IaaS very popular? Let‚Äôs see what specific figures will tell us:
The table below displays the key features of Saas vs PaaS vs IaaS.
This was an overview of SaaS vs PaaS vs IaaS cloud models. You have seen what business benefits they can bring. The choice of the right solution depends on the size and complexity of your business.
For more information about the above three types of cloud computing, check our full article: SaaS vs PaaS vs IaaS: Choosing the Best Cloud Computing Model.
If you have an idea for a great SaaS application, and need a reliable technical partner to help deliver it, let‚Äôs get in touch! Our team is highly experienced in SaaS development, we would love to share our expertise, and help you deliver a successful product.
www.codica.com
www.codica.com
www.codica.com
A Blog about technology, design, and products development‚Ä¶
102 
102¬†claps
102 
Written by
Software development consultancy. We are passionate about innovations and create great online marketplaces with Ruby on Rails, React, Vue and Angular.
A Blog about technology, design, and products development | Ruby on Rails, React and Vue.js
Written by
Software development consultancy. We are passionate about innovations and create great online marketplaces with Ruby on Rails, React, Vue and Angular.
A Blog about technology, design, and products development | Ruby on Rails, React and Vue.js
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.datadriveninvestor.com/saas-vs-iaas-vs-paas-cloud-computing-models-explained-with-its-benefits-276298aea66d?source=search_post---------41,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Cloud Computing has become a hot topic for business and IT industries because of the advantages it provides to the digitally connected world to drive their business forward.
Cloud Computing has grown exponentially over the years and expected to enhance at an even faster pace. If you as an entrepreneur thinking to switch your business to the cloud, whether it is infrastructure deployment or application, make sure that you have got a clear idea about the differences and benefits of various models of cloud services.
www.datadriveninvestor.com
Cloud computing integrates mainly three models that are:
1. Software as a Service (SaaS)
2. Infrastructure as a Service (IaaS)
3. Platform as a Service (PaaS)
Each of these models delivers varied services and benefits. Thus, before picking any model for your business, ensure to understand the difference between SaaS, PaaS, and IaaS. Here below you can find the intro of each model and what services and benefits they offer.
1.Software as a Service (SaaS):
Software as a Service (SaaS) is a crucial element of the cloud-computing ecosystem. It helps the third party to rent or subscribe to a software application and execute it online, rather than purchasing, installing, and managing it. Today, most of the IT sector and businesses are adopting SaaS applications for fundamental business technologies such as email, CRM, HRM, Sales management, financial management billing, and collaboration. The leading SaaS providers incorporate Salesforce, Oracle, SAP, Intuit, and Microsoft.
Benefits of SaaS:
It reduces the time spent in installing and configuring of applications as well as issues that can be faced in the way of the software deployment.
It is cost-effective as you have to pay only for what you are using and not pay heavily on-used licensing.
The SaaS feature has flexible options as it is easy to change the usage plans according to the needs. It also allows subscribers from any location to access the software easily.
It is compatible with the new upgrades, as the subscribers have to simply log-on to already upgraded services.
2.Infrastructure as a Service (IaaS):
Infrastructure as a Service (IaaS) is an instant computing infrastructure, provisioned, and managed over the internet. Many organizations are investing in IaaS for accessing, monitoring, and managing remote datacenter infrastructures. Instead of purchasing the hardware outright, users can purchase IaaS as per the resource on-demand.
Benefits of IaaS:
It includes the ability to scale the resources up and down quickly as per the need of the customers.
It is affordable and cost-effective as you need to pay only for what you use.
It decreases the other expense and complexity of purchasing and handling your physical servers.
It also offers a consolidated disaster recovery infrastructure, by lowering down the costs and increasing manageability.
3. Platform as a Service (PaaS):
Platform as a Service (PaaS) is a cloud computing model in which the third-party provides users with hardware and software tools. Many small businesses rely on PaaS providers for development kits, database tools, and application management requirements to create and deploy applications. The PaaS providers also handle the infrastructure, which includes network, servers, operating systems, and storage.
Benefits of PaaS:
It assists the app makers to develop and deploy the apps in a simple and affordable way.
It allows the developers to create customized apps without any stress of maintaining the software.
It lowers the burden of developers by reducing the amount of coding.
It helps in streamlining the complete application management by reducing the unnecessary human configuration tasks.
Conclusion:
Every cloud models have various features and functionalities that fit for various industry needs. At GoodFirms, you can reach the cloud computing service providers that are evaluated and listed based on various qualitative and quantitative factors.
You can associate with the top cloud computing companies whether you are searching for cloud-based software to create inventive customized applications, looking for varied storage options or need to handle your entire infrastructure. Choose the best-suited model and migrate to the cloud for better prospects of the business.
empowerment through data, knowledge, and expertise.
69 
69¬†claps
69 
Written by
Research Analyst, Content writer at GoodFirms.co
empowerment through data, knowledge, and expertise. subscribe to DDIntel at https://ddintel.datadriveninvestor.com
Written by
Research Analyst, Content writer at GoodFirms.co
empowerment through data, knowledge, and expertise. subscribe to DDIntel at https://ddintel.datadriveninvestor.com
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jrodthoughts/azure-service-fabric-and-the-evolution-of-the-microservices-paas-5f2dd1a3f465?source=search_post---------42,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jesus Rodriguez
Sep 15, 2016¬∑2 min read
A few months ago, Microsoft announced the general availability of the Azure service Fabric: a new platform for developing and running microservices. Functionally, Azure Service Fabric provides some of the most common building blocks of microservices solutions such as the modeling and implementation of stateless-stateful services, messaging, persistence, stateless-stateful actors, service discovery among other relevant capabilities.
The release of the Azure Service Fabric marks an important milestone in the evolution of cloud microservices architectures. At the moment, azure service Fabric is the only platform among the top PaaS -AWS, Azure, Bluemix, Google Cloud- that provides an end to end infrastructure for building and operating microservices. Some experts are considering the Azure Service Fabric the foundation for the next version of Microsoft Azure and the model the framework for the next generation PaaS.
If we analyze the evolution of microservices capabilities across the major PaaS we can come up with the following timeline
Container Services ‚Äî ‚Äî -> Lambda Functions ‚Äî ‚Äî -> Microservices Platforms ‚Äî ‚Äî -> ?
Container Services Winner: Google Cloud
AWS, Azure, Bluemix and Google Cloud have all released services for deploying and managing containers such as Docker or Rocket. Google Cloud has been particularly innovative in this area with the incubation of platforms like Kubernetes that have become some of the most important building blocks of the container ecosystem. One aspect that adds credibility to Google Cloud‚Äôs container offering is the fact that Google itself has been running containers at scale for years.
Lambda FunctionsWinner: AWS Lambda
Lambda functions is a generic cloud term to designate a micro-container responsible for running an atomic function. Azure Functions, Bluemix OpenWhisk, Google Functions and AWS Lambda represent some of the main technologies in the space. Even though some of these technologies look very similar in terms of capabilities, AWS Lambda is the undisputed leader in the space in terms of market traction.
Microservices PlatformsWinner: Azure Service Fabric
While Lambda Functions and Containers are certainly relevant building blocks of microservices architectures, they are not sufficient to implement sophisticated microservices solutions. Other functional areas such as service authoring, discovery, data persistence, messaging, etc are common citizens in microservices solutions. The Azure Service Fabric is the first technology among the PaaS providers that provides an end-to-end experience for the development and management of microservices. If successful, the Azure Service Fabric is likely to become the foundation for new services in the Azure platform. Today technologies like SQL Azure are already leveraging Service Fabric as its underlying stack. From that perspective, technologies such as the Azure Service Fabric are called to become a core element of the next generation PaaS.
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
3 
3¬†
3 
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
"
https://blog.embed.ly/from-saas-paas-or-iaas-to-cloud-api-a865d47efc70?source=search_post---------43,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
We need to figure out a better way to categorize B2B startups. SaaS, PaaS or IaaS aren‚Äôt descriptive enough for API companies, this is the path to Embedly using Cloud API.
Humans are incredibly good at categorization. We love putting labels on things and if we can‚Äôt find a label, we use one of our existing schemas to draw a comparison. This is why most new startups are described as X for Y (AirBnB for Food, Uber for Cats).
SaaS, PaaS and IaaS were all created with this comparison in mind. I mean, Software As A Service just screams ‚Äúwe didn‚Äôt know what to call a hosted version of Microsoft Products so we used an X for Y‚Äù.
Each have very specific meanings in this world.
SaaS: ‚ÄúA software delivery model in which software and associated data are centrally hosted on the cloud.‚Äù Examples include Salesforce, Google Apps and Microsoft Office 365. An individual user interacts with the product.
IaaS: ‚ÄúIn the most basic cloud-service model, providers of IaaS offer computers ‚Äî physical or (more often) virtual machines ‚Äî and other resources.‚Äù Examples include AWS, Rackspace and Dyn.
PaaS: ‚ÄúIn the PaaS model, cloud providers deliver a computing platform typically including operating system, programming language execution environment, database, and web server.‚Äù Examples include Heroku, Google App Engine and dotCloud.
These terms are incredibly important. They allow a customers/developers/investors to frame a conversation around a new product by putting it into one of these predefined categories. They allow Forrester to create outrageous claims about the market and get sales and marketing people excited.
This is all well and good until you don‚Äôt fit into any of these models. We don‚Äôt sell to the end user, we sell to the dudette that builds the SaaS app. We don‚Äôt allow you to host your own VM and we don‚Äôt give you a layer on top of the VM like Heroku does.
People have started getting creative with these terms. Mobile backend companies decided that they didn‚Äôt like any of these labels, so they created their own.
BaaS: Backend as a Service. ‚ÄúA model for providing web and mobile app developers with a way to link their applications to backend cloud storage while also providing features such as user management, push notifications, and integration with social networking services.‚Äù Examples include Parse, Kinvey and StackMob.
This term can now be used it successfully to market and sell product.
Let‚Äôs talk about a segment of the market that explicitly sells to developers, but does not host code. How do they frame themselves?
Here‚Äôs the deal guys, we need to pick. I believe, like every web business, we probably fall into SaaS, but that‚Äôs not specific enough. Selling an API to a developer is completely different then selling Yammer to a user/organization.
The boundary for this definition is the following.
‚ÄúAn organization who‚Äôs main product is a RESTful API that is sold to developers on a metered basis.‚Äù
A few options:
Those are all really bad and we should probably stay away from an ‚ÄúAs a Service‚Äù, because service will always be redundant.
From a marketing and understanding purpose, my vote is Cloud API. This is not a new term, Wikipedia describes it as:
Cloud APIs are application programming interfaces (APIs) used to build applications in the cloud computing market. Cloud APIs allow software to request data and computations from one or more services through a direct or indirect interface.
Cloud, while overused, allows even non technical customers to get an understanding of what we do. We are in ‚ÄúThe Cloud‚Äù! It at least begs the question, ‚Äúwhat is an API?‚Äù
While we could use REST or Web, neither conveys that message as broadly as ‚ÄúCloud‚Äù.
API, while technical, clearly defines the boundary. Service, Platform or Provider are all too broad and won‚Äôt differentiate ourselves from the next company.
From here on out Embedly will be known as a Cloud API company. If you are in the space, we hope you join us.
Thoughts, Data, and Notes from the Embedly Team
24 
24¬†claps
24 
Written by
Making embedding easy.
Thoughts, Data, and Notes from the Embedly Team
Written by
Making embedding easy.
Thoughts, Data, and Notes from the Embedly Team
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/cuelogic-technologies/saas-paas-iaas-decoding-the-3-cloud-computing-service-models-8f03b6c2be41?source=search_post---------44,"There are currently no responses for this story.
Be the first to respond.
Over the years, this technology paradigm has evolved through multiple phases. The earlier forms of computing that preceded modern cloud computing included grid, utility, and on-demand computing. The earliest forms of modern cloud computing that include Software (SaaS), Platform (PaaS) and Infrastructure (IaaS) emerged as a technological outcome that attended the dipping costs of computer and server hardware. Users could purchase individual servers to power their computing requirements.
The cloud paradigm emerged when software makers and hardware vendors combined multiple servers in a concerted bid to harness the immense computing power generated by a grid (or network) of connected servers. Concurrently, the evolution of digital connectivity technologies that underlie the World Wide Web in recent years formally brought about the modern concept of ‚Äúcloud computing.‚Äù In recent times, the purveyors of technology have parlayed cloud-computing systems into multiple tiers of service, variously labeled as SaaS, PaaS, and IaaS.
(SaaS) is a software licensing and delivery model that has gained a significant presence in a wide range of modern corporate, business, scientific, and commercial applications.
SaaS technologies allow users to license proprietary software on a subscription basis ‚Äî monthly or annual. As providers of an ‚Äòon-demand‚Äô service, SaaS service providers host the software on the cloud to which users connect through a browser and an Internet connection. As a hugely cost-effective alternative to on-premise software installations and packages, the SaaS model seamlessly delivers a variety of applications that pertain to enterprise resource planning programs, office, and communications software, payroll and accounting packages, human resources management, mobile applications, etc.
This computing paradigm remains vulnerable to unauthorized access and malevolent hacking expeditions in online domains. Digital miscreants have targeted businesses that operate on the cloud by blocking customer access to critical online systems. This poses real risks that can translate into an erosion of market value for SaaS service providers. In response, service providers must continuously invest in improving security and authentication processes on the cloud, thereby delivering incremental assurances to their clients and customers.
Additional challenges that figure in the development of SaaS-powered products and services include custom third-party payment integration, safe and well-defined database access compliant with GDPR norms, guaranteeing zero-downtime deployment,managing the subscription lifecycle, and building a fully customizable SaaS system.
PaaS is ‚Äúa category of cloud services that provide a platform allowing customers to develop, run, and manage applications without the complexity of building and maintaining the infrastructure typically associated with developing and launching an app.‚Äù
PaaS providers host the hardware and software on their infrastructure, thereby releasing customers from any obligation to install in-house hardware and software to develop or run a new application.
PaaS technologies pose particular problems and risks for service providers. These challenges include balancing control, cost, and capacity of a PaaS-based service, providing full multi-tenancy support, designing role-based access controls, creating audit trails, and integrating third-party services into modern PaaS platforms. Additional challenges may emerge in the form of virtualization management, fine-tuning the PaaS compute architecture, designing inter-operability with other cloud services, and creating technically sound fault tolerance parameters.
IaaS operates by traditional cloud architecture. Per the IaaS cloud-computing paradigm, service providers host the infrastructure such as servers, storage units, networking hardware, virtualization or hypervisor layer, etc. This model negates the legacy business case for investing in on-premise data center infrastructure and equipment. Modern IaaS service providers also offer policy-driven services to clients and customers. These services include monitor service performance, detailed billing of customer services, log access, digital security, load balancing, backup, replication, and recovery, etc.
IaaS represents ‚Äúthe virtual delivery of computing resources in the form of hardware, networking, and storage services. It may also include the delivery of operating systems and virtualization technology to manage the resources. Rather than buying and installing the required resources in their own data center, companies rent these resources as needed,‚Äù according to popular definitions of IaaS.
A raft of business challenges have emerged to face service providers that offer IaaS services to clients and customers. These may include subscriber expectation management, defining support systems that handle different forms of payments from customers, accommodating the need for custom analytics that measures customer profitability and usage, managing the service value chain, and controlling business with multiple partners. Also, service operators must remain agile in terms of experimenting with product prices, product features, the configuration of service packages, and navigating the intricacies of customer licenses. They must also work to actively manage customer expectations and refine the concept of datacentre ‚Äòin-the-sky.‚Äô
The business case for cloud computing technologies and frameworks will continue to burnish its relevance and utility years and decades into the future. The large and incrementally enormous volumes of data generated by modern scientific, commercial, and technological enterprises will require larger data centers powered by innovative technologies. These may form the central planks of local, regional, and national economies in the future. That said, the central role of the cloud may morph into differentiated expressions, marshaled by real-time processing technologies and a deeper engagement with refined versions of civilizational requirements.
Source: Cuelogic Tech Blog
Tech for leaders & developers
5 
Thanks to Kiarash Irandoust.¬†
5¬†claps
5 
Written by
Global organizations partner with us to leverage our engineering excellence and product thinking to build Cloud Native & Data-Driven applications.
Tech for leaders & developers
Written by
Global organizations partner with us to leverage our engineering excellence and product thinking to build Cloud Native & Data-Driven applications.
Tech for leaders & developers
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@cloud66/is-paas-really-the-answer-df8f7db5e28b?source=search_post---------46,"Sign in
There are currently no responses for this story.
Be the first to respond.
Cloud 66
Feb 25, 2016¬∑4 min read
25 February 2016
For years, PaaS has been touted as the ultimate solution for developers. Push code and get out of the way ‚Äî PaaS will take care of the rest. Deploying to a PaaS is easy, but customization requires moving to a DIY PaaS solution. Without a PaaS, developers are stuck performing tedious scripting on top of cloud infrastructure.
So, what‚Äôs a software-driven company to do in order to choose a deployment strategy that is easy, yet customizable? We think there‚Äôs another option to the PaaS decision. First, we need to revisit the reason for PaaS from the perspective that counts: the needs of the developer.
Most developers don‚Äôt want to think about servers, server configuration management, or network configuration. Instead, they want to be able to deploy ideas quickly to try something out, with minimal friction. At this end of the spectrum, developers need:
This is where public PaaS has gained the most traction with developers for simple, monolithic applications.
On the other end of the spectrum, developers also want to know that as their application matures, the PaaS solution will too:
Public PaaS cannot deliver on these requirements. This is why companies have been looking toward DIY PaaS to fill this gap. Developers deploying to DIY PaaS are excited about the potential for ease-of-development and flexiblity. But what does it mean for the business to adopt a DIY PaaS solution?
Companies taking the leap into PaaS often opt for trying a public provider. Initially, the results are positive, proving easy deployment of early stage applications. But as applications mature they quickly run into the problems of cost, limited security options, and lack of flexibility.
As a result, companies have started to explore the idea of building their own PaaS to meet developer needs. However, building a PaaS isn‚Äôt as easy as it seems to be. As companies start to embark on the journey of DIY PaaS, they‚Äôre learning the cost of DIY PaaS is high. The cost and time required, often outweighs the potential for increased agility.
So, developers are caught in the middle:
Selecting the wrong approach can have a negative impact on developer productivity and even their longevity as an employee. If a developer‚Äôs code never sees the light of day (or takes much longer to get there), they will move to another company that allows them more efficiency and freedom. In fact, as this article was being drafted, Nati Shalom from Gigaspaces wrote about similar concerns.
While it may be tempting to do so, software-based companies shouldn‚Äôt allow themselves to get into the business of building their own PaaS. Instead, the focus should be about optimizing for the needs of developers, while focusing on delivering the business capabilities it knows best.
So which PaaS option is the answer? Perhaps the problem is with the limitations of the PaaS options available. What if we looked at a different way to approach the problem?
Perhaps the answer isn‚Äôt which PaaS option is best: public or DIY. Instead, perhaps the focus should move toward a cost-effective way of meeting the needs of the developer at both ends of the spectrum: ease of use in the early stages of application development, and flexibility as the application matures. This is where DevOps as a Service offers an answer.
DevOps as a Service allow developers to easily deploy applications to the company‚Äôs existing cloud infrastructure provider. Unlike public PaaS, DevOps as a Service is completely flexible while offering ease-of-use that requires just a little more initial configuration effort. Advanced options often include continuous release support, rolling upgrades, and complex routing and network management. All without the need to build scripts for server configuration or complex container-based deployment workflows.
Yet, DevOps as a Service remains flexible for supporting custom deployment workflows via an API when the need arises. Many services, including Cloud 66, even support deploying to your own hardware alongside cloud infrastructure for a hybrid cloud approach.
Developers don‚Äôt want to be in the business of server and network configuration. They need something as easy as public PaaS, without the expensive overhead that comes with the flexibility of a DIY PaaS. DevOps as a Service may be the answer that meets the needs of developers throughout the application lifecycle.
Originally published at blog.cloud66.com on February 25, 2016.
DevOps-as-a-Service to help developers build, deploy and maintain apps on any Cloud. Sign-up for a free trial by visting: www.cloud66.com
See all (2,795)
3 
3¬†claps
3 
DevOps-as-a-Service to help developers build, deploy and maintain apps on any Cloud. Sign-up for a free trial by visting: www.cloud66.com
About
Write
Help
Legal
Get the Medium app
"
https://levelup.gitconnected.com/5-software-architectures-you-can-quickly-prototype-on-paas-285414140a26?source=search_post---------47,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Sometimes, as an architect or developer, you want to try a new tech stack or technical solution but just can‚Äôt seem to find the time to install, configure, debug, and figure out an entirely new concept. Experimentation is a lot of work, project deadlines come first, and new tech is often one of your last priorities.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://blog.openebs.io/ah-yes-well-paas-as-you-know-these-days-is-largely-k8s-based-such-as-open-shift-or-otherwise-8e7534369157?source=search_post---------48,NA
https://expertise.jetruby.com/dokku-your-own-paas-6420f22b663f?source=search_post---------49,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
One of today‚Äôs most popular cloud platforms (PaaS) for web app development is Heroku. It‚Äôs been highly marked by developers for its ability to deploy new apps in a very quick and simple way. And since the majority of developers prefer spending their time on coding rather than adjusting a server, Heroku is a reasonable choice for them.
So it was just a matter of time when Jeff Lindsay, a developer from Texas, would create Dokku. Basically, Dokku is a tool written in 100 lines of Bash for transforming ubuntu server into mini-Heroku.
The main benefits of Dokku are low price and simple server deployment.
So why is Dokku so compact? The answer resides in the fact that all heavy work is done by several components it consists of:
To install the latest stable version of Dokku, you need to run the following command:
This operation shouldn‚Äôt take more than 5 minutes.
After Dokku has been installed you can easily deploy apps with the help of ‚Äúgit push‚Äù. They will be built using Heroku‚Äôs buildpacks and then run in containers.
Now you can create your own PaaS that is very simple and handy in use.
We are a team of web and mobile development jedi.
51 
51¬†claps
51 
Written by
JetRuby is a Digital Agency that doesn‚Äôt stop moving. We expound on subjects as varied as developing a mobile app and through to disruptive technologies.
We are a team of web and mobile development jedi. We believe sharing knowledge pushes the industry forward and creates communication bridges. Our technical expertise includes Ruby on Rails, ReactJS, Elixir, Swift, Kotlin, React Native, and many more.
Written by
JetRuby is a Digital Agency that doesn‚Äôt stop moving. We expound on subjects as varied as developing a mobile app and through to disruptive technologies.
We are a team of web and mobile development jedi. We believe sharing knowledge pushes the industry forward and creates communication bridges. Our technical expertise includes Ruby on Rails, ReactJS, Elixir, Swift, Kotlin, React Native, and many more.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/readwrite/ipaas-vs-paas-what-you-need-to-know-and-more-914d601272c7?source=search_post---------50,"There are currently no responses for this story.
Be the first to respond.
The variety of software we use daily can feel endless and overwhelming. It‚Äôs inevitable that the adoption of additional software, widgets, and plugins to complement our core tools with business growth. This can quickly lead to us getting inundated by data silos, disjointed information, additional expenses, and other problems that negatively affect the fluidity and efficiency of our business operations.
From using video conferencing software to conducting daily stand-up meetings to document management software and CRMs, it takes many tools to successfully manage day-to-day business operations.
In fact, the average company uses 137 unique SaaS apps and incurs a total SaaS spend of $4.16m a year.
Blissfully dot com
Fortunately, there‚Äôs a standardized solution on the market, and it comes in the form of iPaaS.
Integration platform as a service (iPaaS) allows organizations to integrate disjointed systems, unifying independent applications to create a seamless internal and external experience. This is something that is extremely difficult to achieve with traditional SaaS (software as a service) implementation.
Before we get into why you should implement iPaaS into your business process improvement strategy, it‚Äôs helpful to discuss platform as a service (PaaS) first.
Despite their similar terminology, iPaaS and PaaS are completely different in terms of functionality.
PaaS is a cloud-based platform where organizations are provided with a complete set of tools to develop, run, and manage their web-based applications. All necessary hardware and software ‚Äî the network, servers, operating system, databases, and storage are hosted on the provider‚Äôs infrastructure.
It is an effective solution to the restrictiveness and expense of an on-premises platform because it allows developers to devote more time to creative aspects than the laboring technicalities of building an infrastructure from scratch.
iPaaS is a cloud-based integration solution that allows organizations to automate integrating software applications, data, and services across on-premises, public, and private cloud environments. A modern enterprise iPaaS is usually billed on a monthly subscription fee or pay-by-use rate. However, like PaaS, offers a complete set of features for your specific integration goals.
iPaaS makes a great supplement for businesses using PaaS and SaaS. It provides users with the integration capabilities needed to unite and streamline their different tools.
In many cases, iPaaS provides the same benefits as PaaS, but does so on a broader scale. Here are some of the benefits of iPaaS.
Implementing an iPaaS solution allows greater flexibility because you can adapt and innovate as your integration needs grow more complex. In addition, iPaaS supports hundreds of applications and endless connections, enabling you to scale on demand without having to implement expensive and restrictive third-party software.
Of course, as your business scales and your volume of data grows, data silos can become a serious problem. If your business is made up of segregated systems, it can lack visibility across departments, negatively impacting the fluidity of internal efficiency and customer satisfaction.
Image source
Implementing a third-party integration software can result in further disorganization as you acquire more segregated tools. However, utilizing iPaaS alongside collaboration software means that everything is integrated and managed from one centralized hub, enabling a much more streamlined process across departments.
At its simplest, iPaaS requires little to no coding ability, meaning urgent problems can often be fixed without escalation. This lessens the strain on developers and makes an ideal solution for citizen integrators.
Traditional custom integration methods like enterprise service business (ESB) and enterprise application integration (EAI) can be costly workarounds. iPaaS eliminates the need to employ multiple third-party tools to a model that is already convoluted with software.
Generally, each tenant requires their own instance to connect to the software. For example, each person on a phone call or a conference call dial-in requires their own connection. However, the iPaaS solution has multi-tenancy capabilities, meaning it creates shared instances and eliminates overload on the system.
Accessing and managing all connections from one centralized hub is a huge advantage of iPaaS, eliminating the restrictiveness of singular departments being responsible for different connections.
Inevitably, every cloud environment is at risk of security threats. However, iPaaS not only provides built-in fraud detectors and intruder alerts, but the centralized system makes it much easier for businesses to identify and resolve these threats.
With real-time data connections and processing speeds, iPaaS eliminates the possibility of delays in access and up-to-date information across departments.
It goes without saying that iPaaS greatly improves workplace productivity and efficiency. Not only is workflow streamlined by automation and centralization, but real-time processing and ease of use make iPaaS an efficient solution for daily business operations.
Despite all the benefits, it‚Äôs necessary to touch on the potential challenges of implementing iPaaS.
As previously mentioned, citizen integrators can successfully use iPaaS for integration purposes. However, the user-friendliness of iPaaS can be overestimated. Many integrations require specific technical knowledge that, if done incorrectly, can create data islands and other problems that negatively impact the overall structure of operations.
Additionally, there are significant risks when it comes to data security and compliance.
Industries like law, healthcare, and finance typically work with many applications that handle sensitive data over the cloud (virtual fax applications are a good example of this). As a result, serious problems can arise when a user who is not versed in regulatory compliance changes an iPaaS system.
In fact, it is business users themselves who pose the highest risk to cloud security.
Image source
Fortunately, many modern iPaaS platforms come with built-in security and compliance capabilities, including SOC 2 Type 2 and GDPR.
There are a huge number of iPaaS providers on the market. Comparison and tech websites are prone to listing providers who are either ESB/iPaaS hybrids or fully traditional integration providers (such as ELT) who have supplemented their solutions with SaaS connectivity.
Along with the fact that there is no universal, base-level set of features and functionalities for iPaaS, trying to find the right provider for your specific needs can become a confusing and laborious task.
iPaaS has an extensive range of integrations to suit many different business models. Here are three common iPaaS uses.
Transferring and synchronizing data from one system to another is particularly beneficial for companies that handle large amounts of data across departments. Considering this process used to happen in batches, iPaaS offers a time-efficient solution. For example, data obtained from call logs can be transferred in real-time to other applications, streamlining customer service and eliminating frustrating data silos.
If you have a large number of external partners or providers, iPaaS negates the need to write code based on APIs. It also allows you to securely monitor data flows and enable better security standards.
iPaaS allows you to integrate independent applications, data, and systems, enabling them to work together across on-premises or cloud environments. Data can be gathered from any integrated system and delivered automatically to an end-user platform.
Determining your organization‚Äôs specific needs and goals is a crucial first step to iPaaS implementation. For example, whether you focus on integrating internal business data for workflow efficiency or integrating communication or CCaaS platforms to improve customer service, it‚Äôs vital to identify where your data lies and whether those applications support integration.
As we dive deeper into cloud dependency and uniformity within internal and external processes, iPaaS has become a staple in business operations.
Image Credit: pixabay; pexels; thank you!
iPaaS vs PaaS: What You Need to Know and More was originally published on ReadWrite by Grace Lau.
ReadWrite is the leading media platform dedicated to IoT‚Ä¶
6 
6¬†claps
6 
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
Written by
The latest #news, analysis, and conversation on the #InternetOfThings
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
"
https://medium.com/cerebrus/from-rpc-to-serverless-prefabricated-paas-accelerates-business-velocity-5bdebe3eb9a8?source=search_post---------51,"There are currently no responses for this story.
Be the first to respond.
We are a long way from Remote Procedure Calls (RPC). We are in serverless land. Here is a quick look at its implications for developers, IT, and its impact on business velocity.
In the serverless world, clients send messages to servers. Servers process messages upon the arrival. Servers send responses back to clients. Servers are spun up as needed. Servers are auto-scaled for the needed load. You get charged for the duration of running the servers. And for the number of messages processed.
While some of this sounds like the ‚Äô90s RPC, event-driven data processing has come a long way since RPC. Now, as a developer, we can simply focus on the logic of processing events. The logic of the business. The logic needed for the realtime, programmable, event-driven enterprise.
This is prefabricated PaaS. This is PaaS-pampering of developers.
No messy server provisioning, message passing, autoscaling, load balancing, securing‚Ä¶ i.e. no operational headaches. It is just you, the logic, and the code.
Prefabricated PaaS reduces the time from concept to code. Call it co-co time.
Costs and vendor lock-in considerations aside, it is goodness.
Broadly speaking, we got here in two steps. Middleware to PaaS first. Then, fine-grained PaaS services got further abstracted for coarse-grained services. Surrounding support and management operations were automated next.
Everyone is on the bandwagon:
It is a serverless nirvana out there!
Yes. Unequivocally.
How? And will it accelerate AI? Aye.
Two more things get layered on to this pampering:
GE Digital‚Äôs acquisition of IQP is an example of the latter. It further democratizes the creation of codified business logic. In short, the democratization continues.
Prefabricated PaaS delivers A.I (Analytics + Integration). So it will accelerate AI and consequently drive business agility. [Q.E.D]
One could say lack of portability (‚Äúlock-in‚Äù) and unpredictable costs are downsides. Those objections exist for IaaS in general. Determining which applications should use serverless would be the other. This concern too is the next refrain of the question, ‚Äúwhich workload should we move to cloud?‚Äù.
Ok. Next big question please?
How about:
If serverless can lower co-co time (concept-to-code time), how should I organize my internal resources to take advantage of it? What are the tradeoff‚Äôs between using internal IT operations and app development teams vs. adopting serverless and unleashing the masses at it?
Time for another co-co talk. This time it is co-co for core-vs-context.
Accelerate your business velocity AND optimize your resources. Think co-co to reduce time from concept to code and to make some good ol‚Äô core-vs-context decisions.
It‚Äôs co-co time in the land of the serverless! Make those decisions well, lest you go cuckoo.
Originally published on medium.com/cerebrus.
‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -
Related Articles
Prefabricated IT Stack
Prefabricated IT and Outsourcing
Digital¬†. Business¬†. Innovation
2 

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
2¬†claps
2 
Written by
Musing about the intersection of technology, business, and society. #Digital #Strategy #Healthcare #Innovation
New Frontiers in Digital Product and Service Innovations
Written by
Musing about the intersection of technology, business, and society. #Digital #Strategy #Healthcare #Innovation
New Frontiers in Digital Product and Service Innovations
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/readwrite/how-to-secure-platform-as-a-service-paas-environments-a2fd5a26460d?source=search_post---------52,"There are currently no responses for this story.
Be the first to respond.
On the whole, the platform supports the full software development and usage life cycle while simultaneously providing developers and users with Internet access. PaaS benefits include ease of use, cost savings, flexibility, and scalability.
A PaaS is frequently not secured the same way an on-premises data center is.
Security is incorporated into PaaS environments. PaaS clients protect their platform accounts, applications, and data. In an ideal world, premise security moves to identity perimeter security.
So the PaaS client should prioritize identification as the primary security boundary. Authentication, operations, monitoring, and logging will be essential to protecting code, data, and configurations.
Undoubtedly, the most effective approach is to employ a real-time automated security system that can detect and halt an assault automatically. Additionally, PaaS users may utilize the platform‚Äôs security features or third-party solutions.
Unauthorized access, assaults, or breaches should be detected and prevented immediately.
You should be able to detect hostile users, odd log-ins, malicious bots, and take-overs, among other anomalies. Along with technology, the application must have security.
Every contact is a possible assault surface. The best way to prevent attacks is to restrict or limit untrustworthy people‚Äôs access to vulnerabilities and resources. To minimize vulnerabilities, security systems must be automatically patched and updated.
Even if the service provider safeguards the platform, the client is ultimately responsible for security. The combination of built-in platform security features, add-ons, third-party solutions, and security methods substantially improves account, app, and data protection. It also guarantees that only authorized users or workers may access the system.
Another approach is to restrict administrative access while creating an audit system to detect potentially hazardous internal team and external user actions.
Administrators should also limit users‚Äô permissions as much as feasible. To guarantee that programs or other actions are properly performed, users should have as minimal permissions as feasible. The attack surface is shrinking, and privileged resources are being exposed.
Assess security risks and vulnerabilities in applications and their libraries. Use the results to enhance overall component protection. For example, daily scanning would be scheduled automatically in an ideal scenario based on the app‚Äôs sensitivity and possible security risks. Include a solution that can be integrated into other tools, such as communication software, or used to notify the relevant individuals when a security danger or attack is identified.
Applications usually rely on both direct and indirect open source requirements. If these weaknesses are not fixed, the application may become insecure.
Testing APIs and validating third-party networks requires analyzing the program‚Äôs internal and external components. Patching, updating, or replacing a secure version of the dependency are all effective mitigating methods.
Penetration testing helps detect and resolve security problems before attackers find and exploit them. However, penetration testing is aggressive and may seem like DDoS assaults. To prevent false alarms, security personnel must work together.
Threat modeling involves simulating assaults from trustworthy borders. This helps identify design weaknesses that attackers might exploit. As a result, IT teams may improve security and create remedies for any identified weaknesses or risks.
Managing privileged accounts enables security teams to see how users interact with the platform. In addition, it allows security teams to assess if select user actions pose a risk to safety or compliance.
Monitor and record user permissions and file actions. This checks for unauthorized access, changes, downloads, and uploads. File activity monitoring systems should additionally record all users who have viewed a file.
An appropriate solution should detect competing log-ins, suspicious activity, and repeated unsuccessful log-in attempts. For example, logging in at awkward hours, downloading dubious material and data, etc. These automated security features stop suspicious behavior and notify security professionals to investigate and fix any security problems.
Encrypting data during transport and storage is the best approach. In addition, human assaults are prevented by securing Internet communication links.
If not, set HTTPS to use the TLS certificate to encrypt and protect the channel and hence the data.
Verify the data constantly.
This guarantees the input data is safe and in the proper format.
Whether it originates from internal users or external security teams, all data must be treated as high-risk. If done correctly, client-side validations and security mechanisms should prevent compromised or virus-infected files from being uploaded.
Analyze the vulnerability code during development. Until the secure code is validated, developers should not release the program into production.
Multi-factor authentication ensures only authorized users may access apps, data, and systems. For example, a password, OTP, SMS, or mobile app may be used.
Most individuals choose weak passwords that are easily remembered and never update them. Therefore, administrators may minimize this security risk by using strong password policies.
This necessitates the use of strong passwords that expire. Ideally, encrypted authentication tokens, credentials, and passwords are saved and transmitted instead of plain text credentials.
Authentication and authorization methods and protocols like OAuth2 and Kerberos are suitable. However, while unique authentication codes are unlikely to expose systems to attackers, they are not error-free.
Avoid using predictable cryptographic keys. Instead, utilize secure essential distribution methods, rotate keys frequently, renew keys on time, and avoid hardcoding keys into apps.
Automatic key rotation enhances security and compliance while reducing data exposure.
Create an auditable security policy with strict access restrictions. For example, it is preferable to restrict access to authorized workers and users.
Applications, APIs, and system logs all offer useful data. In addition, automated log collection and analysis provide essential information. As built-in features or as third-party add-ons, logging services are often excellent for assuring compliance with security laws and other legislation.
Use a log analyzer to interact with your alert system, support your application‚Äôs technological stacks, and have a dashboard.
This includes successful and unsuccessful log-in attempts, password changes, and other account-related events. In addition, an automated approach may be used to prevent suspicious and insecure counter activity.
The customer or subscriber is now responsible for securing an account, application, or data. This needs a security approach that is distinct from that used in traditional on-site data centers. Applications with adequate internal and exterior protection in mind must be developed with safety in mind.
Log analysis reveals security weaknesses and opportunities for improvement. Security teams in an ideal world would target risks and vulnerabilities before attackers were aware of them.
Image Credit: Provided by the author; Thank you!
How to Secure Platform as a Service (PaaS) Environments was originally published on ReadWrite on November 24, 2021 by Usama Amin.
ReadWrite is the leading media platform dedicated to IoT‚Ä¶
51 
51¬†claps
51 
Written by
The latest #news, analysis, and conversation on the #InternetOfThings
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
Written by
The latest #news, analysis, and conversation on the #InternetOfThings
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://blog.codenvy.com/take-control-of-paas-deployment-23e9df9a679?source=search_post---------54,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
With the release of 3.4 we have added a Deployment plug-in that works with Google App Engine. With this plug-in there are 3 ways users can deploy to their PaaS of choice. Each with its own strengths:
Let‚Äôs take a closer look.
There are three pre-configured environments located in the Project Wizard, which you can use to create an application with Google App Engine (GAE) as its deployment target. These environments include Java, Python, and PHP.
You can also import an existing GAE application or convert an application to deploy to GAE:
You can even use the Push-To-Deploy feature and update GAE apps through a 3rd party repo. Visit our docs for more information.
We plan to further develop the GAE plugin, adding in more functionality and making an extensive use of GAE API (download source code, logs, datastore indexes etc).
Heroku and OpenShift use Git, and Codenvy loves Git. You can import projects, work with them in Codenvy, and push updates back to either Heroku, OpenShift or both.
You can import your OpenShift project into Codenvy either from the User Dashboard or from within the workspace at File > Import > Import From Location > GIT.
Once you‚Äôve edited the application, you can easily push your changes back to your PaaS by following the steps in our deployment documentation.
For complete control, you can embed your PaaS‚Äô SDK in your Docker container. We‚Äôve provided examples in our docs for CloudFoundry and AppFog.
When you upload your application to AppFog or Pivotal, create a new app, build a custom environment, or launch it, just navigate to the Terminal and then run the available commands (AppFog and Pivotal offer a lot of them).
This takes a bit more time compared to using a built-in plugin or Git. But, gives you total control over your PaaS account right from your Codenvy workspace.
There‚Äôs a lot more detail and examples in our PaaS Deployment docs ‚Äî check them out and start pushing your project to the world!
PaaS Deployment Docs4-Steps to Docker Based build Environments3.4 Release Notes
Codenvy Blog‚Ää‚Äî‚Ääcloud workspaces for development teams
Written by
MD @ Dell Tech Capital. BOD @ NS1, Orion Labs. Prev: CEO @ WSO2, CEO @ Codenvy (acq. by RHT). Invest @ Sauce Labs, Cloudant, ZeroTurnaround, InfoQ, Sourcegraph.
Codenvy Blog‚Ää‚Äî‚Ääcloud workspaces for development teams
Written by
MD @ Dell Tech Capital. BOD @ NS1, Orion Labs. Prev: CEO @ WSO2, CEO @ Codenvy (acq. by RHT). Invest @ Sauce Labs, Cloudant, ZeroTurnaround, InfoQ, Sourcegraph.
Codenvy Blog‚Ää‚Äî‚Ääcloud workspaces for development teams
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/evoknow/saas-paas-iaas-and-bare-metal-a-game-of-technology-abstraction-4fa748eeae6?source=search_post---------55,"There are currently no responses for this story.
Be the first to respond.
Tech is full of jargon. I feel like a new jargon is invented every few weeks or even every day! I think it would be very interesting if Google were to publish a list of technology terms showing each term‚Äôs debut on the internet. There are terms that you can ignore or forget right after you have heard or read them. And then, some terms will keep appearing in your software‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/fintech-sandbox-the-weekly/working-closely-with-real-customers-led-aimee-gaspar-of-lionx-to-build-a-paas-company-that-better-fcab7166ff91?source=search_post---------56,"There are currently no responses for this story.
Be the first to respond.
While we may not know exactly how FinTech will impact our future, we have an idea as to who will be leading the charge. Our latest blog series, ‚ÄúThe New Faces of FinTech‚Äù, spotlights some of the emerging leaders in the FinTech world and asks their thoughts on the future of the industry. Their origin stories are different, their paths to entrepreneurship are unique, but their impacts on their respective industries are all significant. No one truly knows what the future of FinTech holds, but these leaders may have an inkling as to what we can expect.
Up next is the CEO and Co-Founder of LionX, Aimeelene Gaspar. She‚Äôs built a privacy-as-a-service platform that ensures companies are both complying with data privacy regulations and earning the trust of their customers.
As a former executive and product manager at Wells Fargo and Broadbridge, Aimee understands the foundations of financial services and corporate culture. It‚Äôs part of the reason why she takes security so seriously. She always had an interest in data privacy and its role within major organizations, but it wasn‚Äôt until Equifax‚Äôs major data breach in 2017 that she felt compelled to spring into action. Alongside her co-founder, Andy Carra, Aimee is providing companies with peace of mind, knowing that they‚Äôre adhering to the latest privacy regulations and protecting their customers‚Äô data at all costs.
This is part 8 in the 2020 edition of our ‚ÄúThe New Faces of FinTech‚Äù series created in partnership with growth marketing agency Ideometry. Tune in next week for another installment!
Aimee: LionX offers privacy as a service, which is a technology platform that businesses use to meet the complex and fragmented US consumer privacy requirements when businesses and consumers share information. We make data sharing easy for consumers to use and understand the benefits that come with sharing information with businesses they trust.
We give our clients a technology solution that is easily integrated into their existing websites and mobile apps to help them meet regulations, in addition to creating a user experience that builds loyalty by providing consumers with transparency and control over how their data is used.
Aimee: LionX started as an idea that I shared with my Co-Founder, Andy Carra, many years ago. While the idea behind LionX has certainly evolved since then, the core values of the business are still very much the same. Our goal was to give people more control over their information while making it easier for businesses to protect consumers while efficiently creating the financial products and services consumers want and need. That‚Äôs still our goal today.
It was in the summer of 2017 that Andy and I revisited the idea of starting a business after talking about GDPR in Europe. This was right around the same time when the big data breach hit Equifax, where 148 million consumers had their personal data compromised. We both knew that it was time to get our business up and running, because there was a big demand for what we could offer.
Our highest priority right now is working on customer development and finding that initial pilot partner. We‚Äôre currently in the Customer Validation stage of development. As I continue to talk with various customers, I‚Äôm always learning about their needs and pain points, which helps us validate our hypothesis and fine tune our solutions. Customer feedback is very important to us, and we review feedback alongside market changes to adjust our plan as necessary.
Aimee: We started off thinking LionX would be a direct-to-consumer product, but then shifted to a B2B model when the California Consumer Privacy Act was established. Early on, we filed a patent on our solution and developed a proof of concept. Since then we decided to operate on a B2B business model, we have been working on rearchitecting our solution for businesses, and are now ready to pilot with customers. We also recently raised an Angel round.
Aimee: Our solution is unique in that we are a complete solution for the specific use case of data sharing. This includes a configurable consumer experience to record the entire consent and access process, ensuring the security of personal data and compliance with all regulations. Our solution is best suited for those in financial services, such as credit unions and FinTech lending companies who have a tremendous amount of consumer information and understand the need to meet these complex regulations. In addition we plan to work with other technology partners who service a similar demographic. We‚Äôre proud that our solution is extendable to other verticals, and we fully intend to move into those verticals once we‚Äôve successfully deployed with our initial customers and partners. Our vision is to become the trusted platform for businesses and consumers to share information.
Aimee: Working at larger companies early on taught me a lot about the foundations of financial services and corporate culture. It‚Äôs part of the reason why I take security so seriously. The structure early on at these companies was comfortable, in that I felt safe working at a large organization and was given plenty of opportunities to prove my worth. I was able to collaborate with mentors who taught me and advocated for me. Being a woman in the world of financial services was challenging. It‚Äôs always challenging trying to establish yourself in a field where you‚Äôre in the minority.
When I went to Advent Software, it was a completely different culture, where everyone was so willing to share insights with me and teach me the ropes. I learned how to code while working at Advent and was an engineer for a year, but product management was more my speed. I went on to work for Finaplex, which was later acquired by Broadridge, and joined that team relatively early on in their growth.
My time at Finaplex was incredibly valuable from an educational perspective. I had to learn things quickly and on the fly, and I was fortunate to have tons of opportunities to work on projects. Some went well, others, not so well, but all were incredibly beneficial to my growth as a professional. The team at Finaplex was amazing, everyone was incredibly smart and driven. A lot of their employees went on to become CTOs or start their own companies, so clearly they had a knack for hiring great people.
I worked incredibly hard at Finaplex because I didn‚Äôt want to let the team down. It‚Äôs a real thing when you see the person next to you working hard and feel inspired to match their effort. It made me bring my A-game to every assignment and project. All I could think about was doing what I could to help us be successful. I still carry that mindset with me today.
Aimee: I remember when we first started LionX, I looked at who we were going to be competing against, and there were probably 50 other companies in our space. Now, there‚Äôs at least 300 companies that we‚Äôre competing against. Ultimately, privacy will have a place in every organization. Whether it‚Äôs as a dedicated department or added into an existing role, data security will inevitably be integrated into every company‚Äôs culture. The ideas of data privacy by design are also playing a larger role in all areas of design and engineering. Companies like us aren‚Äôt just providing technology, but we‚Äôre also helping to shape how organizations think about and integrate privacy as part of their culture.
My conversations with customers range from sharing the latest updates on data regulations to philosophical discussions around what privacy means, what the consumer views are and where they may be going. It is my expectation that privacy will continue to play an increasingly major role in shaping how businesses design and deliver solutions to consumers, because consumers are the ones who are demanding it. They ultimately decide which brands can be trusted with their data, and they want to work with brands who align with their values and have their backs.
Aimee: The team at FinTech Sandbox is incredibly collaborative and supportive. Through them, we have been able to access data vendors easily and engage with them to help us develop and grow our company. Learning from the expertise of other entrepreneurs in the community is also an amazing resource to have, and something our company greatly benefits from. With FinTech Sandbox, you get to have candid conversations with industry leaders, so we try everyday to make the most of the opportunities given to us through FinTech Sandbox.
We‚Äôre thrilled to feature some of the incredible companies that are currently participating in the FinTech Sandbox program. If you‚Äôd like to connect and hear from our interviewees in person, be sure to check them out at the upcoming Demo Day, which is now scheduled for October 15 in New York. It‚Äôs a tremendous event that represents a diverse, global group of innovators in FinTech and gives others the chance to see our portfolio companies live and up close.
Ideometry is a Boston-based full-service marketing agency serving a global client base. With a full suite of creative, development, and strategic services, Ideometry helps growth-stage startups and Fortune 500 companies alike get the business results they‚Äôre looking for. If you‚Äôre doing something interesting, we‚Äôd love to hear from you. Get in touch with us at ideometry.com or email hello@ideometry.com.
All things product development and data in finance.
1 
1¬†clap
1 
All things product development and data in finance. Powered by FinTech Sandbox, Boston based non-profit breaking down barriers to entry for FinTech entrepreneurs by providing free access to quality data.
Written by
Boston-based nonprofit accelerating innovation and collaboration in finance.
All things product development and data in finance. Powered by FinTech Sandbox, Boston based non-profit breaking down barriers to entry for FinTech entrepreneurs by providing free access to quality data.
"
https://medium.com/@alibaba-cloud/building-a-fully-open-industrial-intelligent-paas-platform-with-et-industrial-brain-4107f196768a?source=search_post---------57,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Dec 17, 2018¬∑8 min read
By AlibabaCloud Data Intelligence Team
On August 1, the Alibaba Cloud ET Industrial Brain open platform was officially launched. In the enablement ecosystem from awareness, to knowledge, and to wisdom, Alibaba Cloud develops ET Industrial Brain, which enables industrial devices to implement self perception, self diagnosis, self decision making, and self configuration in a true sense, boosting development of the intelligent industry.
ET Industrial Brain builds a fully open industrial intelligent PaaS platform, which supports plug-in type connection of industrial mechanism models and microservices and allows third-party developers to quickly generate various industrial intelligent applications. This platform features the strong component-based upgrade capability. In addition, the ET Industrial Brain open platform consistently reduces the technical skill requirements. It provides supports for process experts and product line experts to create and accumulate knowledge and activates the internal think tanks of the enterprises, forming a virtuous cycle.
ET Industrial Brain is a general architecture that integrates the data factory, algorithm factory, AI workshop, and industrial applications.
Data factory: Functions provided by the data factory can support all the capability fields and items for data management. It provides the one-stop data resource management service for users, and helps users conveniently complete multiple data management applications, including the data architecture, data standard, data quality, data application, and data lifecycle management. This provides the full, standard, clean, and intelligent data for the upper-layer data applications of ET Industrial Brain.
Algorithm factory: It is an industry-oriented comprehensive algorithm management platform. It decouples algorithms from applications and enables reuse of algorithms through integrated management of the algorithm deployment, access, debugging, and call processes. Applications can quickly encapsulate solutions and improve the algorithm engineering efficiency based on the unified interfaces of standardized products.
AI workshop: The industrial brain AI workshop is a WYSIWYG (what you see is what you get) visualized service orchestration tool. Developers can assemble the service flow, service data dictionary, service rule, and industrial rule components by dragging and dropping, thus meeting the AI requirements in specific business scenarios.
Industrial application: An open application service platform leads to the prosperity of the industrial ecosystem. Multi-dimensional and end-to-end intelligent application services are provided from the following dimensions: supply, research, production, sales, energy, and environment.
The ET Industrial Brain open platform provides the ecological cooperation mode for data integration, data analysis, algorithm model, and application development. With the customer authorization and control, the factory information departments, process optimization departments, cooperation companies, third-party companies, and industrial research institutes can participate in the data test and intelligent analysis of enterprises, and the image-based drag-and-drop algorithm of the AI workshop significantly reduces the application difficulties of industrial algorithms. Therefore, implementation is not constrained by a specific company or technology, and an open intelligent industrial ecosystem centered on ET Industrial Brain is built to eventually form a virtuous, active, and innovative intelligent industrial ecosystem.
Based on the ET Industrial Brain open platform, eco partners can implement standardized projects. The implementation cycle is shortened from the original six months to today‚Äôs six months. The implementation process requires no reconstruction of the production line, replacement of devices, or production halt.
The ET Industrial Brain open platform is applicable to supply chain intelligence, R&D intelligence, production line intelligence, marketing intelligence, and device health intelligence.
Supply chain intelligence: It analyzes and optimizes the inventory through accurate sales prediction, and uses the intelligent recommendation algorithm to minimize the inventory and improve the logistics and distribution efficiency.
R&D intelligence: It provides assistance for process optimization, recommends process parameters for different scenarios based on analysis of massive data, and predicts indicator distribution and yield rate of finished products.
Production line intelligence: It perceives the manufacturing process of devices in the workshop based on the running data of devices. Then, it locates the most critical factors that affect the yield rate and the recommended process parameter solutions, and improves the operation efficiency and yield rate.
Production line intelligence: It consolidates all the production, switching, and integration data from the production site to production management, and establishes the comprehensive digital description about the production process.
Device health management: It performs dynamic monitoring, early exception alert and fault prediction on the running status and key parameters of devices, and improves visibility of the general health status of devices.
By May 2018, more than 20 customers that directly adopt ET Industrial Brain. These customers are mainly leading enterprises in each industry or enterprises with good information systems. Major industrial intelligent services include the production process parameter optimization, production yield rate improvement, production device monitoring and warning, product image intelligent check, and supply chain process optimization. ET Industrial Brain currently has serviced some leading enterprises in more than 10 manufacturing fields in China. Typical cases are as follows:
Photovoltaic: ET Industrial Brain helps GCL Photovoltaic, which occupies the largest market share in the world, to improve the yield rate by 1% and increase the annual profit by billions of RMB. ET Industrial Brain also helps Trina Solar, which delivers the largest number of PV components in the world, to improve the yield rate of cells by 7% and increase the annual profit by thousands of RMB.
Rubber: ET Industrial Brain helps Zhongce Rubber, which is the ‚Ññ1 rubber enterprise in China, to improve the internal mixing qualification rate by 5% and increase the annual profit by thousands of RMB.
Oil and Gas: ET Industrial Brain helps Hengyi Petrochemical, which has the highest PTA capacity in the world, to improve the coal combustion efficiency by 3.9% and increase the annual profit by billions of RMB.
Energy: ET Industrial Brain helps DunAn Group, which is the leading enterprise in the wind power generation field in China, to detect potential faults of fans one to two weeks in advance and reduce the annual O&M cost by 30%.
Telecommunications: ET Industrial Brain helps Comba, a world leading radio telecommunication manufacturer, to improve the product commissioning efficiency by 43% to 100%.
Others: ET Industrial Brain also serves other leading enterprises in the manufacturing industry, including GCL System Integration (world‚Äôs leading comprehensive distributed energy system integrator), Pangang Group (world‚Äôs ‚Ññ1 vanadium producer), and Kailin Group (one of the top 3 phosphate rock producers).
Typically, a data collection partner builds the cloud infrastructure on the industrial site, and implements data collection, data matching, and data migration to cloud. You are expected to meet the following requirements:
Cooperation mode: Project cooperation (framework supplier)
Division of responsibilities: Independent sub-contract project
Business model: Project subcontract agreement and standard framework price
Delivery mode: Onsite + Remote
Technical abilities:
As a database development partner, you are expected to clean, consolidate, and analyze data that has been migrated to the cloud, construct the enterprise data model, and provide the data after governance for business applications.
You are expected to meet the following requirements:
Typically, an algorithm development partner provides the vertical industry algorithms, and releases the algorithms to the algorithm factory or AI workshop of ET Industrial Brain to meet the application requirements of the implementation team.
You are expected to meet the following requirements:
Cooperation mode: Release of algorithms
Division of responsibilities: Providing the industrial intelligent algorithms
Business model: Allocation of software purchase/sales profits
Delivery mode: Remote
Technical abilities:
As a system integration partner, you are expected to develop the AI service based on the algorithm models trained in the AI workshop to quickly complete SaaS applications that meet customers‚Äô requirements.
You are expected to meet the following requirements:
Cooperation mode: Project cooperation
Division of responsibilities: Independent sub-contract project
Business model: Project subcontract agreement
Delivery mode: Onsite + Remote
Technical abilities:
Typically, a channel partner expands the vertical industry customers, explores the digital requirements of the industrial enterprises, and sells the Alibaba Cloud ET Industrial Brain products.
You are expected to meet the following requirements:
Cooperation mode: Channel sales
Division of responsibilities: Independent sales and delivery of projects
Business model: Integration with the industrial brain, tiered pricing
Delivery mode: Onsite + Remote
Technical ability: Industrial experience, customer relationship, and business management
The cloud computing and big data based IT AI technology is a field completely different from the traditional industrial sectors. The AI technology must be deployed in the industrial sectors. It requires in-depth integration across different sectors, and collaboration and complementation of multiple skills, technologies, and cultures.
When ET Industrial Brain is being deployed on applications of the industrial production lines, data scientists learn from production process experts based on the cloud computing and Internet infrastructure, and use machine learning to mine and analyze data and predict the industrial models. In this integration process, ET Industrial Brain serves as the middle platform to implement effective exchange and collaboration between technologies, concepts, and knowledge in different fields for the first time, and generates huge economic values for the industries. So, what are you waiting for? Come and join us.
To learn more about Alibaba Cloud ET Industrial Brain, visit https://www.alibabacloud.com/et/industrial
Reference:https://www.alibabacloud.com/blog/building-a-fully-open-industrial-intelligent-paas-platform-with-et-industrial-brain_594261?spm=a2c41.12414249.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
1 
1¬†clap
1 
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@edtechchina/how-does-paas-provider-agora-io-boost-partners-overseas-expansion-amid-global-remote-learning-df89df2c4287?source=search_post---------58,"Sign in
There are currently no responses for this story.
Be the first to respond.
GETChina Insights
May 21, 2020¬∑6 min read
‚ÄúDuring the COVID-19 epidemic, Agora.io‚Äôs daily duration of the voice and video calls of all users doubled, reaching 1.56 billion minutes. The peak value of the minutes increased by seven times and ten times in the education industry, remote work industry, respectively. ‚Äù Said Zhu Chaohua, the product manager of Agora.io.
Founded in 2014, Agora.io enables developers to add HD interactive broadcast, voice, and video calls into mobile and web apps through SDK. Now the company is committed to empowering online education globally with the technological advantages and seeking more cooperation opportunities. The COVID-19 crisis has accelerated OMO in the education sector; thus, will it promote Agora.io‚Äôs overseas footprint? JMDedu writes this article to figure out the answer.
Empowering eight educational scenarios, Agora.io is promoting educational equity
Online education and telecommuting industries have been most affected by the coronavirus. According to the data from iiMedia, during the Spring Festival break, over 18 million Chinese enterprises switched to telecommuting, more than 300 million people were involved. UNESCO also reveals that as of March 4, more than 290 million students worldwide were affected by the school suspension.
The epidemic once again stimulates the growth of online education. Although online classrooms have been relatively mature, they still face significant technical challenges in real-time interaction. To empower remote learning globally, Agora.io improves its online education solutions covering four basic teaching modes(1-on-1, small-sized class, large-sized class, and dual-teacher class) and four innovative educational scenarios (gamification, online music teaching, AI interactive classroom, and group learning for large-sized class).
For 1-on-1 teaching mode, Agora.io has fixed the technical problems by SD-RTN‚Ñ¢, which is the world‚Äôs most widely used and intelligent RTC (Real-time communication) network, introduced by Jin Yeqing, the technical staff at Agora.io.
It allows foreign teachers in North America, the Philippines, and other overseas regions to teach online, addressing the challenges with the cutting edges, including high concurrency, stable messaging mechanism, weak network anti-loss guarantee, and extreme-low latency. It also enables students with poor network connections in China to access more high-quality online resources. Plus, Agora.io introduces dual-teacher into online large-sized class, thus students in third- and fourth-tier regions can listen to the classes taught by excellent teachers from developed areas.
Since Agora.io has built up emergency plans in light of experience to deal with the sudden traffic surges, the company has not made large adjustments amid the outbreak. Still, it has just established some temporary virtual teams to mobilize resources for emergency response. ‚ÄúMeanwhile, in terms of terminal performance and adaptation, we optimized the last mile of the real-time network to ensure smooth interaction even in rural areas.‚Äù Says Dekui Zhao, the Director of Customer Success in charge of educational business.
Covering 200+ regions, Agora.io has established a global vision since its inception
As one of the top players providing leading voice, video, and live interactive streaming services in the Platform-as-a-Service (PaaS) market, Agora.io has taken serving the overseas companies or developers who are going to promote the global business as its mission since the inception.
Agora.io admits that the company will face different challenges when serving educational consumers who are going overseas. ‚ÄúThis is mainly related to their development stage and needs. For example, some customers are looking for market fit, while some focus on attracting more users or expanding brand reputation.‚Äù Says Virginia Liu, SVP, Marketing, and Ecosystems at Agora.io. She also regards that companies who are expanding their footprint overseas always focus on the attributes of education. ‚ÄúIt is difficult to have an in-depth understanding of all aspects of the overseas market.‚Äù Says her.
To satisfy the diversified needs, the company has built up more than 250 data centers across the world, as well as technical and service teams based in different cities, including Bangalore, Tokyo, and London. ‚ÄúThis kind of layout can better help us develop more local customers and support Chinese companies‚Äô global business. ‚Äù Says Jin Yeqing. ‚ÄúOnce our engineer flew express to India to support a social media platform to launch a video call function.‚Äù
Virginia Liu also suggests that the COVID-19 epidemic has spurred online education in more regions. ‚ÄúEducators in Europe and America focus more on sports and hands-on practice, but less on extracurricular tutoring, so many educational activities are still delivered offline.‚Äù
As Edmodo acquired by NetDragon has been selected by the Ministry of Education in the Arab Republic of Egypt to be the designated remote learning platform, Agora.io‚Äôs efforts have also been recognized by the official. Cooperating with the Ministry of Education of several Middle Eastern countries and local K-12 educational institutions, the Saudi Arabian education platform Noon Academy supports students to continue their study amid the global crisis. ‚ÄúThrough the collaboration with engineers at Agora.io, Noon Academy completely moved its business from the original plan to our platform within a week. This practice ensures the quality of the delivery of online resources, as well as the coverage of local users.‚Äù Said Virginia Liu.
Improving RTC edges, Agora.io boosts partners‚Äô growth across all lines of business
As of now, the company‚Äôs service covers more than ten industries, including live social broadcast, education, gaming, finance, medical care, and corporate collaboration in more than 200 countries and regions like Southeast Asia, Middle East, North America, Europe, etc. According to the company, more than 40 Billion minutes of live interactive video and voice content streamed monthly on Agora.io‚Äôs network in Q1.
Internet traffic is surging thanks to the coronavirus, as millions of people work from home or go to school online during the epidemic, but not limited to these two sectors, the development of RTC has allowed ‚Äúnon-contact‚Äù real-time interaction to penetrate all aspects.
Virginia Liu believes that the coronavirus outbreak will generate more diversified virtual real-time interactive scenarios on the consumer side. ‚ÄúInternet + electronic devices + real-time audio and video applications can allow us to enjoy a more colorful online experience, including education, health care, IoT, and many other fields.‚Äù Moreover, the coronavirus has forced consumers to change their minds.
On the enterprise side, a new generation of team collaboration applications will occur as an emerging scenario. Although the digitalization of companies has been carried out for many years, the pandemic has directly accelerated this process worldwide. At the current stage, Agora.io is aiming to boost partners‚Äô growth, even revolutionizing the retail sector. ‚ÄúI think that the real-time communication and digitalization will be fast-growing scenarios with huge potentials, and this trend is likely to continue after the epidemic since it does solve existing problems of teleworking in all the industries.‚Äù Says Virginia Liu.
To get the most up-to-date China EdTech news and stories, please visit our official English website, subscribe to our weekly newsletter, or follow us on LinkedIn and Twitter.
Supporting the EdTech ecosystem in China & globally. Operated by JMDedu, the leading B2B industry media company in China. Website: https://en.jmdedu.com/
1 
1¬†
1 
Supporting the EdTech ecosystem in China & globally. Operated by JMDedu, the leading B2B industry media company in China. Website: https://en.jmdedu.com/
"
https://medium.com/@ContinoHQ/3-common-mistakes-people-make-when-looking-at-multi-cloud-iaas-paas-in-the-enterprise-f5f2cf9d08e0?source=search_post---------59,"Sign in
There are currently no responses for this story.
Be the first to respond.
Contino
Jan 28, 2019¬∑2 min read
These quick thoughts come from the mind of Benjamin Wootton, Co-founder and CTO of Contino.
A few quick thoughts on some approaches that I see time and again in the enterprise that will stop you from getting the most out of your cloud programme.
1. Cloud Broker: Putting big enterprise-y bloatware between you and your cloud APIs
The multi-cloud sales pitches emphasise the consistent experience and controls across clouds, but the reality is that you end up stuck with outdated APIs, leaky abstractions, and tied into lowest common denominator services. Stick with native access to your cloud!
Be careful as data centre-centric software companies are trying to sell their rebadged old stuff as hybrid to remain relevant.
2. Portability Obsession: Avoiding tie in to higher-level services in the name of portability
This means you miss a lot of the time-to-value benefits of the cloud when the chance that you will actually want to move are tiny.
Keep an eye on portability, but don‚Äôt throw the baby out with the bathwater!
3. Split Investment: Reducing momentum by spreading yourself too thin
Building an enterprise cloud platform and getting momentum behind adoption is hard. Splitting your investment, hiring efforts and engineering programmes across multiple clouds means that you will struggle to achieve critical mass or demonstrate rapid ROI, so your cloud adoption programme will come under pressure.
Our advice is to come down off the fence and do some business valuable work with one cloud provider in a cloud-native manner.
So you‚Äôve heard the Gospel of Cloud?
How do you make sure you get everything promised to you?
You need to evolve your operating model!
We‚Äôve worked out the fundamentals through seeing it go well (and not so well) at countless clients and summarised it in our Cloud Operating Model white paper here. If you like clouds, operations or models, there might be something of interest.
Contino is a global DevOps and cloud transformation consultancy that enables highly-regulated organizations to accelerate innovation.
See all (686)
28 
28¬†claps
28 
Contino is a global DevOps and cloud transformation consultancy that enables highly-regulated organizations to accelerate innovation.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/crowdbotics/how-to-know-if-you-should-switch-to-a-platform-as-a-service-paas-solution-b2ec5a2b58be?source=search_post---------60,"There are currently no responses for this story.
Be the first to respond.
Platform as a Service is a cloud computing environment where a third-party service provider offers hardware and software tools for clients over the internet. PaaS allows businesses to easily deploy, run, and manage cloud applications without the complexity of setting up and maintaining their own servers and infrastructure. Thus, PaaS frees developers from having to install in-house hardware and software for development or hosting.
Many PaaS providers also offer fully managed, cloud-based data services along with platform services. These services enable developers to swiftly integrate data into their apps, as well as access and work with that data, all without having to set up and maintain their own databases.
PaaS providers also typically offer value-added tools that enable developers and teams to remain productive when deploying and running their apps.
To better understand the PaaS ecosystem, let‚Äôs review some major PaaS providers.
AWS Elastic Beanstalk is one of the top PaaS providers due to the fact that it has nearly unlimited cloud capabilities. AWS Elastic Beanstalk can be used to deploy and run web applications built using various languages, such as Java, .Net, PHP, Ruby, NodeJS, and Python. You just have to upload your code using your preferred tools, and AWS Elastic Beanstalk will handle everything else, including deployment, provisioning, load balancing, and auto-scaling.
Oracle Cloud Platform has been a key player in the IT field even before the arrival of cloud computing. As a result, it is also a key player in the PaaS market. OCP merges both open source and Oracle proprietary technologies. You can develop apps, deploy, run, manage builds, and oversee operations with ease using OCP. OCP also leverages machine learning to offer essential self-repairing capabilities.
Microsoft Azure is not only a PaaS provider but also offers software-as-a-service (SaaS) and infrastructure-as-a-service (IaaS) components together. PaaS features offered by Azure include all standard features such as infrastructure, servers, storage, networking, middleware, runtime environments, security solutions, OS, databases, analytics, and development tools.
Google App Engine is Google‚Äôs PaaS service. It‚Äôs integrated with Google Cloud Platform, which uses the same infrastructure as the Google search engine.
Similar to other PaaS providers, Google App Engine provides a fully managed cloud platform to develop, deploy, and manage your applications. Therefore, organizations don‚Äôt need to bother with infrastructure provisioning or configuration. They can also let Google App Engine handle scaling.
A CTO must assess various aspects of their business before making the decision to switch to PasS. Some of the main concerns are listed below.
In terms of costs, you need to determine the strategic implication of adopting PaaS. Your return on investment (ROI) should justify the transition. Your costs are not always operational in nature, but also include resources, deployment, and developing the application. For small businesses planning to scale, it‚Äôs vital to understand the business case and the effective ROI for a switch to PaaS.
Security is one of the major concerns that you should investigate when developing a cloud-dependent application or moving their business to PaaS. Security is multifaceted; hence, you will have to handle identity access management, encryption, compliance, roles, policies, and management. It‚Äôs best to determine both your current security requirements and also create a high-level list of likely issues that might arise in the future.
Preparing a better governance plan will help you remain consistent with your development policies. Your governance strategy defines what can be done, who can do what, and how different tasks will be managed.
Deciding to leverage a PaaS platform is usually a technical consideration first and foremost. Therefore, you need to ensure that automated deployment and testing will add value to your business. DevOps is a great fit for cloud computing because of its ability to leverage the technology effectively.
Testing each component, a set, or the entire solution using an automated approach is possible using the cloud, and many cloud platforms are built to support DevOps best practices.
You need to prepare a comprehensive plan to manage and monitor your cloud operations. From a management perspective, you need to look into performance, configurations, and security. Monitoring can be real-time and event-driven for a more reliable, hands-off approach.
How can PaaS give your engineering team an edge? Let‚Äôs take a look.
PaaS enables developers to build apps more quickly than if they had to build and configure their own platforms and infrastructure. PaaS gives developers a complete software development environment which consists of sample code and pre-built components.
PaaS eliminates the need to develop applications from scratch and thereby reduces the costs normally associated with development. PaaS is a reliable option for companies who are trying to reduce their current operational costs, develop an application for the first time, or make the most of limited resources.
Like most other cloud services, PaaS offers dynamic scaling. When you need a more robust infrastructure, your provider will automatically supply it and will scale back when the demand is low. You only have to pay for what you use, which will save you money overall, while ensuring that your clients are not facing slow, lagging connections due to a lack of network capabilities.
PaaS experts keep on incorporating and testing component updates constantly and only deploy them to production when they meet critical conditions. With PaaS, you will get a tech stack that keeps you updated with time and ensures that your application is running on the latest technology.
PasS providers heavily invest in security technology and expertise. They offer continuous security updates for individual stack components. This ensures the safety of user data so that developers can develop apps more confidently with PaaS.
Adopting PaaS is not without a few risks. Here are the primary challenges to consider.
Sometimes it can be difficult to switch PaaS providers once your application is built because it is developed using a particular platform and set of tools. Every vendor may not support the same programming languages, libraries, APIs, operating systems, or architecture that was used to develop and run your application.
Even if it is possible to switch PaaS providers, the process will be hard, time-consuming, and expensive. Changing providers may even require you to rebuild or modify the application to fit the new platform.
All the parts of your company‚Äôs existing infrastructure may not be built for the cloud. If some components cannot be cloud-enabled successfully, you might have to switch various apps and programs to fully integrate, or you may need to remove some of these things from the cloud and within your existing infrastructure.
In the PaaS architecture, most of the application‚Äôs data, along with its code, are stored by the external provider. In some cases, the vendor may store the database through a third party.
In such a condition, it may be difficult to fully evaluate the security measures of a PaaS provider. Nevertheless, you should do your best to understand your provider‚Äôs security and compliance protocols before switching to a PaaS platform.
In order to make a transition to a PaaS solution, first, you need to determine your use case. Are you transitioning to leverage a database, DevOps, security, or governance? You need to do an in-depth future state assessment before you can define the new architecture, provision resources, and migrate to the platform.
Consider a case where you want to leverage the cloud for improved DevOps infrastructure. Your plans may include automating development, production, and testing operations using an Agile approach. To achieve this, you need to choose the tools that you plan to use. Your basic requirements might include continuous coding, continuous integration, and continuous testing. Once you‚Äôve determined which tools and frameworks you intend to use, you can narrow down your search for a PaaS provider to only those platforms that support your desired use case.
Moving to a PaaS service is not just an IT decision. It‚Äôs a business decision, and adopting new technology within the organization is always tricky. There are some major factors that might impact your migration to PaaS.
You have to assess the readiness of your teams to support the new cloud strategy. The roles of cloud architects, developers, and engineers, and the skills they require, are in demand and rapidly evolving. Knowledge of a single platform or any narrowly defined category within the cloud is only a fragment of the skills and experience required.
Teams need to have a deep knowledge of your existing infrastructure, the complex pricing models across cloud providers, and the technical expertise necessary to overcome any challenges that might hold up the process. They need to understand how resources are consumed, how costs are incurred, and how to manage fragmented resources to prevent overprovisioning and underutilization.
On the operations side, teams will need to determine which workloads and applications can be migrated as they are, which should be re-architected, and when to replace or retire expensive features or applications.
You will also need to consider if your company‚Äôs IT team is willing or motivated to make the switch. Employees are reluctant to change by nature. When you have employees who have been doing certain operational processes in a particular way for a long time, they may not be keen to accept changes. You‚Äôll need to hear these employees‚Äô concerns and persuade them that a PaaS migration will benefit them over the long run.
Switching to PaaS is beneficial and sometimes even necessary in some situations. For example, PaaS can be used to streamline workflows when multiple developers are working on the same project. PaaS is especially beneficial when creating custom applications, as it enables developers to focus on the functionalities that make the application unique.
Another major reason for an organization to switch to PaaS is to simplify and reduce organizational expenses. Establishing a physical data center within the organization is a costly and time-consuming affair. It will involve a range of physical resources and skilled technician recruitment. But when you opt for PaaS, the only cost will be for that service. You can also unsubscribe at any time when you feel the service is not needed anymore.
For obvious reasons, PaaS platforms are mostly used by software development companies. They offer numerous benefits to developers, including a perfect environment for developing, testing, and managing applications. In most cases, PaaS is the better choice for software development companies.
In addition to development companies, creative agencies, consultancies, and internal IT teams can leverage PaaS in order to build feature-rich apps and services efficiently, accelerating the time-to-market.
Moreover, PaaS is a good option for startups and other small and growing businesses for two reasons. The first one is that it reduces the cost. The second is that it eliminates risks associated with owning software licenses and maintaining infrastructure.
If you decide that the benefits that PaaS will add to your organization outweigh its potential drawbacks, there are ways to switch over and use PaaS in a way that maximizes its benefits and gives you the best experience.
Ensuring that you are paired with the right PaaS provider is the essential step for ongoing success with this approach. You should choose a provider that is a good fit for your overall business requirements, and only after conducting a thorough assessment of those requirements.
Before the transition, you should consider ensuring that your company will stay compliant with all relevant regulations, have the right security measures in place, and have redundancy and backup processes prepared in case something goes wrong. You should take every opportunity to tailor your PaaS system to exactly what you need.
This can be done by analyzing your data, existing resources, business goals, and current needs, and by working with your provider to find the right environment for your company. If you are worried about executing the migration to PaaS, work with a provider that offers setup and full migration. Whether you completely hand over this aspect of the system to your PaaS provider or add a member of the provider‚Äôs integration team to own IT team temporarily to complete the process together, having an expert on board is a great way to migrate your existing systems without running into problems.
Moreover, you need to make sure that your provider is always ready and willing to provide support at any stage, from the initial implementation and deployment, through monitoring operations and performing upgrades and security patches.
Apart from switching to a PaaS platform mentioned above, you can also use Crowdbotics, which functions as a PaaS platform with built-in, fully customizable DevOps, deployment, and hosting. With the Crowdbotics App Builder, you can build full-code software applications extremely fast without any coding skills. Crowdbotics makes this possible by offering hundreds of widely used code packages and app templates that users can snap into their custom web or mobile app with a single click.
Furthermore, Crowdbotics offers a complete DevOps pipeline for every application you create, including database, hosting, security, staging, and production instances. This automated infrastructure is available both to users of the Crowdbotics App Builder and to our Managed App Development clients, so if you are interested in building a custom app with a modern cloud hosting solution, please get in touch.
The cloud has drastically changed the way software applications are developed and deployed. Businesses are also in search of solutions that help speed up their processes and minimize costs. In most cases, leveraging a PaaS approach adds the necessary flexibility and efficiency that is essential for driving businesses towards growth.
Originally published on the Crowdbotics Blog November 17, 2020.
The fastest way to build your next app.
10 
10¬†claps
10 
Written by
Senior Software Engineer and Freelance Technical Writer. I write about any Computer Science related topic. https://www.linkedin.com/in/shanikawickramasinghe
The fastest way to build your next app.
Written by
Senior Software Engineer and Freelance Technical Writer. I write about any Computer Science related topic. https://www.linkedin.com/in/shanikawickramasinghe
The fastest way to build your next app.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@IBMDeveloper/when-to-use-iaas-faas-paas-and-caas-9049155ebc11?source=search_post---------61,"Sign in
There are currently no responses for this story.
Be the first to respond.
IBM Developer
Jul 2, 2019¬∑2 min read
Newcomers to cloud computing might be a bit put off by the sheer number of acronyms in use, as there are a fair amount. In addition, just about everything is sold as a service (aaS) these days, even transportation. To try to clarify some of the available offerings, let‚Äôs have a look at some of these aaS acronyms, namely infrastructure as a service ( IaaS), platform as a service ( PaaS), containers as a service (Caas), and serverless, which is also known as function as a service ( FaaS).
When trying to decide which of these offerings is most suited to you, one (not incredibly helpful) way to look at it is: how much money do you have to spend?
Let‚Äôs start with the most expensive solution and work our way down. If you have an unlimited budget, you might not need any of these offerings. You could buy your own building, fill it full of racks of servers and networking gear, and hire your own staff to install, run, and maintain it. You‚Äôll probably need a fair share of air conditioning units as well.
But that isn‚Äôt likely the case. Even government entities with unfathomable budgets hire outside companies to run data centers for them. Why? Because realistically, doing all that yourself is quite a pain, and probably what brought about cloud computing in the first place. Which brings us to the first offering up for discussion: infrastructure as a service (IaaS).
You can read the full article on IBM Developer.
Originally published at https://developer.ibm.com.
Open source, code patterns, tutorials, meet-ups, challenges, mentoring, and a global coding community ‚Äî all in one place.
1 
1¬†
1 
Open source, code patterns, tutorials, meet-ups, challenges, mentoring, and a global coding community ‚Äî all in one place.
"
https://medium.com/@mikethebbop/convincing-enterprise-business-looking-for-iaas-saas-paas-to-think-google-aad068d78474?source=search_post---------62,"Sign in
There are currently no responses for this story.
Be the first to respond.
Ira Michael Blonder
Mar 24, 2016¬∑2 min read
Recent Google news reports speak to an interest in building Google Cloud business with enterprise business customers. Just today (March 23, 2016), in an article titled ‚ÄúGoogle Showcases Its Cloud Efforts, Determined to Catch Up to Rivals‚Äù Steve Lohr of the New York Times opined on the topic.
A lot of copy has been written on the addition of Diane B. Greene, one of the founders of VMware, as a step forward, by Google, towards a more attractive presentation for enterprise business prospects. Steve Lohr‚Äôs story shares this topic. On Ms. Greene he notes ‚ÄúShe knows the enterprise computing business, which has not been Google‚Äôs strength‚Äù.
Leaving aside the unhealthy sprinkling of opacity throughout the article (for example, what does ‚ÄúShe Knows‚Äù mean in the sentence I quoted above? Or how did Mr. Lohr reach the conclusion enterprise business has, ‚Äútraditionally‚Äù, bought ‚Äúexpensive software‚Äù?), the main issue I have with Mr. Lohr‚Äôs story, as someone who has collaborated and partnered with enterprise business customers for over 20 years on software purchases, is twofold:
What my customers are looking for are hybrid solutions with a bridge between their on-premises data centers and IaaS/SaaS/PaaS offers. Any potentially attractive hybrid cloud offer will have to include a convincing argument for data security.
Hybrid cloud and access controls built on Microsoft‚Äôs Active Directory may not be flashy. But I‚Äôm confident enterprise business prospects attending the conference will be looking for them as they stroll the exhibit floor. If Oracle can learn to speak the right language, how come Google is struggling?
35 years non stop experience marketing & selling IT products to very large organizations. MA in English. Technical Writer. MARCOM & PR writer. Product Mktng.
1 
1¬†
1 
35 years non stop experience marketing & selling IT products to very large organizations. MA in English. Technical Writer. MARCOM & PR writer. Product Mktng.
"
https://medium.com/readwrite/are-you-making-a-major-security-mistake-with-paas-34aece22a82c?source=search_post---------63,"There are currently no responses for this story.
Be the first to respond.
Not too long ago ‚Äî before PaaS was as prevalent as it is now ‚Äî there was just SaaS. These services mainly delivered various capabilities and applications via the cloud. The SaaS solution is generally well-adopted point solutions. They are managed and run by third-party companies such as Salesforce. The SaaS company takes on the burden of technical issues, storage, and security. SaaS is an out-of-the-box solution, requiring limited IT staff at hand to manage.
The first major milestone in PaaS history came in 2007. After years as a customer relationship management tool, Salesforce launched Force.com. Force is a platform version that allowed businesses to create custom software. With PaaS, businesses gained the power to write their own code and have complete control over database-driven applications.
The value proposition of PaaS is compelling: If the original version of Salesforce lacks a capability your business needs; with PaaS, you can build it yourself.
Of course, Salesforce wasn‚Äôt the only company dipping its toes in the PaaS world. Platforms like Heroku, Amazon Web Services, and Google Cloud have also become major players in the space. By 2013, PaaS had gained major momentum, boasting 2 million apps downloaded on Salesforce‚Äôs AppExchange.
With this evolution, businesses could easily integrate social media and CRM data, allowing for unprecedented insights and streamlined processes. Of course, major companies saw the possibilities PaaS offered early in the technology‚Äôs history and quickly jumped on the bandwagon, driving even more growth in the platform space.
With SaaS, you‚Äôre limited to the features and capabilities that already exist within the program. All you have to do is flip the switch on what capabilities you want to be activated, and you‚Äôre off and running. For PaaS to work well for you, you‚Äôll want to know your company‚Äôs security policies, know what information you have, and know who can upload and access that information.
PaaS, meanwhile, gives you a lot of control ‚Äî but that control comes with a lot of responsibility. As you start to build your own complicated systems on top of a platform, you need to ensure you‚Äôre carefully controlling access to company and customer information.
One of the more common mistakes businesses make when deploying PaaS is assuming that people who administer the system have a firm handle on who has access to what information in the system.
There‚Äôs a misconception that a centralized control mechanism inside the organization oversees what gets built and ensures that it has the appropriate quality and security controls. While Salesforce and similar platforms do have incredibly robust security models that allow businesses to control access in a fine-grained fashion, businesses usually aren‚Äôt doing this correctly. It‚Äôs simply not happening.
This mistake derives from the extreme user-friendly nature of PaaS, particularly Salesforce‚Äôs version. Literally, anyone can build an application on it. The blessing and curse of PaaS are that someone like Bob in finance could be building this excellent business-enabling app that, in the old days, would have been developed as an in-house product such as an Access database.
People are getting things done, and it‚Äôs great, but Bob might not fully understand the risk of storing information in the cloud. Bob could be sending this database around asking people to populate it with data, thinking everything is excellent and secure because it‚Äôs ‚Äúin the cloud.‚Äù
Everyone else trusts Bob and is operating under a mistaken assumption that the security controls are there. Before you know it, you‚Äôve got a huge unsecured database of sensitive information. For example, you might find out later that the application or database is integrated into your website, and customers are typing in their Social Security numbers when asking for help.
Or maybe the database is open to public users ‚Äî a lot of PaaS novices accidentally allow access to the outside world. Suddenly, you‚Äôve got people logging in and changing their own information. The exposure is unthinkably broad. Not great.
You can totally build amazing workflow processes that could transform your business. But before you forge ahead, you need to take a look at PaaS systems as being under the same scope as any other robust data classification formats you commonly leverage to understand the information in any given system. PaaS needs to fall under the same scope and receive the same consideration you have for all your SQL server databases, your in-house systems, and anything you have running on the cloud, such as infrastructures as a service like AWS or Microsoft Azure.
Bottom line: The applications you build with PaaS won‚Äôt necessarily change the strategic posture of your organization, but you do need to think of the technology as being a sophisticated, grown-up system that requires strategic planning and foresight.
PaaS takes a complicated process ‚Äî building software applications ‚Äî and makes it accessible and straightforward. This is great, except there are a lot of things going on behind the curtain that the average Bob from finance might not be able to appreciate. There are a lot of questions he won‚Äôt even know to ask!
When you have blind spots, you may end up storing data that‚Äôs not in line with how you would typically store that type of information. Or maybe you don‚Äôt even know what information is in the system and therefore can‚Äôt possibly know how to protect it correctly. Or, not to pick on Bob from finance again, but he probably doesn‚Äôt even know what the company‚Äôs policies are regarding information storage and sharing.
With PaaS, it‚Äôs all too easy to store super-sensitive information and then allow everybody in your company to run, export, and save reports that have that information.
If you don‚Äôt know the information you‚Äôve got, and you don‚Äôt know how you‚Äôre controlling access to it, then you are absolutely at risk for a data breach. And these days with data breaches, it‚Äôs a matter of when not if. Just in the first half of 2019, nearly 31 million records were exposed.
No industry or business is immune, and the consequences are genuine and very negative. Picture your data breach appearing in a Wall Street Journal headline big. Sure, most data breaches are caused by hackers and criminals. But they are also just as likely to occur from an internal source because of human error or improper security practices.
Using PaaS responsibly boils down to the idea that knowledge is power. Know your company‚Äôs security policies, know what information you have, and know who can upload and access that information. Otherwise, your information will take on a life of its own and will eventually land you in a world of trouble.
Image source: philipp-katzenberger ‚Äî Unsplash
Are You Making a Major Security Mistake With PaaS? was originally published on ReadWrite on October 12, 2019 by Pete Thurston.
ReadWrite is the leading media platform dedicated to IoT‚Ä¶
1 
1¬†clap
1 
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
Written by
The latest #news, analysis, and conversation on the #InternetOfThings
ReadWrite is the leading media platform dedicated to IoT and the Connected World. We work with the industry's top technologies, thinkers, and companies to tell the stories that drive this world forward.
"
https://medium.com/@arschles/good-point-michael-the-system-im-describing-is-similar-to-a-paas-approach-1943f53eedea?source=search_post---------64,"Sign in
There are currently no responses for this story.
Be the first to respond.
Aaron Schlesinger
Dec 22, 2017¬∑2 min read
Michael
Good point, Michael. The system, I‚Äôm describing is similar to a PaaS approach.
I worked on a PaaS for Kubernetes (Deis Workflow) and have seen the pros and cons of the approach. Folks loved ‚Äî and still love ‚Äî Workflow because it makes things so simple.
I purposefully didn‚Äôt mention the word because I want to convey that this thing doesn‚Äôt ship with limitations that other PaaS-es do. Out of the box, it abstracts aggressively, but it has escape hatches. If you don‚Äôt buy into the opinionated approach, simply sidestep the abstractions. But know that some of the tools won‚Äôt work properly if you do.
Buffalo ‚Äî a framework for building Go webapps ‚Äî takes a similar stance. As does Ruby on Rails.
Many PaaS-es reach all the way down into your code, build it for you (buildpacks), and then get it into production. This system assumes you already know how to build your code ‚Äî and even build a Docker image out of your artifacts.
If you want to add buildpacks to the system, build a service in Kubernetes that you send your code to. You‚Äôre responsible for the client-server RPC, storing the Docker image somewhere, and then calling system deploy $MY_IMAGE. Draft does something like this now.
The key point I‚Äôm making here is that the system covers common workloads. You could call it a PaaS because it looks like one out of the box, and that‚Äôs what newcomers need.
But it grows too. You can swap out the templating engine in Rails but you won‚Äôt figure that out on day 1. Similarly, you can opt into Kubernetes primitives as you need; but again, you have to know what you‚Äôre doing.
Gopher, containerizer, and Kubernetes-er
1 
1¬†
1 
Gopher, containerizer, and Kubernetes-er
"
https://medium.com/altoros-blog/2016-in-review-a-varietal-cloud-and-the-paas-revival-b92450aac245?source=search_post---------66,"There are currently no responses for this story.
Be the first to respond.
With Diego 1.0 officially out or ZettaSctructure revolution going on, how else 2016 was different for enterprise IT? This blog post explores two major phenomena of this year: cloud computing growing in a number of specific varieties and the revival of PaaS ‚Äî backed up by figures and facts.
www.altoros.com
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
1 
1¬†clap
1 
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
"
https://medium.com/@marknca/keeping-your-sanity-securing-iaas-paas-and-saas-cloud-services-4b7467f24631?source=search_post---------70,"Sign in
There are currently no responses for this story.
Be the first to respond.
marknca
Mar 2, 2016¬∑7 min read
In most organizations today, cloud services are a fact of life. Whether you‚Äôre deploying and managing servers in the cloud, building on top of a globally distributed platform, or consuming constantly updated services, the cloud is a fundamental part of your IT service delivery‚Ä¶whether you know it or not.
And why wouldn‚Äôt you move to the cloud? The business advantages are clear. You can great reduce the time to deploy new services, reduce your operational burden and costs, and rapidly iterate on new ideas.
There are security advantages as well.
It may require a cultural shift in your organization to accept extending trust to your cloud service providers (CSP), that trust is well place. Top tier CSPs understand that they live and die on their reputation. It‚Äôs in their best interests to deliver a secure service to you.
But that‚Äôs not to say that you don‚Äôt have responsibilities for security when using cloud service. All cloud services (regardless of SPI model; IaaS, PaaS, or SaaS) use this simple model.
Of the main areas of security, the CSP is always responsible for;
Depending on the service, you may be responsible for securing the;
And you are always responsible for;
Put these areas together across all three SPI methods and you get figure 1, ‚ÄúShared Responsibility Model‚Äù.
Looking at cloud security in this manner brings clarity. You can take each type of service (IaaS, PaaS, SaaS) and apply reasonable security controls in order to fulfill your day-to-day responsibilities
It‚Äôs important to note that we‚Äôre talking about day-to-day responsibilities here. You‚Äôre always responsible for the security of your deployments. However you delegate some of the day-to-day work to your CSP. In these cases, you have to trust but verify the work your CSP is doing.
When dealing with IaaS, most of the controls you are used to from the datacenter are still applicable. They‚Äôre just delivered in a different manner in order to optimize for the attributes of a cloud environment.
You see this with controls like intrusion prevent and filtering. Traditionally gateway controls, it is now much more effective to deploy them directly on an instance or virtual machine. This maintains the scalability and flexibility of the cloud without sacrificing security.
Platform deployments can be tricky to secure because of how intertwined your application is with the platform itself. This is a service type where secure design, a strong understanding of the CSP‚Äôs role, and programmable security controls are critical to a successful, secure deployment.
Securing software delivered as a service is typically accomplished using a combination of a CASB (cloud access service broker) and configuring the native service controls in order to meet your security needs.
While the plan for securing each service type is clear, the pace of change in this space is a major challenge.
Cloud services (of all types) are readily available. It‚Äôs never been easier to stand up a new application or service.
This rapid pace of innovation is a huge boon to business. IT is finally a consistent enabler within the organizations.
The challenge is for security to keep pace.
Innovation in at an all time high in the security space but even with current levels of investment and effort, it‚Äôs difficult for security controls to keep pace with the new services being developed.
This rapid pace of change is leading to more and more security solutions being required to properly secure the vast number of services that each organization is using.
The average organization uses a lot of services. Ok, I‚Äôm sure there‚Äôs an actual number but it‚Äôs hard to nail down. Depending on the source, the average is somewhere between 5 and 700. So let‚Äôs settle on ‚Äúlots‚Äù.
Solid guidance exists on how best to secure each of these services according to your needs. The challenge is stitching the security of each of these services together into a cohesive whole.
The industry (lead by organizations like the Cloud Security Alliance, of which Trend Micro is a member) is working towards a common goal to help address this challenge.
The goal is to be able to provide tools that can organizations can get to easily work together (regardless of vendor) in order to provide a comprehensive security solution around cloud services.
The strategic vision and guidance is already in place with the Cloud Control Matrix (the CCM, a living document currently at version 3.0.1). This document lays out the types of controls that should be applied to various cloud services.
In addition to the CCM, there are a number of efforts in place to help organizations combine the right tools for their security needs. The Cloud Security Open API shows a lot of promise in helping make this a reality.
Separate from these efforts are the individual roadmaps for each cloud security tool. This is a very active and innovate space (yes, I realize I have a bit of bias here but just look around at the number of cybersecurity startups and established companies efforts and I think you‚Äôll agree).
But each of these efforts are a medium term solution at best. What are organizations supposed to do now to address this problem?
When attempting to address this problem today there are 3 main areas where you should focus your efforts.
First you want to try and reduce the organizations overall exposure when it comes to using cloud services.
At solid first action is to attempt to inventory the number and type of services currently in use. To do this you should enlist a combination of technology and old fashioned methods (a/k/a asking teams what they are using).
With a better idea of what you‚Äôre attempting to secure, you can then start working with the teams throughout the organization to ensure that they are aware of the risks and security challenges associated with the services they use.
An ongoing discussion and education campaign is a pillar of the good security practice and critical to address the issue of multi-service use.
These discussions will also help inform your internal security policies. A strong, realistic policy will help establish a baseline for all stakeholders. It lays out what the norms for your organization and acts as a standard to compare against for any new business initiatives.
Above all, the responsiveness of your internal IT services is instrumental in reducing your overall exposure. Many teams don‚Äôt want to go against policy or organizational standards but don‚Äôt have a choice when internal service delivery is unresponsive.
As exposure is inventoried and scaled back (hopefully), your next step should be to implement a robust monitoring practice.
This will require a lot of initial work with an ongoing effort.
The variety of services and security controls applied to those services creates a unique challenge for each organization.
In general, you want to start with the lowest common denominator for monitoring (access logs, basic API access, network traffic, etc.). Where possible these should be tied to business metrics and risk.
For example, knowing that a business unit‚Äôs use of a cloud storage service is increasing week over week is a good monitoring metric (GB used) tied to a business risk (the exposure of that data on a 3rd party service).
Due to the nature of the problem, you best approach is a lot of spit, glue, and hope. This step requires a lot of manual effort but is crucial to being able to answer the deceptively simple questions, ‚Äúwhere is the organization‚Äôs data stored and what‚Äôs it exposure?‚Äù.
With time, your monitoring practice will mature and you‚Äôll grow to have a better understanding of your business requirements.
The lessons you learn should be applied to selecting cloud services that align with your business needs as well as your security strategy and tactics.
The organization should select services that allow you to easily get data in and out, provide support for standard APIs (or at least logical and well supported APIS), and have a strong reputation for services and security.
Choosing a provider based on these attributes will go a long way to ensuring that you have a consistent approach to onboarding new cloud services.
Building a coherent security practice for organizations using multiple cloud services is a challenge today and will continue to be a challenge for the foreseeable future.
The most efficient way to address this challenge is to focus on;
These three areas create a solid foundation for your security practice.
This will allow you to adapt and grow as the strategy for cloud security evolves, as more and more services support standard APIs, and as security technologies continue to provide innovate solutions that better address the new reality of modern IT service delivery.
This essay was built on a talk I presented at the CSA Summit during RSA 2016, ‚ÄúDefending The Whole. Iaas, PaaS, and SaaS‚Äù. It was originally posted in 2 parts on the Trend Micro blog (part 1, part 2). The slides are available on SlideShare.
For some additional thoughts and perspective on my talk, check out this piece by Rob Wright for TechTarget‚Äôs SearchCloudSecurity site.
Mark is a seasoned infromation security professional currently focused on researching & teaching cloud security and usable security systems at scale. Catch him on Twitter or at his site, markn.ca.
‚òÅÔ∏èüî¨ Cloud Strategist @LaceworkInc . @awscloud Community Hero. Builder. Working to make security easier for everyone. Opinionated but always looking to learn
See all (2,068)
‚òÅÔ∏èüî¨ Cloud Strategist @LaceworkInc . @awscloud Community Hero. Builder. Working to make security easier for everyone. Opinionated but always looking to learn
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@ghaff/devops-early-adopters-say-open-source-and-paas-are-key-e8795b88d287?source=search_post---------71,"Sign in
There are currently no responses for this story.
Be the first to respond.
Gordon Haff
Jan 5, 2016¬∑3 min read
With DevOps approaches being used to create and run software across an increasingly broad spectrum of organizations, we‚Äôre now at the point where we can gain quantitative insights from early adopters about DevOps adoption that go beyond the handful of Web-scale anecdotes from the usual suspects. These insights, garnered from an IDC InfoBrief sponsored by Red Hat, DevOps, Open Source and Business Agility (June 2015) include open source as a top priority enabler, the wide range of benefits accrued from using platform-as-a-service (PaaS), and significantly faster software release cycles.
The majority (82%) of the 220 US and European-based IT decision makers surveyed identified open source as a critical or significant enabler of their DevOps strategy. Open source use spanned a variety of technologies including operating systems such as Linux, cloud infrastructure, platform-as-a-service, provisioning, and infrastructure monitoring. IT operations and developer team productivity/agility were cited as benefits of open source as were access to innovation and ease of customization.
At the same time, these early adopters strongly (46%) preferred to use vendor-supported editions of open source software. Indeed, only 12% said that their preferred strategy was to download software from free open source community sites and integrate on their own or with help from service providers.
Many discussions of DevOps talk to the cultural changes required to improve collaboration and increase transparency. However, this survey points to the changes in tooling expected as well. The majority (93%) of the respondents believed that they‚Äôll need new enabling technologies to succeed with DevOps; 85% plan to deploy these new technologies onto either on-premise infrastructure (49%) or dedicated infrastructure at a co-location, hosting, or outsourcing site (36%).
Prominent among the new technologies was Platform-as-a-Service, with 80% expecting PaaS to play a critical role in their DevOps initiatives. They cited benefits such as improved developer and IT operations collaboration (46%), more stable and reliable development environments (40%), greater standardization of development environments (37%), development speed (36%), and faster access to open source community-driven innovation (34%). According to the IDC Infobrief: ‚ÄúPlatform-as-a-service integrates cloud infrastructure, self-service developer platform and tools, and lifecycle management with DevOps processes ‚Äî speeding time to value for both developers and operations.‚Äù
With respect to both PaaS and DevOps more broadly, growth metrics rather than cost cutting is the focus. In IDC‚Äôs words, ‚Äúcustomer facing benefits lead the way‚Äù with increased customer satisfaction and engagement (49%), increased employee productivity (46%), and increased company revenues (45%) the top three responses to the question ‚ÄúBy the end of 2017, what impact do you expect DevOps to have on the overall performance of the business?‚Äù Reduction of operational expenses gets mentioned as well (44%), but it‚Äôs not the main motivation.
The expected impact of DevOps on software release cycles is especially notable ‚Äî specifically an 10x average expected increase in the total number of annual code releases by 2017. The pace may still not be at the level of an Amazon Web Services or a Facebook but it‚Äôs still a major shift from the 63% who today are pushing out two or fewer releases annually per application. At the same time, it‚Äôs worth noting that it will be important to enable data sharing and other connections between these new developments and existing applications. Nearly two-thirds of DevOps projects will need to integrate with legacy systems according to the survey.
This survey primarily focused on key technologies and technology enablers related to DevOps. However, in DevOps, tools are tightly coupled to process and culture. Agile methodologies (43%), implementing common monitoring across dev and ops (43%), and broadly enabling self-service (38%) were all seen as organizational responses to a DevOps strategy. Indeed, the open source aspect plays into DevOps in a broader way than its use in popular DevOps tooling. That‚Äôs because DevOps mirrors central aspects of open source as an approach to developing software in areas such as collaboration, transparency, and working across distributed teams. DevOps uses open source but it also embodies the open source way of developing innovative software.
Red Hat cloud guy, photographer, traveler, writer. Opinions are mine alone.
1 
1
1¬†
1 
1
Red Hat cloud guy, photographer, traveler, writer. Opinions are mine alone.
"
https://medium.com/terri-hanson-mead/microsoft-azure-in-life-sciences-qualifying-the-cloud-iaas-paas-c46816976faf?source=search_post---------72,"There are currently no responses for this story.
Be the first to respond.
As life sciences companies, especially biotech companies, become more and more virtual, they are shifting (or have shifted) to the cloud for applications and infrastructure. It‚Äôs the right thing to do, especially since most don‚Äôt appreciate the value of technology in optimizing business performance and getting to market faster (separate rant).
Simply throwing the responsibility over the fence to the vendors does not relieve a life sciences company of its obligations around ensuring data quality and integrity.
Savvy life sciences companies know this and qualify their underlying cloud infrastructure, whether on AWS, Google Cloud Platform (GCP), or Microsoft Azure.
The qualification process is more than a compliance activity; it can provide value to the business in demonstrating system and process controls, and ensure data integrity. It‚Äôs all about the data, after all.
In this blog post, I share my recommendations for qualifying Microsoft Azure. I will cover the same for GCP in a separate post.
For the purposes of this post, I am focusing on IaaS and PaaS, and not SaaS. For validating a SaaS solution, check out this post from 2018 and this post from 2019.
Qualification versus Validation
In this post I will use the terms synonymously but generally speaking, you qualify infrastructure and you validate applications for a company‚Äôs intended use.
ISPE GAMP5
I am a GAMP girl so my qualification approach is based on the International Society of Professional Engineer‚Äôs guidance documents as detailed in GAMP5 and the associated guidance documents.
CSV versus CSA
FDA released its draft guidance on Computer Software Assurance for Manufacturing, Operations, and Quality System Software and while it was expected to be finalized in 2020, it is now on the docket for fiscal year 2021 per FDA‚Äôs Center for Devices and Radiological Health (CDRH).
The guidance document is intended to shift validation approaches from CSV (computer system validation) to CSA (computer software assurance). If you‚Äôve been following a risk-based approach (as defined in GAMP5) and have been using your noggin to focus on intended use and the value add to the business, there‚Äôs not much of a shift.
Risky Business
Two years ago I qualified GCP for a client (blog post to come) and followed a similar approach for Azure for another client this past year.
It may appear to be largely a documentation effort but it‚Äôs more than that. It‚Äôs all about defining what is needed for the business, executing against those requirements, documenting the baseline, and maintaining the platform in a controlled fashion.
With IaaS and PaaS (and SaaS), there is a lot of reliance on the vendor, and therefore the customer (the life sciences company) needs to oversee the vendor and the platform to ensure an acceptable level of control based on the company‚Äôs risk assessment and risk tolerance. To not do so is a risky business and compliance proposition.
Risk-Based Approach
A risk-based approach was the best thing to happen to computer systems and software when GAMP5 was released. It meant that we could prioritize what we focused on, company by company, system by system, process by process.
This also meant that those folks who liked to apply a cookie-cutter approach to computer validation had to start applying critical thinking to their validation / qualification efforts. It‚Äôs not easy if you just want to check boxes and follow checklists.
A risk-based approach offers up flexibility for companies leveraging software and technology. It is not a one-size fits all approach.
This isn‚Äôt rocket science but if you have not been through a qualification or validation effort, this will be challenging as there‚Äôs a steep learning curve. I have yet to figure out how to get my clients to understand this process until after they‚Äôve gone through it. Expect some discomfort as you go through it for the very first time.
What is Microsoft Azure?
Microsoft Azure is cloud computing services (IaaS, PaaS, SaaS) deployed through Microsoft managed data centers. The companies I work with rely on it as the virtual backbone for virtual machines and other Azure assets to support business applications, databases, and web deployment.
It‚Äôs essential a virtual data center in the cloud.
Above and Below the Line
I draw the line at the virtual machines. Anything above that line is at the application level and should be covered under those application validation plans and activities. Below the line is in scope for the Azure platform.
If we think in terms of a bare metal data center, IT historically commissioned the servers and prepared for application and database installation.
This typically included installing things like the operating system, anti-malware software/tools, monitoring tools, backup software or agents, and other baseline tools used by IT. This is all below the line and what I consider in-scope for the qualification of the Azure platform.
Then it‚Äôs handed over to the folks managing the application project. What they do, even with the help of IT, is above the line.
Deliverables
Remember, if it‚Äôs not documented, it didn‚Äôt happen. I highly recommend that all of the validation deliverables be approved and stored in the company‚Äôs validated document management system (eDMS).
‚Äî GxP assessment for the Azure platform based on its intended use and what is expected to reside on the platform
‚Äî Risk assessment for the Azure platform and determination as to whether to audit Microsoft for Azure
‚Äî Vendor qualification asessment and possible (paper) audit
‚Äî Validation plan for the Azure platform
‚Äî Functional requirement specification (combined FRS/FRA/TMX document)
‚Äî Functional risk assessment (combined FRS/FRA/TMX document) for the Azure platform
‚Äî Technical specification documents for the platform and the virtual machines and other Azure assets on the platform; these provide baseline documentation for operation and control and are created after the migration or the platform / virtual machines / other assets are configured or installed.
‚Äî Migration plan or protocol including verification activities
‚Äî Executed migration and supporting documentation
‚Äî Migration plan summary report
‚Äî Testing summary to document any verification activities performed whether automated or manual
‚Äî Traceability matrix (combined FRS/FRA/TMX document)
‚Äî Procedures (SOPs) and work instructions (WIs) to operate and maintain the Azure platform in a controlled fashion
‚Äî Trained administrators on the platform and SOPs/WIs
‚Äî Trained personnel on the SOPs/WIs
‚Äî Validation plan final report
What is not on the list?
‚Äî Installation Qualfication (IQ): there‚Äôs nothing to install and therefore nothing to verify
‚Äî Operational Qualification (OQ): if you are focusing on qualifying for intended use, performing an OQ provides no added value
‚Äî Performance Qualification (PQ): we can debate whether this is necessary or not. My clients have decided not to do any verification testing on the platforms (Azure / GCP) and have left the verification testing to the application layer. Or they have performed automated and manual testing and have summarized in a document that they approve and store with the validation deliverables.
Procedures and Work Instructions
Assuming the SOPs are in place to support validated systems (computer validation, SDLC, change management, backup/restoration, deviation management, training, security/passwords, monitoring, etc.), the following should be considered at a minimum:
‚Äî MS Azure Platform operation and maintenance procedure including monitoring
‚Äî Work instructions to support the platform administration including administration of virtual machines and other Azure assets, backup and restoration, user and security administration, etc.
The timeline of the activities will depend on where/what you are migrating from (assuming you are), what is being migrated, the impact to the business, and the available resources to work on the configuration, migration, and qualification project.
So, it depends.
Some words of wisdom based on my experience with these qualification and migration projects:
‚Äî Work with an experienced and well-referenced Azure vendor (assuming you are working with a vendor) who understands CSV/CSA
‚Äî Work with an Azure vendor who will detail their activities and assumptions in their statement of work before you start the project. Trust me on this one.
‚Äî Create the timeline of activities and include the qualification tasks in a single project / project plan. The vendor will only care about their portion but there‚Äôs a lot more to it than the technical activities.
‚Äî Train the team on what to expect with the qualification activities and the post-migration activities. It won‚Äôt make 100% sense at first but it will at the end.
‚Äî Have the SOPs/WIs in place prior to the migration and the production cutover.
‚Äî Be flexibile. Things will not go 100% to plan. Apply critical thinking to address issues as they arise and continue to focus on the goal(s) of the qualification effort.
Qualification and validation do not end after the project is over. It starts at the beginning with a kernel of an idea and goes through to retirement.
Don‚Äôt forget to operate and maintain in a controlled fashion your beautifully qualified Azure platform.
Still Have Questions or Need Some Help?
Feel free to reach out to me with any questions you might have via email at terri.mead@solutions2projects.com or through my website SolutionsProjects, LLC. I‚Äôd be happy to have an initial call, free of charge, to discuss your qualification project.
Related article: Solutions2Projects, LLC
Living my best life‚Ä¶one day at a time
Written by
IT consultant, expert witness, YouTuber, helicopter pilot. Making the world a better place, especially for women. Award winning author of Piloting Your Life.
I want to live in a world where everyone has the opportunity to live freely, equally and have an extraordinary life. #PilotingYourLife #Angel Investing #Digital Health #Sol2Proj #Womanism #Tipsy
Written by
IT consultant, expert witness, YouTuber, helicopter pilot. Making the world a better place, especially for women. Award winning author of Piloting Your Life.
I want to live in a world where everyone has the opportunity to live freely, equally and have an extraordinary life. #PilotingYourLife #Angel Investing #Digital Health #Sol2Proj #Womanism #Tipsy
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@kief/i-agree-that-building-with-paas-and-serverless-saves-massive-amounts-of-time-and-money-over-b1874e889046?source=search_post---------73,"Sign in
There are currently no responses for this story.
Be the first to respond.
Kief Morris
Jul 24, 2017¬∑2 min read
Andrew Walker
I agree that building with PaaS and Serverless saves massive amounts of time and money over building your own automated infrastructure on top of IaaS cloud. I also see IT teams putting up roadblocks, FUD, etc. to keep things the way they‚Äôre used to.
But there‚Äôs another big blocker, which is application architecture. Using PaaS, and even more with serverless, requires your applications to be built from the ground up for that model. For a green field project, or a major rebuild, the target architecture should be these. But most organizations moving to cloud have a fair bit of existing code, which is non-trivial to rebuild for a radically new architecture.
So IaaS offers a way to migrate to cloud for these people. It has costs ‚Äî automating a cloud-based infrastructure is non-trivial. And ideally it‚Äôs a stepping stone, that allows new code to be written for a more modern architecture. Your experience may vary, based on the types of clients you work with ‚Äî in my experience, medium to large, more established businesses face a multi-year journey to completely rebuild their systems to be truly cloud native. So IaaS is a valid, pragmatic choice for quite a few people.
I‚Äôd also suggest that positioning this as Google vs. Amazon is a red herring. Google has an IaaS platform (GCE), which is just as expensive to automate as AWS EC2. And AWS does offer serverless (Lambda) and containerized services (ECS), so you can build a completely cloud-native system on AWS, with all of the cost savings offered by GKE or AppEngine.
I don‚Äôt disagree with your article, BTW, just pointing out there are more angles to the story.
Cloud Practice Lead at ThoughtWorks. Author of ‚ÄúInfrastructure as Code‚Äù, from O‚ÄôReilly.
See all (262)
1
1
Cloud Practice Lead at ThoughtWorks. Author of ‚ÄúInfrastructure as Code‚Äù, from O‚ÄôReilly.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@cyril_lakech/votre-strat%C3%A9gie-cloud-paas-docker-hybrid-a-des-impacts-sur-les-d%C3%A9vs-20e8002ccb83?source=search_post---------74,"Sign in
There are currently no responses for this story.
Be the first to respond.
Cyril Lakech
Sep 21, 2016¬∑7 min read
L‚Äô√©volution actuelle de l‚ÄôIT tend √† utiliser des services dit ‚Äúmanag√©s‚Äù, qui fonctionnent tout le temps, dans le ‚ÄúCloud‚Äù et dont on n‚Äôa pas besoin de se soucier. Par exemple chez les fournisseurs de Cloud public on peut nommer: Elastic Cloud, Mongo Atlas, DynamoDB, Google App Engine. Tout le monde ne suit pas ce mouvement, mais c‚Äôest une tendance qui gagne du terrain. J‚Äôen parlais il y a peu:
medium.com
Il y a 2 approches int√©ressantes qui utilisent ce type de services ‚Äúmanag√©s‚Äù : soit les d√©l√©guer compl√®tement √† des tiers, soit les mettre en place soit m√™me sur son infrastructure, en utilisant des plateformes comme Open Shift, OpenStack, Kubernetes et/ou Rancher et ainsi cr√©er son propre PaaS priv√©.
D‚Äôun c√¥t√©, sur notre Cloud priv√©, on est responsable de la mise en place de la plateforme qui permettra de cr√©er les services ‚Äúmanag√©s‚Äù, de l‚Äôautre, sur un Cloud public, on remet cette responsabilit√© √† un tiers. Dans les 2 cas, il faudra des √©quipes pour g√©rer ces services. Dans le cas o√π l‚Äôon cr√©√© sa propre plateforme, l‚Äô√©quipe sera un peu plus cons√©quente et se composera de d√©veloppeurs qui r√©aliseront des solutions pour que d‚Äôautres d√©veloppeurs d‚Äôapplications m√©tier puissent d√©ployer leur code.
Pour simplifier les choses (sic), en plus de ces 2 approches, d‚Äôautres mouvements de fond se dessinent :
Ces strat√©gies sont compatibles entre elles, on peut faire son PaaS priv√© et utiliser des conteneurs pour d√©ployer ses applis, et on peut aussi utiliser un Cloud public et utiliser des services manag√©s. Mais on peut √©galement cr√©er un PaaS priv√© avec ses propres services manag√©s ou encore d√©ployer des conteneurs sur un Cloud public. Et on peut aussi utiliser des services manag√©s comme AWS Lambda et les lier √† d‚Äôautres services dans son cloud priv√©‚Ä¶
Bref, on peut hybrider toutes ses strat√©gies ensembles: Avoir une application pour laquelle on r√©duit notre p√©rim√®tre de responsabilit√© au maximum (Public Cloud + services manag√©s publics) et une autre application o√π on g√®re un maximum de chose par nous m√™me (Private Cloud + services manag√©s faits maison). Et cerise sur le g√¢teau, on peut aussi hybrider ces approches au sein d‚Äôune m√™me application, o√π chaque composant suit une strat√©gie diff√©rente. On peut choisir la strat√©gie qui correspond le mieux aux besoins du projet ou du module de l‚Äôapplication. Apr√®s, il faut savoir g√©rer la coh√©rence d‚Äôensemble dans son SI.
Il existe √©galement d‚Äôautres approches, comme celle de continuer sur une approche IaaS classique voir m√™me d‚Äôaller jusqu‚Äô√† g√©rer soit m√™me son datacenter avec ses propres baies. M√™me si elles sont loin d‚Äô√™tre insignifiantes en proportion, je les trouve moins int√©ressantes et c‚Äôest pour cette raison subjective que je les passe sous silence.
Comme c‚Äôest un peu flou et pour tenter de s‚Äôy retrouver donnons quelques exemples avec des produits existants; pla√ßons nous du point de vue des √©quipes de d√©veloppement applicatif, celles qui consomment les services manag√©s. Ce monde se d√©coupe suivant ces 2 strat√©gies:
Ce qui donne comme l√©gende de lecture :
On obtient ces quelques exemples:
Pour simplifier, on consid√®re dans cette r√©partition que pour un cloud priv√©, les √©quipes qui mettent √† disposition des services manag√©s sont diff√©rentes des √©quipes de d√©veloppement applicatif. C‚Äôest pour cette raison que les √©quipes de d√©veloppement applicatif ont moins de besoins en comp√©tences d‚Äôinfra. Si elles utilisent un OpenShift Container Plateform par exemple; une √©quipe d√©di√©e s‚Äôoccupe d‚Äôop√©rer la plateforme de services manag√©s sur le cloud priv√© et les √©quipes de d√©veloppement d‚Äôapplicatif consomment les services mis √† disposition. Bien entendu, l‚Äôentreprise a quand m√™me besoin de comp√©tences en infrastructure dans l‚Äô√©quipe d√©di√©e au cloud priv√©.
Bref, il existe √©norm√©ment de solutions diff√©rentes, priv√©es, publiques, hybrides, extensibles, interconnect√©es, compatibles. Difficile √† suivre et impossible de d√©terminer quelle est la meilleure approche. Tout d√©pend du contexte, des objectifs, des √©quipes en place‚Ä¶ ce qui est certain c‚Äôest que cela impacte fortement les d√©veloppeurs.
Souhaite t-on que les d√©veloppeurs d‚Äôapplications utilisent des services manag√©s (public et/ou priv√©s) ?
Souhaite t-on utiliser des services PaaS sur un Cloud public ?
Souhaite t-on que les d√©veloppeurs applicatifs utilisent des services manag√©s au niveau OS (containers par exemple) ?
Bref, l‚Äôid√©e √©tait de montrer que la strat√©gie Cloud mise en place peut poser des questions importantes pour l‚Äôentreprise et qu‚Äôelle peut avoir un impact fort sur le m√©tier des d√©veloppeurs.
Les besoins de l‚Äôentreprise ne sont pas forc√©ment les m√™me que les besoins des d√©veloppeurs. Pourtant, mieux vaut aligner ces besoins!
On peut se dire : ‚Äúpeu importe‚Äù. Mais les d√©veloppeurs de qualit√© sont pr√©cieux, il faut les conserver et en attirer d‚Äôautres. Une des mani√®res d‚Äôatteindre cet objectif est de mettre en place un environnement de travail qui leur convienne.
De nombreux d√©veloppeurs pr√©f√®rent mettre les mains dans toutes les couches de l‚Äôapplication et prennent du plaisir √† d√©finir leur image Docker, le load-balancing, le fail-over... D‚Äôautres ne veulent pas entendre parler d‚ÄôOPS et veulent se concentrer sur le d√©veloppement applicatif‚Ä¶ Certains aiment varier les plaisirs, c‚Äôest mon cas.
J‚Äôai eu la chance de travailler dans des contextes avec des strat√©gies cloud diff√©rentes; PaaS Public, PaaS Priv√©, Datacenter interne, et je pense que c‚Äôest une bonne chose de ne pas s‚Äôenfermer dans une seule strat√©gie pour le moment en tant que d√©veloppeur. Toutes ces approches sont int√©ressantes !
Les d√©veloppeurs les plus connus, reconnus techniquement et les plus exp√©riment√©s ont une pr√©f√©rence pour une approche o√π ils doivent g√©rer un maximum de choses: Rancher, Docker, Netflix OSS, Consul, Kubernetes. Les approches PaaS public les attirent moins car il y a moins de choses √† apprendre, il ‚Äúsuffit‚Äù de consommer la plateforme.
Nous faisons tous des choix qui peuvent compl√®tement changer le contexte de travail du d√©veloppeur, avec leurs avantages et leurs inconv√©nients:
Est-ce que comme le mar√©chal ferrant en son temps avec l‚Äôarriv√©e de l‚Äôautomobile, le DEV+OPS sera oblig√© de se reconvertir ? On va le savoir bient√¥t ;)
Suivez moi sur twitter @cyril_lakech¬†;-)
‚òÖ SaaS Director @qimaone ‚òÖ ex @axa @adeo @chtijug ‚òÖ Zoo Keeper ü¶¶ü¶Åüêßü¶äü¶Ü ü¶Ö#hiring
1 
1
1¬†
1 
1
‚òÖ SaaS Director @qimaone ‚òÖ ex @axa @adeo @chtijug ‚òÖ Zoo Keeper ü¶¶ü¶Åüêßü¶äü¶Ü ü¶Ö#hiring
"
https://blog.schwarty.com/a-paas-for-web-apps-with-custom-domains-46b17e1db14?source=search_post---------75,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
You know those sites that you have, the one for your aunt‚Äôs hobby and your friend‚Äôs small business? The sites that get minimal traffic and have a micro footprint yet need a custom domain. Doesn‚Äôt it drive you nuts that there doesn‚Äôt seem to be a low cost hosting solution for those? A service that would be easy to deploy to and set up.
Sure, you could spin up a micro VM to host them. But then you have to install and manage a web server, create new sites in the file system and the web server, set up the deployment pipeline. Blah blah blah. It just feels too heavy for these mini sites.
I would love to be able to use a service in which I could create a new site and set the custom domain(s) via a web portal and start deploying. Maybe I could pay for a pack of sites or pay on a per site basis. Sure, it sounds like Windows Azure Web Sites. But how about $50 per year for 5 sites with custom domains (as many as you want to bind)? That feels like a good fit. I don‚Äôt think I have more than 5 extended family members who even care about the web, let alone need a site.
Word on the streets is that Windows Azure Web Sites runs about $10 per month for custom domain supported sites and you get some of the power of the cloud, but, I don‚Äôt know, $120 a year just feels a bit much for this need. These sites do not require a database or any custom modules. The traffic load and resource requirement for these is nil.
Maybe I need to do a better job convincing myself that my family members are worth the $120 a year!
This whole personal dilemma actually got me thinking about another scenario. What about web apps? Static HTML/JavaScript apps that have a payload of the markup, css and client scripts only. Web apps that get all of their data from AJAX calls to an endpoint API that does not need a custom domain because it is not visible to the end user.
What if you could create an AngularJS web app and deploy the client to a Web App PaaS (Platform as a Service), add your custom domains and then flip over to a free Windows Asure Web Sites account and set up your API under a *.azurewebsites.net domain?
What would drive this PaaS? Maybe node.js and nginx? Sure, those could be a good fit. But what about this new hotness that just dropped on the web? ASP.NET vNext. This definitely sounds like a fit. But how would that play out?
ASP.NET vNext Powered Web App PaaS
Go check out https://github.com/aspnet/Home. I followed the instructions there and got the sample apps up and running fast.
This vNext thing is ridiculously cool, thanks in part to the npm...I mean the kpm. It spits out console lines like it's quoting node package manager. I ran kpm restore to pull down the bits (per sample app), ran the k web command to start the site instance and hit the URL in the browser and the site was running. I then went into the project dir and added an index.html file, switched to browser and navigated to it. Bam! Static resources served up.
Next I opened the project.json file, found the entry for server.urls=http://localhost:5001 that sets the binding up and tried adding another domain separated by a comma. I mean, it does say urls and not url. Navigated to the other URL for kicks to see if this puppy worked like a web.config change and got no response. Flipped back to Powershell and tried a ""stop"". It stopped! No documentation needed. :) Started it again and received an exception. I took a guess that the comma is not the separator, tried a semi-colon and it worked! Went to both URLs and saw the same thing. Hot damn!
Using the wildcard DNS site http://xip.io/ and my localhost IP of 127.0.0.1 I simulated a couple of custom domains, adding them to the project.json file:
Stopped and started the site again and had full support for all of the following domains:
That was stupid easy.
So, create a web portal that will allow users to create a new site and enter custom domain bindings. Behind the curtain, have code to create the new dir, configure the project.json with the domain names, load it with vNext bits and spin it up with the k web command and you've new'd up a web app instance in the PaaS.
Now we just wait for Microsoft‚Äôs story for Web Deploy to these vNext app dirs, because we all know friends don‚Äôt let friends FTP.
So many thoughts exploding for the potentials in the web space with this stuff. Gears turning, mind threatening to go go go Godzilla all over the web stack with vNext. I had to look away from the .NET MVC sample (a web passion of mine) and the great write up on it by Mike Wasson because, well, humans need to sleep sometime!
But before I sign off, go check out Hanselman‚Äôs latest post The Future of .NET on the Server: ASP.NET vNext content and videos from TechEd 2014. Good luck just reading and not staying up all night playing! :)
Articles about front end web development and Angular
Written by
Host of @AngularAir. Google Developer Expert for Angular and Web Technologies. Writer, trainer and speaker.
Articles about front end web development and Angular
Written by
Host of @AngularAir. Google Developer Expert for Angular and Web Technologies. Writer, trainer and speaker.
Articles about front end web development and Angular
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@alibaba-cloud/what-is-the-difference-between-kubevela-and-paas-an-in-depth-interpretation-fde0e24f7389?source=search_post---------76,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Feb 2, 2021¬∑8 min read
By Deng Hongchao, Senior Technical Expert at Alibaba Cloud and the core maintainer of OAM and KubeVela project, with the title of ‚Äúthe Second Kubernetes Operator‚Äù.
After the release of the KubeVela project, many community members across the world asked a similar question: Is KubeVela exactly the same as PaaS products like Heroku? This question is frequently raised because the experience on KubeVela is really great. It can nearly be considered as the Heroku of Kubernetes.
Today, I‚Äôd like to talk about this topic: What is the difference between KubeVela and PaaS?
Note: The PaaS mentioned in this article includes both classic PaaS products, such as Heroku, and various Kubernetes-based ‚Äúcloud-native‚Äù PaaS. Although their underlying implementations are different, they provide similar usage interfaces and experiences to users. OpenShift is an exception. As a project that is more complicated than Kubernetes itself, OpenShift is an authentic release version of Kubernetes. It is not included in the easy-to-use and user-oriented PaaS discussed in this article.
Here is the conclusion: Although KubeVela can bring users an experience similar to that of PaaS, KubeVela is not a PaaS product.
Most PaaS products provide complete lifecycle management functions for an application. They also focus on providing a simple and user-friendly experience and improving R&D efficiency. In these aspects, the goal and user experience of KubeVela are highly consistent with that of PaaS. However, in terms of the implementation details of KubeVela, the overall design and implementation of KubeVela are actually very different from that of various PaaS projects. From the user perspective, these differences are directly reflected in the ‚Äúextensibility‚Äù of the entire project.
In detail, although the user experience is good, PaaS itself is often not extensible. Let‚Äôs take a look at the new Kubernetes PaaS project, such as Rancher Rio. This project provides a good application deployment experience. For example, rio run allows quick deployment of containerized applications, automatic allocation of domain names, and access rules. However, what if we want Rio to support more capabilities to meet different user demands?
For example:
The key point is that these capabilities are common in the Kubernetes ecosystem, and some are even built-in capabilities in Kubernetes. However, to support any of the aforementioned capabilities in PaaS, a round of development is required for PaaS. Additionally, large-scale reconstruction is likely required due to previous assumptions and designs.
For example, I have a PaaS system that assumes that all applications are run through Deployment. So, the release and scaling functions of this PaaS system are also implemented directly according to Deployment. Now, users are asking for in-place update, which requires the availability of CloneSet in PaaS. The whole system may have to be reconstructed. This problem is even worse when it comes to the O&M capability. For example, my PaaS system supports the Blue Green Deployment strategy. Therefore, a lot of interaction and integration are required between PaaS and traffic management, monitoring, and other systems. Now, if I want my PaaS system to support a new strategy called Canary Release, all the interaction and execution logic must be reconstructed, which is a huge workload.
Of course, not all PaaS are completely inextensible. PaaS products with strong engineering capabilities, such as Cloud Foundry and Heroku, have their own plug-in capabilities and center. These products, on the premise of ensuring user experience and the capability controllability, open up certain plug-in capabilities, such as allowing users to access their own databases or developing some simple features. However, no matter how this plug-in mechanism is designed, it is actually a small closed ecosystem exclusive to PaaS. In the cloud native era, the open source community has already created an almost ‚Äúunlimited‚Äù capability pool, that is, the Kubernetes ecosystem. It outshines any small ecosystem exclusive to PaaS.
The preceding problems can be collectively referred to as the ‚Äúcapability dilemma‚Äù of PaaS.
In contrast, KubeVela aims to use the entire Kubernetes ecosystem as its ‚Äúplug-in center‚Äù from the beginning, and to ‚Äúdeliberately‚Äù design each of its built-in capabilities as independent and pluggable plug-ins. This highly extensible model actually has sophisticated design and implementation. For example, how does KubeVela ensure that a completely independent trait is bound to a specific workload type? How to check whether there is any conflict between these independent traits? These issues are solved by taking Open Application Model (OAM) as the model layer of KubeVela. In short, OAM is a highly extensible application definition and capability assembly model.
Moreover, definition files of any workload type and trait can be stored on GitHub after being designed and produced. Thus, these files can be used by any KubeVela user in the world in their own Appfile. For more information, see Documentation of $ vela cap (management commands for plug-in capability).
So, KubeVela advocates the future-oriented cloud-native platform architecture. For this architecture:
The following figure shows the overall architecture of KubeVela:
In terms of architecture, KubeVela has only one controller running on Kubernetes as a plug-in. This provides Kubernetes with application-layer-oriented abstractions and a user-oriented interface based on abstractions, called Appfile. The core of the Appfile and even KubeVela operation mechanism is OAM. Based on OAM, KubeVela provides a capability assembly process based on registration and self-discovery for system administrators. It allows system administrators to connect any capability in the Kubernetes ecosystem to KubeVela. Thus, KubeVela can adapt to different scenarios (such as AI PaaS and database PaaS) by ‚Äúmatching one core framework with different capabilities‚Äù.
Specifically, system administrators and platform developers can use the preceding process to register any Kubernetes API resources (including CRD) and corresponding controllers on KubeVela as ‚Äúcapabilities‚Äù. Then, these capabilities are encapsulated into available abstractions (that is, to become part of the Appfile) through the CUE template language.
Next, let‚Äôs demonstrate how to insert the alerting mechanism in KubeWatch community into KubeVela as an alert trait.
First, you need to determine what the capability represented by CRD corresponds for, a workload type or a trait? The difference here is that workload type determines the way running your code. Trait refers to the maintenance, management, or operating method of ongoing code instances.
As an alerting mechanism, KubeWatch is naturally used as a trait. At this time, it can be registered by writing a yaml file of TraitDefinition:
The server-side Runtime built in KubeVela recognizes the TraitDefinition registration event that is monitored, and then incorporates this capability into the platform management.
After this step, KubeWatch registration is done and available in KubeVela platform. However, in the next step, it still needs to be exposed to users, so we need to define an interface for external use of this capability.
In fact, although most communities are very capable, they are more complicated for end users and are very difficult to learn and get started. Therefore, in KubeVela, platform administrators can further encapsulate capabilities to expose simple and easy-to-use interfaces to users. In most scenarios, a few parameters are enough for these interfaces. For capability encapsulation, KubeVela chooses the CUE template language to connect the user interface with the backend capability. It also naturally supports fully dynamic template binding, which means changing the template without restarting or redeployment of the system. The following example shows the template of the KubeWatch trait:
Add the template to the Definition file and apply $ kubectl apply -f in Kubernetes. Then, KubeVela automatically recognizes and processes the input. At this time, the user can directly declare and use the newly added capability in the Appfile. For example, the user can send alarm information to the designated Slack channel:
As you can see, this KubeWatch configuration is a new capability expanded through a third party. Managing the Kubernetes extension capability through the KubeVela platform is just as simple like this. With KubeVela, platform developers can quickly build a PaaS on Kubernetes and rapidly encapsulate any Kubernetes capability into an end-user-oriented upper-layer abstraction.
The preceding example just shows a very small part of KubeVela extensibility. In subsequent articles, I will introduce more details about the KubeVela capability assembly process, such as:
The native extensibility and capability assembly mechanism fundamentally distinguish KubeVela from most PaaS projects. They are also the reason why the implementation and model of KubeVela are essentially different from that of most PaaS projects. Therefore, the core goal of KubeVela is to provide users with simple application management, and deliver fully Kubernetes-native extensibility and flexibility for platform administrators.
The KubeVela project is an official project of the OAM community. It is maintained by several senior members of the cloud native community from Alibaba and Microsoft. It is also the core component of Alibaba Cloud EDAS and multiple internal application management platforms supporting the Double 11. KubeVela aims to build a future-oriented cloud-native PaaS architecture, bringing the best practices such as horizontal extensibility and application-centered features to everyone. It also hopes to promote and even lead the development of the cloud native community in the application layer.
Want to know more?
www.alibabacloud.com
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jpaulreed/pass-the-paas-plz-d4474511fa0c?source=search_post---------77,"Sign in
There are currently no responses for this story.
Be the first to respond.
J. Paul Reed
Mar 18, 2015¬∑2 min read
A couple of weeks ago at the Velocity Summit, one of the open space topics was on current and future use of the aaS‚Äôs (platform-as-a-service, software-as-a-service, and infrastructure-as-a-service).
The thesis was in some number of years, everyone would be using aaS‚Äôs in some form to build their software/services, and no one would be maintaining their own datacenters anymore.
As you might imagine, an interesting conversation ensued.
No matter your position on this assertion, I had a couple thoughts during the discussion:
A lot of the discussion glossed over the role of automation complexity and our industry‚Äôs general immaturity when it comes to designing, building, and operating automation.
This point is relevant in a world where we string a bunch of services together with REST API bailing wire and notification duct tape: there are some surprises with respect to complexity that we‚Äôre still not adept at dealing with.
One of the examples I always pull out to illustrate this point is ValuJet Flight 592. Without retelling the entire story, Flight 592 is an example of an organization trying to cut costs and relying on outsourcing to do it.
ValuJet employed a number of external vendors, who didn‚Äôt communicate effectively with each other. Due to this, one crew put flammable material together with a fuel source inside a compartment that did not have fire suppression systems, because it was intended for use with inflammable cargo.
Disaster ensued. And all because a single entity operating a complex system strung a bunch of simpler systems together in ways where they weren‚Äôt allowed to communicate, and the degrees of freedom in their behaviors hadn‚Äôt been modeled against the existing system in operation.
Sound familiar at all?
I posed the question: has there been a notable catastrophic failure that can be tied back to stringing automated services together and unexpected behavior we were incapable of modeling and accounting for?
The question remained unanswered for the duration of the session, but I posit that if there hasn‚Äôt been one yet, we‚Äôre due for one.
Salesforce was mentioned as the primary (successful) example and leading indicator of businesses moving functions that were once thought to be business critical (and thus important to be kept in-house) off to an external vendor.
What wasn‚Äôt mentioned: Salesforce runs their own datacenters.
What do you think?
Are we on an inexorable march toward outsourcing any and everything? Is it all just a matter of time?
Build & release engineering / DevOps / human factors; Managing Partner at Release Engineering Approaches: Simply ship. Every time. @ShipShowPodcast alumn.
See all (515)
Build & release engineering / DevOps / human factors; Managing Partner at Release Engineering Approaches: Simply ship. Every time. @ShipShowPodcast alumn.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/terri-hanson-mead/google-cloud-platform-gcp-in-life-sciences-qualifying-the-cloud-iaas-paas-6059824bed29?source=search_post---------78,"There are currently no responses for this story.
Be the first to respond.
As life sciences companies, especially biotech companies, become more and more virtual, they are shifting (or have shifted) to the cloud for applications and infrastructure. It‚Äôs the right thing to do, especially since most don‚Äôt appreciate the value of technology in optimizing business performance and getting to market faster (separate rant).
Simply throwing the responsibility over the fence to the vendors does not relieve a life sciences company of its obligations around ensuring data quality and integrity.
Savvy life sciences companies know this and qualify their underlying cloud infrastructure, whether on AWS, Google Cloud Platform (GCP), or Microsoft Azure.
The qualification process is more than a compliance activity; it can provide value to the business in demonstrating system and process controls, and ensure data integrity. It‚Äôs all about the data, after all.
In this blog post, I share my recommendations for qualifying Google Cloud Platform. I covered the same for Microsoft Azure in a separate post.
For the purposes of this post, I am focusing on IaaS and PaaS, and not SaaS. For validating a SaaS solution, check out this post from 2018 and this post from 2019.
Qualification versus Validation
In this post I will use the terms synonymously but generally speaking, you qualify infrastructure and you validate applications for a company‚Äôs intended use.
ISPE GAMP5
I am a GAMP girl so my qualification approach is based on the International Society of Professional Engineer‚Äôs guidance documents as detailed in GAMP5 and the associated guidance documents.
CSV versus CSA
FDA released its draft guidance on Computer Software Assurance for Manufacturing, Operations, and Quality System Software and while it was expected to be finalized in 2020, it is now on the docket for fiscal year 2021 per FDA‚Äôs Center for Devices and Radiological Health (CDRH).
The guidance document is intended to shift validation approaches from CSV (computer system validation) to CSA (computer software assurance). If you‚Äôve been following a risk-based approach (as defined in GAMP5) and have been using your noggin to focus on intended use and the value add to the business, there‚Äôs not much of a shift.
Risky Business
Two years ago I qualified GCP for a client and recently followed a similar approach for Azure for another client this past year. The approaches to both are nearly identical.
It may appear to be largely a documentation effort but it‚Äôs more than that. It‚Äôs all about defining what is needed for the business, executing against those requirements, documenting the baseline, and maintaining the platform in a controlled fashion.
With IaaS and PaaS (and SaaS), there is a lot of reliance on the vendor, and therefore the customer (the life sciences company) needs to oversee the vendor and the platform to ensure an acceptable level of control based on the company‚Äôs risk assessment and risk tolerance. To not do so is a risky business and compliance proposition.
Risk-Based Approach
A risk-based approach was the best thing to happen to computer systems and software when GAMP5 was released. It meant that we could prioritize what we focused on, company by company, system by system, process by process.
This also meant that those folks who liked to apply a cookie-cutter approach to computer validation had to start applying critical thinking to their validation / qualification efforts. It‚Äôs not easy if you just want to check boxes and follow checklists.
A risk-based approach offers up flexibility for companies leveraging software and technology. It is not a one-size fits all approach.
This isn‚Äôt rocket science but if you have not been through a qualification or validation effort, this will be challenging as there‚Äôs a steep learning curve. I have yet to figure out how to get my clients to understand this process until after they‚Äôve gone through it. Expect some discomfort as you go through it for the very first time.
What is Google Cloud Platform (GCP)?
The Google Cloud Platform (GCP) is a suite of clud computing services providing infrastructure as a service (IaaS), platform as a service (PaaS) and serverless computing environments in Google managed data centers. This includes computing, data storage, data analytics, application deployment, and machine learning.
The companies I work with rely on it as the virtual backbone for virtual machines, storage, and other GCP assets to support business applications, databases, and web deployment.
Above and Below the Line
I draw the line at the compute instances, containers, management tools, security, and storage. Anything above that line is at the application level and should be covered under those application validation plans and activities. Below the line is in scope for the GCP platform.
If we think in terms of a bare metal data center, IT historically commissioned the servers and prepared for application and database installation.
This typically included installing things like the operating system, anti-malware software/tools, monitoring tools, backup software or agents, and other baseline tools used by IT. This is all below the line and what I consider in-scope for the qualification of the GCP platform.
Then it‚Äôs handed over to the folks managing the application project. What they do, even with the help of IT, is above the line.
Deliverables
Remember, if it‚Äôs not documented, it didn‚Äôt happen. I highly recommend that all of the validation deliverables be approved and stored in the company‚Äôs validated document management system (eDMS).
‚Äî GxP assessment for the GCP platform based on its intended use and what is expected to reside on the platform
‚Äî Risk assessment for the GCP platform and determination as to whether to audit Google for GCP
‚Äî Vendor qualification asessment and possible (paper) audit
‚Äî Validation plan for the GCP platform
‚Äî Functional requirement specification (combined FRS/FRA/TMX document)
‚Äî Functional risk assessment (combined FRS/FRA/TMX document) for the GCP platform
‚Äî Technical specification documents for the platform and the virtual machines and other GCP assets on the platform; these provide baseline documentation for operation and control and are created after the migration or the platform / virtual machines / other assets are configured or installed.
‚Äî Migration plan or protocol including verification activities
‚Äî Executed migration and supporting documentation
‚Äî Migration plan summary report
‚Äî Testing summary to document any verification activities performed whether automated or manual
‚Äî Traceability matrix (combined FRS/FRA/TMX document)
‚Äî Procedures (SOPs) and work instructions (WIs) to operate and maintain the GCP platform in a controlled fashion
‚Äî Trained administrators on the platform and SOPs/WIs
‚Äî Trained personnel on the SOPs/WIs
‚Äî Validation plan final report
What is not on the list?
‚Äî Installation Qualfication (IQ): there‚Äôs nothing to install and therefore nothing to verify
‚Äî Operational Qualification (OQ): if you are focusing on qualifying for intended use, performing an OQ provides no added value
‚Äî Performance Qualification (PQ): we can debate whether this is necessary or not. My clients have decided not to do any verification testing on the platforms (Azure / GCP) and have left the verification testing to the application layer. Or they have performed automated and manual testing and have summarized in a document that they approve and store with the validation deliverables.
Procedures and Work Instructions
Assuming the SOPs are in place to support validated systems (computer validation, SDLC, change management, backup/restoration, deviation management, training, security/passwords, monitoring, etc.), the following should be considered at a minimum:
‚Äî GCP Platform operation and maintenance procedure including monitoring
‚Äî Work instructions to support the platform administration including administration of virtual machines and other GCP assets, backup and restoration, user and security administration, etc.
The timeline of the activities will depend on where/what you are migrating from (assuming you are), what is being migrated, the impact to the business, and the available resources to work on the configuration, migration, and qualification project.
So, it depends.
Some words of wisdom based on my experience with these qualification and migration projects:
‚Äî Work with an experienced and well-referenced GCP vendor (assuming you are working with a vendor) who understands CSV/CSA
‚Äî Work with a GCP vendor who will detail their activities and assumptions in their statement of work before you start the project. Trust me on this one.
‚Äî Create the timeline of activities and include the qualification tasks in a single project / project plan. The vendor will only care about their portion but there‚Äôs a lot more to it than the technical activities.
‚Äî Train the team on what to expect with the qualification activities and the post-migration activities. It won‚Äôt make 100% sense at first but it will at the end.
‚Äî Have the SOPs/WIs in place prior to the migration and the production cutover.
‚Äî Be flexibile. Things will not go 100% to plan. Apply critical thinking to address issues as they arise and continue to focus on the goal(s) of the qualification effort.
Qualification and validation do not end after the project is over. It starts at the beginning with a kernel of an idea and goes through to retirement.
Don‚Äôt forget to operate and maintain in a controlled fashion your beautifully qualified GCP platform.
Still Have Questions or Need Some Help?
Feel free to reach out to me with any questions you might have via email at terri.mead@solutions2projects.com or through my website SolutionsProjects, LLC. I‚Äôd be happy to have an initial call, free of charge, to discuss your qualification project.
Related article: Solutions2Projects, LLC
Living my best life‚Ä¶one day at a time
I want to live in a world where everyone has the opportunity to live freely, equally and have an extraordinary life. #PilotingYourLife #Angel Investing #Digital Health #Sol2Proj #Womanism #Tipsy
Written by
IT consultant, expert witness, YouTuber, helicopter pilot. Making the world a better place, especially for women. Award winning author of Piloting Your Life.
I want to live in a world where everyone has the opportunity to live freely, equally and have an extraordinary life. #PilotingYourLife #Angel Investing #Digital Health #Sol2Proj #Womanism #Tipsy
"
https://medium.com/@alibaba-cloud/from-single-tenant-iaas-to-multi-tenant-paas-multi-tenant-isolation-with-maxcompute-47280c741117?source=search_post---------79,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Jul 18, 2018¬∑8 min read
In the big data session of the 2017 Computing Conference Beijing Summit, Li Xuefeng, a senior technical expert from Alibaba Cloud, talked about multi-tenant isolation on a financial big data platform. He started his speech with the problems of tenant isolation in a traditional single-tenant IaaS architecture and then talked about the multi-tenant PaaS architecture of Alibaba Cloud MaxCompute and how MaxCompute implemented secure isolation. We will discuss these architecture details in this article.
As shown in this figure, the bottom layer of the single-tenant big data product architecture is HDFS2, on which resource control platforms such as Hadoop Yarn and MESOS reside. We can implement specific computing models, such as MR, Hive, HBASE, and Spark over the resource control platforms. In this ecosystem, the IaaS platform is generally available to the same tenant. When new business requirements arise, the tenant can apply for a batch of VM clusters on the IaaS platform, and then deploy open-source products on the clusters. This ecosystem encounters following problems from the perspective of isolation:
Firstly, the IaaS single-tenant big data product architecture has logic issues in actual use. Users must know the specific logic of each product for data analysis. For example, users must understand the Hive logic when using SQL and possess knowledge of Spark when using Spark. It is possible to control the cost of learning at a low level with fewer products, but this increases exponentially when we have to use multiple products collaboratively. Additionally, different open-source products usually cannot identify the logical model of each other, which worsens the logic issue in authentication scenarios.
Secondly, each open-source product has its priority definition for system operation. When we use only one open-source product, jobs get executed based on the priority system of this product. Jobs of higher priorities obtain more resources than those of lower priorities, and we get a better estimate of their running durations. However, when we have to use multiple open-source products together, the IaaS single-tenant big data architecture cannot optimize the job execution priorities globally.
Lastly, open-source products often offer user-defined logic, for example, UDF of MR or Hive. Running user-defined code in big data products brings security risks. For example, Hadoop Yarn simply isolates user-defined code with Linux Containers. In this isolation mechanism, the user-defined code logic runs in the same kernel as the Hadoop process. If the attacking program in the code logic affects the kernel, the big data product processes running in the same kernel are also affected. Generally, a job of a big data product runs on most of or even all machines in a cluster, depending on the size of the data shard. In this case, the entire cluster becomes vulnerable to security risks. In an extreme condition, the entire computing cluster may break down when a hacker exploits a kernel vulnerability to attack a machine successfully, and the job shard is large enough.
To address these problems, MaxCompute offers PaaS multi-tenancy capability using a proprietary system architecture.
In the above PaaS multi-tenant architecture diagram, MaxCompute runs over the Apsara operating system. It depends on the Apsara Fuxi module to provide unified resource control, the Apsara Pangu module to provide unified storage, and the Apsara Nvwa module to provide consistency service. MaxCompute uses the same computing engine to offer multiple computing models, including SQL, MR, graph computing, PAI, and near real-time.
Now, this computing engine offers qualified computing capabilities for financial users on the public cloud.
MaxCompute uses the following methods to implement multi-tenancy:
We will now discuss these three isolation mechanisms offered by MaxCompute in detail.
Currently, a MaxCompute instance provides a unified tenant system, no matter how many physical clusters the instance is running on. In this tenant system, the data resource view and privilege management model for the same tenant is unique and bound to the tenant model. In real-world applications, a tenant on MaxCompute maps to a project, which contains all resources, properties, and privileges of the tenant.
As shown in the preceding figure, a project consists of three parts: properties, subject, and object. Properties of a project include information such as quota, owner, payment account, and region. All authorized accesses in a project must use the user IDs as the subject, based on which MaxCompute offers a role model for authority aggregation. The resources we have used in the above-mentioned computing models (such as MR and Hive) are all mapped to a specific object in a project. For example, resources in the SQL model are table objects, and resources in the UDF model are function objects.
Based on the preceding logical model, MaxCompute offers a set of authentication and authorization mechanisms for privilege control. A project owner has all the privileges over the project. Any user who wants to use this project for computing must get authorization from the project owner first (using the GRANT statement). When accessing the project, a user submits its user ID as the user identity to perform operations such as reading and writing tables, creating functions, or adding and deleting resources. MaxCompute uses a unified ACL logic to determine whether the current user ID has the required privilege before it allows execution of such operations.
The computing engine of MaxCompute depends on the Apsara operating system to offer resource operation and isolation capabilities.
As shown in the preceding figure, when we submit Job-0 to Job-n to the Apsara Fuxi module, the Fuxi scheduling system assigns operation levels to these jobs based on operation levels of users. The operation levels correspond to properties in a project. The Fuxi module converts Job-0 to Job-n into Fuxi jobs and then dispatches them to nodes of a computing cluster. Finally, a server in the computing cluster runs jobs of multiple tenants simultaneously. All these jobs run as Fuxi workers.
When the Fuxi engine on a machine in the cluster receives a worker plan, it sets the Cgroup parameter on this machine based on the quota of the user to which the worker belongs. In this way, jobs submitted by different users run with different Cgroup parameter settings on the physical machine. Currently, MaxCompute leverages the Cgroup capability of the Linux kernel to allocate CPU, memory, and other resources to a certain process on a physical machine.
Finally, let‚Äôs have a look at the operation isolation mechanism provided by MaxCompute to ensure secure operation of user-defined logic. When the Fuxi module runs user-defined code logic, it pulls an isolated environment and runs the code in an isolated process. For the Fuxi module, this process is the same as other processes but runs in an isolated system. That is, this is a common process for the Fuxi module but is isolated from untrusted code processes.
We can classify operation isolation further into process isolation, device isolation, and network isolation.
A single process running untrusted code (which may contain malicious code) may damage the computing platform. MaxCompute offers an embedding isolation solution to prevent this potential security risk. The innermost layer of this solution provides Java sandbox and Python sandbox. The language-specific sandboxes implement innermost isolation. For example, Java UDF can restrict the classes that can be loaded, and Python UDF can restrict specific functions. At the intermediate layer, MaxCompute isolates processes based on Linux kernel mechanisms, including namespace, Cgroup, and secomp-bpf. At the outermost layer, MaxCompute offers lightweight VMs (created in several hundreds of milliseconds) using in-depth custom Linux kernel and a minimized hypervisor. Finally, the untrusted code runs on a hypervisor over the physical machine. The Fuxi module treats the untrusted code as a hypervisor process, but the untrusted code is running in an isolated environment.
MaxCompute also supports hardware acceleration for a user-defined code. For example, PAI supports direct GPU access. MaxCompute supports GPU pass-through into a VM in PCIe pass-through mode, which allows guest processes to access the GPU over the PCIe bus and GPU driver in the guest kernel.GPU access from a VM over the PCIe bus has a similar speed to GPU access from a physical machine. Also, this GPU access mode removes the need to install the GPU driver on a physical machine, thereby eliminating the impact of GPU driver on platform stability and reliability.
MaxCompute offers the network isolation capability for users‚Äô code logic on some products. It creates a virtual network between the VMs provisioned by the Fuxi module. These VMs can communicate directly through the virtual network, ensuring compatibility between open-source code running in the VMs. You can also see from the preceding figure that the user-defined code logic does not connect to the physical network directly, whereas the trusted code running on Fuxi, including the code in the MaxCompute framework, uses the physical network for communication. This guarantees a low communication latency in the MaxCompute framework.
We have discussed how Alibaba Cloud MaxCompute uses logical isolation, resource isolation, and network isolation methods to provide secure isolation for big data processing. You can learn more about MaxCompute and other Alibaba Cloud products and solutions at www.alibabacloud.com.
Reference:
https://www.alibabacloud.com/blog/from-single-tenant-iaas-to-multi-tenant-paas---multi-tenant-isolation-with-maxcompute_593817?spm=a2c41.11774969.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@alibaba-cloud/configure-a-new-capability-for-kubernetes-paas-in-20-minutes-bf292bfdc523?source=search_post---------80,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Apr 1, 2021¬∑11 min read
by @wonderflow
In November 2020, KubeVela was officially launched. As a simple, easy-to-use, and highly extensible application management platform and core engine, Alibaba Cloud engineers can build a cloud-native PaaS. An instance will be used in this article to explain how to get a new KubeVela-based PaaS capability online within 20 minutes.
Before the tutorial in this article, please install KubeVela and its dependent Kubernetes environments on your local computer.
The basic architecture of KubeVela is shown in the following figure:
KubeVela adds Workload Type and Trait to extend capabilities for users. The service provider of the platform registers and extends through the Definition file and shows the extended functionality up through the Appfile. The official documents have the basic writing procedures, including extension examples of Workload and Trait:
The following section takes a built-in WorkloadDefinition as an example to introduce the basic structure of the Definition file:
It seems long and complicated, but don‚Äôt worry, it is divided into two parts:
This article will break down these sections and make detailed explanations. It is very simple to learn.
This part is no more than 11 lines. In total, 3 lines introduce functions of webservice and 5 lines are fixed format. Only 2 lines have specific information.
These two lines represent the CRD name used in this Definition and the format is <resources>.<api-group>. People familiar with Kubernetes know the resources are located through api-group, version, and kind. kind corresponds to resources in the K8s restful API. Take Deployment and Ingress as an example, the relationship is as listed below:
Why introduce the concept of resources when a kind exists? A CRD, in addition to kind, has fields like status and replica. These fields need to be decoupled from the spec and updated separately in the RestfulAPI. Therefore, there are additional resources besides the one that corresponds to kind. For example, the status of the Deployment is deployments/status.
The simplest way to write Definition without extension is to splice them according to the combination of Kubernetes resources and write the name, resources, and api-group correspondingly:
The steps for O&M feature registration (TraitDefinition) are the same:
Then, Ingress, as an extension of KubeVela, is written:
In addition, some other model layer functions have been added to TraitDefinition:
All of these capabilities are optional. This article doesn‚Äôt cover its usage, but it will be elaborated on in subsequent articles.
Now that we have discussed a basic extension mode without extensions, the remainder of this article is about abstract templates based on CUE.
For more details about CUE, please see Basic Introduction to CUE. This article will not elaborate on CUE.
KubeVela‚Äôs Appfile is simple to write, but the Kubernetes objects are relatively complex YAML files. KubeVela provides an easier way to keep the Appfile simple and extensible. This is what a CUE Template does in the Definition.
Let‚Äôs take a look at a YAML file of a Deployment, as shown below. Many of them are fixed frameworks in the template part. Users only need to fill in a small number of fields in the parameter part:
In KubeVela, the fixed format of a Definition file is divided into output and parameter. Output is the template section, and parameter is the parameter section.
Modify the Deployment YAML file to the template format of the Definition:
This format is very similar to JSON. This is the format of CUE, which is a superset of JSON. In other words, the CUE format adds some simple rules based on JSON rules, making it easier to read and use:
After the template section, it‚Äôs a parameter section. The parameter is a variable reference.
As shown in the preceding example, the template parameter in KubeVela is created through parameter, and parameter is used as a reference to replace some fields in output.
Through the combination of the two parts above, we can already write a complete Definition file.
For debugging, it can be split into two files. One part is in the YAML file, named def.yaml:
The other is in the CUE file named def.cue:
First, format def.cue. During this process, the CUE tool does some verification. It can also perform deeper debugging by running the cue command.
After debugging, the YAML file can be assembled using the script:
Apply the YAML file to the Kubernetes cluster:
Once the new ability kubectl is applied to Kubernetes, there is no need to restart or update. Users of KubeVela can see the new capability and use it immediately.
The usage method in Appfile is listed below:
Execute vela up to run the application:
Let‚Äôs check the status of the application. Through HEALTHY Ready: 1/1, we know that the application is running normally.
Above, we have already experienced the whole process of extending KubeVela through template replacement. Some complex requirements, such as conditional judgments, loops, complex types, require some advanced usage.
If there are some complex parameters in the template that contain structs and nested structs, the struct definition can be used.
1. Define a struct type that contains 1 string, 1 integer, and 1 struct:
2. Use this struct type as an array in a variable:
3. The variable reference is used in the same target:
4. The Appfile is written according to the structure defined by the parameter:
Some parameters are added baed on certain conditions:
Write a value in Appfile:
In some cases, a parameter may or may not exist, which means a parameter is optional. Thus, it should match the conditions. When a field does not exist, the judgment condition is _variable ! = _|_ .
In this case, the config of the Appfile does not need to be filled in. If you fill it in, you should render it, and vice versa.
The following can be used to set a default value for some parameters:
In this case, the image parameter can be omitted in Appfile. The nginx:v1 can be used by default:
Map-Type Loop
Write the following in the Appfile:
Array-Type Loop
Write the following in the Appfile:
You may notice that the names defined in the parameter are written twice in the Appfile. One is written under the services and each service is distinguished by its name. The other is written in specific name parameters. The repetition should not be written by users. Therefore, a built-in context is defined in KubeVela, which stores some common environment context information, such as the application names and keys. A name parameter doesn't have to be added while using the context in the template. The name parameter is automatically added when KubeVela runs the rendering template.
KubeVela also provides some extensions to the annotations of cuelang to automatically generate documents for the CLI.
Annotations with +usgae at the beginning will become the descriptions of parameters, and the annotations with +short at the beginning are abbreviations used in CLI.
This article introduces the process and principle of adding a new capability in KubeVela and the writing method of a capability template through real-world cases and detailed descriptions.
After the addition of a new capability by a platform administrator, how can users of the platform learn how to use it? KubeVela can add new capabilities and automatically generate usage documents in Markdown format. You can check the KubeVela official website; all of the usage documents in References/Capabilities are automatically generated according to the template of each capability. Finally, you welcome to write some interesting extensions and submit them to KubeVela's Community Warehouse.
www.alibabacloud.com
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@LawrenceHecht/private-cloud-and-paas-run-for-the-hills-ebfc2c2a317b?source=search_post---------81,"Sign in
There are currently no responses for this story.
Be the first to respond.
Lawrence Hecht
Jun 30, 2017¬∑1 min read
Originally published in The New Stack Update.
The headline is a bit sarcastic, but the concern is real. If you use containers, then you‚Äôre likely to believe container orchestrators are a viable alternative to your current private cloud or PaaS platform. According to a survey of container users (by 451 Research, on behalf of CoreOS), 80 percent of container users think ‚ÄúKubernetes or other container management or orchestration platforms are sufficient to replace‚Äù PaaS, and 75 percent say the same about private cloud. No wonder companies like Red Hat have relabeled PaaS offerings like OpenShift as container management solutions.
Reality check: While private cloud growth is decelerating, it‚Äôs not going away. Containers are facing disruption from serverless. While orchestrators may be ‚Äúsufficient,‚Äù many companies will find no reason to change what is working. In fact, if they do make a change, companies may opt for platforms where developers can choose to deploy apps to either VMS, containers or a function.
Edit/analyze/curate. Interest in #techpr/AR, #techpolicy, #blockchain #opendata, #analytics. Know about politics, econ, #enterpriseIT and surveys
Edit/analyze/curate. Interest in #techpr/AR, #techpolicy, #blockchain #opendata, #analytics. Know about politics, econ, #enterpriseIT and surveys
"
https://medium.com/altoros-blog/the-government-of-south-korea-creates-an-open-paas-with-cloud-foundry-6ed3a845ed29?source=search_post---------82,"There are currently no responses for this story.
Be the first to respond.
With one of the world‚Äôs most advanced IT infrastructures, South Korea builds an open PaaS ‚Äî utilizing the eGovFrame development framework and Cloud Foundry ‚Äî to ensure compatibility of multiple solutions delivered by local IT vendors.
https://www.altoros.com/blog/south-korea-adopts-cloud-foundry-as-its-paas/
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
"
https://m.chmarny.com/paas-not-just-about-runtime-data-services-are-the-next-differentiator-bbddee7ca7dc?source=search_post---------86,"few longer thoughts, because every once in a while 140 characters is just not enough

I learn best by doing. And recently, most of the projects I‚Äôve been building are either REST or gRPC-base services deployed as container images into Cloud Run on GCP. That means that I increasingly find myself recreating a lot of the same infra and app deployment flows.


Why not Medium My main reason for migrating off Medium was the paywall Medium introduced while back. I actually understand why they did it. The unlimited access price: $5/month ($50/year) is too high, but still, I get it.
For me though, the objective was to allow readers to easily discover and read my posts.


Increasing large amount of technical news I read come from the posts shared on Hacker News or on Twitter. While both of these services have search options, neither of these seem to be advanced enough to narrow my searches at the desired level or to setup automatic delivery.


All complexity needs to be abstracted, right? This reductionist statements misses nuance around the inherent cost/benefit tradeoffs, especially when you consider these over time.
Don‚Äôt get me wrong, there often are good reasons for additional layers to make things simpler (grow adoption, lowering toil, removing friction, etc.


I recently joined the Office of CTO in Azure at Microsoft and wanted to ramp up on one of the open source projects the team has built there called Dapr. Dapr describes itself as:
A portable, event-driven runtime that makes it easy for developers to build resilient, microservice stateless and stateful applications that run on the cloud and edge and embraces the diversity of languages and developer frameworks.


We are entering a period where custom, highly-optimized, vertical solutions are becoming viable option again. This is a good news for ISVs with proven domain expertise and skilled development resources.
Why do I think so? We now have:
Plethora of feature-rich developer frameworks, message queues, scalable data stores, and even lower-level components in the OSS community with great documentation and a large number of use-case validation Growing number of custom solution companies (more than just ISVs) with existing deep vertical/domain expertise who are also increasingly now investing in hiring and training strong development teams Virtually every Cloud provider offering either a raw Kubernetes service or managed container execution platform which (regardless how you feel about these technologies) creates ubiquitous surface area that can be addressed with a single solution Yes, there still are many ways in which these custom development efforts can fail.


When dealing with file permissions in a non-root image or building apps that include static content (like css or templates), I sometime get an error resulting from the final image content mismatch with my expectations.
Most of the time the errors are pretty obvious, simple fix and rebuild will do.


While the idea of a serverless platform and long running workloads does seem somewhat ‚Äúunnatural‚Äù at first, smart people are already working on that (looking at you @Knative community). In the meantime, a simple approach is sometimes all you may need.


A co-worker recently told me about flic.io buttons. These button caught my attention because they can include triggers for single, double, or hold click and can be easily wired up to all kinds of actions.
I instantly thought of of a few really interesting applications.


Next week, April 9‚Äì11, Google will be hosting this year‚Äôs Cloud Next Conference in San Francisco. The conference is already sold out, but there will be a livestream from keynotes and video available shortly after the sessions.
This year, we have a lot of content to share, and I have the privilege of presenting in four sessions‚Ää‚Äî‚Ääand hope to do at least six live demos.

"
https://medium.com/@sramana/cloud-stocks-paas-strategy-makes-the-unity-ipo-soar-7471cfbee0f4?source=search_post---------88,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Feb 15, 2021¬∑5 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
Analysts estimate that the global online gaming industry will grow from $152 billion in 2019 to $196 billion by the year 2022 at a CAGR of 9%. Mobile gaming share is estimated to grow from 45% in 2019 to just under 50% by 2022. During the same period, console gaming share is expected to remain mostly flat at 31% while PC gaming share is expected to decline from 23% to 20%.
Unity‚Äôs Offerings
San Francisco-based Unity was founded by David Helgason, Joachim Ante, and Nicholas Francis in 2004 as a technology company to provide multiplatform tools and services and help create and operate interactive 3D and 2D content. Unity‚Äôs services took off when the iPhone was launched in 2007, and since then, it has moved to higher-quality productions and tools. Its customers not only include game developers but also artists, architects, filmmakers, and automotive designers who utilize its services to build other interactive apps.
Content built on the Unity platform delivers a more engaging and immersive experience for end users than traditional static content. The interactive feature not only helps end-users connect with the content but also with one another. Its real-time feature allows it to instantly adapt to end-user behavior and feedback.
3D content on Unity shows shape and depth, allowing developers and users to permit multiple viewing angles, and enable augmented and virtual reality. It also allows for collaboration between creators, helping them visualize and iterate on their 2D and 3D creations in real-time and edit content simultaneously. Besides helping build better content, it also leads to significant reductions in design and development cycle times.
According to Unity, apps created on its platform record more than 3 billion downloads a month. Over 120 million gamers on an average per month communicate across its platform using either voice or text capabilities. Its platform is available in 190 countries and its developers start around 150,000 new projects every day.
Improvements in computational power, greater connectivity and the proliferation of devices like smartphones, PCs and consoles have led to an explosion of immersive and interactive content. While these trends have helped other app developers as well, it is the gaming industry that has benefited enormously from these factors.
Keeping in mind the growing importance of cloud offerings, last quarter, Unity launched Cloud Content Delivery, a network aimed at simplifying costs, keeping app size down, and providing scale to small and large studios alike. Cloud Content Delivery is an end-to-end solution for storing, managing, and deploying content releases. It was built to run cloud-based games as efficiently as possible, while consistently keeping players engaged.
Unity‚Äôs Financials
Unity was a privately held company till last September. It had raised $1.3 billion in nine funding rounds from investors including D1 Capital Partners, Light Street Capital, Bienville Capital Sequoia Capital, Canada Pension Plan Investment Board, Silver Lake, Altimeter Capital, and DFJ Growth. Unity went public in September last year when it raised $1.3 billion at a valuation of $13.7 billion and by selling stock at $52 each.
It recently reported its third quarter results where revenues grew 53.3% to $200.8 million. Adjusted loss was $0.09 per share, surpassing market estimates of a loss of $0.15.
In key metrics, customers that generated more than $100,000 of revenue in the trailing twelve months as of September 2020 grew to 739 compared to 553 recorded a year ago. Dollar-based net expansion rate improved to 144% compared to 132% a year ago.
Unity expects to end the current year with revenues between $752-$756 million. It forecast revenues of $200-$204 million for the current quarter.
Unity‚Äôs PaaS Strategy: Platform or API
Developers on the Unity platform can build games and applications that can be deployed and operated across more than 20 platforms, including Windows, Mac, iOS, Android, PlayStation, Xbox, Nintendo Switch, and other augmented and virtual reality platforms. Access to the Unity platform is available on a freemium model. While individuals can access and start building on the platform for free, Unity has multiple tiers for other developers. Access to the platform costs anywhere from $399 per year per seat for companies with revenues or funding of less than $200,000 per year to $200 per month per seat for organizations with larger revenues or funding and bigger seat requirements.
Unity‚Äôs PaaS Strategy: Developer Community
Unity‚Äôs multi-platform engine and development tools have had strong growth in its developer community. It attracted an impressive one million developers within the first seven years of the release of its platform. The next million come at a faster pace with developers doubling to 2 million in 2013. When Unity went public last year, it announced that it had a more than 1.5 million monthly active creators on its platform.
Unity‚Äôs PaaS Strategy: Marketplace and Metrics
According to Unity, apps created on its platform record more than 3 billion downloads a month. Over 120 million gamers on an average per month communicate across its platform using either voice or text capabilities. Its platform is available in 190 countries and its developers start around 150,000 new projects every day.
Unity has leveraged the PaaS strategy successfully. Read my recent article Which SaaS Players Will Win in PaaS to understand how to leverage this high growth PaaS market.
Unity‚Äôs stock has grown rapidly since listing. It is trading at $126.07 with a market capitalization of $34.48 billion. It had touched a 52-week high of $174.94 in December 2020.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://medium.com/@pauldjohnston/yes-but-paas-is-more-about-putting-an-entire-application-framework-into-the-third-party-system-1b67f30164f3?source=search_post---------89,"Sign in
There are currently no responses for this story.
Be the first to respond.
Paul Johnston
Apr 7, 2016¬∑1 min read
Marc MacLeod
Yes, but PaaS is more about putting an entire application framework into the third party system than it is about putting individual functions.
If you change something you still have to upload the entire application rather than a tiny element and breaking changes are more likely.
Serverless is more about coding for each individual event you want to respond to than it is about the servers.
And with PaaS you still have to think about provisioning and still have to think about uptime and still have to think about a bunch of stuff that you just don‚Äôt with serverless.
Quick example: a friend built a mobile game with a heroku backend built with rails. They launched, and found that the application had provisioned about 10 times the number of servers they were expecting. They found a bug and re-deployed of course, but still had scaling issues.
Serverless avoids that issue. You‚Äôd find that one or two of your functions might be taking longer than expected, but not the whole application.
ServerlessDays CoFounder (Jeff), ex AWS Serverless Snr DA, experienced CTO/Interim, Startups, Entrepreneur, Techie, Geek and Christian
ServerlessDays CoFounder (Jeff), ex AWS Serverless Snr DA, experienced CTO/Interim, Startups, Entrepreneur, Techie, Geek and Christian
"
https://medium.com/@sramana/cloud-stocks-digitalocean-goes-public-with-strong-isv-paas-strategy-454590e7f6b4?source=search_post---------90,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Apr 5, 2021¬∑4 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
According to an IDC report, the global IaaS and PaaS market for individuals and organizations with less than 500 employees is expected to grow at 27% CAGR from $44.4 billion in 2020 to reach $115.5 billion by 2024. New York-based DigitalOcean (NYSE: DOCN) is a leading player in the segment that went public last week.
DigitalOcean‚Äôs Offerings
DigitalOcean was founded in 2012 by Alec Hartman, Ben Uretsky, Jeff Carr, Mitch Wainer, and Moisey Urtesky based on a realization that the cloud was the new way to build modern-day web applications. The founders believed that software developers, entrepreneurs, and SMBs needed better solutions from cloud computing providers to leverage the opportunities provided by innovative cloud infrastructure technologies. DigitalOcean grew to offer infrastructure and PaaS solutions to these organizations and teams without requiring them to have DevOps experience.
To make development easier for developers, DigitalOcean provides on-demand infrastructure and platform tools for developers, startups, and SMBs that are easy to use and access while being reliable and affordable. It provides a range of capabilities to access compute, network, and storage infrastructure as well as software-managed services that provide additional capabilities for managing more robust infrastructure needs.
Today, DigitalOcean caters to more than 570,000 customers in over 185 countries. It has built a developer learning community with over 34,000 developer tutorials, technical guides, and community-generated Q&As. The company has over 5 million developers on its platform, which includes over 30,000 ISVs.
DigitalOcean provides similar services that giants like Amazon and Microsoft provide but focuses primarily on smaller-sized customers and individual developers. It has built up a business by keeping its products easy to use. Unlike Amazon and Microsoft, DigitalOcean does not have a slew of product offerings. It has a few products, including the customizable Linux-based virtual machines that it calls droplets, data-storage options, networking tools, and three databases. It is looking to add analytics software and add data center infrastructure in more places around the world in the coming quarters.
DigitalOcean‚Äôs Financials
DigitalOcean earns revenues by charging its customers a monthly fee based on the usage of its services. The growth of cloud computing and developer action globally has resulted in a significant growth of DigitalOcean‚Äôs financials as well. Revenues have grown from $203.1 million for fiscal 2018 to $254.8 million in fiscal 2019 to $318.4 million for fiscal 2020. DigitalOcean is still not profitable and reported a loss of $36 million in fiscal 2018, $40.4 million in fiscal 2019 and $43.6 million for fiscal 2020.
DigitalOcean went public last week. Prior to going public, it had raised $455.6 million in 13 rounds of funding, with the most recent round being held in May last year. Its investors include Andreessen Horowitz, Access Industries, EquityZen, Kliwla Family Office AG, Viaduct Ventures, Mighty Capital, Opus Bank, Barclays Investment Bank, East West Bank, and HSBC Bank.
It raised $775.5 million from its IPO where it sold its stock at $47 apiece. It is currently trading at $43.80 with a market capitalization of $4.61 billion.
I believe that DigitalOcean is a formidable player in the space. It boasts of an impressive PaaS strategy as is reflected in the size of its developer community. By keeping it simple, DigitalOcean has successfully built a PaaS ecosystem that will sustain growth for both itself and its developers.
It is early days, but the stock hasn‚Äôt had a promising start so far as the timing of the IPO coincides with significant market turbulence in cloud stocks.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://rominirani.com/a-few-paas-ing-thoughts-c36ec05b085e?source=search_post---------92,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Google App Engine has suddenly been thrown into spotlight with a critical piece written by Carlos Ble at his blog.
I got my share of mixed feelings while reading his post. Why, you may ask? I have been spending a better part of my free time digging into the Google App Engine, which is a PaaS platform that allows you to write web applications in either Java or Python. Heck, I have even combined all my findings and published them as a free eBook over here.
Should I get all defensive about Google App Engine and try and blast each of Carlos‚Äô points. Actually not. I do not work for Google and neither does my company currently do any work in Google App Engine. All my investigations into Google App Engine has been purely out of my interest and my goal of discovering a good platform to help showcase some of my applications.
What Carlos has mentioned in his blog post should not be construed as a way to get more publicity or the fact that Google App Engine is completely useless. If a platform or product needs to be successful, it needs to have its healthy dose of people who love it, hate it, just about like it, just about manage to work with it and many more feelings in between. Google is not a stupid company, its engineers are smart too and anyone can easily conclude that they know much more about the shortcomings of their App Engine platform than Carlos or its users, like you and me.
If you have the time to go through Carlos‚Äô post and the colorful comments that follow, one thing struck me in particular. The concept of Cloud Computing is not being bashed at all in totality. This model of computing is real and no one is debating that. Given that, it is important to look at the 3 flavors of Cloud Computing: IaaS, PaaS and SaaS. We will keep SaaS aside for the moment. IaaS and PaaS are clearly defined. You need computing resources (Storage, CPU, etc) and complete control to run whatever you want via your own application stack, go with IaaS. Amazon does a fantastic job over there. To anyone dealing with PaaS, it is clear that all vendors in that space mandate a programming model. There are no Ifs and Buts about it.
Let us dig into that a little. By mandating a Programming Model, the PaaS vendors are clearly telling you that your application needs to be written as per their software stack and the APIs that it makes available to you. You cannot just think about taking your inhouse web application and deploying it on Google App Engine and think that it will work. No. Never. Unless it is a Servlet, doing ‚ÄúHello World‚Äù. Every PaaS vendor addresses infrastructure by wrapping APIs around it. They give you APIs for Authentication, Data Storage, Caching, Messaging, Networking and much more. What does it mean? It means you have to retrofit your application to use those APIs to get maximum mileage out of the PaaS platform. This is because those APIs are closely tied into how the PaaS will provide you elasticity. Let us look at Database support. Since the beginning of time, Google App Engine does not support SQL database storage (I am not talking about its Enterprise edition that has MySQL support). This means that your data storage mechanism has to be written (or rewritten) to fit into the NoSQL like service that the Google Datastore provides. Does it have restrictions? Is there are paradigm shift in thinking to move to that? The simple answer is ‚ÄúYes‚Äù. But which software in this world does not have restrictions? If it was that simple, the world would have needed only one programming language. Anyways, that‚Äôs not the point. The point is that you have to adjust as you move to a PaaS platform. PaaS platform mandate a programming model and you need to follow that. As you go through that, you need to modify your thinking first and then your code and measure, measure and measure constantly what is working and what is not? And keep adapting as per that. All companies do that with their products, especially public facing live applications and this is not different.
Will all applications fit within Google PaaS? You don‚Äôt need me to tell you that they will not. What is it particularly that I like about Google App Engine. For me, its biggest selling point has been the low cost to entry (don‚Äôt mistake that for zero cost of entry!). I have developed several Proof of Concept applications that demonstrate some idea in my head and hosted them all on Google App Engine. Some of the applications are still live and running today. I have a good feeling what works and what doesn‚Äôt and have adapted my applications. I find it works best for applications that you have the luxury of writing from scratch. I would be careful to simply assume that my enterprise apps can be hosted tomorrow as-is on its platform, for reasons described above.
I have talked to a lot of folks about Google App Engine. And I intentionally mention to them things like the 30-second limit for requests and the 1000-record limitation. I think when you mention this to any software engineer, the first reaction is akin to an electric shock and then the outpouring starts. Without even thinking about what application they are going to write, they claim this platform is not for them. Here are some of the remarks that I have heard from them in response to the above limitations : How could Google do something like this? A 30 second limit for requests? Do you know my application will need much more than that? What no SQL? What are you talking? Have you lost your mind? Is there even a thing like that? What happened to your education and those C.J.Date RDBMS primers? :-)
All the above concerns are valid but my only response is that in a PaaS, it is a give and take relationship. You lose your full control over how you write things. In return you get the scalability for a fraction of the cost. You get your IT infrastructure managed without you even understanding it. Once you understand this symbiotic relationship, which is true in every other aspect of our life too, things settle down and then it does not look ‚Äúcloudy‚Äù anymore (no pun intended!)
One more point. There are enough success stories for both Amazon (IaaS) and Google (PaaS). Ask any of them about their journey and there will be stories of pain, adjustments and finally making it work. There will be companies now, who will post their success stories with Google App Engine too to mitigate the bad press. But I personally don‚Äôt worry about that. What I am excited about is that this light started by Carlos, will result in more information coming out about Google App Engine and that includes stories from the trenches. I will be keeping my eyes open to scan resources that will spring up and learning more about the platform. Big Advantage to Google App Engine now, if they embrace the open nature of the comments and actually take up some of the limitations, that even they know about, on a war footing!
Finally I would like to conclude, that there is no point in telling people that you need to read the documentation and understand the platform completely before committing your resources to using the particular product or platform. This model does not scale anymore. It does not get you to the market faster anymore. And it goes very much against the fundamental notion of getting the Early Mover Advantage. Think about how many articles in the recent 1‚Äì2 years, that you have come across from even giants like Twitter and Facebook, publicly stating that technology X or Y did not work or scale for them, and hence they had to develop that infrastructure themselves or replace it with something better suited to them. Are we expecting a Google or a Amazon to tell you, ‚ÄúHey! You know what? Our platform really sucks if you want to do A,B,C.‚Äù They can give some general guidelines and best practices but everything else has to be discovered, shared and that is all Carlos is trying to say here. There will be only one winner in the end, the PaaS platform itself.
Long Live Cloud Computing! Long Live IaaS and PaaS!
Technical Tutorials, APIs, Cloud, Books and more.
Written by
My passion is to help developers succeed. ¬Ø\_(„ÉÑ)_/¬Ø
Technical Tutorials, APIs, Cloud, Books and more.
Written by
My passion is to help developers succeed. ¬Ø\_(„ÉÑ)_/¬Ø
Technical Tutorials, APIs, Cloud, Books and more.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@sramana/cloud-stocks-c3-ai-should-be-doing-isv-focused-paas-ea11a50bf4ca?source=search_post---------93,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Mar 8, 2021¬∑5 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
According to a recent report, the global enterprise AI software market is estimated to grow at 24% CAGR from $18 billion in 2020 to reach $44 billion by 2024. Tom Siebel‚Äôs C3.ai (NYSE: AI) is a recently listed player in this market, which announced its third quarter results that surpassed market‚Äôs expectations.
C3.ai‚Äôs Financials
C3.ai‚Äôs third quarter revenues grew 19% to $49.1 million, ahead of the market‚Äôs estimate by 2.3%. Adjusted loss per share of $0.23 surpassed the Street‚Äôs estimates of $0.16.
Its subscription revenues grew 23.3% over the year to $42.7 million. Professional service revenues dropped 3.7% to $6.4 million.
For the fourth quarter, C3.ai expects revenues of $50-$51 million, compared with the market‚Äôs forecast of $48.4 million.
C3.ai‚Äôs Offerings
C3.ai was set up in 2009 by entrepreneur Tom Siebel and Patricia House to become an enterprise AI software provider that can help organizations accelerate their digital transformation journey. Its AI suite provides comprehensive services that help organizations build enterprise-scale AI applications more efficiently and cost-effectively.
Today, the C3.ai suite offers four key products. Its core technology is a comprehensive application development and runtime environment that allow customers to rapidly design, develop, and deploy Enterprise AI applications of any type.
The second suite of offerings is the C3.ai Applications that have been built using the C3.ai Suite and include a large portfolio of industry-specific and application-specific turnkey AI solutions that can be immediately installed and deployed. C3.ai is also partnering with the likes of Microsoft and Adobe to deliver industry-specific AI CRM. As part of its tie-ups with these leaders, C3.ai has integrated the Microsoft CRM stack, the Adobe marketing automation stack, and its own stack to bring to the market a family of applications that offer AI-enabled CRM software.
Finally, its recently launched C3 AI Ex Machina is a predictive analytics application that empowers people to develop, scale, and produce AI-based insights without the need to write code. Users can use the simple and intuitive drop-down tools to apply predictive analytics to their business and improve the digitization of company operations. Users can solve a limitless amount of use cases, such as customer churn prevention, supplier delay mitigation, assess reliability prediction, and fraud detection.
It was also recently granted a patent for systems, methods, and devices for an enterprise AI application development platform. The patent protects the use of model-driven architecture for the design, development, deployment, and operation of next-gen cyber-physical software applications and business processes, the application of advanced data aggregation, data persistence, data analytics, and machine learning methods, as well as methods meant for implementing abstraction and continuous processing of aggregated data with a model-driven architecture. It also protects embedding capabilities in a model-driven architecture type system and the use of canonical data models.
C3.ai believes that it has a rapidly growing addressable market size. It pegs the market at $174 billion in 2020, growing to $271 billion in 2024. It includes enterprise AI software, enterprise infrastructure software, and enterprise applications market as part of this addressable opportunity.
I think C3.ai is in a strong position to address this market. In the third quarter, 86% of its revenue was its SaaS-based recurring revenue. 65% of that comes from applications that include a portfolio of offerings for various verticals such as banking and utilities. The remaining 35% of its software revenue comes from the platform where companies like Shell are running over 200 projects built on top of its platform. C3.ai believes that in a steady state, license revenue will contribute 60% of its revenues and the remaining 40% will come from its platform offerings.
C3.ai‚Äôs PaaS Strategy
C3.ai has a PaaS strategy that focuses on AI solutions. Its stack also includes highly verticalized offerings that cater to industries such as banking, utilities, transportation, health care, and retail. But it does not, as yet, have an ISV-focused PaaS strategy. An ISV strategy could help it open up its platform for more use-cases that expand its deployment in other verticals and, in turn, help these developers get access to a customer base looking for highly efficient AI-based solutions.
C3.ai‚Äôs stock is currently trading at $91.49 with a market capitalization of $9.30 billion. It touched a 52-week high of $166. 60 last month. The stock had fallen to a 52-week low of $50.23 in March last year. C3.ai had listed in December last year when it raised $651 million by selling its stock at $42 apiece. Its valuation at the time of listing was $9.6 billion. Prior to listing, it had raised $228.5 million in funding from investors including Breyer Capital, InterWest Partners, Sutter Hill Ventures, TPG Growth, Thomas Siebel, Wildcat Venture Partners, Pat House, Bolt Innovation Group, and Constellation Technology Ventures. Its last round of funding was held in January 2018, when it raised $100 million at an undisclosed valuation. An earlier round held in March 2017 had valued the company at $1.4 billion.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article. I am an investor in this company.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://medium.com/@sramana/cloud-stocks-atlassian-makes-over-100m-in-paas-in-2020-d1bc380434f1?source=search_post---------94,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Feb 16, 2021¬∑4 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
Last week, Atlassian (NASDAQ: TEAM), a leading provider of team collaboration and productivity software, reported its second quarter results that surpassed estimates. Atlassian has been focusing on becoming a cloud-first company and recently announced a three-year migration path to the cloud for on-premises customers.
Atalssian‚Äôs Financials
Second quarter revenue grew 23% to $501.4 million, ahead of the market‚Äôs forecast of $475 million. Adjusted EPS was $0.37, the same as last year and better than the market‚Äôs forecast of $0.32.
Net loss was $621.5 million, compared with net income of $124.1 million a year ago. Net loss spiked mainly due to a debt security charge of $539.1 million.
Cash and cash equivalents, and short-term investments at the end of Q2 2021 totaled $1.8 billion. Total employee headcount increased by 467 to 5,752 with the majority of the additions in R&D.
By segment, Subscription revenues grew 36% to $310.7 million, driven by cloud products as well as data center offerings. Maintenance revenues grew 12% to $131.3 million. Perpetual license revenue declined 24% to $22.1 million. Other revenues, which includes revenue from marketplace apps, increased 9% to $37.3 million.
Net new customers grew by 11,617 to 194,334 in Q2, driven by cloud products and an improved cloud customer experience. It added 8,620 customers in Q1.
For the third quarter, Atlassian expects revenues of $475-$490 million with an adjusted EPS of $0.20- $0.21. Analysts had estimated earnings of $0.25 per share on revenue of $472 million.
Atlassian‚Äôs New Offerings
In November 2020, Atlassian introduced Jira Service Management, which integrates initiatives such as service desk, incident management, real-time-communications, and asset and configuration management into one solution. This doubles its TAM from 45 million software team members to a 100 million technical workers including IT teams. These numbers sound very aggressive. I wasn‚Äôt aware that there are so many technical workers in the world.
Atlassian‚Äôs Shift to Cloud
Last quarter, Atlassian announced its plans to transition to a major shift to cloud. Atlassian announced the end of new server license sales beginning February 2, 2021 and the end of support for all server products as of
February 2, 2024. It introduced a robust migration program,
including tools, incentives, and customer support. For data center customers, Atlassian announced new capabilities and integrations that make it easier for cloud and data center products to work together. The cloud transition might be challenging for a couple of quarters, but it creates value over the long term.
I believe Atlassian has time and again proved its value, especially with its PaaS strategy. In fiscal year 2020, the Atlassian Marketplace generated over $400 million in purchases and revenue from the Marketplace apps was $103.5 million. It has over 25,000 third-party developers on the Atlassian platform and a network of over 500 solution partners. Click here to read more on the analysis of Atlassian‚Äôs PaaS strategy.
Atlassian is one of the very few companies to have a fully fleshed out PaaS strategy and there is a lot that other SaaS companies can emulate to win in PaaS. Read my recent article Which SaaS Players Will Win in PaaS to understand how to go about it.
Atlassian‚Äôs stock is trading at $247.54 with a market capitalization of $61.90 billion. In the past year, its stock has nearly doubled. Since going public four years ago, its market cap has zoomed from $6 billion to $57.6 billion. It touched a 52-week high of $250.03 in December and a 52-week low of $110.01 in March.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article. I am an investor in this company.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://stacksense.io/understanding-caas-paas-container-platforms-and-application-platforms-ffb44e1d1c9?source=search_post---------95,"Sign in
What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Krish
Apr 18, 2018¬∑5 min read
There is quite a bit of confusion in how the terms CaaS, PaaS, Container Platforms, and Application Platforms are used. The confusion exists in the market and we want to use this post to clarify what these terms mean in the context of a cloud-native ecosystem. The difference between CaaS or PaaS and Container Platforms or Applications Platforms is nothing new. Even in the early cloud computing days, there were always two ways to build platforms to deploy applications, IaaS+ vs PaaS, The same distinction applies to the container world. It is about the level of abstraction (or the control) one wants to have and whether the organization is comfortable using the public cloud.
A container as a Service (CaaS) is a hosted container infrastructure that offers an easy way to deploy containers on an elastic infrastructure and it is offered as a public cloud service. CaaS is suitable in contexts where developers want more control over container orchestration. With CaaS, organizations can deploy complex applications on containers without worrying about the limitations of opinionated platforms like Heroku or Google App Engine. Think of CaaS as the elastic container infrastructure just like how IaaS was elastic VM infrastructure. If we draw a line with flexibility on the left and abstraction on the right for the container world, CaaS is on the leftmost side of the line.
These are public cloud services that are more container-centric where the containers can be used to deploy application code and the dependencies. CaaS is for deploying applications when you want more control over the components of the applications.
PaaS is a public cloud service that offers a simple interface for developers to deploy their apps. Modern PaaS offerings use containers that are compliant with Open Container Initiative specs. These are public cloud services that are more application-centric with an abstraction at the developer level. Like CaaS, PaaS can be used to deploy the applications but the user need not manage the underpinnings of various components underneath (or, looking at it from the other side, users lose control over the application components). Any organization that is comfortable using public clouds and has a very small or no IT team should just use PaaS.
Container Platforms are suitable for deploying CaaS like deployment on-premises or on hybrid cloud/multi-cloud. They provide CaaS like interfaces for developers with an added benefit of a choice for the underlying infrastructure. Not every organization is comfortable using public clouds and some organizations want to use multi-cloud. Container platforms help solve such use cases.
Container platforms don‚Äôt impose restrictions like some of the application platforms and are suitable for lift and shifting complex applications to containers. As is the case with CaaS, Container Platforms help deploy both application code and dependencies using containers.
These are container-based platform abstractions that give a developer interface to deploy the applications. Think of this as PaaS but on-premises or on hybrid cloud/multi-cloud. The IT operations can deploy the platform in any infrastructure they want and provide an easy application deployment interface for the developers. This is more opinionated than container platforms.
Some application platforms take a more opinionated approach to application architectures, supporting only 12-factor apps (stateless apps) while others support both stateless and stateful applications. The difference between Application Platforms and Container Platforms lies in the additional automation that adds developer workflows, DevOps pipelines, managing the interconnections between the containers underpinning the application code and their dependencies.
Note 1: The above flow diagram is a simplified framework to help you decide between various options in the market. For a more detailed dive in, please contact us for advisory services
Note 2: The list of vendors given as examples is by no means exhaustive or complete. These are some of the major vendors in the market but there are many more who are not covered in this post
Note 3: OpenShift Container Platform straddles both Application Platforms and Container Platforms. If we look at the Abstraction vs Flexibility line, OpenShift Container Platform will sit between most container platforms listed above and Pivotal CloudFoundry
Future Asteroid Farmer, Analyst, Modern Enterprise, Startup Dude, Ex-Red Hatter, Rishidot Research, Modern Enterprise Podcast, and a random walker
See all (529)
This blog helps enterprise decision-makers understand the emerging technologies and it is part of Rishidot Research publications
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@sramana/cloud-stocks-workday-drives-enterprise-use-cases-through-paas-anaplan-taps-into-consultants-3118c0633ea2?source=search_post---------96,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Mar 6, 2021¬∑6 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
According to a recent report, the global cloud-based ERP market size is expected to grow from $45.3 billion in 2020 to $101.1 billion by 2025 at a CAGR of over 17%. SaaS-based enterprise services provider Workday (NASDAQ: WDAY) recently announced its fourth quarter results that continued to outpace market expectations.
Workday‚Äôs Financials
Workday‚Äôs fourth quarter revenues grew 15.9% to $1.13 billion, ahead of the Street‚Äôs forecast of $1.12 billion. Non GAAP EPS was $0.73, also ahead of the market‚Äôs forecast of $0.55. For the quarter, net loss decreased to $71 million compared to loss of $120.7 million a year ago.
By segment, Subscription services revenues grew 19.8% to $1.01 billion while professional services revenues declined 8.2% to $125.4 million.
For the full year, Workday‚Äôs revenues grew 19% to $4.32 billion and GAAP loss was $1.19 per share compared with a GAAP loss of $2.12 per share a year ago.
For the first quarter, Workday expects subscription revenues of $1.018-$1.02 billion and professional services revenues of $139 million. Workday expects to end the year with $4.38-$4.4 billion in subscriptions revenues and $590 million in professional services revenue. The market was looking for revenues of $1.16 billion for the quarter with an EPS of $0.58.
Workday‚Äôs Acquisition
Recently, Workday announced its plans to acquire Denmark-based Peakon for approximately $700 million. Founded in 2014 by Christian Holm, Dan Rogers, Kasper Hulthin, and Philip Chambers, Peakon is a platform that works to improve employee engagement, inclusion, and growth. Prior to the acquisition, Peakon had raised $68 million in four rounds of funding from investors including Balderton Capital, Atomico, EQT Ventures, Indivest Partners, Heartcore Capital, and Tommy Ahlers.
Workday plans to leverage the acquisition to build a continuous listening platform that will allow customers to capture real-time sentiment, facilitate ongoing feedback, and access personalized, prescriptive recommendations for actions. It will also merge Peakon‚Äôs technology that determines and distributes surveys and information with its own employee insight tools to help leaders with the ability to discover and respond to employee needs and behaviors.
Besides acquisitions, Workday continues to grow its product portfolio and accumulate accolades. Last quarter, it was positioned as a Leader in the 2020 Gartner Magic Quadrant for Cloud HCM Suites for more than 1,000 Employee Enterprises, for the fifth year in a row. For the fourth year in a row, it was awarded the Best in KLAS in enterprise resource planning for Workday Financial Management, Workday Human Capital Management, and Workday Supply Chain Management solutions for healthcare. In terms of product enhancements, it recently announced the release of a COVID-19 vaccine management solution that integrates real-time HR data with immunization information, thus providing customers with the insight and resources needed to help foster healthier workforces and safer workplaces.
Workday‚Äôs PaaS Strategy
I find Workday as a promising player within the PaaS segment. Unlike some of the other players who have chosen the API path, Workday has opened its platform, Extend, to partner to build and customize applications and extensions on top of the capabilities already delivered on Workday to meet business needs. Extend allows organizations to leverage a familiar user, administration, and reporting experience and enforce the same security controls while gaining real-time access to Workday people and financial data for additional business needs.
Since its release last year, Workday has seen use cases such as the development of a compensation review app that simplifies budget allocation during the comp cycle, a training validation app that ensures line-worker certification and safety in compliance with FDA, a student counseling app that connects students with mentors, and a billing app that interfaces with paid learning content. Companies like Netflix and IBM are citing examples of increased efficiencies due to the use of apps that have been developed on Workday.
Workday‚Äôs PaaS strategy remains focused on System Integrators catering to enterprises, and enterprise IT extending functionality. It is yet to open its platform to ISVs. The company believes that its customers are getting great value from Extend and is seeing its customers ‚Äúbuild mini apps or an extensions‚Äú, but it does not see the benefit of opening its platform to ISVs right now.
Its stock is trading at $237.02 with a market capitalization of $57.60 billion. It hit a 52-week high of $282.77 last month and a 52-week low of $107.75 in March last year.
Rival Anaplan also recently delivered a strong quarter.
Anaplan‚Äôs Financials
Revenues for the quarter grew 24.7% to $122.5 million, ahead of the Street‚Äôs forecast by 2.9%. Adjusted loss for the quarter was $0.07 per share, compared with the Street‚Äôs forecast of a loss of $0.10 per share.
By segment, subscription revenues grew 25.7% to $112.6 million and professional services revenues grew 14.2% to $10 million. Its dollar-based expansion rate was 114%.
Anaplan expects revenues between $126.5-$127.5 million, significantly higher than the Street‚Äôs estimates of $127.16 million. For fiscal 2022, Anaplan expects revenues between $550-$555 million, higher than the Street‚Äôs estimates of $553.44 million.
Anaplan‚Äôs Collaboration
Recently, Anaplan announced its collaboration with AWS to enable its enterprise planning application to be made available on AWS. The collaboration will expand the reach of the Anaplan platform and will deliver added value to its customers by helping to efficiently leverage solutions of AWS and easily integrate with AWS data sources and advanced intelligence capabilities. It will also provide its customers with flexible data management over data residency, thus allowing customers to comply with requirements and simplifying the use of Anaplan across global teams and markets.
The partnership will also build on the recently announced Anaplan PlanIQ with Amazon Forecast by allowing for seamless access to third-party data, like weather patterns and forecasts, into Anaplan PlanIQ. The integration will allow modelers and planners to leverage advanced machine learning-based forecasting capabilities to embed forecast predictions directly into their planning processes. Anaplan‚Äôs connected planning will, in return, help use these forecasts to improve overall business performance.
Anaplan‚Äôs PaaS Strategy
Anaplan too has an active PaaS strategy. It opened its data platform a few years ago, to allow organizations and developers to build apps to solve planning problems. Anaplan has been extending its platform use cases by partnering with several consultants to get them to build apps that make it easier to perform a wide range of activities including financial forecasting, project management, and merchandise planning on Anaplan directly. The platform offers 100s of Anaplan, Partner, and Community created Apps in services ranging from finance, supply chain planning, sales, workforce management, marketing, IT, and training. It also allows developers to build accelerators that are basic applications that can help organizations jump-start the process of building custom planning models and apps on the platform.
Its stock is currently trading at $57.44 with a market capitalization of $8.15 billion. It touched a year high of $86.17 in February. The stock had fallen to a low of $26.04 in March last year.
I think both Workday and Anaplan should take a page from Salesforce‚Äôs playbook on PaaS. Salesforce has figured that a successful PaaS strategy needs not only an open platform but a marketplace as well.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article. I am an investor in this company.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://medium.com/tinted-glass/parlez-vous-paas-26a318f9030d?source=search_post---------97,"Sign in
There are currently no responses for this story.
Be the first to respond.
Hari Harikrishnan
Apr 14, 2013¬∑3 min read
Several years ago I visited Parfumerie Gallimard in Grasse, France. Grasse is famous as the perfume capital of the world and Gallimard is the 2nd oldest perfumery in the world. There I learnt about how the les nez (‚Äúnoses‚Äù ‚Äî the perfumers who compose perfumes with their fine-tuned olfactory senses) create new perfumes. The vocabulary used to describe perfumes have evolved over centuries. Lately, words used to describe types of PaaS (Platform as a Service) reminded me of Grasse and made me wonder about when we will get sophisticated in our description of PaaS, similar to how we came to be good at describing perfumes, wines, and steaks.
Over the last decade we have come to terms with SaaS (Software as a Service) and IaaS (Infrastructure as a Service). PaaS (loosely thought of as ‚Äúmiddleware‚Äù in the cloud) however, is a newer phenomena, resulting from the maturing of its siblings, and is a raging topic of discussion. (Tap here to see more on its fit in the IT stack). The fact that PaaS is still maturing is evident from the episode below.
I was discussing PaaS with an esteemed colleague of mine. During the discussion, I commented that person A is working on ‚Äúeye-PaaS‚Äù. She said person B is working on ‚Äúeye-PaaS‚Äù. I was insistent on A, she on B. We moved on. I started writing on the board my thoughts on PaaS. When I wrote ‚ÄúiPaaS‚Äù, she said ‚ÄúIPaaS‚Äù (with capital ‚ÄúI‚Äù). We quickly realized that while I was talking about some full-bodied cabernet, she was referring to some fine textured pinot. Suffices it to say, we recognized our follies and carried on constructively, if not gamely.
Eye-PaaS or Aye-PaaS?
Today PaaS has so many flavours that it is indescribable. The vocabulary is catching up, or everyone is making up their vocabulary in an attempt to be understood; so much so that we have aPaaS, iPaaS, dbPaaS‚Ä¶resulting in [a-z]PaaS. Wait, it doesn‚Äôt stop there! We use APaaS, DPaaS, IPaaS‚Ä¶resulting in [A-Z]PaaS. What next? How about Italicized PaaS? Bolded PaaS? Helvetica PaaS? Should we say eye-PaaS or aye-PaaS? If aye-PaaS refers to middleware in the cloud, does nay-PaaS refer to on-premise (not cloud) middleware? Back in Grasse if they cared about PaaS, the noses would call it ‚Äúne PaaS‚Äù. So this rant comes full circle as I go from le nez to ne PaaS, completing the transgression from perfumes to technology and vocabulary to fonts, phoenetics & linguistics.
If you are still reading‚Ä¶it appears that the resulting state of PaaS currently looks like this:
The left is seemingly well understood, classified and documented; the right is in flux and is being crafted, not because we are intentionally trying to confuse the listener, but due to a re-mixing of functionality as we move parts of technology to the cloud while concurrently adding new functionality for the cloud.
Do we speak PaaS? Yes, we do, but speaking is quite different from communicating, as is evident from the episode above. Over time we have found the right vocabulary to describe perfumes, wines, and steak. Let‚Äôs hope we find the right vocabulary to describe PaaS too ‚Äî spicy PaaS, fruity PaaS, nutty-with-a-hint-of-tobacco PaaS, rare PaaS, medium-well PaaS, and so on ‚Äî without having to carry a decoder ring to decipher what we are hearing. In a few years we may forget the faux-pas of our PaaS and live in paz. In the meantime, it is fine to confess that we do not speak PaaS well. Je ne parle pas PaaS.
Musing about the intersection of technology, business, and society. #Digital #Strategy #Healthcare #Innovation
See all (201)

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
Thoughts on the Interplay of Technology, Business, & Society
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@sramana/cloud-stocks-saas-players-that-will-win-in-paas-98374e7d93ee?source=search_post---------98,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Jan 14, 2021¬∑4 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
At the end of 2020, I wrote Big Idea 2021: SaaS Companies Will Create 10 Million Jobs with the central thesis that SaaS players would evolve into PaaS to create deeper moats around their core market positions and gain access to the related force multiplier.
To recap on the assumptions:
As you may have followed in the ensuing discussion, my assumption is that the trend would follow an 80:20 rule, with 20% of the SaaS companies becoming high performing PaaS players with robust developer eco-systems. In other words, around 200 companies would drive the industry trend forward.
My assumption is that these 200 companies have already achieved a certain scale, most likely, $100M+ in ARR.
It is, however, not the case that the top 200 SaaS players are currently ALL working on PaaS. Very few, in fact, have fully fleshed out PaaS strategies. Fewer actually have any developer ecosystem to write home about. I heard through my network that Twilio is generating $100M in PaaS ecosystem revenue. Shopify has about 4k developers, Atlassian has 25k. These are the frontrunners, besides, of course, Salesforce.
To assess which SaaS companies are likely to successfully transition into PaaS leaders, I use the following framework:
PaaS needs developers. Developers come in various shapes and sizes. Lots of developers are sitting inside large companies and learning the technical capabilities of a platform, its APIs, etc. There are also freelancers with relevant expertise. Finally, there are small, entrepreneurial companies (including solo entrepreneurs running virtual companies), with the aspiration of becoming the next Veeva, perhaps.
Any SaaS player who wants to win in PaaS would need to have a strategy in place to nurture all three segments, especially the last of these categories: the small ISVs.
To get there, the first two categories of developers inside large companies, as well as the freelancers, need to be considered as a pipeline. There are many developers inside large companies who are Bootstrapping with a Paycheck. The freelancers have gigs, but often develop apps on the side.
Nurturing a developer community requires commitment and resources.
Training comes in two forms: technical and business. There is considerable investment for a developer to build expertise on a platform. This journey needs to be made as smooth and as easy as possible.
Equally important is the business training of the developers who have the aspiration of succeeding as entrepreneurs. Salesforce‚Äôs success hinged on the early realization of this need. They had an accelerator early on for their developer ecosystem.
Entrepreneurs want customers. The draw of joining a PaaS ecosystem is being able to access customers. Having a robust marketplace strategy is the key to fluid customer engagement. Salesforce did this superbly with AppExchange, and Apple with its App Store.
Salesforce and Apple have had dedicated venture funds for their developer ecosystems. They have also worked with other investors who have supported ventures germinating in their ecosystems.
Currently, I see SaaS companies in various stages of evolution:
So.
This is where we begin 2021.
I would love to work with SaaS players with serious PaaS ambitions.
It would be super interesting to track the progress of this trend through this new decade and contribute to its development.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Photo by Scott Webb on Unsplash
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://medium.com/@sramana/cloud-stocks-salesforce-can-transform-slack-paas-acquisition-still-pending-d3be54620dc8?source=search_post---------99,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Mar 2, 2021¬∑5 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
Salesforce (NYSE: CRM) recently announced its fiscal fourth-quarter results that surpassed market expectations. While the company continues to grow through acquisitions and product development, its weak earnings outlook for the current year sent the stock falling 5% in the after-hours session.
Salesforce‚Äôs Financials
Salesforce‚Äôs revenues for the fourth quarter grew 20% to $5.82 billion, above analyst estimates of $5.68 billion. Adjusted earnings of $1.04 per share was also better than the market‚Äôs forecast of $0.75 per share.
By segment, Subscription and support revenues grew 20% to $5.48 billion, Professional services and other revenues grew 18% to $341 million.
Revenues for the year grew 24% to $21.25 billion with Subscription and Support revenues growing 25% to $19.98 billion and Professional services and Other revenues increasing 21% to $1.28 billion. Adjusted earnings was $4.92 per share.
For the first quarter, Salesforce forecast revenues of $5.88-$5.89 billion with an EPS of $0.88-$0.89. The market was looking for revenue of $5.72 billion and an EPS of $0.76. Salesforce expects to end the current fiscal year with revenues of $25.65-$25.75 billion and an EPS of $3.39-$3.41. The market was looking for revenues of $25.42 billion for the year with an EPS of $3.54.
Salesforce‚Äôs Vaccination Cloud
Earlier last month, Salesforce also announced the release of Vaccine Cloud, a technology to help government agencies, healthcare organizations, businesses, nonprofits, and educational institutions deploy and manage their vaccine programs more rapidly, safely, and efficiently. Currently, several government and nonprofit agencies worldwide are tasked with providing Covid-19 vaccines to citizens. However, most of these agencies and organizations do not have the technology infrastructure in place to handle the complexity, speed, and scale necessary for vaccine administration. Governments are partnering with private sector companies to manage this mass vaccination effort. Salesforce is helping these agencies manage the technology specifically for vaccine logistics.
Salesforce‚Äôs Acquisitions
Recently, Salesforce announced the acquisition of Virginia-based Acumen Solutions. Founded in 1999 by David V. Joubran, Acumen leverages Salesforce‚Äôs technologies to provide solutions that help companies and government agencies deliver connected digital experiences. Digital transformation is especially critical under the current pandemic conditions.
Salesforce plans to leverage Acumen‚Äôs expertise within its Professional Services division by integrating it with Acumen‚Äôs industry knowledge and expertise. It will also be able to provide customers with products and solutions that better suit their needs. Acumen‚Äôs funding and financial details prior to the acquisition are not disclosed.
Last year, Salesforce had also announced the $27.7 billion acquisition of Slack. The deal is currently being reviewed by the DoJ. A few analysts believe that Salesforce may have overpaid for Slack, but Slack is delivering strong financials of its own so far. Slack recently reported revenues of more than $250 million, trending at $1 billion revenue run rate with more than 100 customers paying over $1 million in ARR. Besides the financials, Slack will also be able to turbo-charge Salesforce‚Äôs social media efforts by helping Salesforce learn Slack‚Äôs social skills that have made Slack a very popular tool. Additionally, Slack will also become a fertile ground for Salesforce to deploy its PaaS expertise.
Salesforce already has a very successful PaaS strategy. As I have said earlier, it is a PaaS leader that has figured out how the model works. Salesforce has over 4,000 apps with more than 8.4 million installs and a wide array of over a thousand developers and consultants building apps on the platform. Meanwhile Slack has over 2,200 apps and integrations across several verticals on its platform. Developers use its platform to automate workflows and customize Slack apps. Startups use the Slack platform to drive user engagement and adoption. Over 115 private venture-backed startups offer integrations with the Slack platform across categories like Analytics, Team Culture, Sales, Finance, and Security.
Salesforce has figured out that the right platform and marketplace strategy can help build a sustainable ecosystem that is beneficial to both Salesforce and the developers. A strong developer ecosystem, education, app marketplace, accelerator, and venture-fund are the components of a compelling PaaS strategy. Under Salesforce‚Äôs aegis, Slack‚Äôs platform is sure to soar. You can read more about my views on PaaS here.
Overall, this was another stellar quarter and year for Salesforce. Among key metrics, current remaining performance obligations grew 20% to $18 billion, compared with the market‚Äôs estimates of a 16% growth or $17.4 billion. Billings also grew 22% to $10.6 billion, ahead of the market‚Äôs consensus of $10.2 billion. Acumen will add the capability to execute against government spending, thus continuing to deliver growth.
Meanwhile, Salesforce‚Äôs stock is trading at $217.54 with a market capitalization of $199.64 billion. It had touched a record high of $284.50 in August last year. The stock fell to a 52-week low of $115.29 in March last year due to the global crisis.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations, and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article. I am an investor in this company.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Photo credit: Jo Bruni/Flickr.com
Founder of the 1M/1M global virtual incubator
Founder of the 1M/1M global virtual incubator
"
https://medium.com/@mattkiser/idc-innovators-report-names-algorithmia-a-platform-as-a-service-paas-pioneer-f0b4cafb8429?source=search_post---------100,"Sign in
There are currently no responses for this story.
Be the first to respond.
Matt Kiser
May 18, 2016¬∑2 min read
Algorithmia is excited to announce that we‚Äôve been selected as one of the top five worldwide pioneers in the platform as a service market by International Data Corporation (IDC).
The recent IDC Innovators Report evaluates startups under $50 million in revenue based on their inventive technologies, and groundbreaking business models.
At Algorithmia, we‚Äôre creating an open marketplace for algorithms and algorithm development, where developers can turn code into the building blocks needed to create, share, and remix algorithmic intelligence at scale.
‚ÄúAlgorithms are being developed all the time, but they‚Äôre not getting into the hands of the people and applications that could benefit from them the most,‚Äù Diego Oppenheimer said, founder and CEO of Algorithmia.
Algorithms are crucial in the modern technology economy as companies look to create intelligent applications from their data, and Algorithmia solves this by making state-of-the-art algorithms accessible and discoverable by everyone ‚Äî not just those that work at top-five global technology companies.
‚ÄúRapid growth and the availability of low-cost cloud infrastructure is bringing new challenges to outdated business models by startups building innovative solutions challenging legacy businesses,‚Äù Larry Carvalho said, IDC research manager, platform as a service. ‚ÄúA new set of easily consumable cloud services is accelerating the ability to build and deliver new functionality.‚Äù
Other companies mentioned in the IDC Innovators Report include Reltio, CloudMunch, Kismatic, and Iron.io.
Originally published at blog.algorithmia.com on May 17, 2016.
Editor at WTF Just Happened Today. Former Algorithmia, Business Insider, Forbes, and SPIN.
See all (1,198)
Editor at WTF Just Happened Today. Former Algorithmia, Business Insider, Forbes, and SPIN.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@sramana/cloud-stocks-new-relic-should-accelerate-its-paas-strategy-d0ab52153f18?source=search_post---------101,"Sign in
There are currently no responses for this story.
Be the first to respond.
Sramana Mitra
Jan 20, 2021¬∑4 min read
I‚Äôm publishing this series to discuss a topic that I follow closely ‚Äî cloud stocks, trends, strategy, acquisitions, and more. I like fundamentals-focused business building, and outline the principles of fundamentals-focused business building in my free Bootstrapping course.
According to a recent report, the global Application Performance Management (APM) industry is expected to grow 11% annually over the next few years to become a $11.2 billion industry by 2027. New Relic (NYSE: NEWR) announced its quarterly results that continue to outpace market expectations.
New Relic‚Äôs Financials
For the second quarter, New Relic‚Äôs revenues grew 14% to $166 million, ahead of the analysts‚Äô estimates by 1.61%. GAAP loss grew from $16.9 million a year ago to $42.9 million. Non-GAAP loss of $0.07 per share fell short of the market‚Äôs forecast of $0.01 per share.
Among key metrics, customers with more than $100,000 in revenues grew to 1,039 from 908 a year ago. 77% of ARR was from Enterprise Paid Business Accounts, compared with 71% a year ago.
For the third quarter, New Relic forecast revenues of $163-$165 million with non-GAAP net loss per diluted share of $0.13-$0.17. The Street was looking for revenues of $166.62 million for the quarter with a net loss of $0.01 per share.
New Relic‚Äôs Acquisition
Recently, New Relic announced its plans to acquire San Francisco-based Pixie Labs. Pixie Labs was set up to simplify the process of troubleshooting and live debugging applications in environments with Kubernetes by providing instant access to telemetry data, without manually adding instrumentation to the code. The acquisition will expand New Relic‚Äôs opportunity to serve the Kubernetes market and accelerate observability across organizations of all sizes. Prior to the acquisition, Pixie Labs had raised $9.2 million from one round of funding from investors GV and Benchmark. Its financial details are not disclosed.
Kubernetes is a fast growing market. According to a recent survey by the Cloud Native Computing Foundation, 83% of survey respondents use Kubernetes in production, compared with 58% in 2018. Despite the increase in adoption, the Kubernetes support for software engineering teams remains lackluster. New Relic is hoping to address this market through the acquisition.
New Relic‚Äôs Partnership Expansion
During the quarter, New Relic also announced a five-year partnership with AWS. As part of the partnership, the two companies are committed to increase product integration and development as well as joint go-to-market activities meant to help customers speed up and de-risk the cloud adoption journey. The agreement will make it easier for developers to send telemetry data from AWS services into New Relic One, thus improving observability and accelerating cloud adoption. New Relic One is also now available in AWS Marketplace and will allow customers to consolidate their billing by purchasing New Relic One directly through AWS.
As I mentioned earlier, New Relic is just beginning to implement its PaaS strategy. It allows developers to integrate on its platform using API and SDKs. Last year, it also released New Relic One Observability Platform that helps connect user experience and business data with additional capabilities like New Relic Logs, Traces, Metrics, and AI. Developers have access to curated content and New Relic One allows customers and partners to build their own observability applications.
But New Relic does not have a marketplace to transform to a full-fledged PaaS organization. A PaaS strategy will also help New Relic find suitable acquisition targets to continue to expand its portfolio.
Its stock is trading at $77.67 with a market cap of $4.86 billion. The stock hit a 52-week low of $33.49 in March.
Disclosure: All investors should make their own assessments based on their own research, informed interpretations and risk appetite. This article expresses my own opinions based on my own research of product-market fit, channel execution, and other factors. My primary interest is in product strategy. While this may have bearing on stock movements, my writings tend to focus on long-term implications. The information presented is illustrative and educational, but should not be regarded as a complete analysis nor recommendation to buy or sell the securities mentioned herein. I am not a registered investment adviser and I am not receiving compensation for this article.
Looking For Some Hands-On Advice?
For entrepreneurs who want to discuss their specific businesses with me, I‚Äôm very happy to assess your situation during my free online 1Mby1M Roundtables, held almost every week. You can also connect with me during our Rendezvous meetups, and check out my Bootstrapping Course, our YouTube channel, podcast interviews with VCs and Founders.
Photo credit: QConPictures/Flickr.com
Founder of the 1M/1M global virtual incubator
See all (3,442)
Founder of the 1M/1M global virtual incubator
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/textes-parus-sur-textes/paas-publishing-as-as-service-8f9c46f17311?source=search_post---------103,"There are currently no responses for this story.
Be the first to respond.
D√©j√† mentionn√©e dans ce blog, la soci√©t√© SharedBooks propose une site sur lequel il est possible de personnaliser un livre, et d‚Äôen commander une version imprim√©e. SharedBooks vient de conclure un partenariat strat√©gique avec Mark Logic Corporation, une soci√©t√© qui propose des solutions pour la structuration XML des contenus √©ditoriaux. L‚Äôun fournit le ‚Äúworkflow‚Äù √©ditorial, ( la cha√Æne de production informatis√©e ), l‚Äôautre l‚Äôinterface permettant d‚Äôassembler les contenus et offrant l‚Äôacc√®s √† l‚Äôimpression √† la demande, ainsi que la possibilit√© de toucher directement le client final : et voil√† un service de cr√©ation et de distribution de contenu compl√®tement orient√© ‚Äúplateforme‚Äù.
<xmp><explication></xmp>Que siginifie ‚Äústructurer en XML des contenus √©ditoriaux‚Äù ? Tr√®s sch√©matiquement, cela signifie ajouter une couche d‚Äôinformations √† un texte, au moyen de balises ins√©r√©es dans le fichier du texte. Quiconque a approch√© le langage HTML sait ce que sont des balises. Il s‚Äôagit de mentions qui se pr√©sentent pr√©c√©d√©es et suivies de chevrons. Les balises ne sont pas cens√©es √™tre affich√©es, le lecteur ne les verra pas. Elles portent une information destin√©e √† √™tre interpr√©t√©e par des machines. Elles sp√©cifient tout le texte situ√© entre une balise ouvrante <xmp><commeCeci></xmp> et une balise fermante <xmp></commeCeci></xmp> . La diff√©rence entre les deux ? le signe ‚Äú/‚Äù qui suit le chevron ouvrant d‚Äôune balise indique qu‚Äôil s‚Äôagit d‚Äôune balise fermante. Les balises peuvent fournir de l‚Äôinformation sur la structure du texte, de type : ‚Äútout ce qui est situ√© entre ces deux balises constitue le titre d‚Äôun chapitre‚Äù. Elles peuvent aussi donner de l‚Äôinformation sur le sens du texte, indiquer de quoi il parle : ‚Äútout ce qui se situe entre ces deux balises est un recette de cuisine‚Äù. Voici une explication bien sch√©matique, mais il n‚Äôest vraiment pas difficile d‚Äôen apprendre plus sur XML en se livrant √† quelques recherches sur le web‚Ä¶
Avec ce syst√®me somme tout assez simple, il est ensuite possible d‚Äôadresser des portions de texte, de les d√©signer, de les retrouver, de les manipuler. On obtient ainsi de l‚Äôinformation structur√©e, un petit peu comme l‚Äôest l‚Äôinformation contenue dans une base de donn√©es, mais avec une structuration offrant plus de souplesse et de possibilit√©s.<xmp></explication></xmp>
Le m√©tier de Mark Logic, c‚Äôest d‚Äôaider avec une gamme d‚Äôoutils XML les √©diteurs √† structurer leurs contenus, pour une publication qui peut se faire sur papier mais aussi en num√©rique. Les flux XML ainsi cr√©√©s peuvent alimenter par exemple des plateformes de e-learning, tout comme ils peuvent, moyennant certaines transformations, √™tre mis en forme pour une publication imprim√©e. En regardant la liste de leurs clients, on voit que les √©diteurs professionnels et universitaires y sont plus nombreux que les √©diteurs de litt√©rature g√©n√©rale.
Le m√©tier de SharedBooks, c‚Äôest de proposer au client final une interface qui va lui permettre √† la fois d‚Äôintervenir sur le contenu d‚Äôun livre, et d‚Äôen commander une version imprim√©e. Il s‚Äôagit d‚Äôune forme particuli√®re d‚Äôimpression √† la demande, coupl√©e √† de la personnalisation.
On voit imm√©diatement l‚Äôint√©r√™t du partenariat ainsi cr√©√© : la possibilit√© pour les clients de Mark Logic, des √©diteurs pour certains d‚Äôentre eux, d‚Äôutiliser les d√©veloppements de SharedBooks pour acc√©der √† la fois aux outils de customisation, et √† l‚Äôimpression √† la demande. Et, une fois qu‚Äôon dispose de contenu structur√©, de tels outils ouvrent la porte √† quantit√© de produits nouveaux, qui peuvent √™tre diffus√©s directement sur le web.
Voici le communiqu√© de presse :
SharedBook Inc., la solution d‚Äô√©dition personnalis√©e en ligne, et Mark Logic Corporation, qui fournit la solution leader du march√© XML server, ont conclu un accord de partenariat strat√©gique qui va faire de SharedBooks la solution privil√©gi√©e de commercialisation des contenus XML d√©livr√©s via Mark Logic Server.
L‚Äôaccord va permettre aux deux compagnies de conjuguer leurs services pour permettre aux √©diteurs et aux d√©tenteurs de contenus d‚Äôexploiter leurs actifs num√©rques en d√©ployant rapidement des produits √† haute valeur ajout√©e.
La plateforme de personnalisation √©ditoriale SharedBook offrira aux clients de Mark Logic, actuels et futurs, une solution SaaS (Software as a Service), permettant la r√©utilisation de contenus, leur r√©-agencement dans des ≈ìuvres d√©riv√©es des contenus trait√©s par MarkLogic server en utilisant les connecteurs de contenus d√©velopp√©s par SharedBooks.
‚ÄúCe partenariat d√©montre la flexibilit√© de notre plateforme technologique‚Äù, a d√©clar√© Caroline Vanderlip, CEO de SharedBook. ‚ÄúLes outils de ‚Äúfront end‚Äù de SharedBooks compl√®tent MarkLogic server pour offrir une solution ‚Äúgo-to-market‚Äù.
‚ÄúSharedBool offre √† Mark Logic une interface utilisateurs innovante‚Äù a d√©clar√© Jeff Faraday, directeur des partenariats chez Mark Logic Corporation. ‚ÄúMarkLogic et SharedBook sont positionn√©s sur ce march√© pour offrir aux clients un service formidable. Nous pr√©voyons un partenariat de longue dur√©e, dont b√©n√©ficieront les deux parties.‚Äù
Articles issus du blog ‚ÄúteXtes‚Äù de Virginie Clayssen, qui‚Ä¶
Written by

Articles issus du blog ‚ÄúteXtes‚Äù de Virginie Clayssen, qui r√©fl√©chit tout haut sur les questions li√©es au livre num√©rique, au web et √† l‚Äô√©dition. Mes propos n‚Äôengagent que moi.
Written by

Articles issus du blog ‚ÄúteXtes‚Äù de Virginie Clayssen, qui r√©fl√©chit tout haut sur les questions li√©es au livre num√©rique, au web et √† l‚Äô√©dition. Mes propos n‚Äôengagent que moi.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@nesters/i-hired-a-p-a-as-a-startup-founder-heres-what-she-did-to-us-b2c92c04808b?source=search_post---------104,"Sign in
There are currently no responses for this story.
Be the first to respond.
Kitan David
Dec 27, 2017¬∑4 min read
A lot of decisions are made in eateries and local joints, and chicken republic was where I met Lara Alonge for the first time and she was hired.
Wait! 56 hours earlier
I was scrolling through Facebook after a long day with a lot of jobs still on my desk undone, but man no go kill himself na, I tire enter body that day. I noticed three friends of mine Victor A. Fatanmi, Bolaji Fawole and Daniel Falonipe were tagged in a single post by a lady named Lara Alonge as ‚Äú3 amazing Fa‚Äôs‚Äù in her life, these guys also happened to be great people in my circle and that drew my attention to her.
I actually went through her wall that night, more like I was stalking her. I noticed her ability to carefully represent her imagination from an interesting perspective, she wrote about friends, to boli (roasted plantain), to the hot sun and fashion. I chatted her up telling her of how I needed a P.A. in my life and if she wouldn‚Äôt mind. She agreed and we met at chicken republic 56 hours later for physical assessment and chit chat.
Again I have a problem, I believe in people more than they believe in themselves or is that a quality of a social startup CEO?
We met, described what we do at Planet NEST and SeedDev in details, she loved it. Really it was more like I was wooing a sexy girl, yeah she‚Äôs got a piercing and she‚Äôs beautiful. I told her I would get back to her, yes I wanted her but for due process sake, I had to ask Victor Fatanmi about it and he said she‚Äôs really cool for the job.
Finally, I have a P.A.
Again, a few folks called me to say that getting a P.A. was a bad idea at the moment simply because I can‚Äôt afford an extra person on my payroll, but biko work and deadlines are killing me here, will y‚Äôall come me out, I told them it was too late, I hired her already.
So what did Lara Alonge do?
Luckily for her, she resumed work on her birthday and as the culture at work, we had a birthday cake and a small party to celebrate life.
We often get into a position as a founder where we create structures for our workers to complete their tasks and we don‚Äôt complete ours, Lara made me very effective, she takes my to do list in the morning and makes sure I complete them all before the day was over, it was like she was my boss, when she walks through the door at noon, to check how far I have gone, my heart goes Skrrrrr pa.
She made me very time conscious, I get to meetings on time and she schedules my time with those that want to see me, more like she had a clock all over her face. She co-owned my calendar.
I sleep averagely 4 hours per day and some days less, on the nights I have less, she notices it in my eyes the next day and ensures I get at least 45 minutes sleep at work, y‚Äôall now know what happened those mornings when my car was parked outside and my office was locked with my P.A. telling you ‚ÄúI‚Äôm quite busy‚Äù with a smile.
When I go to speak at events, she takes video recordings for me to listen to myself afterwards and majorly improve my grammar, the blunders are then corrected by my girlfriend who studied English at University of Ibadan at night and sometimes Opeyemi Olugbemiro ‚Äî Chief Editor at Zumalo.com.
Lara carefully spends time watching my spending noting down what I spent and what I bought for the company thereby separating my finances from company finances. Rock Capita, our financial consultant firm has also helped greatly in this. For those of you that can relate, the finance aspect was like a mountain taken off my neck
Amazing is an understatement to who she was. Why the use of the word ‚ÄúWas‚Äù? Her contract ended on the 22nd of December and she went on to be the CEO of La‚Äôelan Ushering Company, a leading corporate ushering company in Nigeria.
She boosted efficiency, and that affected results and revenue.
One more thing I enjoyed is the way my friends tease me when they heard I have a P.A ‚ÄúKitan is now a big boy‚Äù and the respect clients gave me when they call me and my P.A answers the phone.
Really, y‚Äôall need a P.A. in your life.
If you work in a startup and you‚Äôre competent, you might be able to run one or be a founder yourself in the nearest future.
And yes, I need a new P.A. I will drill you hard, but if you are up for the task you can hit me up. You get to work with awesome us. (kitandavid@planetnest.org)
A terrible writer that manages to tell interesting stories. UX and Consulting pays the bills, Human Capital Dvlpment gives the most joy. Future Academy Africa
See all (730)
270 
2
270¬†claps
270 
2
A terrible writer that manages to tell interesting stories. UX and Consulting pays the bills, Human Capital Dvlpment gives the most joy. Future Academy Africa
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/hackernoon/my-journey-to-achieving-devops-bliss-without-useless-aws-certifications-a7cbf7c539d1?source=search_post---------106,"There are currently no responses for this story.
Be the first to respond.
The story of how I transformed from a naive full-stack engineer struggling with AWS and PaaS providers to loving my life and achieving DevOps bliss.
Make sure to read ‚Äòtil the end to find a free daily email course!
‚ÄúBEEP BEEP BEEP BEEP BEEP‚Äù
The ‚Äúshiny phone‚Äù was shouting at me and flashing it‚Äôs light like a tiny little ambulance illuminating the dark room for fractions of a second at a time.
I had been dreading this moment.
I pulled the sheet over my eyes and closed them tightly. Maybe if I just hid under the blanket for 10 more seconds it would stop.
‚ÄúBEEP BEEP BEEP‚Äù
The shiny phone‚Äôs alarm droned on.
‚ÄúNever again.‚Äù I thought to myself as I dragged myself out of bed and stumbled across the room to the light switch, nearly tripping over some overflowing pillows I‚Äôd thrown on the floor during the night.
As the lights blazed on I closed my eyes tightly again as I tried to adjust.
The year was 2010, and I was a newly graduated computer scientist ready to take on the world, or preferably conquer it. Though most definitely not ‚Äúbright-eyed and bushy tailed‚Äù in this moment.
My childhood was less than cushy, and I had dreams of grandeur. I conjured up images in my head of Forbes magazines with my face: ‚ÄúThe next Mark Zuckerburg!‚Äù or ‚Äú30 under 30‚Äù (missed that one), ‚ÄúIs it web scale! Yes!‚Äù
My parents had gone through a divorce that resulted in some poor financial situations to say the least, and I wanted to be able to provide for not just myself, but them as well. I had dreams of buying them homes, and paying their debts, and taking care of my siblings too if I could.
My dad would always ask, and still does: ‚ÄúAre you rich yet? Can I retire?‚Äù ‚ÄúI‚Äôm working on it!‚Äù I‚Äôd reply.
And now it was finally my moment, I was at my first full time gig as a ‚ÄúUX Engineer‚Äù building the new front-end for a startup‚Äôs platform. I‚Äôd been studying high scalability and DDD in my spare time in college and I was ready to take on the world.
I was the 8th employee, so I figured my equity would probably be a pretty good start when the company blew up, too. Turns out it wasn‚Äôt - we were acquired 11 days before my vesting period. So it goes.
Anyway.
This meant as part of my junior engineering job, I was on rotation for carrying ‚Äúthe shiny phone.‚Äù
‚ÄúThe shiny phone‚Äù was the 24/7 technical emergency line established for the start-up I had joined. If things were blowing up, someone had to know, and react, quickly! The format that this message was delivered? ‚ÄúThe shiny phone‚Äù. And boy did it shine!
The shiny phone was a flip phone (cause those were still a thing), which as you may have guessed, was made out of a shiny material. Clever.
The CTO, Kevin, had decided that after several months on the job, I was sufficiently ready to be put on the rotating list of individuals who received the phone. Each person who got the phone, was responsible for responding to any system alerts that were sent to it via SMS (repeatedly) at any time while they had it.
I secretly dreaded my turn. I didn‚Äôt know if I would be ready if it went off.
After all, Sergey was a SQL wizard, and Kevin could pull together new features over night like Richard in Silicon Valley. ‚ÄúHey guys, I rewrote like, everything last night and made it way better, hope you don‚Äôt mind!‚Äù
I also wanted to be able to handle an issue if it came up. I wanted them to think ‚Äúthis guy‚Äôs got it ‚Äî glad we hired him!‚Äù
But mostly, I just hoped it didn‚Äôt happen.
And now in the dead of night, the third day on the third week of November, at 3:37AM, the shiny phone had gone off.
‚ÄúBEEP BEEP BEEP BEEP BEEP BEEP‚Äù
I stumbled back over to my nightstand and flipped open the phone. I remember feeling a chill run through my body and down my arms. It was a cold night even though the heat was on.
23 messages.
‚ÄúFATAL ERROR: DB Server is down. Unable to connect to 10.10.0.1‚Äù
‚ÄúFATAL ERROR: UI is down. Unable to connect to https://ourwebsite‚Äù
‚ÄúBEEP BEEP‚Äù
More of the same.
üò≥
I grabbed a sweater out of my dresser and put it on as I walked across the room to the corner where my laptop sat on a flimsy rolling desk I‚Äôd bought for about $20 for my college dorm room four years prior. I sat down in my cheap, uncomfortable, also probably about $20 office chair.
‚ÄúOk ‚Äî I got this.‚Äù I thought as a rolled myself into position over some poorly placed wires on the hardwood floor.
I had a checklist of what to do if something went wrong‚Ä¶ what could go wrong? Err, what else could go wrong?
First, I had to create a remote desktop connection to my desktop at the office.
Check.
Next, I had to log in to the admin portal to check the statuses.
Uh oh‚Ä¶ the admin UI isn‚Äôt loading‚Ä¶
‚ÄúCan I ping the servers?‚Äù
Nope. No ping.
‚ÄúThis is bad‚Äù I thought, as I tried a few more IP addresses, it seemed like everything was down.
Against my pride, I knew I needed to wake Sergey up slightly before four in the morning.
I fumbled with the bright blue buttons of the shiny phone as I tried to look up his number, conveniently located as one of the only few numbers in the pre-touchscreen device. ‚ÄúWhat a poor UX‚Äù I though to myself as the phone began to ring.
‚ÄúHello‚Äù Sergey answered in his heavy Russian accent.
‚ÄúHi Sergey, sorry to wake you‚Äù I explained. ‚ÄúThe shiny phone is going off, I tried following the checklist to restore the services but nothing is working.‚Äù
‚ÄúOk, I‚Äôll look at it‚Äù he groggily replied as he hung up the phone. Guess I was done?
As I crawled back into bed I was a bit relieved, and also a bit disappointed as a realized this is not something I could have possibly fixed at the time.
As it turns out, there was a failure at a datacenter where we rented servers. Someone had to actually go and replace a physical machine in a physical location to get things running again.
It was at that moment I wondered how companies anywhere are able to keep everything up at all times.
How it was possible to deploy systems that can scale to meet the demands of enterprises, can be nimble and flexible enough that it is not cost prohibitive to startups, and that were highly available.
Mostly, I just didn‚Äôt ever want to have to have another shiny phone.
It wasn‚Äôt until four years later that it would be my responsibility to be in charge of setting up a system from end to end, and making sure it stayed up.
I had grown a lot from an engineering perspective, but my extent of Operations and production deployments thus far was deploying to Heroku, or making a Pull Request that an Ops team would be responsible for getting into production later on.
To me, Ops was still an afterthought.
I had been focused on learning how to build distributed systems with Node, while being a full-stack engineer with a front-end focus (Backbone was the flavor of the day). I was lucky enough to have gained an amazing mentor, Matt Walters, as a colleague at that FinTech company in the couple years prior, where we built a private equity trading platform together.
Something he often told me: ‚ÄúWith simplicity of services, some complexity necessarily moves to the architecture.‚Äù
And now, as the CTO of my own startup, I was responsible for ALL of the complexity, no matter where it lie.
I was smart going in to the project, though, I knew I needed good design patterns, and not a monolith, and I could definitely sorta draw a chart that described a system that would work and so I went for it!
At this point I‚Äôd spent most of my efforts trying to engineer and architect any potential problems away. I was still experimenting with design patterns and architecture. I hadn‚Äôt accepted failure of services and infrastructure was inevitable, I just thought those before me just needed to be better. ‚ÄúIf they used this pattern, or this language, or this tool‚Ä¶‚Äù I‚Äôd tell myself.
At the time, architecture for me, didn‚Äôt even consider the infrastructure I was running on or how it ran there, or even much about how it got there for that matter.
So what did I do for Ops? What most other engineers I knew did ‚Äî used a PaaS. One could say I took a ‚ÄúPaaS‚Äù on learning AWS. ü§£
A PaaS is a ‚ÄúPlatform as a Service‚Äù ‚Äî These are platforms like Heroku or Modulus (gone)
I knew I needed to learn AWS. I knew if I wanted to be able to automate all of my problems away some day, I‚Äôd need to (so I thought then), but for now, I had things to build, and quickly!
My deploys were pretty terrible looking back then. They looked something like this:
There are a lot of problems with this.
It‚Äôs an error prone manual task. It‚Äôs not easily repeatable. You need to know things other than ‚Äúgit commit‚Äù, your services communicate over the internet, and of course it‚Äôs painful and something you want to avoid.
So then you do it less frequently, which amplifies your need for GitFlow and process and time spent deploying and changing delicate sets of carefully configured PaaS instances, which actually makes every deploy more risky, and more complicated.
On top of that, now you are trying to remember two different states of the world you created, master, and dev, so you can make hotfix branches. And you‚Äôre cool and using ‚Äúmicroservices‚Äù so now you need to remember states for like 14 branches, and how 7 different projects are dependent on each other in different ways like mixes of shared databases and logs change events from databases to trigger updates on other services.
Your junior engineers are confused about GitFlow and creating hotfix branches so you need to teach them that, and someone wants to add a cache, and you‚Äôre like ‚Äúlol does our DBaaS have Redis too??‚Äù
Architecture and Design Patterns to the rescue! As Udi Dahan said (sarcastically): ‚Äúthrow all the D‚Äôs at it! DDD! TDD! BDD! ADD!‚Äù We will engineer all the problems away!
‚ÄúThrow all the D‚Äôs at it! DDD! TDD! BDD! ADD!‚Äù ‚Äî Udi Dahan
And so I tried throwing D‚Äôs at it.
I thought it was great ‚Äî and the UI was. I used CSS animations and it felt like a native app in a web browser. It was real time thanks to Meteor, and I was again able to shift away the responsibility of DevOps and deployments by being accepted as one of the first companies invited to their beta DevOps platform Galaxy.
Once again, I‚Äôd avoided learning AWS.
Problem with that, is eventually I stopped using Meteor, and started using more pure Node. Again I was left with only PaaS providers as an option.
I got to the point where I was running about 30 services per environment, and the PaaS cost was really starting to grow at $15/m each ‚Äî and database services, and complicated deploys literally by the dozens. Given how expensive engineering time is, factoring the time spent deploying things, the costs were not insignificant.
I lived with this for a few years, still focusing my time on better engineering. Better design patterns, scalable microservices, architectures, proxies, but still put off the dreaded task of learning AWS. I still kept failing to achieve the simplicity and beauty that I wanted to achieve.
Something was missing.
I had heard rumblings about things like codified infrastructure, and Continuous Deployment.
I was pretty sure I needed these things, but I had no idea how to get there.
I did know one thing though, a giant shadow of a mountain called AWS loomed over me, and I knew I needed to reach the top to find the answer.
So, I did what I like to do when I want to learn things fast: I bought a course on AWS!
And I hated AWS.
I hated the UI.
I hated that I was being taught about UIs instead of programming.
I hated that what I was being taught would result in hard to reproduce, manual, and error prone tasks.
And I hated that I didn‚Äôt get any benefit beyond AWS‚Äôs closed infrastructure when there were cool things going on with Digital Ocean, Google Cloud, and Azure. I couldn‚Äôt say for sure if AWS would be the platform I wanted to use in a year or two or three. Maybe Google would blow them away. Maybe they wouldn‚Äôt.
But still, for a couple of months, when I could bring myself to get over my hatred (or fear) of AWS, I would watch the videos, and go into the AWS UI and do the things. Until eventually, I decided there needed to be a better way. After all, I didn‚Äôt want to spend a bunch of time getting myself locked in a box.
Needless to say, I didn‚Äôt get very far with my AWS course.
I have now built the DevOps systems for a website with 14+ million yearly users, have built the DevOps system for a blockchain company, two artificial intelligence APIs, and a FinTech platform. All increasingly better than the last.
And let me tell you a secret‚Ä¶
It definitely WAS NOT from learning AWS.
It was abandoning the then standard practices and focusing on a new emerging technology that was getting a ton of hype at the time: containerization.
So I started to read everything I could about containerization. I went and bought several books on Leanpub, I read blogs, and docs, and code. AND CODE.
And I loved it.
There was an entire ecosystem of tooling built for deploying containers I realized, and if I could just learn how to package my code into a container, well, then deploying would be easy!
One of the most exciting things I read, was when I had really figured out how to use containers well for all sorts of development tasks that made my life easier, that Docker was coming out with a tool called a ‚ÄúDAB‚Äù or distributed application bundle, and you‚Äôd be able to simply write a yaml file that describes how your system should run, and then just give that to something called an orchestrator and it would just do all of the other AWS stuff for you.
The created volumes, mapped them, security groups, ASGs, loadbalancers, a whole bunch of other stuff that I hadn‚Äôt even heard of and way better than I could have ever made it myself.
Beyond that, they literally manage containers in production for you, I learned. As in they allowed you scale them with a single command, they would automatically recover from failures if they broke by restarting the service, and all you had to do was literally click a button to set it up!
Instead of learning AWS, I realized, I should learn containerization and then, all I need to do, is provide MY containers to an orchestrator, which I set up on AWS by clicking a button! Perfect!
All I had to do was click a button in order to get a production ready system on AWS. Orchestrators ‚úÖ.
It‚Äôs kinda like you see in movies the big shipping container yards where various nefarious activities are happening in the dead of night. Or some poor soul is lost and no one knows which container he‚Äôs in.
Imagine if all of those things inside all of those containers, were not in containers.
Imagine if instead tens of thousands of items were just sprawled across some big empty lot.
The shipping and unloading process would be more than quite a bit more complicated!
My mind shifts to mental images of giant cranes trying to pick up items like one of those annoying crane game at a highway rest stop taunting you with some new Beats headphones and a defunct claw.
The reason the cranes can do their jobs of picking up and organizing containers, is because containers are all standard dimensions. It can pack them into neatly defined rows until they are at capacity.
So all you need to do, is figure out how to get your stuff into the container, and it will get shipped.
Cranes are very powerful tools, that a human can simply operate to arrange, move, order, ship, and receive containers.
Orchestrators are kinda like cranes.
Orchestrators also powerful tools that basically operate themselves to deploy, assign, recover from failures, and inspect software containers. They know what servers have capacity, and they put your containers there, and wire them up to networks to run.
Moreover, containers solve a whole bunch of other problems too! Like the infamous my code runs here but not there bug, and various testing scenarios.
So I went all in on containers.
I learned the ins, outs, ups, downs, and in-betweens because I knew if I did, then I could just give them to an orchestrator, and then that thing would handle all the AWS or Azure or Google Cloud stuff I needed!
This is what really freed me.There were countless benefits beyond what I had originally intended. Such as being able to take advantage of a whole ecosystem that was previously unavailable to me.
That‚Äôs not to say there still wasn‚Äôt more to learn. There was. A lot. But knowing that one piece was the key that connected the two worlds between development and operations. How could I not get on top of this revolutionary technology?
All I needed to do was create a single file that is shipped with each project that described the environment it needed. Also, the hard part of this environment was already created and maintained for me by the Node team. Then I just needed to give it to the orchestrator.
‚ÄúWith simplicity of the services, some complexity necessarily moves to the architecture‚Ä¶ and infrastructure, and process.‚Äù I thought. ‚ÄúThe key that connects all of those pieces is the Dockerfile.‚Äù
Containerizing my apps was the starting point that unlocked all of the other potentials and benefits because when you enter the ecosystem of containerization, not only do you get orchestrators, but you get libraries and libraries of production ready systems like databases that other people have already containerized!
Do you remember coding before having a package manager like npm?
Imagine how difficult today‚Äôs programming tasks would be without something like npm.
If you aren‚Äôt using containers and orchestrators ‚Äî that‚Äôs what you‚Äôre missing out on for entire deployed databases, and queues, and caches and probably most things you can think of that you‚Äôd want to deploy!!!
Want to know how I install a database? Add a couple of lines to a YAML file.
Are you understanding how powerful this is?
Things like running Redis used to look like a mountain, and now with the containerization tools I had, that mountain was literally about five lines in a YAML file.
Someone asks ‚ÄúCan we run XYZ?‚Äù And you‚Äôre like ‚ÄúYup‚Ä¶. anndddd‚Ä¶. Done.‚Äù
How many hours a week would that save you and your colleagues?
Now you‚Äôre probably thinking ‚Äî great, a new mountain of things to learn and understand.
I feel you. These are the same struggles that I went through.
That‚Äôs why I‚Äôve made it my mission to help engineers like you bridge the gap between building applications, and running them in production. I also want to teach you the simple cloud native microservice patterns I use to build scalable systems for billion dollar enterprises.
Simplicity is everything to me.
Complication is the enemy and you need to fight it.
You must be one with the cloud. Got it?
To get you started on your journey in I have created a FREE 21 day email course, ‚ÄúGetting Dangerous With DevOps‚Äù, that will lead you through containers and orchestrators as it teaches you how to deploy a Next.js application to AWS without wasting your time on useless AWS certifications!
If you want to receive my free email course ‚ÄúGetting Dangerous With DevOps‚Äù with 21 bite sized lessons sent to your inbox daily, head on over to https://www.devopsbliss.com to sign up!
If you‚Äôve found this useful and want to say thank you, the best way to do so is giving me 50 claps (click and hold the clap button), and sharing my story on your social media sites! Make sure you FOLLOW ME for more articles about DevOps, microservices, architecture, patterns, NodeJS, DDD, testing, Fullstack, and maybe even some CSS!
#BlackLivesMatter
3.5K 
2
how hackers start their afternoons. the real shit is on hackernoon.com.¬†Take a look.

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
3.5K¬†claps
3.5K 
2
Written by
I make things for the internet, that scale, look nice, and make money!
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Written by
I make things for the internet, that scale, look nice, and make money!
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://towardsdatascience.com/build-and-deploy-machine-learning-web-app-using-pycaret-and-streamlit-28883a569104?source=search_post---------107,"Sign in
There are currently no responses for this story.
Be the first to respond.
Moez Ali
Jun 18, 2020¬∑11 min read
In our last post on deploying a machine learning pipeline in the cloud, we demonstrated how to develop a machine learning pipeline in PyCaret, containerize Flask app with Docker and deploy serverless using AWS Fargate. If you haven‚Äôt heard about PyCaret before, you can read this announcement to learn more.
In this tutorial, we will train a machine learning pipeline using PyCaret and create a web app using a Streamlit open-source framework. This web app will be a simple interface for business users to generate predictions on a new dataset using a trained machine learning pipeline.
By the end of this tutorial, you will be able to build a fully functional web app to generate online predictions (one-by-one) and predictions by batch (by uploading a csv file) using trained machine learning model. The final app looks like this:
This tutorial will cover the entire workflow starting from training a machine learning model and developing a pipeline in Python, developing a simple web app using streamlit and deploying the app on the Heroku cloud platform.
In the past, we have covered containerization using docker and deployment on cloud platforms like Azure, GCP and AWS. If you are interested in learning more about those, you can read the following stories:
PyCaret is an open source, low-code machine learning library in Python that is used to train and deploy machine learning pipelines and models into production. PyCaret can be installed easily using pip.
Streamlit is an open-source Python library that makes it easy to build beautiful custom web-apps for machine learning and data science. Streamlit can be installed easily using pip.
GitHub is a cloud-based service that is used to host, manage and control code. Imagine you are working in a large team where multiple people (sometimes hundreds of them) are making changes. PyCaret is itself an example of an open-source project where hundreds of community developers are continuously contributing to source code. If you haven‚Äôt used GitHub before, you can sign up for a free account.
Heroku is a platform as a service (PaaS) that enables the deployment of web apps based on a managed container system, with integrated data services and a powerful ecosystem. In simple words, this will allow you to take the application from your local machine to the cloud so that anybody can access it using a Web URL. In this tutorial, we have chosen Heroku for deployment as it provides free resource hours when you sign up for a new account.
Deployment of machine learning models is the process of putting models into production so that web applications, enterprise software and APIs can consume a trained model and generate predictions with new data points.
Normally machine learning models are built so that they can be used to predict an outcome (binary value i.e. 1 or 0 for Classification, continuous values for Regression, labels for Clustering etc. There are two broad ways to predict new data points:
Online prediction scenarios are for cases where you want to generate predictions on a one-by-one basis for each datapoint. For example, you could use predictions to make immediate decisions about whether a particular transaction is likely to be fraudulent.
Batch prediction is useful when you want to generate predictions for a set of observations all at once. For example, if you want to decide which customers to target as part of an advertisement campaign for a product you would get prediction scores for all customers, sort these to identify which customers are most likely to purchase, and then target maybe the top 5% customers that are most likely to purchase.
In this tutorial we will build an app that can do both; online prediction as well as batch prediction by uploading a csv file containing new data points.
An insurance company wants to improve its cash flow forecasting by better predicting patient charges using demographic and basic patient health risk metrics at the time of hospitalization.
(data source)
To build a web application that supports online (one-by-one) as well as batch prediction using trained machine learning model and pipeline.
Training and model validation are performed in an Integrated Development Environment (IDE) or Notebook either on your local machine or on cloud. If you haven‚Äôt used PyCaret before, click here to learn more about PyCaret or see Getting Started Tutorials on our website.
In this tutorial, we have performed two experiments. The first experiment is performed with default preprocessing settings in PyCaret. The second experiment has some additional preprocessing tasks such as scaling and normalization, automatic feature engineering and binning continuous data into intervals. See the setup code for the second experiment:
The magic happens with only a few lines of code. Notice that in Experiment 2 the transformed dataset has 62 features for training derived from only 6 features in the original dataset. All of the new features are the result of transformations and automatic feature engineering in PyCaret.
Sample code for model training in PyCaret:
Notice the impact of transformations and automatic feature engineering. The R2 has increased by 10% with very little effort. We can compare the residual plot of linear regression model for both experiments and observe the impact of transformations and feature engineering on the heteroskedasticity of model.
Machine learning is an iterative process. The number of iterations and techniques used within are dependent on how critical the task is and what the impact will be if predictions are wrong. The severity and impact of a machine learning model to predict a patient outcome in real-time in the ICU of a hospital is far more than a model built to predict customer churn.
In this tutorial, we have performed only two iterations and the linear regression model from the second experiment will be used for deployment. At this stage, however, the model is still only an object within a Notebook / IDE. To save it as a file that can be transferred to and consumed by other applications, execute the following code:
When you save a model in PyCaret, the entire transformation pipeline based on the configuration defined in the setup() function is created. All inter-dependencies are orchestrated automatically. See the pipeline and model stored in the ‚Äòdeployment_28042020‚Äô variable:
We have finished training and model selection. The final machine learning pipeline and linear regression model is now saved as a pickle file (deployment_28042020.pkl) that will be used in a web application to generate predictions on new datapoints.
Now that our machine learning pipeline and model are ready we will start building a front-end web application that can generate predictions on new datapoints. This application will support ‚ÄòOnline‚Äô as well as ‚ÄòBatch‚Äô predictions through a csv file upload. Let‚Äôs breakdown the application code into three main parts:
This section imports libraries, loads the trained model and creates a basic layout with a logo on top, a jpg image and a dropdown menu on the sidebar to toggle between ‚ÄòOnline‚Äô and ‚ÄòBatch‚Äô prediction.
This section deals with the first functionality of the app i.e. Online (one-by-one) prediction. We are using streamlit widgets such as number input, text input, drop down menu and checkbox to collect the datapoints used to train the model such as Age, Sex, BMI, Children, Smoker, Region.
This part deals with the second functionality i.e. prediction by batch. We have used the file_uploader widget of streamlit to upload a csv file and then called the native predict_model() function from PyCaret to generate predictions that are displayed used streamlit‚Äôs write() function.
If you remember from Task 1 above we finalized a linear regression model that was trained on 62 features that were extracted using 6 original features. However, the front-end of our web application has an input form that collects only the six features i.e. age, sex, bmi, children, smoker, region.
How do we transform the 6 features of a new data point into 62 used to train the model? We do not need to worry about this part as PyCaret automatically handles this by orchestrating the transformation pipeline. When you call the predict function on a model trained using PyCaret, all transformations are applied automatically (in sequence) before generating predictions from the trained model.
Testing AppOne final step before we publish the application on Heroku is to test the web app locally. Open Anaconda Prompt and navigate to your project folder and execute the following code:
Now that the model is trained, the machine learning pipeline is ready, and the application is tested on our local machine, we are ready to start our deployment on Heroku. There are a couple of ways to upload your application source code onto Heroku. The simplest way is to link a GitHub repository to your Heroku account.
If you would like to follow along you can fork this repository from GitHub. If you don‚Äôt know how to fork a repo, please read this official GitHub tutorial.
By now you are familiar with all of the files in the repository except for three files: ‚Äòrequirements.txt‚Äô , ‚Äòsetup.sh‚Äô and ‚ÄòProcfile‚Äô. Let‚Äôs see what those are:
requirements.txt file is a text file containing the names of the python packages required to execute the application. If these packages are not installed in the environment where the application is running, it will fail.
setup.sh is a script programmed for bash. It contains instructions written in the Bash language and like requirements.txt, it is used for creating the necessary environment for our streamlit app to run on the cloud.
Procfile is simply one line of code that provides startup instructions to the web server that indicate which file should be executed when an application is triggered. In this example, ‚ÄòProcfile‚Äô is used for executing setup.sh which will create the necessary environment for the streamlit app and the second part ‚Äústreamlit run app.py‚Äù is to execute the application (this is similar to how you would execute a streamlit application on your local computer).
Once all the files are uploaded onto the GitHub repository, we are now ready to start deployment on Heroku. Follow the steps below:
Step 1 ‚Äî Sign up on heroku.com and click on ‚ÄòCreate new app‚Äô
Step 2 ‚Äî Enter App name and region
Step 3 ‚Äî Connect to your GitHub repository
Step 4 ‚Äî Deploy branch
Step 5 ‚Äî Wait 10 minutes and BOOM
App is published to URL: https://pycaret-streamlit.herokuapp.com/
We have received overwhelming support and feedback from the community. We are actively working on improving PyCaret and preparing for our next release. PyCaret 2.0.0 will be bigger and better. If you would like to share your feedback and help us improve further, you may fill this form on the website or leave a comment on our GitHub or LinkedIn page.
Follow our LinkedIn and subscribe to our YouTube channel to learn more about PyCaret.
As of the first release 1.0.0, PyCaret has the following modules available for use. Click on the links below to see the documentation and working examples in Python.
ClassificationRegressionClusteringAnomaly DetectionNatural Language ProcessingAssociation Rule Mining
PyCaret getting started tutorials in Notebook:
ClusteringAnomaly DetectionNatural Language ProcessingAssociation Rule MiningRegressionClassification
PyCaret is an open source project. Everybody is welcome to contribute. If you would like to contribute, please feel free to work on open issues. Pull requests are accepted with unit tests on dev-1.0.1 branch.
Please give us ‚≠êÔ∏è on our GitHub repo if you like PyCaret.
Medium: https://medium.com/@moez_62905/
LinkedIn: https://www.linkedin.com/in/profile-moez/
Twitter: https://twitter.com/moezpycaretorg1
Data Scientist, Founder & Author of PyCaret
See all (5)
735 
5
Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.¬†Take a look.
735¬†claps
735 
5
Your home for data science. A Medium publication sharing concepts, ideas and codes.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@brenda.clark/heroku-alternatives-top-5-picks-9095cef91d91?source=search_post---------108,"Sign in
There are currently no responses for this story.
Be the first to respond.
Brenda Clark
Mar 9, 2018¬∑7 min read
There‚Äôs no denying that leveraging a Platform-as-a-Service (PaaS) like Heroku is a great way to develop and deploy a wide range of web-based projects with minimal fuss. This cloud platform has a wide appeal and provides tremendous value for millions of developers and IT professionals. But here‚Äôs something you must know: Heroku is not always the best bet and it is important to understand when to employ another approach.
Simply put, there are a few concerns with Heroku, which include exorbitant cost, unorganized documentation, unintuitive CLI design, lack of language support, non-flexible pricing tiers, vendor lock-in with AWS, relatively short stack life cycle, and many other technical limitations. Based on latest research, more than 10,000 users each month search for ‚ÄúHeroku alternatives‚Äù on Google.
So, if you‚Äôre one of them and looking for a more stable backend platform for your app, then this article is specifically meant for you. Luckily, there are numerous alternatives to Heroku, but only a handful of them are genuinely useful. Below we have discussed five of the best Heroku alternatives along with their pros and cons.
Back4App is a BaaS with the same flexibility of a PaaS like Heroku. Being one of the most powerful and popular BaaS solutions available today, Back4App is the perfect replacement for Heroku, thanks to its flexible pricing tiers, faster deployment speed, and many other distinctive features. Unlike Back4App, Heroku gets really expensive once you leave its free tier. It‚Äôs not just the Heroku service that is costly, the add-ons as well are pretty steep.
Moreover, in case of Heroku, larger applications tend to have slower deployments, however, Back4App has no such technical glitches. Developers can make use of this powerful platform to create and deploy scalable and extensive mobile applications at a lightning pace without boilerplate code, infrastructure hassles, and technical locks.
Pros:
¬∑ No vendor lock-in;
¬∑ Flexible pricing plans;
¬∑ Easy & smooth migration from Parse;
¬∑ Parse hosting in any cloud environment;
¬∑ Open source with a large developer community;
¬∑ An automated backup system that keeps your data secure and accessible;
¬∑ More than 40k happy customers worldwide and over 500 million connected devices;
¬∑ A dedicated team of engineers working on product improvement and support;
¬∑ A meticulously-designed architecture that helps you to improve your app‚Äôs performance and maximize productivity.
Cons:
¬∑ Lack of Documentation;
¬∑ Non-standardized UI inside the docs‚Äô page;
Firebase is another viable alternative to Heroku, and for good reason. Just like Heroku, Firebase has great CLIs which make deployment possible in just a few commands. It provides SSL encryption, custom domains, backend storage (which is a simple NoSQL database with a supporting GUI for manual entries), and everything else you would want for your app.
One of its key facets is its low price (the cost per GB of real-time data is relatively low), which gives Firebase an upper hand over Heroku and other app platforms. Also, it takes a huge burden off developers from the server viewpoint.
Pros:
¬∑ Fast and real-time updates;
¬∑ Google Analytics and AdSense support;
¬∑ Cross-platform API, cross-device support;
¬∑ Free tier up to 100 simultaneous connections;
¬∑ Robust APIs for JavaScript (including several frameworks like Angular).
Cons:
¬∑ Vendor lock-in;
¬∑ No simple way to add ‚ÄúCloud Code‚Äù;
¬∑ Not possible to set custom permissions;
¬∑ Not designed for collaborative workflows;
¬∑ Only support static files (such as HTML, JavaScript, images);
¬∑ Developers can‚Äôt run any server-side node scripts inside their own server instance.
Another suitable alternative to Heroku is Google App Engine (GAE), which is a free tool for mounting and hosting web applications in Google-managed data centers. In technical terms, GAE is an online cloud platform which allows you to build scalable web applications and mobile backends leveraging built-in tools and API, including NoSQL datastore, user authentication API, and Memcache.
Both Heroku and GAE are logically similar as they both are PaaS solutions. Like Heroku, Google‚Äôs Cloud Platform provides you with a ready-made environment in which you can deploy your code and apps. However, it has a different pricing model and interface. Simply put, Google‚Äôs Cloud Platform interface is extremely intuitive and easy to use. It scales your apps based on traffic so that you only pay for the resources you use. With App Engine, you can take advantage of Google‚Äôs immense knowledge of running massively scalable, performance-driven systems.
Pros:
¬∑ Flexible pricing;
¬∑ Cloud-based RESTful APIs;
¬∑ Much easier to run asynchronous tasks;
¬∑ Access to big data resources for reporting and analytics;
¬∑ GAE apps are easy to create, easy to maintain, and easy to scale.
Cons:
¬∑ Platform tie-in;
¬∑ No standard SQL DB;
¬∑ Sudden downtime and task queue failures;
¬∑ Logging in is recorded and accessible through a web console;
¬∑ If you want to try GAE for free, you‚Äôll be forced to use Cloud Datastore, which is a NoSQL database;
¬∑ The migration is almost impossible as you‚Äôre technically married to Google and its future decisions.
Kubernetes is a Google-backed open-source container storage program for managing containerized applications in a clustered environment. It is a portable, powerful, and useful tool which can handle containers and offer immense scalability and automation at the same time. From a developer‚Äôs standpoint, it provides a robust mechanism to easily deploy and manage applications (just like Heroku), but without the constraints and vendor lock-in of an actual PaaS. This is why it is considered a good replacement for Heroku.
One of its major concerns is that it is difficult to use and is despised by most developers. Having said that, it is widely accepted by the community of developers, despite the hard installation process. One of last year‚Äôs biggest hits in the gaming industry, Pokemon Go, also used Kubernetes to manage their product and scale rapidly. The main reason behind its popularity is the amount of flexibility it offers and also the fact that it has the support of Google, one of the leading tech giants.
Pros:
¬∑ Backed by Google (GKE) and RedHat (OpenShift);
¬∑ Eliminates infrastructure lock-in by providing core capabilities for containers without imposing restrictions;
¬∑ Offers inbuilt logging and monitoring tools;
¬∑ Supports a diverse range of workloads, which include stateless, stateful, and data-processing workloads;
¬∑ Auto-scaling based on factors such as CPU utilization;
¬∑ Largest community among container orchestration tools (over 50k commits and 1,200 contributors).
Cons:
¬∑ Hard to set up and configure;
¬∑ DIY installation can be complex;
Like Heroku, AWS is another commonly used cloud service that lets you deploy, monitor, and scale web and mobile applications. It provides you with cloud computing resources and is great for hosting applications. Two of its major offerings include Elastic Beanstalk (which is PaaS) and Elastic Compute Cloud (which is IaaS).
Heroku‚Äôs platform provides abstract computing environments known as dynos, which are strictly confined to application processes. That is to say, no other services can run on dynos. Amazon‚Äôs Elastic Compute Cloud (EC2) is the closest equivalent to Heroku‚Äôs dynos. With EC2, developers can rapidly convey and oversee applications (both web and mobile) in the Amazon Web Services Cloud without agonizing over the framework that runs those apps. EC2 is much cheaper than Heroku (one of its biggest advantage) and provides more RAM, Swap space, Storage space, and Compute power in its comparison.
Pros:
¬∑ It lets businesses distribute storage volumes independent of its computing system;
¬∑ Leveraging EC2, an enterprise can expand or reduce its capacity in just a few minutes instead of hours or days;
¬∑ Instant provisioning of new servers;
¬∑ Multiple geographic areas to run servers with a standard interface;
¬∑ Entire AWS ecosystem of services and support and community to build on.
Cons:
¬∑ Instance types are rigid;
¬∑ All servers are virtual;
¬∑ It does not include enterprise-grade support by default;
¬∑ Billing is extremely confusing;
¬∑ The learning curve is sometimes steep for larger companies;
¬∑ Cross-region communication is not available natively;
¬∑ No VPN Network to the internal network.
Still Not Able to Decide? Let Us Help!
All of the above-mentioned platforms are considered excellent as far as developing and deploying your application is concerned. However, the choice depends on a plethora of factors, including the size of your app, your financial constraints, availability of resources, and also the level of customization you need. All of these platforms differ each other in terms of user engagement, pricing, deployment, functionality, and features. Also, each of them has its own benefits and drawbacks, so a thorough knowledge of what each platform offers is essential in making the right choice. In the end, it all comes down to personal preference. Being a hardcore app developer, I‚Äôd personally recommend you to use Back4App for your next app project. I‚Äôve been using it for a while now, and I must say the experience has been wonderful and trouble-free. Thanks to their serverless architecture, you don‚Äôt have to worry about managing servers and backend infrastructures. Plus, the freemium package they offer is beyond words. It allows you to run multiple apps comfortably without upgrading to a paid subscription.
If you‚Äôre ready to give Back4App a try, then don‚Äôt wait any longer. Sign up here for free today and cut your platform costs by 4X.
Tech addicted and Software Architect
1.2K 
7
1.2K¬†claps
1.2K 
7
Tech addicted and Software Architect
About
Write
Help
Legal
Get the Medium app
"
https://read.acloud.guru/iaas-paas-serverless-the-next-big-deal-in-cloud-computing-34b8198c98a2?source=search_post---------109,NA
https://medium.com/swlh/are-containers-still-relevant-3a888c5c3438?source=search_post---------110,"There are currently no responses for this story.
Be the first to respond.
When sitting down to start a new project, or figuring out a road map for an existing one, the options for actually running your workloads have never been more wide open. Admittedly, we live in an era where we are spoiled for choice when it comes to platforms; between open-source‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/bitnami-perspectives/running-containers-in-openshift-629af79945b5?source=search_post---------111,"There are currently no responses for this story.
Be the first to respond.
Top highlight
OpenShift is Red Hat container application platform. It is based on Kubernetes and to keep things short we are going to call it a PaaS. The new OpenShift v3 represents a big bet by Red Hat to re-write the software entirely in Go and leverage Kubernetes. Indeed when you use OpenShift, you get a Red Hat distribution of Kubernetes plus the OpenShift functionalities around code deployment, automated builds and so on, that you are used to with a typical PaaS.
What stands out with OpenShift, and what Red Hat touts quite often is the focus on security.
I am not a security expert but when you look at Kubernetes and if you avoid the polemic around secrets, you will find that Kubernetes has a lot of nice security features. RBAC is now the default setup when you use kubeadm to bootstrap your cluster, network isolation can be enforced with network policies and Pods can be controlled very tightly with Pod security policies. Add to that the authentication mechanisms, TLS setup for all components and admission controls and it is looking like a pretty strong and secure system, at least to me.
But security sometimes comes at a price for early adopters. In OpenShift‚Äôs case, they use Kubernetes Pod security policies by default, they are called Security Context Constraints (i.e scc). The most visible aspect of using scc by default is that containers that run their processes as ROOT will not run in OpenShift.
So if you start with minishift and try to run a basic Docker image that does not specify a non ROOT user, then it will fail. This means quite sadly that currently our Bitnami images won‚Äôt run on OpenShift. While we are working on a long term fix, namely to use a non-privileged user in our Dockerfile, I am going to show you how to temporarily circumvent this issue.
To get started with Openshift use minishift. It is a custom minikube , meaning it will start a virtual machine on your local desktop/laptop and in this VM, openshift (i.e k8s) will be setup. The client oc will also be easily configured as it is a wrapper around kubectl .
Download and start it like minikube (except that the default driver is xhyve so if you use Virtual Box‚Ä¶):
Setup the Openshift client oc in your shell:
To modify a scc you need to be an admin on Openshift, so login as the admin of your minishift (this just switches the k8s context):
Then edit the scc called anyuid:
If you do not log in as the admin user, the RBAC rules in place will not let you edit the security constraints. Then add a users section that look like this:
Basically you are letting the default service account in the myproject namespace run Pods whose containers run processes as any uid , including the ROOT user. Note that the myproject is the namespace that your regular user has access to. This was generated by minishift automatically, and you can find it in your k8s context with oc config view .
Switch back to minishift as a regular user ( oc config just like kubectl config ):
You are now ready to create an app using a container where the process runs as ROOT. You relaxed the pod security policy. This is not ideal as you should always use principles of least privilege. oc new-app looks a lot like kubectl run
And you now have a running Bitnami mariadb on OpenShift ( oc logs like kubectl logs :
While you can circumvent the default security context constraints in OpenShift, this is not ideal. That‚Äôs why at Bitnami we are now working to modify our container application templates to harden them and ensure they work nicely with OpenShift out of the box.
@sebgoa
@bitnami
Loved by devs, Trusted by ops: Bitnami makes easy to use‚Ä¶
32 
32¬†claps
32 
Written by
@sebgoa, Kubernetes lover, R&D enthusiast, co-Founder of TriggerMesh, O‚ÄôReilly author, sports fan, husband and father‚Ä¶
Loved by devs, Trusted by ops: Bitnami makes easy to use cloud images, containers, and VMs that work on any platform.
Written by
@sebgoa, Kubernetes lover, R&D enthusiast, co-Founder of TriggerMesh, O‚ÄôReilly author, sports fan, husband and father‚Ä¶
Loved by devs, Trusted by ops: Bitnami makes easy to use cloud images, containers, and VMs that work on any platform.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@shijuvar/deploying-go-web-apps-with-docker-1b7561b36f53?source=search_post---------112,"Sign in
There are currently no responses for this story.
Be the first to respond.
Shiju Varghese
Dec 13, 2014¬∑5 min read
In my previous post, ‚ÄúThe Evolution Of Cloud PaaS To Container Ecosystem‚Äù, we have discussed the evolution of Cloud PaaS to container technologies such as Docker and Kubernetes. In this post, I will demonstrate how to deploy a Go web app into an application container using Docker. You can download the sample app from https://github.com/shijuvar/golang-docker
Docker is a revolutionary application container platform for developing, shipping, and running apps on the container virtualization environment. A container is lightweight Linux environment which can be used as an abstraction layer for your apps. When you develop apps for virtual machines, you are actually interacting with an infrastructure layer including operating systems, network infrastructure layers. An application container separate your apps from your infrastructure and it separate your app from where it runs. Application container lets you develop apps against idealized operating system ‚Äî a static Linux environment, instead of developing apps against idealized hardware environment in traditional virtual machines. This capability provides great opportunities to application developer and IT administrators for developing, managing and shipping distributed apps. IMHO, application container technology is the big revolution after Cloud computing.
Docker revolutionized the application container technology with their powerful ecosystem. The Docker ecosystem consisting of Docker Engine, a portable, lightweight run-time and packaging tool for building containerized apps, and Docker Hub, a cloud service for sharing apps and automating workflows. Docker Hub is a registry system in the Docker ecosystem for storing Docker images, from where you upload or download images. You will be created containers from an image. Docker lets the developers containerize their apps which can run on anywhere. Docker allows you compose your containerized apps by linking between different containers. Docker is a great platform for building next-generation distributed apps with a Microservices architecture where you can put your Microservice apps into individual containers and compose these apps by linking between containers.
Docker client tool works with all operating systems. If you want to run Docker clients in Mac and Windows, you need to run boot2docker, which is a lightweight Linux distribution for Docker.
Let‚Äôs a write a simple HTTP server in Go for deploying into a container using Docker. The source repository is available at https://github.com/shijuvar/golang-docker
Code Listing ‚Äî main.go
When you run the command ‚Äúdocker build‚Äù in the Docker client‚Äôs terminal, Docker can build images by reading the instructions from a Dockerfile. Dockerfile is a text file that contains all the commands to build a Docker image. Let‚Äôs write a Dockerfile for building our Docker image for install and run our Go HTTP server in a Docker container.
Code Listing ‚Äî Dockerfile
In the above Dockerfile, we are building our image from a base image Golang which is created for running Go apps where Gopath configured at /go. The image name golang:latest means that we are building our image from Golang image with latest tag. Using the ADD command, we are adding the Go package source into our container‚Äôs Gopath. Then, we install our Go app to bin folder of Gopath and finally setting up the entry point for the app. The EXPOSE command exposing port 8080 for for the HTTP server.
In my local machine, I am working with boot2docker client. The source repository is located on github.com\shijuvar\golang-docker. Let me mount the source repository directory with the Dcoker container.
Before executing the mount command, I had created a shared folder named golang-docker to map local directory github.com\shijuvar\golang-docker in the VM VirtualBox. In the mount command, we mount the shared folder golang-docker with /home/Docker/golang-docker directory.
Let‚Äôs run the ‚Äúdocker build‚Äù command from golang-docker directory to build our Docker image by reading instructions from Dockerfile.
The above build command reads instructions from the Docker file. The command ‚ÄúFROM golang:latest‚Äù in the Dockerfile, will fetch the golang:latest image from Dokcer Hub. The ‚ÄúADD‚Äù command add the package source into Gopath of golang image. The ‚ÄúRUN‚Äù command build the Go package and the ‚ÄúENTRYPOINT‚Äù command set up entry point for our container for running the golang-docker command by default, when the container starts. The ‚ÄúEXPOSE‚Äù command expose port 8080 for our HTTP server. We tag the resulting image as golang-docker.
The docker build command did build the docker image from golang base image and finally build the Go package and exposed port 8080 from the container. Let‚Äôs run the Docker image by publishing an external port to container‚Äôs port 8080.
In the above run command, we run the golang-docker repository by publishing external port 3000 to container‚Äôs port 8080, and gives container‚Äôs name as goweb. Even we can use port 8080 to multiple containers and map these ports with different ports of external system. The ‚Äîrm flag specify to remove the container image when our HTTP server exits.
Now you can access your web app from a web browser. If you are using Linux system you can access the web app from http://localhost:3000/. I am using boot2docker Docker client for Windows where the exposed IP address for boot2docker is 192.168.59.103. Let me navigate to http://192.168.59.103:3000/ for accessing the Go web app hosted on a Docker container.
In this post, we developed a simple HTTP server in Go and deployed the web app into a application container using Docker. We fetch a golang image from Docker Hub for creating our Docker image. Docker Hub is a important component in Docker ecosystem where we can leverage thousands of preconfigured images for building our containers. Using Docker, we can separate apps from infrastructure and develop apps against an idealized operating system ‚Äî a static Linux environment. Docker is a great platform for building distributed apps with Microservices architecture.
You can follow me on twitter at @shijucv. I do provide training and consulting on Go programming language (Golang) and distributed systems architectures, in India.
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
38 
3
38¬†
38 
3
Consulting Solutions Architect and Trainer on Go and Distributed Systems, with focus on Microservices and Event-Driven Architectures. Author of two books on Go.
"
https://medium.com/@allo/%D0%BE-%D0%BA%D0%B0%D1%80%D1%88%D0%B5%D1%80%D0%B8%D0%BD%D0%B3%D0%B5-820285ead178?source=search_post---------113,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alexander Lozhechkin
Jun 10, 2018¬∑10 min read
–ï—Å—Ç—å IaaS, PaaS, SaaS, –∞ –µ—Å—Ç—å –ü–∞—Ç—Ä–∏—Å–∏—è –ö–∞–∞—Å.–ê–Ω–µ–∫–¥–æ—Ç –¥–ª—è –ò–¢-—à–Ω–∏–∫–æ–≤
–†–æ–≤–Ω–æ –≥–æ–¥ –Ω–∞–∑–∞–¥ —è –≤–ø–µ—Ä–≤—ã–µ –ø—Ä–æ–∫–∞—Ç–∏–ª—Å—è –Ω–∞ –∫–∞—Ä—à–µ—Ä–∏–≥–µ. –Ø –¥—É–º–∞–ª, —á—Ç–æ —è –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–º, –∫—Ç–æ –ø—Ä–∏–æ–±—â–∏–ª—Å—è –∫ —ç—Ç–æ–º—É –≤–∏–¥—É –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –Ω–æ –æ–∫–∞–∑–∞–ª–æ—Å—å, —á—Ç–æ —ç—Ç–æ —è –µ—â—ë –±—ã–ª –≤ –ø–µ—Ä–≤—ã—Ö —Ä—è–¥–∞—Ö. –ó–∞ —ç—Ç–æ—Ç –≥–æ–¥ —è —É—Å–ø–µ–ª –ø—Ä–æ–∫–∞—Ç–∏—Ç—å—Å—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ—Ö –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞—Ö –ú–æ—Å–∫–≤—ã, –ï–≤—Ä–æ–ø—ã –∏ –®—Ç–∞—Ç–æ–≤. –û—Å–≤–æ–∏–ª –±–∞–π–∫—à–µ—Ä–∏–Ω–≥ –∏ —Å–∞–º–æ–∫–∞—Ç—à–µ—Ä–∏–Ω–≥. –° —Ç–µ—Ö –ø–æ—Ä –∫–∞—Ä—à–µ—Ä–∏–Ω–≥ —Å—Ç–∞–ª –æ—á–µ–Ω—å –º–∞—Å—Å–æ–≤—ã–º, –Ω–æ —è –≤—Å—ë —Ä–∞–≤–Ω–æ –¥—É–º–∞—é, —á—Ç–æ –Ω–∞—Å—Ç–æ—è—â–∞—è –º–∞—Å—Å–æ–≤–æ—Å—Ç—å —É –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ –µ—â—ë –≤–ø–µ—Ä–µ–¥–∏. –í –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–µ –Ω–∞–ø–∏—Å–∞–Ω–æ —Å—Ç–æ–ª—å–∫–æ –Ω–µ—Å—É—Å–≤–µ—Ç–Ω–æ–π —á—É—à–∏, —á—Ç–æ —è –Ω–µ —Å–º–æ–≥ —É—Å—Ç–æ—è—Ç—å –∏ —Ä–µ—à–∏–ª –Ω–∞–ø–∏—Å–∞—Ç—å, –∫–∞–∫ –≤—Å—ë –æ–±—Å—Ç–æ–∏—Ç –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ.
–û shared-economy —è —É–∂–µ –ø–∏—Å–∞–ª. –Ø —Ç–∞–º —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª –æ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–µ, –∫–∞–∫ –ø—Ä–∏–º–µ—Ä–µ shared-economy. –£—Å–ª—ã—à–∞–ª –º–Ω–æ–≥–æ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ–≥–æ –≤ —Å–≤–æ–π –∞–¥—Ä–µ—Å –æ—Ç –ª—é–±–∏—Ç–µ–ª–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.
robot-review.ru
–°–≤–æ–µ–π –º–∞—à–∏–Ω—ã –≤ –ú–æ—Å–∫–≤–µ —É –º–µ–Ω—è –Ω–µ—Ç. –í–ø—Ä–æ—á–µ–º, —Å–≤–æ–µ–π –º–∞—à–∏–Ω—ã —É –º–µ–Ω—è –Ω–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –≤ –ú–æ—Å–∫–≤–µ, –Ω–æ –∏ –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –≥–æ—Ä–æ–¥–æ–≤ –º–∏—Ä–∞, –≥–¥–µ —è –±—ã–≤–∞—é. –°–≤–æ–µ–π –º–∞—à–∏–Ω—ã —É –º–µ–Ω—è –Ω–µ—Ç –Ω–∏–≥–¥–µ, –∫—Ä–æ–º–µ –ú—é–Ω—Ö–µ–Ω–∞, –≥–¥–µ —è —Ç–æ–∂–µ –ø–ª–∞–Ω–∏—Ä—É—é –æ—Ç –Ω–µ—ë –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è. –ö–∞–∫ –∏ –æ—Ç –º–æ—Ç–æ—Ü–∏–∫–ª–∞. –ü–æ—Ç–æ–º—É, —á—Ç–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á—Ç–æ-—Ç–æ, —á–µ–º –ø–æ–ª—å–∑—É–µ—à—å—Å—è –º–∞–∫—Å–∏–º—É–º 10% —Å–≤–æ–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, –æ—á–µ–Ω—å –Ω–µ—Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ. –ù—É –∏ –ø—Ä–æ—Å—Ç–æ –Ω–µ –æ—á–µ–Ω—å —ç—Ç–∏—á–Ω–æ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –æ–±—â–µ—Å—Ç–≤—É.
–í–µ–¥—å –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ª—é–¥–µ–π, –≤–ª–∞–¥–µ—é—â–∏—Ö –º–∞—à–∏–Ω–∞–º–∏, –ø–æ–ª—å–∑—É—é—Ç—Å—è –∏–º–∏ –æ—Ç —Å–∏–ª—ã –ø–∞—Ä—É —á–∞—Å–æ–≤ –≤ —Å—É—Ç–∫–∏. –¢–æ –µ—Å—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ 22 —á–∞—Å–∞ –∏—Ö –º–∞—à–∏–Ω–∞ –ø—Ä–æ—Å—Ç–æ —Å—Ç–æ–∏—Ç, –∑–∞–Ω–∏–º–∞—è –º–µ—Å—Ç–æ –∏ –Ω–µ –ø—Ä–∏–Ω–æ—Å—è –ø–æ–ª—å–∑—ã. –ò —Ö–æ—Ä–æ—à–æ –µ—â—ë, –µ—Å–ª–∏ –æ–Ω–∞ —Å—Ç–æ–∏—Ç –Ω–∞ –∑–µ–º–ª–µ, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–µ–π –≤–ª–∞–¥–µ–ª—å—Ü—É –º–∞—à–∏–Ω—ã (–Ω–∞ —Å–≤–æ–µ–π –∑–µ–º–ª–µ –¥–µ–ª–∞—é –≤—Å—ë, —á—Ç–æ –∑–∞—Ö–æ—á—É), –Ω–æ –≤–µ–¥—å —á–∞—â–µ –≤—Å–µ–≥–æ –≤—Å–µ —á–∞—Å—Ç–Ω—ã–µ –º–∞—à–∏–Ω—ã 80% –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–Ω–∏–º–∞—é—Ç –º–µ—Å—Ç–æ –≤ –≥–æ—Ä–æ–¥–µ, –ø—Ä–∏—á—ë–º –º–µ—Å—Ç–æ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ.
–ü–æ—Ä–∞—Å—Å—É–∂–¥–∞–µ–º –Ω–µ–º–Ω–æ–∂–∫–æ –ø—Ä–æ —ç—Ç–æ. –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –ª—é–¥—è–º —Ö–æ—á–µ—Ç—Å—è –∂–∏—Ç—å —Ä—è–¥–æ–º —Å –¥—Ä—É–≥–∏–º–∏ –ª—é–¥—å–º–∏. –ó–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Ä–µ–¥–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—Ç—à–µ–ª—å–Ω–∏–∫–æ–≤ –ª—é–¥–∏ —Å—Ç—Ä–µ–º—è—Ç—Å—è –∂–∏—Ç—å –≤–º–µ—Å—Ç–µ, —Å–æ–∑–¥–∞–≤–∞—è –¥–µ—Ä–µ–≤–Ω–∏ –∏ –≥–æ—Ä–æ–¥–∞. –ü—Ä–∏—á—ë–º —á–µ–º –±–æ–ª—å—à–µ –ª—é–¥–µ–π –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ä—è–¥–æ–º, —Ç–µ–º –ª—É—á—à–µ –∏–º –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –∂–∏—Ç—å. –í –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–µ –∞—ç—Ä–æ–ø–æ—Ä—Ç—ã, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –±–µ–∑ –ø–µ—Ä–µ—Å–∞–¥–æ–∫ –∏ –Ω–µ–¥–æ—Ä–æ–≥–æ —É–ª–µ—Ç–µ—Ç—å –ø–æ –º–Ω–æ–≥–∏–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º. –í –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–µ –º—É–∑–µ–∏ –∏ —Ç–µ–∞—Ç—Ä—ã. –í –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–µ —à–∫–æ–ª—ã –∏ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—ã. –í –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã. –í –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–µ –º–µ—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã. –ü–æ—Ç–æ–º—É, —á—Ç–æ –≤ –±–æ–ª—å—à–∏—Ö –≥–æ—Ä–æ–¥–∞—Ö –µ—Å—Ç—å –º–Ω–æ–≥–æ —Ö–æ—Ä–æ—à–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤. –¢–æ –µ—Å—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç: –±–æ–ª—å—à–µ –ª—é–¥–µ–π ‚Äî –ª—É—á—à–µ —É—Å–ª—É–≥–∏ ‚Äî –±–æ–ª—å—à–µ –ª—é–¥–µ–π.
–ù–æ –µ—Å—Ç—å –æ–¥–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞. –ß—Ç–æ–±—ã –±–æ–ª—å—à–æ–π –≥–æ—Ä–æ–¥ –Ω–µ —Ä–æ—Å –±–µ–∑–≥—Ä–∞–Ω–∏—á–Ω–æ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø–æ –º–µ—Ä–µ —Ä–æ—Å—Ç–∞ –Ω–∞—Å–µ–ª–µ–Ω–∏—è, –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è —Ç–µ—Å–Ω–∏—Ç—å—Å—è. –ò –¥–∞–∂–µ –µ—Å–ª–∏, –∫–∞–∫ –≤ –®—Ç–∞—Ç–∞—Ö, –º–Ω–æ–≥–∏–µ –±—É–¥—É—Ç –∂–∏—Ç—å –≤ –æ–¥–Ω–æ—ç—Ç–∞–∂–Ω—ã—Ö –¥–æ–º–∏–∫–∞—Ö, —Ü–µ–Ω—Ç—Ä –≥–æ—Ä–æ–¥–∞ —Å –º—É–∑–µ—è–º–∏, —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞–º–∏, –º—É–∑–µ—è–º–∏, —Ç–µ–∞—Ç—Ä–∞–º–∏ –∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º–∏, –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–æ–≤–æ–ª—å–Ω–æ —Ç–µ—Å–Ω—ã–º. –ê –µ—Å–ª–∏ –≤–µ—Å—å –ø—Ä–∏–≥–æ—Ä–æ–¥ –±—É–¥–µ—Ç –æ–¥–Ω–æ—ç—Ç–∞–∂–Ω—ã–º, —Ç–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –µ—Ö–∞—Ç—å –¥–æ —ç—Ç–æ–≥–æ —Å–∞–º–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –ø—Ä–∏–¥—ë—Ç—Å—è –æ—á–µ–Ω—å –¥–æ–ª–≥–æ. –ò –µ—Å–ª–∏ –µ—Ö–∞—Ç—å –¥–æ–ª–≥–æ –Ω–µ —Ö–æ—á–µ—Ç—Å—è ‚Äî —Ç–æ –ø—Ä–∏–¥—ë—Ç—Å—è –∂–∏—Ç—å –ø–æ–±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É. –ì–¥–µ –∑–µ–º–ª—è –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –¥–æ—Ä–æ–≥–æ. –ò –ø–æ—ç—Ç–æ–º—É –ø—Ä–∏–¥—ë—Ç—Å—è –∂–∏—Ç—å –ø–æ—Ç–µ—Å–Ω–µ–µ. –û–ø—è—Ç—å –∂–µ, –∫—Ä—É–≥ –∑–∞–º–∫–Ω—É–ª—Å—è.
–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –±–æ–ª—å—à–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞—Å–µ–ª–µ–Ω–∏—è ‚Äî –Ω–µ–∏–∑–±–µ–∂–Ω–æ–µ —Å–ª–µ–¥—Å—Ç–≤–∏–µ –∂–µ–ª–∞–Ω–∏—è –ª—é–¥–µ–π –∂–∏—Ç—å —É–¥–æ–±–Ω–æ. –°—Ç–æ–∏–º–æ—Å—Ç—å –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –º–µ—Ç—Ä–∞ –ø–ª–æ—â–∞–¥–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∑–µ–º–ª–∏ –≤ –±–æ–ª—å—à–æ–º –≥–æ—Ä–æ–¥–µ –≤–∑–ª–µ—Ç–∞–µ—Ç –¥–æ –Ω–µ–±–µ—Å. –î–æ–º–∞ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –≤—Å—ë –≤—ã—à–µ, –∫–≤–∞—Ä—Ç–∏—Ä—ã –≤—Å—ë –º–µ–Ω—å—à–µ. –ò –≤–æ—Ç —Ç—É—Ç –ª–æ–≥–∏—á–Ω–æ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å ‚Äî –∞ –º–æ–∂–µ–º –ª–∏ –º—ã —Å–µ–±–µ –ø–æ–∑–≤–æ–ª–∏—Ç—å 10 –º–µ—Ç—Ä–æ–≤ –ø–ª–æ—â–∞–¥–∏ –≥–æ—Ä–æ–¥–∞ –æ—Ç–¥–∞—Ç—å –Ω–µ –¥–æ–º–∞–º, –Ω–µ –¥–æ—Ä–æ–≥–∞–º, –∞ –ø–∞—Ä–∫–æ–≤–∫–µ? –ò–º–µ–Ω–Ω–æ —Å—Ç–æ–ª—å–∫–æ –º–µ—Å—Ç–∞ –∑–∞–Ω–∏–º–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–π –ª–µ–≥–∫–æ–≤–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å. –ü—Ä–∏—á—ë–º –∞–≤—Ç–æ–º–æ–±–∏–ª—å, –∫–æ—Ç–æ—Ä—ã–π 80% –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ –ø—Ä–∏–Ω–æ—Å–∏—Ç –Ω–∏–∫–∞–∫–æ–π –ø–æ–ª—å–∑—ã, –Ω–∏–∫—É–¥–∞ –Ω–µ –µ–¥–µ—Ç, –∞ –ø—Ä–æ—Å—Ç–æ —Å—Ç–æ–∏—Ç –Ω–∞ –æ–±–æ—á–∏–Ω–µ. –ó–∞–Ω–∏–º–∞—è —Ç–∞–∫–æ–µ –¥–æ—Ä–æ–≥–æ–µ –º–µ—Å—Ç–æ. –î–∞–∂–µ –µ—Å–ª–∏ –ø–∞—Ä–∫–æ–≤–∫–∞ –ø–ª–∞—Ç–Ω–∞—è –∏ –≤–ª–∞–¥–µ–ª–µ—Ü –º–∞—à–∏–Ω—ã –ø–ª–∞—Ç–∏—Ç —Å–≤–æ–∏ 70 –∏–ª–∏ –¥–∞–∂–µ 200 —Ä—É–±–ª–µ–π –≤ —á–∞—Å –∑–∞ –ø–∞—Ä–∫–æ–≤–∫—É ‚Äî —ç—Ç–æ –Ω–µ—Å—Ä–∞–≤–Ω–∏–º–æ –¥–µ—à–µ–≤–ª–µ, —á–µ–º –º–æ–≥–ª–∞ –±—ã –ø—Ä–∏–Ω–æ—Å–∏—Ç—å —ç—Ç–∞ –∑–µ–º–ª—è, –µ—Å–ª–∏ –±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å —Å —Ç–æ–ª–∫–æ–º. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Ç–æ–≥–æ –∂–µ –º—É–∑–µ—è, —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞, —Ö–æ—Ä–æ—à–µ–≥–æ –º–µ—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ –∂–∏–ª—å—è.
–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–∞—Ä–∫–æ–≤–∫–∞ ‚Äî –æ—á–µ–Ω—å –¥–æ—Ä–æ–≥–æ–µ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ. –ì–æ—Ç–æ–≤—ã –ª–∏ –≤—ã –±—ã–ª–∏ –æ—Ç–¥–∞—Ç—å 10 –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–æ–≤ —Å–≤–æ–µ–π –∫–≤–∞—Ä—Ç–∏—Ä—ã –¥–ª—è –ø–∞—Ä–∫–æ–≤–∫–∏ —Å–≤–æ–µ–π –º–∞—à–∏–Ω—ã. –ò–ª–∏ –¥–≤–∞–¥—Ü–∞—Ç—å ‚Äî –¥–ª—è –¥–≤—É—Ö? –í—Ä—è–¥ –ª–∏. –ê –ø–æ—á–µ–º—É –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ, —á—Ç–æ –≥–æ—Ä–æ–¥ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º —ç—Ç—É –ø–ª–æ—â–∞–¥—å? –î–∞ –µ—â—ë –∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ? –ü–æ—ç—Ç–æ–º—É –ø–∞—Ä–∫–æ–≤–∫–∞ –ø—Ä–æ—Å—Ç–æ –æ–±—è–∑–∞–Ω–∞ –±—ã—Ç—å –¥–æ—Ä–æ–≥–æ–π. –ò –ø–æ—ç—Ç–æ–º—É –∂–µ –≤–ª–∞–¥–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–º –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –∂–∏–∑–Ω—å—é –≤ –≥–æ—Ä–æ–¥–µ. –•–æ—á–µ—à—å –≤–ª–∞–¥–µ—Ç—å —Å–≤–æ–µ–π –º–∞—à–∏–Ω–æ–π ‚Äî –ø–æ–∫—É–ø–∞–π –∑–∞–≥–æ—Ä–æ–¥–Ω—ã–π –¥–æ–º. –•–æ—á–µ—à—å –∂–∏—Ç—å –≤ –≥–æ—Ä–æ–¥–µ –ø–æ–±–ª–∏–∂–µ –∫ –º—É–∑–µ—è–º, —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º –∏ —Ç–µ–∞—Ç—Ä–∞–º ‚Äî –µ–∑–∂–∞–π –Ω–∞ —Ç—Ä–∞–º–≤–∞–π—á–∏–∫–µ.
–¢–∞–∫ –±—ã–ª–æ –¥–æ –Ω–µ–¥–∞–≤–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –ö–æ–≥–¥–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –±—ã–ª–∞ –ª–∏–±–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å, –ª–∏–±–æ —Ç–µ—Å–Ω—ã–π –∏ –Ω–µ—É–¥–æ–±–Ω—ã–π –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, –ª–∏–±–æ —Ç–∞–∫—Å–∏. –ö–∞—Ä—à–µ—Ä–∏–Ω–≥, –Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥, –∫–∞–∫ —Ä–∞–∑ —Å—Ç–∞–ª —Ç–µ–º –æ—Ç–ª–∏—á–Ω—ã–º –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤ –ª–∏—á–Ω–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ª–∏—à—ë–Ω –µ–≥–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–≤. –ò, —è–≤–ª—è—è—Å—å –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–æ–º, –ª–∏—à—ë–Ω –µ–≥–æ –º–∏–Ω—É—Å–æ–≤.
–í —á—ë–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∫–∞—Ä—à–µ—Ä–∏–≥–∞: ‚Ä¢ –í—ã –µ–¥–µ—Ç–µ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–∞—à–∏–Ω–µ –∑–∞ —Ä—É–ª—ë–º, –∫—É–¥–∞ —Ö–æ—Ç–∏—Ç–µ –∏ –∫–∞–∫ —Ö–æ—Ç–∏—Ç–µ ‚Ä¢ –ü—Ä–∏ —ç—Ç–æ–º –≤—ã –Ω–µ –¥—É–º–∞–µ—Ç–µ –æ —Ä–µ–º–æ–Ω—Ç–µ, —Å—Ç—Ä–∞—Ö–æ–≤–∫–µ, —Å–º–µ–Ω–µ —Ä–µ–∑–∏–Ω—ã –Ω–∞ –∑–∏–º—É, –º–æ–π–∫–µ –∏ –∑–∞–ø—Ä–∞–≤–∫–µ ‚Ä¢ –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç–∞–∫—Å–∏, –≤–∞–º –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è —Å–æ—Å–µ–¥—Å—Ç–≤–æ–≤–∞—Ç—å —Å –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–º –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–º –∑–∞ —Ä—É–ª—ë–º (–¥–ª—è –º–µ–Ω—è, –∫–∞–∫ –¥–ª—è –Ω–µ–∏—Å—Ç–æ–≤–æ–≥–æ –º–∏–∑–∞–Ω—Ç—Ä–æ–ø–∞ –∏ –∏–Ω—Ç—Ä–æ–≤–µ—Ä—Ç–∞ ‚Äî —Ä–µ—à–∞—é—â–µ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ) ‚Ä¢ –í—ã –Ω–µ –¥—É–º–∞–µ—Ç–µ –æ —Ç–æ–º, —á—Ç–æ –µ—Å–ª–∏ –≤—ã –≤ –æ–¥–Ω—É —Å—Ç–æ—Ä–æ–Ω—É –ø–æ–µ—Ö–∞–ª–∏ –Ω–∞ –º–∞—à–∏–Ω–µ, —Ç–æ –Ω–∞ –º–∞—à–∏–Ω–µ-–∂–µ –ø—Ä–∏–¥—ë—Ç—Å—è –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∏ –Ω–∞–∑–∞–¥ (–∫–∞–∫ –ø—Ä–∏—à–ª–æ—Å—å –±—ã —Å–¥–µ–ª–∞—Ç—å —Å–æ —Å–≤–æ–µ–π –º–∞—à–∏–Ω–æ–π)
–û—Å—Ç–∞–Ω–æ–≤–ª—é—Å—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ. –õ—é–±–æ–π –±–æ–ª—å—à–æ–π –≥–æ—Ä–æ–¥ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø–µ—Ä–µ–¥–≤–∏–∂–µ–Ω–∏—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–µ–Ω. –î–ª—è –≥—É–º–∞–Ω–∏—Ç–∞—Ä–∏–µ–≤ –ø–æ—è—Å–Ω—é: –∏–∑ —Ç–æ—á–∫–∏ –ê –≤ —Ç–æ—á–∫—É –ë –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±—Ä–∞—Ç—å—Å—è –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ. –ê –≤–æ—Ç –∏–∑ —Ç–æ—á–∫–∏ –ë –≤ —Ç–æ—á–∫—É –ê ‚Äî –Ω–∞–æ–±–æ—Ä–æ—Ç, –æ—á–µ–Ω—å –¥–æ–ª–≥–æ. –ü–æ—ç—Ç–æ–º—É –æ—á–µ–Ω—å –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–æ–±–Ω–æ —Å –æ–∫—Ä–∞–∏–Ω—ã –≤ —Ü–µ–Ω—Ç—Ä —É—Ç—Ä–æ–º –µ—Ö–∞—Ç—å –Ω–∞ –º–µ—Ç—Ä–æ, –∞ –≤–æ—Ç –ø–æ—Ç–æ–º –µ—Ö–∞—Ç—å –Ω–∞ –æ–∫—Ä–∞–∏–Ω—É –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–æ–±–Ω–µ–µ –Ω–∞ –º–∞—à–∏–Ω–µ. –ò –ø—Ä–∏ —ç—Ç–æ–º –µ—â—ë –∏ –≤ –º–∞–≥–∞–∑–∏–Ω –∑–∞–µ—Ö–∞—Ç—å –∑–∞ –ø–æ–∫—É–ø–∫–∞–º–∏. –ï—â—ë –¥–ª—è –ª—é–±–∏—Ç–µ–ª–µ–π –≤—ã–ø–∏—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏—á–Ω–∞—è –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–∏—è. –ö–æ–≥–¥–∞ –Ω–∞ —Ä–∞–±–æ—Ç—É –ª—É—á—à–µ –µ—Ö–∞—Ç—å –Ω–∞ –º–∞—à–∏–Ω–µ, –∞ –≤–æ—Ç –æ–±—Ä–∞—Ç–Ω–æ ‚Äî –Ω–∞ —Ç–∞–∫—Å–∏. –í –æ–±—â–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤, –∫–æ–≥–¥–∞ ‚Äú—Ç—É–¥–∞‚Äù –∏ ‚Äú–Ω–∞–∑–∞–¥‚Äù –µ—Ö–∞—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–æ–±–Ω–µ–µ –ø–æ-—Ä–∞–∑–Ω–æ–º—É ‚Äî –º–∏–ª–ª–∏–æ–Ω. –°–æ —Å–≤–æ–µ–π –º–∞—à–∏–Ω–æ–π –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –¥—É–º–∞—Ç—å –æ —Ç–æ–º, —á—Ç–æ –µ—Å–ª–∏ —Ç—É–¥–∞ –ø–æ–µ—Ö–∞–ª –Ω–∞ –º–∞—à–∏–Ω–µ, —Ç–æ –Ω–∞ –º–∞—à–∏–Ω–µ-–∂–µ –ø—Ä–∏–¥—ë—Ç—Å—è –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –æ–±—Ä–∞—Ç–Ω–æ. –ê —Å –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–º —Ç–∞–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç.
–ï—â—ë –æ–± –æ–¥–Ω–æ–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ —è, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è —É–∑–Ω–∞–ª –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º –æ–ø—ã—Ç–µ. –Ø –≤ –∞–≤–∞—Ä–∏–∏ –ø–æ–ø–∞–¥–∞–ª –æ—á–µ–Ω—å –º–∞–ª–æ –≤ —Å–≤–æ–µ–π –≤–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ. –ù–æ –∑–Ω–∞—é, —á—Ç–æ –∫–∞–∫–æ–π –±—ã —Ö–æ—Ä–æ—à–µ–π –Ω–µ –±—ã–ª–∞ —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –Ω–∞ –º–∞—à–∏–Ω—É, –∞–≤–∞—Ä–∏—è ‚Äî –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ –±–æ–ª—å—à–∞—è –ø—Ä–æ–±–ª–µ–º–∞. –ù—É–∂–Ω–æ –¥—É–º–∞—Ç—å –æ —Å–µ—Ä–≤–∏—Å–µ, –æ —Ç–æ–º, –∫–∞–∫ —ç–≤–∞–∫—É–∏—Ä–æ–≤–∞—Ç—å –º–∞—à–∏–Ω—É, –æ —Ç–æ–º, –∫–∞–∫ –ø–æ—Ç–æ–º –ø—Ä–æ–¥–∞–≤–∞—Ç—å –º–∞—à–∏–Ω—É –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ. –í –æ–±—â–µ–º, —Å –∞–≤–∞—Ä–∏–µ–π –ø—Ä–æ–±–ª–µ–º—ã —Ç–æ–ª—å–∫–æ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è. –ê —Å –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–º –æ–∫–∞–∑–∞–ª–æ—Å—å –≤—Å—ë –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ ‚Äî –≤—ã–∑–≤–∞–ª –ì–ê–ò, –ø–æ–ª—É—á–∏–ª —Å–ø—Ä–∞–≤–∫—É, –æ—Å—Ç–∞–≤–∏–ª —Ä–∞–∑–±–∏—Ç—É—é –º–∞—à–∏–Ω—É –Ω–∞ –æ–±–æ—á–∏–Ω–µ, –ø—Ä–æ—à—ë–ª 200 –º–µ—Ç—Ä–æ–≤ –¥–æ –¥—Ä—É–≥–æ–≥–æ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ –∏ –ø–æ–µ—Ö–∞–ª –¥–∞–ª—å—à–µ, –∑–∞–±—ã–≤ –ø—Ä–æ –∞–≤–∞—Ä–∏—é, –∫–∞–∫ —Å—Ç—Ä–∞—à–Ω—ã–π —Å–æ–Ω. –í –æ–±—â–µ–º, Car as a Service (CaaS), —Å–º. —ç–ø–∏–≥—Ä–∞—Ñ.
–Ø –¥–∞–ª—ë–∫ –æ—Ç –∏–¥–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞. –ò —É –Ω–µ–≥–æ –µ—Å—Ç—å, –∫–æ–Ω–µ—á–Ω–æ, –∫—É—á–∞ –º–∏–Ω—É—Å–æ–≤ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å–æ —Å–≤–æ–µ–π –º–∞—à–∏–Ω–æ–π: –º–∞–ª–µ–Ω—å–∫–∏–π –≤—ã–±–æ—Ä –º–∞—Ä–æ–∫ –∏ –º–æ–¥–µ–ª–µ–π, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤—Å—è–∫–∏–π —Ä–∞–∑ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –º–∞—à–∏–Ω—É –¥–ª—è —Å–µ–±—è, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–µ—Ç—Å–∫–∏—Ö –∫—Ä–µ—Å–µ–ª (—á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ—à–∞–µ—Ç—Å—è mifold ‚Äî http://www.mifold.com/) –∏ —Ç.–¥. –ù–æ, –Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥, –≤—Å–µ —ç—Ç–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –Ω–∏–≤–µ–ª–∏—Ä—É—é—Ç—Å—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞–º–∏.
–Ø –æ—á–µ–Ω—å —Ä–∞–¥, —á—Ç–æ –≤ –ú–æ—Å–∫–≤–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞—Ä—à–µ—Ä–∏–Ω–≥ (–≥–¥–µ —Ç—É—Ç —Ä–∞–∑–¥–∞—é—Ç –ø–µ—á–µ–Ω—å–∫–∏ –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É –°–æ–±—è–Ω–∏–Ω–∞?) –∏ –Ω–∞–¥–µ—é—Å—å, —á—Ç–æ –Ω–∞ —ç—Ç–æ–º –æ–Ω–∏ –Ω–µ –æ—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è. –ö–æ–Ω–µ—á–Ω–æ, –≤–º–µ—Å—Ç–µ —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–æ–º, –∫–∞—Ä—à–µ—Ä–∏–Ω–≥ –≤—Ä—è–¥ –ª–∏ –ø—É—Å—Ç—è—Ç –Ω–∞ –≤—ã–¥–µ–ª–µ–Ω–∫–∏ (–∏, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –ø—Ä–∞–≤–∏–ª—å–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Å–∫–æ—Ä–æ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ –±—É–¥–µ—Ç —É–∂–µ —Å—Ç–æ–ª—å–∫–æ, —á—Ç–æ —ç—Ç–æ –±—ã –æ–±–Ω—É–ª–∏–ª–æ –≤—Å–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ—Å). –ù–æ –≤–æ—Ç —Å–¥–µ–ª–∞—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∫–æ–≤–∫–∏ –≤ —Ü–µ–Ω—Ç—Ä–µ –¥–ª—è –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ –±—ã–ª–æ –±—ã –æ—á–µ–Ω—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –ù—É –∏–ª–∏ —Ö–æ—Ç—è –±—ã –ø–æ–≤—ã—Å–∏—Ç—å —Ü–µ–Ω—ã –Ω–∞ –ø–∞—Ä–∫–∏–Ω–≥ –¥–æ 300‚Äì500 —Ä—É–±–ª–µ–π –≤ —á–∞—Å –∏ –æ—Ç–º–µ–Ω–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –ø–∞—Ä–∫–æ–≤–∫—É –ø–æ –≤—ã—Ö–æ–¥–Ω—ã–º –±—ã–ª–æ –±—ã –µ—â—ë –ª—É—á—à–µ. –ò —Å–¥–µ–ª–∞—Ç—å –ø–∞—Ä–∫–æ–≤–∫—É –ø–ª–∞—Ç–Ω–æ–π –≤–æ –≤—Å—ë–º –≥–æ—Ä–æ–¥–µ, –≤–∫–ª—é—á–∞—è –¥–≤–æ—Ä—ã ‚Äî —Ç–æ–ª—å–∫–æ —Ç–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–±–µ–¥–∏—Ç—å –ø—Ä–æ–±–∫–∏. –ê –µ—â—ë –ª—É—á—à–µ —Å–¥–µ–ª–∞—Ç—å, –∫–∞–∫ –≤ –Ø–ø–æ–Ω–∏–∏ ‚Äî –≥–¥–µ –∫—É–ø–∏—Ç—å –º–∞—à–∏–Ω—É –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–µ–µ –≤–∞–º –ø–∞—Ä–∫–æ–≤–æ—á–Ω–æ–µ –º–µ—Å—Ç–æ. –Ø –æ—á–µ–Ω—å –Ω–∞–¥–µ—é—Å—å, —á—Ç–æ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º —Ç–∞–∫ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç –∏ –≤ –ú–æ—Å–∫–≤–µ (—Ö–æ—Ç—å –∏ –≤—Ä—è–¥ –ª–∏ –¥–æ –≤—ã–±–æ—Ä–æ–≤).
–°–∞–º–∏–º –∫–æ–º–ø–∞–Ω–∏—è–º-–æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ —Ç–æ–∂–µ –µ—Å—Ç—å, –∫—É–¥–∞ —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è. –ú–∞—à–∏–Ω –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–∏–ª—å–Ω–æ –±–æ–ª—å—à–µ (—á—Ç–æ –∏ —Ç–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç), –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–∏–ª—å–Ω–æ –ø—Ä–æ—â–µ –∏ —É–¥–æ–±–Ω–µ–µ. –ù—É–∂–Ω–æ –Ω–µ –≤–æ–µ–≤–∞—Ç—å –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º, –∞ –Ω–∞–æ–±–æ—Ä–æ—Ç, –æ–±—ä–µ–¥–∏–Ω—è—Ç—å—Å—è —Å –ø–æ–º–æ—â—å—é –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–≤. –ß—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å —Å —Å—É—Ç–æ—á–Ω—ã–º–∏ —Ç–∞—Ä–∏—Ñ–∞–º–∏ (–∫–æ—Ç–æ—Ä—ã–µ —Å–µ–π—á–∞—Å –ø—Ä–æ—Å—Ç–æ –∑–∞–æ–±–ª–∞—á–Ω—ã–µ), –¥–∞ –∏ —Å —Ç–∞—Ä–∏—Ñ–∞–º–∏ –≤–æ–æ–±—â–µ ‚Äî —Ö–æ—Ç—è —ç—Ç–æ –∏ —Ç–∞–∫ —Å–µ–π—á–∞—Å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–º–µ—Å—Ç–µ —Å —Ä–∞—Å—Ç—É—â–µ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–µ–π.
–ù–∞–ø–æ—Å–ª–µ–¥–æ–∫, —Ä–∞—Å—Å–∫–∞–∂—É —Ç–µ–ø–µ—Ä—å –æ —Å–≤–æ—ë–º –æ–ø—ã—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞. –ù–∞—á–Ω—É —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö:
–ö YouDrive —É –º–µ–Ω—è –æ—Å–æ–±–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ, –≤–µ–¥—å –∏–º–µ–Ω–Ω–æ —Å –Ω–∏—Ö –Ω–∞—á–∞–ª—Å—è –º–æ–π –æ–ø—ã—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–º. –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –æ—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω—ã–µ –º–∞—à–∏–Ω–∫–∏ (—Ç–æ–≥–¥–∞ –±—ã–ª–∏ —Ç–æ–ª—å–∫–æ –°–º–∞—Ä—Ç—ã, —Å–µ–π—á–∞—Å –µ—â—ë –∏ BMW, Mercedes, Mini, –∏ —Ç.–¥.), –æ—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω–∞—è (–Ω–∞ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç) –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ –¢–µ–ª–µ–≥—Ä–∞–º–µ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏, –º–∞–ª–µ–Ω—å–∫–∞—è –∑–æ–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞—Ä–µ–Ω–¥—ã, —Å–æ–∑–¥–∞–≤–∞–≤—à–∞—è —Ö–æ—Ä–æ—à—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –º–∞—à–∏–Ω –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞ –∏ –≤ –º–µ—Å—Ç–∞—Ö —Å–∫–æ–ø–ª–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å ‚Äú–ø–µ—Ä–µ–¥–∞—Ç—å‚Äù –º–∞—à–∏–Ω—É –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –∑–æ–Ω—ã –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (—É—Å–ª—É–≥–∞ –≤–æ–æ–±—â–µ —É–Ω–∏–∫–∞–ª—å–Ω–∞—è, –∏ —É –Ω–∞—Å –∏ –≤ –º–∏—Ä–µ), —Å –≤—Å–µ–≥–¥–∞ –∑–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∏ —Å –æ–º—ã–≤–∞–π–∫–æ–π –º–∞—à–∏–Ω–∞–º–∏. –í –æ–±—â–µ–º –≤—Å—ë –∑–¥–æ—Ä–æ–≤–æ! –ù–æ, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∑–∞ –≥–æ–¥ YouDrive —Å–∏–ª—å–Ω–æ –∏—Å–ø–æ—Ä—Ç–∏–ª—Å—è. –°–Ω–∞—á–∞–ª–∞ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –ª–∏—à–∏–ª–∏ –ø–æ—á—Ç–∏ –≤—Å–µ—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤ –æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π –≤—ã—Å–æ–∫–∏—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ (–∞ —è –≤–µ–¥—å –∫–æ–≥–¥–∞-—Ç–æ –±—ã–ª –≥–æ—Ç–æ–≤ –Ω–∞ —Ç–∞–∫—Å–∏ –∏–ª–∏ –¥—Ä—É–≥–æ–º –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–µ –¥–æ–µ—Ö–∞—Ç—å –¥–æ –º–∞—à–∏–Ω—ã YouDrive, —á—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å —Å–≤–æ–π —Å—Ç–∞—Ç—É—Å), –æ—Ç–º–µ–Ω–∏–ª–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –Ω–æ—á–Ω—É—é –ø–∞—Ä–∫–æ–≤–∫—É, –ø–æ—Ç–æ–º —Ä–∞—Å—à–∏—Ä–∏–ª–∏ –∑–æ–Ω—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞—Ä–µ–Ω–¥—ã, –∏–∑-–∑–∞ —á–µ–≥–æ –º–∞—à–∏–Ω —Å—Ç–∞–ª–æ —Ä–µ–∑–∫–æ –º–µ–Ω—å—à–µ. –ê, –Ω–∞–ø—Ä–∏–º–µ—Ä –ø–∞—Ä–∫–æ–≤–∫—É –≤ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞—Ö –∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å—É—Ç–æ—á–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã —Ç–∞–∫ –∏ –Ω–µ —Å–¥–µ–ª–∞–ª–∏‚Ä¶ –í –æ–±—â–µ–º –∏–∑ –æ—á–µ–Ω—å –ª–æ—è–ª—å–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è YouDrive —è –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ —Ç–æ–≥–æ, –∫—Ç–æ –ø—Ä–∏ –ø—Ä–æ—á–∏—Ö —Ä–∞–≤–Ω—ã—Ö –≤—ã–±–µ—Ä–µ—Ç –Ω–µ –µ–≥–æ, –∞ —Ç–æ–≥–æ, –∫—Ç–æ –±—É–¥–µ—Ç –±–ª–∏–∂–µ. –ù–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –æ—Ç–¥–∞–º –∏–º –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ –≤ —Å–≤–æ—ë–º —Ä–µ–π—Ç–∏–Ω–≥–µ, –∑–∞ –ø—Ä–æ—à–ª—ã–µ –∑–∞—Å–ª—É–≥–∏ –∏ –≤ –Ω–∞–¥–µ–∂–¥–µ, —á—Ç–æ –æ–Ω–∏ –∏—Å–ø—Ä–∞–≤—è—Ç—Å—è –∏ –ø–æ–≤–µ—Ä–Ω—É—Ç—Å—è –∫ –ª–æ—è–ª—å–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –ª–∏—Ü–æ–º. –ê –∏–Ω–∞—á–µ –æ—á–µ–Ω—å —Å–∫–æ—Ä–æ —Ä–∏—Å–∫—É—é—Ç –æ–ø—É—Å—Ç–∏—Ç—å—Å—è –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ –Ω–∏–∂–µ –¥–∞–∂–µ –î–µ–ª–∏–º–æ–±–∏–ª—è.
–ü–æ—è–≤–ª–µ–Ω–∏—è –Ø–Ω–¥–µ–∫—Å.–î—Ä–∞–π–≤–∞ –±–æ—è–ª–∏—Å—å –≤—Å–µ –∏–≥—Ä–æ–∫–∏ —Ä—ã–Ω–∫–∞ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞. –ò –±–æ—è–ª–∏—Å—å –Ω–µ –∑—Ä—è! –û–Ω–∏ —Å—Ä–∞–∑—É –≤—ã—à–ª–∏ —Å –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–º –ø–∞—Ä–∫–æ–º –º–∞—à–∏–Ω –∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç –µ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å, —Å —É–¥–æ–±–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏ (–∏–Ω–æ–≥–¥–∞ ‚Äî —Ç–∞–∫ –∫–∞–∫ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∞–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ), —Ö–æ—Ä–æ—à–µ–π (—Ö–æ—Ç—å –∏ –Ω–µ —Å—Ä–∞–∑—É) –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π, –ø–∞—Ä–∫–æ–≤–∫–æ–π –≤ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞—Ö (–º–æ–∂–µ—Ç –∏ –Ω–µ –≤—Å–µ—Ö, –Ω–æ –¥–ª—è –º–µ–Ω—è –≤—Å—ë —Ä–∞–≤–Ω–æ –≤ –ú–æ—Å–∫–≤–µ –∫—Ä–æ–º–µ –®–µ—Ä–µ–º–µ—Ç—å–µ–≤–æ –Ω–µ—Ç –∞—ç—Ä–æ–ø–æ—Ä—Ç–æ–≤). –û—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è —Ñ–∏—á–∞ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤ –º–∞—à–∏–Ω—ã –ø–ª–∞–Ω—à–µ—Ç—ã —Å —Å–µ—Ä–≤–∏—Å–∞–º–∏ —è–Ω–¥–µ–∫—Å–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π —Å –ø—Ä–æ–±–∫–∞–º–∏. –ù–æ –µ—Å—Ç—å –∏ –æ–≥—Ä–æ–º–Ω—ã–π (–¥–ª—è –º–µ–Ω—è) –º–∏–Ω—É—Å ‚Äî –≤ –Ø–Ω–¥–µ–∫—Å–µ –Ω–µ —Ç–æ, —á—Ç–æ –Ω–µ—Ç —Å—É—Ç–æ—á–Ω—ã—Ö —Ç–∞—Ä–∏—Ñ–æ–≤ (–≤–æ–Ω, —É YouDrive –∏—Ö —Ç–æ–∂–µ –Ω–µ—Ç), –Ω–æ –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ –Ω–µ–ª—å–∑—è –±—Ä–∞—Ç—å –º–∞—à–∏–Ω—É –±–æ–ª—å—à–µ, —á–µ–º –Ω–∞ —Å—É—Ç–∫–∏. –ü–æ—á–µ–º—É? –≠—Ç–æ –∂–µ –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –≥–ª—É–ø–æ—Å—Ç—å ‚Äî –ª—é–±–æ–º—É –∫–∞—Ä—à–µ—Ä–∏–Ω–≥—É –≤—ã–≥–æ–¥–Ω–æ, —á—Ç–æ–±—ã –º–∞—à–∏–Ω–∞ –±—ã–ª–∞ –≤ –∞—Ä–µ–Ω–¥–µ, –∞ –Ω–µ —Å—Ç–æ—è–ª–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ –Ω–∞ —É–ª–∏—Ü–µ. –ó–∞–≥–∞–¥–∫–∞. –ù–æ –≤ –Ø–Ω–¥–µ–∫—Å —è –≤–µ—Ä—é, –æ–Ω–∏ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ —Ä–∞–∑–≤–∏–≤–∞—é—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É —è –Ω–∞–¥–µ—é—Å—å, —á—Ç–æ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º –ø–∞—Ä–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ–º —Å–µ—Ä–≤–∏—Å–∞ –æ–Ω–∏ –≤—ã–π–¥—É—Ç –Ω–∞ –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ.
–ë–µ–ª–∫—É —è —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞ –Ω–µ–≤–∑–ª—é–±–∏–ª. –ò—Ö –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ —Ä—ã–Ω–∫–µ –æ—á–µ–Ω—å —á–∞—Å—Ç–æ –≤—ã–∑—ã–≤–∞–ª–∏ –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ —Å –∏–¥–∏–æ–º–æ–π ‚Äú–±–µ–ª–∫–∞-–∏—Å—Ç–µ—Ä–∏—á–∫–∞‚Äù (—è —Å–µ–π—á–∞—Å –ø—Ä–æ –∏—Ö –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π –≤—ã—Ö–æ–¥ –∏–∑ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–≤ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–≤ ‚Äî —Ö–æ—Ç—è –ø—Ä–∏ —ç—Ç–æ–º –æ–Ω–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–æ –æ—Å—Ç–∞–ª–∏—Å—å –≤ –Ø–Ω–¥–µ–∫—Å.–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–µ). –ù–æ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º, –ø–æ—Å–º–æ—Ç—Ä–µ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é –æ–¥–Ω–æ–π –∏–∑ —Å–æ–∑–¥–∞—Ç–µ–ª—å–Ω–∏—Ü —Å–µ—Ä–≤–∏—Å–∞ (—Ä–∞—Å—Å–∫–∞–∑–∞–≤—à–µ–π, —á—Ç–æ —Å–µ—Ä–≤–∏—Å –æ–Ω–∏ —Å–æ–∑–¥–∞–ª–∏ ‚Äú–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏ –∏ –¥–µ–Ω—å–≥–∏ –±—ã–≤—à–∏—Ö –º—É–∂–µ–π‚Äù) —è –∫–∞–∫-—Ç–æ –ø—Ä–æ–Ω–∏–∫—Å—è. –ù–∞—á–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –≤—Ç—è–Ω—É–ª—Å—è. –Ø –∑–Ω–∞—é, —á—Ç–æ —É –ë–µ–ª–∫–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –ø—Ä–µ–¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –∏ —è —Å–∞–º —Å—Ç–∞–Ω—É —Ç–∞–∫–∏–º. –ü–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ Belka Black —Å –º–µ—Ä—Å–µ–¥–µ—Å–∞–º–∏ ‚Äî —Ö–æ—Ä–æ—à–∏–π –∑–∞—Ö–æ–¥ –Ω–∞ —ç—Ç–æ. –ê –µ—â—ë –Ω–µ–ø–ª–æ—Ö–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –º–Ω–æ–∂–µ—Å—Ç–≤–æ –º–∞—à–∏–Ω, –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ —Ä–∞–∑—É–º–Ω—ã–µ —Å—É—Ç–æ—á–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã, –ø–∞—Ä–∫–æ–≤–∫–∞ –≤ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞—Ö ‚Äî –≤—Å—ë —ç—Ç–æ —Å–∏–ª—å–Ω—ã–µ –∫–æ–∑—ã—Ä–∏. –¢—Ä–µ—Ç—å–µ –º–µ—Å—Ç–æ.
Anytimecar ‚Äî —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π –∫–∞—Ä—à–µ—Ä–∏–Ω–≥ –≤ –†–æ—Å—Å–∏–∏ –∏ –≤ –ú–æ—Å–∫–≤–µ. –û–Ω –±—ã–ª –¥–ª—è –º–µ–Ω—è –≤—Ç–æ—Ä—ã–º, –∫–æ—Ç–æ—Ä—ã–π —è –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª –ø–æ—Å–ª–µ YouDrive –∏ –±—ã–ª, –∫–æ–Ω–µ—á–Ω–æ, –æ—á–µ–Ω—å –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ –ø–æ—Ä–∞–∂—ë–Ω. –ü–æ—Å–ª–µ ‚Äú—Ö–∏–ø—Å—Ç–µ—Ä—Å–∫–æ–≥–æ‚Äù YouDrive, –≥–¥–µ –≤—Å—ë –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ –¥–ª—è –ª—é–¥–µ–π –∏ –∫–∞–∫ —É–¥–æ–±–Ω–µ–µ, Anytimecar —Å–æ —Å–≤–æ–∏–º –∫—Ä–∞–π–Ω–µ —É–±–æ–≥–∏–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º, —Ç–æ–ø–ª–∏–≤–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –∑–≤–æ–Ω–∏—Ç—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É, —á—Ç–æ–±—ã –∑–∞–ø—Ä–∞–≤–∏—Ç—å –º–∞—à–∏–Ω—É (–∏ –º–∞—à–∏–Ω–∞–º–∏ —Å –≤–µ—á–Ω–æ –ø—É—Å—Ç—ã–º–∏ –±–∞–∫–∞–º–∏ –∏ –±–µ–∑ –æ–º—ã–≤–∞–π–∫–∏, –∫–∞–∫ —Å–ª–µ–¥—Å—Ç–≤–∏–µ) ‚Äî –≤—Å—ë —ç—Ç–æ —Å–æ–∑–¥–∞–≤–∞–ª–æ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ –ø–æ—Å–ª–µ –º–∞–≥–∞–∑–∏–Ω–∞ Apple Store –ø–æ–ø–∞–ª –≤ —Å–µ–ª—å–ø–æ, –≥–¥–µ –ø—Ä–æ–¥–∞–≤–µ—Ü –≤ –∫–∞–∂–¥–æ–º –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ –≤–∏–¥–∏—Ç –≤–æ—Ä–∞. –ê –µ—â—ë —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å –º–∞—à–∏–Ω—ã –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –∞—Ä–µ–Ω–¥—ã ‚Äî –¥–æ —Ç–∞–∫–æ–≥–æ –Ω–µ –¥–æ–≥–∞–¥–∞–ª—Å—è –Ω–∏ –æ–¥–∏–Ω –∫–∞—Ä—à–µ—Ä–∏–Ω–≥! –ù–æ –≤ –ø–ª—é—Å–∞—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–µ—â–∏: –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∞—Ç—å –º–∞—à–∏–Ω—É –ø–æ –Ω—É–∂–Ω–æ–º—É –∞–¥—Ä–µ—Å—É, –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å—É—Ç–æ—á–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤—ã–±–æ—Ä —Å–∞–º–∏—Ö –º–∞—à–∏–Ω (–æ–Ω–∏ –±—ã–ª–∏ –ø–µ—Ä–≤—ã–º–∏, –∫—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –º–∞—à–∏–Ω—ã –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è). –í –æ–±—â–µ–º, Anytimecar —è –≤—Å—ë —Ä–∞–≤–Ω–æ –ª—é–±–∏–ª, –∫–∞–∫ –ø–∏–æ–Ω–µ—Ä–æ–≤, –Ω–æ —Å–æ–≤—Å–µ–º –Ω–µ —É–¥–∏–≤–ª—ë–Ω, —á—Ç–æ –∏—Ö –≤ –∏—Ç–æ–≥–µ –∫—É–ø–∏–ª –î–µ–ª–∏–º–æ–±–∏–ª—å. –ñ–∞–ª—å, —á—Ç–æ —ç—Ç–æ –±—ã–ª –î–µ–ª–∏–º–æ–±–∏–ª—å‚Ä¶
–°–∞–º—ã–π –±–æ–ª—å—à–æ–π –≤ –†–æ—Å—Å–∏–∏ –∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –≤ –ú–æ—Å–∫–≤–µ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥. –ò —Å–∞–º—ã–π —É–±–æ–≥–∏–π. Hyundai Solaris, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è ‚Äî —ç—Ç–æ –Ω–µ –º–∞—à–∏–Ω–∞, –∞ –Ω–µ–¥–æ—Ä–∞–∑—É–º–µ–Ω–∏–µ. Renault Kaptur ‚Äî –µ—â—ë —Ö—É–∂–µ. –¢–∞–∫–æ–µ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ –≤—Å–µ –∏–Ω–∂–µ–Ω–µ—Ä—ã –†–µ–Ω–æ —Å–æ–±—Ä–∞–ª–∏—Å—å –≤–º–µ—Å—Ç–µ –Ω–∞ –º–æ–∑–≥–æ–≤–æ–π —à—Ç—É—Ä–º —Å —Ü–µ–ª—å—é —Å–¥–µ–ª–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–±–æ–≥—É—é –º–∞—à–∏–Ω—É. –û—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–æ —Å –í–ê–ó–æ–º –Ω–µ –ø—Ä–æ—à–ª–æ –¥–∞—Ä–æ–º, –ø–æ—ç—Ç–æ–º—É –∏–º —ç—Ç–æ —É–¥–∞–ª–æ—Å—å! –ê –∫–æ–≥–¥–∞ –î–µ–ª–∏–º–æ–±–∏–ª—å –µ—â—ë –∏ –∑–∞–∫–ª–µ–∏–ª –≤—Å–µ –º–∞—à–∏–Ω—ã —Ä–µ–∫–ª–∞–º–æ–π –õ–î–ü–†, –æ–Ω–∏ –Ω–∞–≤—Å–µ–≥–¥–∞ –≤ –º–æ—ë–º —Ä–µ–π—Ç–∏–Ω–≥–µ –æ–ø—É—Å—Ç–∏–ª–∏—Å—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –º–µ—Å—Ç–æ. –ü–æ—ç—Ç–æ–º—É —É–±–æ–≥–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ –Ω–µ—É—Ö–æ–∂–µ–Ω–Ω—ã–µ –º–∞—à–∏–Ω—ã —è –¥–∞–∂–µ –Ω–µ –±—É–¥—É —É–ø–æ–º–∏–Ω–∞—Ç—å. –ù–æ, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, —á–∞—â–µ –≤—Å–µ–≥–æ –±–ª–∏–∂–∞–π—à–µ–π –º–∞—à–∏–Ω–æ–π –±—É–¥–µ—Ç –∏–º–µ–Ω–Ω–æ –î–µ–ª–∏–º–æ–±–∏–ª—å, –ø–æ—ç—Ç–æ–º—É –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–∏–º —Å–µ—Ä–≤–∏—Å–æ–º –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ. –ü—Ä–∏—Ö–æ–¥–∏—Ç—Å—è —Ç–µ—Ä–ø–µ—Ç—å.
–í –ú–æ—Å–∫–≤–µ –µ—Å—Ç—å –µ—â—ë –∫—É—á–∞ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–≤: –≤—Å—è–∫–∏–µ Rentmee, Car4You, TimCar, EasyRide, Car5, MatreshCar –∏ —Ç.–¥. –Ω–æ, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –Ω–∏—Ö –Ω–∞—Å—Ç–æ–ª—å–∫–æ –º–∞–ª–æ –º–∞—à–∏–Ω, —á—Ç–æ —à–∞–Ω—Å—ã –æ–∫–∞–∑–∞—Ç—å—Å—è –∏–º —Ä—è–¥–æ–º —Å –≤–∞–º–∏ ‚Äî –∫—Ä–∞–π–Ω–µ –º–∞–ª—ã. –ü–æ—ç—Ç–æ–º—É –≤ –Ω–∏—Ö –º–æ–∂–Ω–æ –¥–∞–∂–µ –Ω–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è, –∞ –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–º ‚Äî YouDrive, –≤ –∫–æ—Ç–æ—Ä–æ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–∑ –Ω–∏—Ö —É–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ (–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —É–±–æ–≥–∏–µ —Å–µ—Ä–≤–∏—Å—ã ‚Äî —ç—Ç–æ –±—ã–ª –æ—Ç–ª–∏—á–Ω—ã–π —Ö–æ–¥ YouDrive!)
–í –º–∏—Ä–µ —è –µ—â—ë –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª Car2Go, ZipCar, DriveNow –∏ –µ—â—ë –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–≤—Å–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, –≤—Ä–æ–¥–µ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π –≤ –ö–æ–ø–µ–Ω–≥–∞–≥–µ–Ω–µ. –¢—É—Ç –ø–æ–º–æ–≥–ª–æ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–º–µ—Ü–∫–∏—Ö –ø—Ä–∞–≤ ‚Äî –Ω–µ —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏–º–∏ –ø—Ä–∞–≤–∞–º–∏ –±—É–¥–µ—Ç –ø—Ä–æ—Å—Ç–æ —Ç–∞–º –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è. –ò —Å—Ä–∞–≤–Ω–∏–≤–∞—è –Ω–∞—à–∏ —Å–µ—Ä–≤–∏—Å—ã —Å –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º–∏ –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –Ω–∞—à–∏ —Å–∏–ª—å–Ω–æ –ª—É—á—à–µ! –í—Å—ë-—Ç–∞–∫–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è ‚Äî –≤–µ–ª–∏–∫–∞—è –≤–µ—â—å. –£ –Ω–∞—à–∏—Ö –∏ —Ç–∞—Ä–∏—Ñ—ã —Å–∏–ª—å–Ω–æ –Ω–∏–∂–µ, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–¥–æ–±–Ω–µ–µ. –ù–æ –≤–æ—Ç —á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –Ω–∞—à–∏–º –∑–∞–ø–∞–¥–Ω—ã–º –∫–æ–ª–ª–µ–≥–∞–º ‚Äî —Ç–∞–∫ —ç—Ç–æ —Ç–æ, —á—Ç–æ –æ–Ω–∏ –æ—Å–Ω–æ–≤–∞–Ω—ã —Å –±–æ–ª—å—à–∏–º —É—á–∞—Å—Ç–∏–µ–º –∏–ª–∏ —Å–∞–º–∏–º–∏ –∞–≤—Ç–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è–º–∏ ‚Äî –ø–æ—ç—Ç–æ–º—É –ø—Ä—è–º–æ –≤ –±–æ—Ä—Ç–æ–≤–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –≤–∏–¥–Ω–æ, –Ω–∞—Ö–æ–¥–∏—Ç–µ—Å—å –ª–∏ –≤—ã –≤ –∑–æ–Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞—Ä–µ–Ω–¥—ã –∏–ª–∏ –Ω–µ—Ç, –º–∞—à–∏–Ω–∞ —Å–∞–º–∞ –ø—Ä–æ–∫–ª–∞–¥—ã–≤–∞–µ—Ç –ø—É—Ç—å –∫ –∑–∞–ø—Ä–∞–≤–∫–µ, –µ—Å–ª–∏ —Ç–æ–ø–ª–∏–≤–∞ –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–µ–º–Ω–æ–≥–æ. –ê –µ—â—ë –º–Ω–µ –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –≤ —Å–º–∞—Ä—Ç–∞—Ö Car2Go, —á—Ç–æ —Ç–∞–º –Ω–µ–ª—å–∑—è —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–∫–ª–æ–Ω —Å–ø–∏–Ω–∫–∏ –∏ –≤—ã—Å–æ—Ç—É —Å–∏–¥–µ–Ω—å—è ‚Äî —Ç–æ–ª—å–∫–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ä—É–ª—è. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –Ω–µ –Ω—É–∂–Ω–æ –¥–æ–ª–≥–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å–∏–¥–µ–Ω—å–µ –ø–æ–¥ —Å–µ–±—è –ø–æ—Å–ª–µ –ª—é–±–∏—Ç–µ–ª–µ–π –ø–æ–µ–∑–¥–∏—Ç—å –ª—ë–∂–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä.
–ù–æ –≤ —Ü–µ–ª–æ–º, –∫–æ–Ω–µ—á–Ω–æ, –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ –ø—É—Ç–∏. –Ø –ø—Ä–∏–∑–Ω–∞—é—Å—å —á–µ—Å—Ç–Ω–æ, —á—Ç–æ —è–≤–ª—è—é—Å—å —Ä–µ—Ç—Ä–æ–≥—Ä–∞–¥–æ–º –∏ –Ω–µ –≤–µ—Ä—é, —á—Ç–æ —É–∂–µ —á–µ—Ä–µ–∑ –ø—è—Ç—å –ª–µ—Ç, –∫–∞–∫ —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ, —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ –≤—ã—Ç–µ—Å–Ω—è—Ç self-driving cars. –Ø –¥—É–º–∞—é, —á—Ç–æ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏—è –ø–æ–µ–∑–¥–∏—Ç—å –∑–∞ —Ä—É–ª—ë–º —Å–∞–º–æ–º—É –µ—â—ë —Ö–≤–∞—Ç–∏—Ç –Ω–∞ –Ω–∞—à –≤–µ–∫. –ê –≤–æ—Ç –≤–ª–∞–¥–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–º –≤ –≥–æ—Ä–æ–¥–µ, –¥—É–º–∞—é, —Å–∫–æ—Ä–æ —Å—Ç–∞–Ω–µ—Ç —Ç–∞–∫–∏–º –∂–µ –Ω–æ–Ω—Å–µ–Ω—Å–æ–º, –∫–∞–∫ –≤–ª–∞–¥–µ–Ω–∏–µ –ª–æ—à–∞–¥—å—é. –ú–∞—à–∏–Ω–∞ –¥–æ–ª–∂–Ω–∞ –µ–∑–¥–∏—Ç—å, –∞ –Ω–µ —Å—Ç–æ—è—Ç—å 22 —á–∞—Å–∞ –∏–∑ 24-—Ö –Ω–∞ –ø–∞—Ä–∫–æ–≤–∫–µ.
–í –æ–±—â–µ–º, –≤—Å–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É—é —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–µ –∏ –Ω–∞—á–∞—Ç—å –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å. –£ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫–∞—Ä—à–µ—Ä–∏–Ω–≥–æ–≤ –µ—Å—Ç—å —Å–≤–æ—è –º–∞—à–∏–Ω–∞, —Ç–∞–∫ —á—Ç–æ –Ω–µ –±–æ–π—Ç–µ—Å—å –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å. –ê —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ–Ω—Ä–∞–≤–∏—Ç—Å—è –∏ –≤–∞–º, –Ω–∞–¥–µ—é—Å—å, –∑–∞—Ö–æ—á–µ—Ç—Å—è –æ—Ç —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–∞—à–∏–Ω—ã –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è, —Ç–µ–º —Å–∞–º—ã–º –≤–Ω–µ—Å—è —Å–≤–æ—é –ª–µ–ø—Ç—É –≤ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø—Ä–æ–±–æ–∫ –≤ –≥–æ—Ä–æ–¥–µ.
–ê –ø–æ—Å–ª–µ –≤–∞–º (–∫–∞–∫ –∏ –º–Ω–µ) –∑–∞—Ö–æ—á–µ—Ç—Å—è –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏ –≤–µ–ª–æ—à–µ—Ä–∏–Ω–≥ –∏ —Å–∞–º–æ–∫–∞—Ç—à–µ—Ä–∏–Ω–≥. –ò –¥–∞–∂–µ –ø—Ä–æ–∫–∞—Ç–∏—Ç—å—Å—è –Ω–∞ –∞–≤—Ç–æ–±—É—Å–µ. –ò –æ–∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –Ω–µ —Ç–∞–∫ —É–∂ –∏ –ø–ª–æ—Ö. –ò —á—Ç–æ –∂–∏—Ç—å –≤ –≥–æ—Ä–æ–¥–µ –º–æ–∂–Ω–æ –∏ —É–¥–æ–±–Ω–æ –∏ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ, –Ω–µ —Å–æ–∑–¥–∞–≤–∞—è –ø—Ä–æ–±–ª–µ–º –¥—Ä—É–≥–∏–º.
–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –õ–æ–∂–µ—á–∫–∏–Ω (https://medium.com/@allo/%D0%BE-%D0%B7%D0%B0%D0%BC%D0%B5%D1%82%D0%BA%D0%B0%D1%85-ce3a8bdd56af)
116 
4
116¬†
116 
4
–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –õ–æ–∂–µ—á–∫–∏–Ω (https://medium.com/@allo/%D0%BE-%D0%B7%D0%B0%D0%BC%D0%B5%D1%82%D0%BA%D0%B0%D1%85-ce3a8bdd56af)
"
https://medium.com/code-prestige/como-manter-sua-aplica%C3%A7%C3%A3o-no-heroku-acordada-6fda00ee397a?source=search_post---------114,"There are currently no responses for this story.
Be the first to respond.
O Heroku √© uma plataforma como servi√ßo (PaaS) simplesmente fant√°stica. Antes de pensar em utilizar infraestruturas mais robustas e completas como a Amazon AWS, Google Cloud ou a Microsoft Azure para as minhas aplica√ß√µes (e as da Code Prestige), na maior parte das vezes consigo test√°-las primeiramente no Heroku. A sua simplicidade e o fato de possuir planos gratuitos de uso a tornam uma op√ß√£o muito boa para aplica√ß√µes n√£o cr√≠ticas.
Mas como alegria de desenvolvedor(a) dura pouco, h√° uma s√©rie de restri√ß√µes que envolvem o plano gratuito da ferramenta. Um dos problemas que costumam acontecer √© o da nossa aplica√ß√£o morrer ap√≥s um problema cr√≠tico e continuar sepultada sem que recebamos qualquer tipo de notifica√ß√£o. Para um MVP de um produto, uma valida√ß√£o de mercado ou uma demonstra√ß√£o para um potencial cliente, isso pode ser fatal.
Para conseguir reverter esta situa√ß√£o e mantermos um hist√≥rico da sa√∫de das nossas aplica√ß√µes em Node.js enquanto elas est√£o hospedadas de forma gratuita, vou ensinar alguns truques bem simples.
Se voc√™ for utilizar o Heroku como ambiente de produ√ß√£o, ele oferece uma s√©rie de ferramentas bacanas por um pre√ßo acess√≠vel.
Este primeiro truque √© o que acredito ser o mais trivial e provavelmente √© a primeira solu√ß√£o que vem a mente das pessoas. A ideia √© basicamente usar a fun√ß√£o setInterval() do JavaScript para fazer uma requisi√ß√£o para a aplica√ß√£o a cada X minutos. Algo deste g√™nero:
Podemos aproveitar esta artimanha para utilizar algum servi√ßo que nos avise sobre a aplica√ß√£o, como um SMS, e-mail ou algo do g√™nero. Se n√£o recebemos o check esperado, sabemos que algo est√° errado.
O Pingability √© um servi√ßo que basicamente executa o c√≥digo do exemplo anterior pra gente, ou seja, a cada X minutos, ele d√° um ping na aplica√ß√£o para verificar seu funcionamento. No seu plano gratuito, conseguimos realizar at√© 750 verifica√ß√µes mensais. Fazendo uma estimativa simples, podemos ter uma ideia de quantas verifica√ß√µes podemos fazer:
Seu funcionamento √© muito simples. Basicamente o que precisamos √© registrar a URL da aplica√ß√£o no Heroku e o tempo de intervalo desejado. Feito isso, o servi√ßo se encarregar√° de pingar a aplica√ß√£o para verificar sua sa√∫de.
O bacana √© que o servi√ßo guarda todas estas informa√ß√µes e te envia diariamente um e-mail com elas. No plano pago, h√° uma infinidade de outros indicadores, gr√°ficos e afins que a ferramenta disponibiliza.
[UPDATE] Uma outra alternativa dada por um dos nossos leitores, o Adeonir , √© o Uptime Robot. Funciona de forma semelhante ao Pingability e oferece uma s√©rie de indicadores, alertas e integra√ß√µes.
Esta √© uma alternativa bem diferente (baseada neste artigo), mas que tamb√©m funciona. A ideia aqui √© utilizar um script dentro de uma planilha para realizar esta tarefa. Para isso, crie uma nova planilha e ent√£o:
E pronto. O Google executar√° o script com base nas configura√ß√µes e sua atividade ser√° registrada na planilha. Desta maneira, conseguimos salvar os status na planilha para uma f√°cil visualiza√ß√£o.
Estas s√£o algumas das alternativas mais famosas para monitorarmos a sa√∫de de aplica√ß√µes web hospedadas gratuitamente no Heroku. At√© o momento todas elas parecem estar funcionando bem, mas lembre-se de que este artigo n√£o √© atemporal, ou seja, as pol√≠ticas da empresa podem mudar e estes truques podem parar de funcionar.
√â importante lembrar que no plano gratuito do Heroku, as aplica√ß√µes dormem ap√≥s 30 minutos de inatividade. At√© a data em que este artigo foi escrito, todos as aplica√ß√µes gratuitas compartilham uma cota de 550 horas por m√™s. N√£o esque√ßa de levar isso em considera√ß√£o na hora de configurar seus alertas.
Gostou? Recomende üëè este artigo e acompanhe nossa publica√ß√£o para n√£o perder os pr√≥ximos conte√∫dos!
Siga nossa publica√ß√£o e n√£o perca os pr√≥ximos artigos! http://www.codeprestige.com.br ‚Äî Facebook, Twitter, Youtube
Artigos, not√≠cias e dicas sobre o melhor da tecnologia.
89 
1
89¬†claps
89 
1
Artigos, not√≠cias e dicas sobre o melhor da tecnologia.
Written by
Desenvolvedor de Software, Fundador da CodePrestige e autor do livro ECMAScript 6 - Entre de cabe√ßa no futuro do JavaScript
Artigos, not√≠cias e dicas sobre o melhor da tecnologia.
"
https://medium.com/boltops/trying-to-speed-up-aws-elastic-beanstalks-eb-deploy-d9fc781c85e8?source=search_post---------115,"There are currently no responses for this story.
Be the first to respond.
As I‚Äôve covered in Jack and the Elastic Beanstalk, Elastic Beanstalk is a great PaaS offering from AWS that allows developers to deploy and run their applications on EC2 instances. I been tinkering with a few different ways to speed up the eb deploy command from my local machine and was able to speed it up somewhat. Though honestly I was hoping for better results. I will detailed the results to show what I learned.
Note, the project and all it‚Äôs files are available on GitHub at tongueroo/hi under the docker-cache branch.
For EB I use Docker because it standardizes the deployment unit. There are a few ways to deploy your code to EB when using Docker. You can either have a Dockerfile or Dockerrun.aws.json in the project. EB looks for both of these files to build a docker image when deployments happen. The script that actually handles the docker build is at /opt/elasticbeanstalk/hooks/appdeploy/pre/03build.sh.
So doing as little as possible in the Dockerfile will yield the fastest EB deployment. In fact if you look at the 03build.sh script you can see that when only a Dockerrun.aws.json exists, EB will generate a barebones simple Dockerfile with a FROM and EXPOSE statement as defined in the Dockerrun.aws.json. This makes a lot of sense because then there are no dependencies to pull in and the deployment will less likely break. All you effectively need is the Docker image to exist and be pulled down successfully. So the ideal deployment is that a Docker image gets built, Dockerrun.aws.json file gets updated with the image name, and it gets shipped to EB. I normally only make use of the Dockerrun.aws.json file to deploy.
While only using a Dockerrun.aws.json is ideal for production deployments, from the development perspective it is a pain. Having to build and a Docker image each time you want to make a slight change and deploying repeatedly to an environment is slow. It is especially painful if it is a rather large ruby image with a slow connection. The ideal approach is to not deploy the container on my Mac OSX laptop but on a build server. But when I‚Äôm developing I prefer to try and develop on my own machine when possible.
I remember a developer mentioning to me many times that he prefers the eb deploy command to handle deployment because it was simply faster most of the time for him. Basically, after the initial eb deploy, as long as the servers were not freshly launched instances, eb deploys would be very fast because the Docker cache layers would exist. When you are trying to rapidly develop and are constantly deploying a change to staging instances over and over, using the eb deploy flow makes complete sense. It just does not make sense in a production environment because you do not want instances building a lot of dependencies when AutoScaling up occurs.
Building the Docker image live on the instance felt really dirty to me. I would image all the dependencies being downloaded, installed and built whenever code was deployed to a EB environment. What happens if apt-get or RubyGems is down? It feels like there is just too many things that could go wrong, especially if the Dockerfile must install a long list of things. So I have normally kept with building pre-building the Docker image using a Dockerrun.aws.json and deploying that as a unit instead of using eb deploy.
I then saw this StackOverflow post How to speed up CI build times when using docker? and it reminded me of a concept that I have tried before. The idea is simple, you create a cache baseline Docker image that has the app dependencies and packages already installed and push that image to the Docker registry. You then use that Docker image as the starting baseline image and eb deploy will build from that starting point. In this way when you use eb deploy it will only have to deploy incremental code changes. As long as the incremental code changes do not require a ton of new dependencies to be installed, which is often the case, then the deploy will be fast.
It is a compromise that results in the best from each world. You get the speed of eb deploy whenever the Docker cache layers exist. You also get the reliability of having the packages cached in the baseline Docker image. The dependencies are baked in and pulled down with the initial Docker image. EB is no longer installing packages on the fly when AutoScaling occurs. It does not matter if apt-get or RubyGems is down then.
The big caveat with this approach is that you have to remember to update the cache Docker image from time to time and this manual task sucks for humans beings to do. If you get lazy and forget to update the baseline image then the slowness and all the unreliable awfulness that I mentioned creeps back as the code strays away from the baseline.
So I set out to simplify the manual task of creating this baseline image and updating the starting point of the FROM statement. The structure that I ended up setting up was to create two Dockerfiles: a standard Dockerfile and a Dockerfile.base file.
Here‚Äôs what the two files initially look like. First the Dockerfile.base:
The important thing here is that I‚Äôm installing the RubyGems as part of the baseline Dockerfile.base. For theDockerfile:
The FROM statement for Dockerfile has tongueroo/hi initially but that gets automatically changed with the ufo tool. The ufo tool is coverage thorough in: Ufo ‚Äî Easily Build Docker Images and Ship Containers to AWS ECS. The ufo tool has a handy command, ufo docker base , to build the base image and automatically update the current Dockerfile FROM statement. You can see that the FROM statement is updated in the example below.
All you have to do is initially set ‚Äútongueroo/hi‚Äù in the FROM statement and then ufo docker base will add a timestamped tag to the end of the ‚Äútongueroo/hi‚Äù as part of this process:
Using ufo docker base you can easily update the cache image with a single command and commit the new Dockerfile. It be good to put this in a scheduled job somewhere so it always automatically updates the cached image.
The project and all it‚Äôs files are available on GitHub at tongueroo/hi under the docker-cache branch.
Let‚Äôs do some rudimentary speed tests to see how much of a difference this cache strategy buys us. For each benchmark case, I‚Äôm going to start with a fresh instance without any of the Docker cache layers. Then I‚Äôm going to run eb deploy twice for each case.
The first case is when I‚Äôm using only one Dockerfile and building everything from a ruby 2.3.3 image.
The second case is when I using a Dockerfile and a Dockerfile.base.
You can see that for eb deploy when there are no Docker cache layers, there is about a 1 minute and 26 seconds deployment speed improvement. When the Docker cache layers exists, on the second deploy, there is no real difference in the deploy times with either method. This makes complete sense.
For simple projects like the tongueroo/hi example project there is a gain of about a minute and a half. For real projects it makes a larger difference. I copied a Gemfile from one of the real applications I‚Äôm working on and tried the same test. Without cached Docker image:
With cached Docker image:
So the difference is 2 minutes and 18 seconds in a case with a real project.
For any eb deploy after the initial deploy, regardless of the strategy we take, it is very fast. This is because after the first deploy, the Docker layers already exist on the EC2 instance and so when EB builds the image the second time around it does not have to rebuild those Docker layers. This speedy eb deploy of about 30 seconds is a nice benefit.
Using this extra Docker baseline image as cache is one strategy to speed up the eb deploy command. However, the results were not as great as what I hoped for fresh instances but it is a few minutes of speed up.
One cliff note is that this strategy will also help speed up CI build times if you are on non-dedicated hardware and using one of the cloud based CI tools like CircleCI. It speeds it up because once again dependencies aren‚Äôt being install every time. If you are on dedicated hardware then this strategy add value because the server will have the docker cache layers. Running a dedicated instance to take advantage of Docker layers will always be the fastest approach and whether or not it is worth managing that server is up to you. Another technique, which I‚Äôll cover in another post, is setting up a remote Docker daemon so that the build and push happens on an EC2 instances where the network will be blazing fast.
Thanks for reading this far. If you found this post useful, I‚Äôd really appreciate it if you recommend this post (by clicking the clap button) so others can find it too! Also, connect with me on LinkedIn.
P.S. Be sure to join the BoltOps newsletter to receive free DevOps tips and updates.
All AWS All the Time
164 
1
164¬†claps
164 
1
Written by
Get Infrastructure Out of the Way
All AWS All the Time
Written by
Get Infrastructure Out of the Way
All AWS All the Time
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@product.protocol/product-protocol-and-dokkur-join-forces-450d35c42927?source=search_post---------116,"Sign in
There are currently no responses for this story.
Be the first to respond.
Product Protocol
Jul 27, 2019¬∑2 min read
We are glad to announce new Product Protocol official partner ‚Äî Dokkur. Its goal is to provide an affordable PaaS solution for applications whose owners cannot afford to build expensive infrastructure.
Taking famous Heroku service as a prototype, Dokkur team made it easier and cheaper. Dokkur is primarily focused on small applications that need good technical solutions: from fast deployment to operational services. The project uses Amazon as a cloud platform. Supported programming languages: Ruby, Node.js, Clojure, Python, Java, Gradle, Grails, Scala, Play, PHP, Go, as well as custom Docker image. They are focused primarily on business and IT-specialists, who want to deliver their product to the final customer as soon as possible.
The Dokkur project positions itself as one service for all infrastructure tasks ‚Äî from urgent deployment for demonstration purposes to creating a copy of the system on a new server for a specific client.
Supported Database Management Systems: CouchDB, Elasticsearch, MariaDB, Memcached, Mongo, MySQL, Nats, Postgres, RabbitMQ, Redis, RethinkDB.
The use of the service allows companies to save working time and to reduce the cost of building infrastructure and expensive specialists. In case of Product Protocol Dokkur will help to achieve the highest possible efficiency, security and will assist in managing structured databases.
We hope for fruitful cooperation!
Product Protocol is a open-source protocol for crowdfunding/crowdlending campaigns based on digital assets issuing https://pprotocol.io/
169 
169¬†
169 
Product Protocol is a open-source protocol for crowdfunding/crowdlending campaigns based on digital assets issuing https://pprotocol.io/
"
https://medium.com/thipwriteblog/%E0%B8%AA%E0%B8%A3%E0%B8%B8%E0%B8%9B%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%A0%E0%B8%97%E0%B8%82%E0%B8%AD%E0%B8%87-cloud-computing-service-%E0%B8%A1%E0%B8%B5%E0%B8%AD%E0%B8%B0%E0%B9%84%E0%B8%A3%E0%B8%9A%E0%B9%89%E0%B8%B2%E0%B8%87-544e2c6a8c85?source=search_post---------117,"There are currently no responses for this story.
Be the first to respond.
‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤ Cloud Provider ‡∏≠‡∏¢‡∏π‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 20 ‡πÄ‡∏à‡πâ‡∏≤ ‡πÅ‡∏ï‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡∏∏‡πâ‡∏ô‡∏´‡∏π‡∏Ñ‡∏∏‡πâ‡∏ô‡∏ï‡∏≤‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡πá‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏°‡πÄ‡∏à‡πâ‡∏≤‡∏¢‡∏±‡∏Å‡∏©‡πå‡πÉ‡∏´‡∏ç‡πà ‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô ‚ÄúBig Three‚Äù ‡∏Ç‡∏≠‡∏á‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå ‡∏ô‡∏±‡πà‡∏ô‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ Amazon Web Service (AWS), Google Cloud Platform (GCP) ‡πÅ‡∏•‡∏∞ Microsoft Azure ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏à‡πâ‡∏≤‡∏Å‡πá‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏õ
‡∏≠‡πâ‡∏≠! ‡∏Ç‡∏≠‡∏¢‡πâ‡∏≥‡∏ß‡πà‡∏≤ ‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á ‚Äú‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‚Äù ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà ‚Äú‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‚Äù ‡∏ô‡∏∞
‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á Cloud Service ‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏û‡∏ß‡∏Å‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏Ç‡∏≤‡∏Å‡πá‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤ Cloud Computing Stack ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£‡πÄ‡∏≠‡∏≤ keyword ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ research ‡∏ï‡πà‡∏≠ ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô 3+1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏ß‡∏Å‡∏´‡∏ô‡∏∂‡πà‡∏á?‡∏Å‡πá‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤.. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏≠‡∏≤‡πÅ‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ô‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏ö‡πà‡∏≠‡∏¢‡πÜ ‡∏à‡∏∞‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 3 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÅ‡∏£‡∏Å ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ö‡∏ß‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏¢‡πà‡∏≠‡∏¢‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏≠‡∏á
Step ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ types ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏∞!!
‡∏≠‡πà‡∏∞! ‡∏Å‡πá‡∏¢‡∏±‡∏á‡∏î‡∏π‡∏¢‡∏≤‡∏ß‡πÜ ‡∏à‡∏≥‡∏¢‡∏≤‡∏Å‡πÜ ‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏µ‡πÉ‡∏ä‡πà‡∏°‡∏∞ ‡∏á‡∏±‡πâ‡∏ô‡∏î‡∏π‡∏õ‡∏≤‡∏Å thip ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡πà‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏ô‡πÑ‡∏õ‡∏Ñ‡πà‡∏∞‚Ä¶
‚Äú ‡πÅ‡∏≠‡∏™-‡πÅ‡∏û‡∏™-‡πÅ‡∏ã‡∏™-‡πÅ‡∏ü‡∏™ ‚Äù
‚Äú ‡πÅ‡∏≠‡∏™-‡πÅ‡∏û‡∏™-‡πÅ‡∏ã‡∏™-‡πÅ‡∏ü‡∏™ ‚Äù
‚Äú ‡πÅ‡∏≠‡∏™-‡πÅ‡∏û‡∏™-‡πÅ‡∏ã‡∏™-‡πÅ‡∏ü‡∏™ ‚Äù
Infra ‚Äî Platform ‚Äî Software ‚Äî Function
‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏ö‡∏≤‡∏á‡πÄ‡∏à‡πâ‡∏≤ ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏∏‡∏Å service ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏™‡∏µ‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏≤‡∏á‡πÄ‡∏à‡πâ‡∏≤‡∏Å‡πá‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏Ñ‡πà‡∏ö‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πá‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤ ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£ ‡∏Ç‡∏≠‡∏á‡πÄ‡∏à‡πâ‡∏≤‡πÑ‡∏´‡∏ô
‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡∏™‡∏≤‡∏¢‡∏¢‡πà‡∏≠‡∏à‡∏∞‡∏Ç‡∏≠‡∏ö‡∏£‡∏µ‡∏ü‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏°‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏≠‡∏≠‡∏Å
‡πÇ‡∏î‡∏¢ cloud provider ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏à‡πâ‡∏≤‡∏Å‡πá‡∏à‡∏∞‡∏°‡∏µ products ‡∏¢‡∏¥‡∏ö‡∏¢‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å‡∏Å‡∏Å ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏à‡πâ‡∏≤‡∏Å‡πá‡∏à‡∏∞‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô Web Server ‡∏Ç‡∏≠‡∏á AWS ‡∏à‡∏∞‡∏ä‡∏∑‡πà‡∏≠ ‚ÄúEC2‚Äù ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á Microsoft Azure ‡∏à‡∏∞‡∏ä‡∏∑‡πà‡∏≠ ‚ÄúApp Service‚Äù ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ô‡∏µ‡πâ
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏Ñ‡∏£‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏¢‡∏±‡∏á‡∏à‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà ‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏ß‡∏ô‡πÑ‡∏õ‡∏ß‡∏±‡∏ô‡∏•‡∏∞ 1 ‡∏£‡∏≠‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞ 1 service
‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÉ‡∏Ñ‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≠‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏á ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ö‡∏£‡∏µ‡∏ü‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Å‡∏Å555+ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏î‡πà‡∏∞ ‡πÅ‡∏ï‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏Å‡∏î clapsss ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏´‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏°‡∏≤‡∏ö‡∏£‡∏µ‡∏ü‡∏ö‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏ô‡∏≠‡∏∞!
‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
medium.com
Programming, Technology, Work Life, Finance, Storyteller, Lifestyle, Content Creator, Podcast
32 
Some rights reserved


By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
32¬†claps
32 
Written by
Software Engineer & Freelance Writer | thipwriteblog@gmail.com
‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏ß ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏•‡πà‡∏≤ ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô ‡∏ä‡∏≠‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‡∏ä‡∏≠‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏´‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏≠‡∏ö‡∏Å‡∏±‡∏ô‡∏Å‡πá‡∏Å‡∏î Follow ‡πÑ‡∏ß‡πâ‡∏ô‡∏∞ ‚ù§
Written by
Software Engineer & Freelance Writer | thipwriteblog@gmail.com
‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏ß ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏•‡πà‡∏≤ ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô ‡∏ä‡∏≠‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‡∏ä‡∏≠‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏´‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏≠‡∏ö‡∏Å‡∏±‡∏ô‡∏Å‡πá‡∏Å‡∏î Follow ‡πÑ‡∏ß‡πâ‡∏ô‡∏∞ ‚ù§
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/swift2go/serverless-google-app-engine-flex-docker-runtime-cloud-sql-backend-with-swift-vapor-web-alfian-c8310acfea0d?source=search_post---------118,"There are currently no responses for this story.
Be the first to respond.
You can also read this article in my Xcoding With Alfian blog website using the link below.
www.alfianlosari.com
Google App Engine is a Platform as a Service (PaaS) solution provided by Google Cloud for customer to build scalable backend service without managing server deployment, load balancing, and scaling the infrastructure. As developers, we just need to focus on writing the code and deploy the code to the Cloud. App Engine handles all the process of infrastructure deployment automatically such as virtual machine instantiation, load balancing, autoscaling, Google Global DNS network, task queue, memcache, health check, Stackdriver Logging, and even traffic splitting different version of our backend application. The equivalent services of App Engine are AWS Beanstalk and Salesforce Heroku.
cloud.google.com
App Engine is the first PaaS solution provided by GCP when it was started in 2008. It had many limitations such as java only runtime language support, Google Datastore to store the application structured data, 1 minute timeout between request & response, and sandboxing with limited access to install custom dependencies into the virtual machine environment.
As of end of 2018, Google Cloud provides 2 environments to use App Engine, one is standard environment with constrained environments and support for languages such as Python, Go, node.js. The other one is the Flexible Environment where developers have more freedom such as running custom runtimes using docker, longer request & response timeout, and ability to install custom dependencies/software, and SSH into the virtual machine. The pricing between standard and flexible environment is also different, you can see how the pricing works by visiting the pricing documentation of each environment.
cloud.google.com
cloud.google.com
In this article, we will use Google App Engine Flexible Custom Runtime to build a Swift Vapor Backend Web Framework server using Docker and deploy it live in the Cloud using Google Cloud SDK. It will also connect to Google Cloud SQL to store the todo app data of the application.
We are going to deploy a web API using Swift Vapor 3 Web Framework. Vapor 3 has several main features that are really awesome such as:
The performance of Vapor is also very promising by looking at the average latency performance using Plaintext benchmark from the graph below (taken from VAPOR medium article).
Clone or download the app from GitHub repository into your local machine by clicking on the link below.
github.com
The app consists of many different components, inside Sources/App directory. Several of the key parts are:
You can run the app locally, but before that you need to install and run MySQL server in your local machine, then create user, password, and database named todo. Make sure to export all the environment variables inside the configure.swift into your shell. Then run swift build and the compiled app inside the .build directory. Use cURL to perform the CRUD operation (see README.md for API specification inside the cloned project directory).
To deploy our app to Google App Engine Flexible custom runtime, we need to provide Dockerfile containing the docker image that we want to run inside the container. The Dockerfile is located in the cloned repository root directory. Open it and take a peek.
Inside, we tell docker to use the IBM Swift image running latest Ubuntu from docker repository. Expose the port 8080 of the container to the host machine 8080 app engine default port. Copy the current folder into the app directory and set it as working directory. It also build the Swift package using the configuration release. Lastly, as the entry point of the container, it runs the application server from the build directory.
For the MySQL server hosting, we are going to use GCP Cloud SQL managed database solution. It provides 2 SQL database to use, MySQL and PostgreSQL. Our app is using the MySQL to store the todo list data. You need to create Google Cloud SQL instance by using either Google Cloud Console or using the SDK.
Here are the instructions if you prefer using the console to setup the instance:
To deploy the app from our local machine, we need to install Google Cloud SDK. Before that, we need to set the configuration and environment variables for the App Engine. Go to the cloned repository project directory and open app.yaml.
Inside we tell the App Engine to use the custom runtime and flexible environment. We also set the manual scaling and just 1 instance for testing purpose. In production, you can set the automatic scaling with the maximum number of machine to upscale. In environment variables, set the MySQL user, password, database, ip, instance name to your Cloud SQL instance configuration. There are many customization that we can configure such as machine type, memory, disk, network. You can visit the documentation to view all the configurations parameter.
cloud.google.com
To deploy the app, just type:
Grab a coffee and take your time, it will take about 5‚Äì10 minutes for the deployment starting from uploading our code to Google Cloud Build Repository and setup it in App Engine.
After it finished, type the command below to view the application http address. We are going to test the app using cURL in the next section.
Inside your shell, use cURL to perform following operations to test our API endpoint. Replace the ADDRESS placeholder with your app HTTP address.
App Engine Flex uses Stackdriver Logging under the hood to provide realtime log for all the server request and response that we can view inside the dashboard in Google Cloud Console.
You can also view your App Engine instances by visiting the App Engine dashboard to monitor various metrics such as CPU utilization, memory, disk, latency, even SSH into your local machine using the dashboard.
!!! After finishing the project, make sure to disable the application from the App Engine Console and stop the Cloud SQL instance to avoid continuous billing.!!
Google App Engine Flexible Custom Runtime provides really powerful and also simple solution to deploy scalable backend sever without managing and worrying about the dev-ops configuration. We can even create microservices architecture by deploying different services of our application inside one project. While it‚Äôs very good for smaller startup that have limited human resources to manage the infrastructure, in longer term as our user base are growing, the computing cost can be quite high compared to using infrastructure as a service solution like Google Compute Engine.
In my personal opinion, when our application user base has become larger, company has more resources, and business logic become more complex, we can migrate to Google Kubernetes Engine or Google Compute Engine managed instance group for more flexibility and customization.
a place where Swift Developers share knowledge.
106 
1
106¬†claps
106 
1
Written by
Mobile Developer and Lifelong Learner. Currently building super app @ Go-Jek. Xcoding with Alfian at https://alfianlosari.com
a place where Swift Developers share knowledge.
Written by
Mobile Developer and Lifelong Learner. Currently building super app @ Go-Jek. Xcoding with Alfian at https://alfianlosari.com
a place where Swift Developers share knowledge.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/linagora-engineering/writing-a-medium-com-clone-ad1bffb9c065?source=search_post---------119,"There are currently no responses for this story.
Be the first to respond.
At the end of the last year we, at Linagora, decided to contribute to the Open Government Toolbox Hackathon with Open-PaaS project by providing a medium.com like platform where users can create articles, vote, launch discussions, ‚Ä¶ The current article shows how we built this new module by reusing the components provided by the Open-PaaS platform (named OP next).
At the heart of this new module, named linagora.esn.article, there are‚Ä¶ articles! To keep it simple, an article contains a title, a body, can be commented, can be liked and users can vote with +1, 0, -1. Let‚Äôs go more into details now.
When we started to develop OP almost three years ago, the first idea was about developing a so-called Enterprise Social Network (ESN), you know, Facebook, but for work. This meant mainly dealing with collaborations, ‚Äòwalls‚Äô, activity streams, comments, i.e. blah blah blah.
The first collaboration type we implemented was the community one. A community is an entity with a title, a description, a list of members and has a least an ‚Äúactivity stream‚Äù. The activity stream name is self explanatory: we record everything users are doing in this stream, then we are able to build and display the activity as a timeline. In the case of a community, the discussions between users are implemented using an activity stream. These are not standard discussions from newest to oldest like you can have in a messaging application, but this is an ‚Äòintelligent‚Äô display where old messages with newest responses are displayed before old messages with old responses for example (we can also imagine display a message with most likes first, etc.).
On the frontend side, this is ‚Äòjust‚Äô using an Angular component (line 24 in the snippet below):
As other resources in any good social network, an article may be liked. Here we reuse the like component already available in OP. To keep it simple, a like is a link of type ‚Äòlike‚Äô between resources: a source (the user who likes the article) and a target (the article).To be as generic as possible, we use Tuples. A Tuple has an id and a type:
User Tuple = {objectType: ‚Äòesn.user‚Äô, id: ‚ÄòUserId‚Äô}Article Tuple = {objectType: ‚Äòesn.article‚Äô, id: ‚ÄòArticleId‚Äô}
And so we are able to like anything in OP (in the screenshot above, we can like comments, of course).
What will be nice in a civic centric platform like the OGP one will be to be able to vote on article, because it is not really the same as liking something. Guess what? A vote is also a link of type ‚Äòvote‚Äô between a user and an article, but this one is pondered with a weight: A user can vote for (+1), against (-1) or ‚Äúdon‚Äôt care‚Äù (0. Which is better than nothing, well it is another debate‚Ä¶).
Building such new collaborative module with OpenPaaS for the OGP toolbox in just some days really shows the potential of the platform, its power of its core components and architecture.
We are Open Source Engineers, Hacking Awesome Stuff
20 
20¬†claps
20 
We are Open Source Engineers, Hacking Awesome Stuff
Written by
Lead Dev at @linagora
We are Open Source Engineers, Hacking Awesome Stuff
"
https://medium.com/the-vue-storefront-journal/storefront-cloud-is-out-ab1da9cc1115?source=search_post---------120,"There are currently no responses for this story.
Be the first to respond.
The last few months were a real rush. We worked silently (stealth mode) on a PaaS solution based on Vue Storefront. We wanted to have it ready before Meet Magento New York. Now, it‚Äôs ready!
Vue Storefront got pretty solid
Meet Magento New York, 2017 was the place of the first public Vue Storefront project announcement. Now, with 3.3K stars on Github, a few dozen live-sites, over 800 devs in the community and 80 active contributors, the project has proved its value.
It started and will be continued as an Open Source project with a monthly release cycle. We‚Äôre pushing it forward faster than ever ‚Äî working mostly on quality, not quantity with each new release.
We‚Äôre really grateful to our Community for helping to make this happen. We‚Äôve had a think ‚Äî we believe we can make it even better.
The solution integrated with Storefront Cloud
The Vue Storefront goals were to improve the Customer and Developer‚Äôs experience. Developer‚Äôs love our tech stack and the simplicity of working with the platform, and customers appreciate the speed and user experience it provides.
Vue Storefront works great as a framework, however, there are still dev-ops, and maintenance resources required to make it happen at scale. We decided that this is the missing piece of the puzzle, and we can provide it, resulting in a one-stop integrated service.
Storefront Cloud is a mobile-first eCommerce platform that helps you build an engaging user-experience across devices.
‚ÄúThe Progressive Web App (PWA) and Accelerated Mobile Page (AMP) standards ‚Äî introduced by Google, and currently getting traction, can be a game changer in this situation. A native-like user experience, and page loading times < 1s can increase conversion rates by 20‚Äì50% and more.‚Äù ‚Äî Patryk PiƒÖtek, Co-founder of Storefront Cloud
The Storefront Cloud platform provides users with a complex mobile and desktop eCommerce frontend that is connected with your existing backend system.
It‚Äôs based on Vue Storefront. This allows you to use PWA and AMP technologies, which make the experience faster and smoother for the client, especially on mobile devices. Moreover, with the integrated Open Loyalty platform, merchants are provided with a whole set of tools for re-engaging users and managing all touchpoints (offline and online).
The scalability is unlimited ‚Äî and the scale is tailored by the Cloud Team to client‚Äôs traffic and sales needs. The Storefront Cloud stack has been built on Kubernetes. It‚Äôs based on micro-services, headless architecture using Amazon Web Services (like Cloudfront), Fastly, ElasticSearch and other cloud services to provide the required scalability and speed.
No changes to your existing eCommerce are required. Storefront Cloud users are provided with full access to Vue Storefront and Open Loyalty solutions for preparing a customized user experience tailored to industry and customer habits.
All Storefront Cloud users will receive access to the Storefront Cloud Help Center and a set of Command Line tools for managing the Kubernetes cluster, as well as the code deployments and staging environments.
Batteries Included
We‚Äôre providing Storefront Cloud users with a full set of tools required to manage the infrastructure and deployments.
You can check our Command Line tool on Github and read the Developer‚Äôs docs.
Beta Access Program
The service is currently available in the closed Beta Access Program for our partners and agencies. Please contact us to get an invitation and to test Storefront Cloud!
The official journal of Vue Storefront community.
278 
1
278¬†claps
278 
1
The official journal of Vue Storefront community. The latest news on meet-ups, contributions, releases, and the community surrounding Vue Storefront‚Ää‚Äî‚Ääthe top open source solution for progressive web apps dedicated to mobile-first eCommerce. (www.vuestorefront.io)
Written by

The official journal of Vue Storefront community. The latest news on meet-ups, contributions, releases, and the community surrounding Vue Storefront‚Ää‚Äî‚Ääthe top open source solution for progressive web apps dedicated to mobile-first eCommerce. (www.vuestorefront.io)
"
https://blog.jeremylikness.com/lift-and-shift-your-net-app-to-azure-41c1fd6a9e43?source=search_post---------121,
https://medium.com/rd-shipit/como-a-migra%C3%A7%C3%A3o-para-o-google-cloud-platform-em-2018-potencializou-o-crescimento-da-rd-station-8e2fdf744427?source=search_post---------122,"There are currently no responses for this story.
Be the first to respond.
A RD Station nasceu em 2011 como um produto SaaS (Software as a Service), 100% em cloud que tinha como base uma PaaS (Platform as a Service) chamada Heroku. O Heroku ajudou a ganhar muita velocidade e a otimizar boa parte do pipeline de desenvolvimento. Essa solu√ß√£o oferecia desde deploy com apenas 1 comando e gest√£o simplificada em produ√ß√£o, at√© um marketplace que conectava m√∫ltiplos servi√ßos (por exemplo monitoramento e bancos-como-servi√ßo), eliminando a necessidade de termos times dedicados de SRE e DevTools, como temos hoje. Sim, acredite, essas eram ‚Äúinova√ß√µes‚Äù na √©poca :)
O crescimento do nosso produto e do n√∫mero de clientes foi exponencial, por√©m ali por volta de 2015 percebemos que a solu√ß√£o que t√≠nhamos n√£o atendia mais as nossas necessidades. Quer√≠amos customizar nosso uso para ter mais controle da opera√ß√£o e estruturar melhor nossos servi√ßos, entretanto, isso n√£o era transparente e nem muito configur√°vel. Decidimos ent√£o migrar para uma IaaS (Infrastructure as a Service), que ao mesmo tempo que traria mais controle, tamb√©m exigiria mais desenvolvimento e governan√ßa do nosso lado.
Em 2016 testamos pelo menos dois provedores conhecidos do mercado usando uma parcela dos seus servi√ßos, entretanto nunca ficamos completamente satisfeitos (nossa r√©gua √© bem alta, confesso). Acontece que ou a solu√ß√£o era boa no aspecto t√©cnico (ex: diversifica√ß√£o de servi√ßos, escalabilidade, disponibilidade), ou era boa apenas no atendimento (suporte ativo, capacidade de resolu√ß√£o de problemas). Depois de muitos e muitos testes, decidimos usar o Google Cloud Platform como nosso principal provedor de servi√ßo na nuvem (cloud), e de l√° pra c√° essa foi a melhor decis√£o que tomamos.
A seguir vou os crit√©rios que utilizamos nessa tomada de decis√£o e tamb√©m os aprendizados que tivemos at√© aqui. Espero que esse conte√∫do te ajude a tomar uma boa decis√£o quando for necess√°rio fazer uma escolha parecida.
Antes de tudo √© preciso entender que uma decis√£o sobre um fornecedor cloud n√£o √© meramente por requisitos t√©cnicos. Toda parte t√©cnica, servi√ßos dispon√≠veis, investimento de P&D, capacidade e hist√≥rico de crescimento, performance, etc, √© sim super importante (na verdade ela √© fundamental, pois sem isso pouco importa olhar para o resto). Por√©m, os fornecedores atuais j√° entregam de forma parecida boa parte dessas coisas, quase como um celular, que voc√™ n√£o escolhe por ‚Äúfazer liga√ß√£o ou n√£o‚Äù pois isso j√° √© esperado. Ele precisa entregar mais do que o esperado.
No entanto, o restante tamb√©m √© importante. No que tange isso, gosto de pensar em ao menos mais 3 itens: custo, suporte e valor ao neg√≥cio.
O fato √© que o custo que sua solu√ß√£o tem para rodar, impacta diretamente na sua margem. Quanto menor seu custo, melhor sua margem, simples. Se voc√™ consegue crescer sua base de clientes descolada do custo de cloud, excelente, voc√™ tem uma solu√ß√£o eficiente. √â esperado que seu COGS (custo de infra para servir seu produto por cliente), diminua proporcionalmente com o tempo.
Para isso, √© importante contar com um provedor que tenha boa base de pre√ßo, ofere√ßa descontos fixos em m√°quinas, possua cobran√ßa local com menor impostos (ou hedge de d√≥lar), e que tenha cupons para migra√ß√£o ou atenua√ß√£o dos custos. Dica b√¥nus: vale revisar a infra-estrutura para consumir menos e tamb√©m negociar bons contratos. Voc√™ precisar√° negociar isso, por√©m s√≥ conseguir√° quando atingir um tamanho mais relevante.
Por fim, tome cuidado com fornecedores menores ou menos estruturados, j√° vi empresas mudarem seu empacotamento de servi√ßos e pre√ßos sem crit√©rio, afetando diretamente seus clientes e exigindo migra√ß√µes a toque de caixa.
Com rela√ß√£o ao suporte, ao escalar nosso neg√≥cio aprendemos que √© importante ter ao lado um parceiro estruturado, que possa n√£o s√≥ ajudar a evitar problemas (por exemplo, atrav√©s de servi√ßos para evolu√ß√£o da arquitetura, revis√£o de custos etc), como tamb√©m dar um suporte extra durante incidentes. Dependendo da configura√ß√£o do seu time, a l√≠ngua pode ser uma barreira tamb√©m.
Em nossa experi√™ncia vimos que alguns fornecedores cloud n√£o estavam preparados para oferecer esse suporte mais pr√≥ximo pois atuavam em um modelo mais ‚Äúfa√ßa voc√™ mesmo‚Äù, em que o cliente adotava no in√≠cio da jornada empreendedora, mas depois n√£o tinham estrutura para acompanhar. Crescer e escalar muito sem isso pode ser um risco.
Custo e valor s√£o conceitos diferentes, por√©m nem sempre um provedor de servi√ßo na nuvem consegue adicionar valor ao seu neg√≥cio, exceto quando ele ajuda seu neg√≥cio a crescer mais ou melhor. ‚ÄúCrescer mais‚Äù pode acontecer atrav√©s da constru√ß√£o de novos canais ou bizdev de produtos, j√° ‚Äúcrescer melhor‚Äù √©, por exemplo, quando esse fornecedor consegue potencializar o desenvolvimento das pessoas que fazem parte da sua equipe t√©cnica. Em ambos os cen√°rios, essa parceria agrega valor no servi√ßo que voc√™ vende, seja em resultados institucionais, seja em capital intelectual.
Quando adotamos o GCP, h√° 3 anos, entendi que a proposta de valor deles era resolver de forma mais estruturada todos os pontos listados anteriormente.
Na pandemia, em 2020, pude tamb√©m confirmar toda parceria que est√°vamos construindo e o respeito que tratam seus clientes. Diante do cen√°rio nebuloso dos primeiros meses, onde est√°vamos entendendo diariamente tudo que estava acontecendo e ajudando nossos clientes com fluxo de caixa (em especial setores impactados e empresas com pouca visibilidade), o Google se mostrou um grande parceiro ao congelar o d√≥lar para evitar ainda mais problemas. Isso refor√ßou bastante sua cultura e abertura pra conversar.
Recentemente fizemos uma nova negocia√ß√£o com GCP na ordem de dezenas de milh√µes, que nos refor√ßa como um dos principais clientes do Brasil. Seguimos com nosso uso intenso, tanto no aspecto de quantidade de servi√ßos, como no volume de dados, e suporte muito pr√≥ximo. Em paralelo tamb√©m estamos desenhando programas de desenvolvimento em conjunto, que ir√£o auxiliar nossa equipe internamente a contar com toda a expertise do time deles.
Estou super animado com nosso momento e tudo que est√° por vir! O fortalecimento dessa parceria com o Google √© uma possibilidade a mais de desenvolvimento para nosso time aprender com uma empresa refer√™ncia mundial. E se voc√™ quiser conhecer mais sobre nosso modelo de trabalho e cultura, confira nossas oportunidades de carreira. Temos vagas para diferentes produtos e est√°gio de carreira.
Conte√∫do, opini√£o, viv√™ncia e compartilhamento de ideias da‚Ä¶
42 
2
42¬†claps
42 
2
Conte√∫do, opini√£o, viv√™ncia e compartilhamento de ideias da equipe de Produto e Engenharia da RD Station @RD
Written by
Co-founder / CTO @ResDigitais. Endeavor Entrepreneur. Angel. Dad.
Conte√∫do, opini√£o, viv√™ncia e compartilhamento de ideias da equipe de Produto e Engenharia da RD Station @RD
"
https://betterprogramming.pub/how-can-cloud-services-help-improve-your-businessess-efficiency-ea3fb038948e?source=search_post---------123,"Sign in
There are currently no responses for this story.
Be the first to respond.
SeattleDataGuy
Mar 28, 2020¬∑5 min read
In the 20th century, companies relied on servers and computers that were on the premises.
This meant when new servers had to be spun up, it could take weeks or even months to get everything set up. From getting the budget approved, to putting out orders, to having‚Ä¶
"
https://medium.com/@gmusumeci/how-to-deploy-an-azure-app-service-using-terraform-33f69b72e099?source=search_post---------124,"Sign in
There are currently no responses for this story.
Be the first to respond.
Guillermo Musumeci
Jun 26, 2020¬∑3 min read
Azure App Service Web Apps is a PaaS (Platform as a Service) platform service that lets us quickly build, deploy, and scale enterprise-grade web, mobile, and API apps.
We can focus on the application development and Azure App Service will take care of the infrastructure required, and automatically scale our apps.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@tsuyoshiushio/automatically-deploy-and-configure-eventhubs-stream-analytics-and-cosmosdb-using-terraform-16aa5a34240e?source=search_post---------125,"Sign in
There are currently no responses for this story.
Be the first to respond.
Tsuyoshi Ushio
Mar 19, 2018¬∑4 min read
When you deploy SaaS/PaaS/Serverless resources on Azure, Which measure are you using? We can use Azure CLI, PowerShell, ARM template and so on. However, I prefer Terraform for this purpose. I‚Äôd like to share why and several tips for the deployments. I believe it helps your deployment life much simpler.
Also, I‚Äôm share with you the whole sample source template for the deployment.
Terraform is the HashiCorp product, written by go. As an architecture point of view, the concept of ARM is very cool. However,when you use it for deployment, it is NOT human readable also indent matters. We need to specify a lot of parameters which I don‚Äôt care for. No comments. The ARM template is focus on resource deployment, so it has few support for configuration.
IMO, ARM template and architecture is cool as a base architecture of Azure. However, we need something to hide the complexity and make life simpler. For example, if you want to deploy ResourceGroup, you can write like this in terraform.
Simple and easy to understand, right?
You can refer which resource can deploy via Terraform in here.
More than that, you can find Modules to deploy much easily. It packages several resources with one module.
You can use variables and instruct them an dependencies. This is the code for deploy EventHubs. As you can see, several variables. ${azurerm_resource_group.test.*} is variable taken from the ResourceGroup which you already deployed.
Also, you can see ${var.event_hub_namespace} which is defined in advance. This script is written on terraform.tf file. You can add terraform.tfvars file for set the variables. like this.
terraform.tfvars
Also, you can see depends_on it instruct this resource is waiting for a creation of the azurerm_resource_group.test resource.
You can refer the output values. For example, when you create a cosmos db, you want to get the key and set the other resources. This is also very simple. just specify the resrouce name and specify the output value name. You can find which output value available on the Azure Provider page.
Sometimes, you can find that your target resource is not supported. In this case, I can‚Äôt find Stream Analytics resource provider. Also, We can deploy CosmosDB account, however, I can‚Äôt create database and collections. How to do it?
If you can‚Äôt find whole resource, you can use ARM template integration. You can download the ARM template from Azure Portal. Then try to deploy via Azure Portal. Before push the ‚ÄúCreate‚Äù button, you can find ‚ÄúAutomation Options‚Äù from this link, you can get ARM template for the target resource.
Then you can call this ARM template from Terraform. As you can see, it simply specify the template.json file of the ARM template. then pass the parameters.
Sometimes, you don‚Äôt want to avoid to use ARM, right? then You might use local exec provisioner. I wanted to create a database and collection after the creation. In this case, I use Azure CLI to create these and call it after the cosmod db account has been created. You can pass the parameter to it.
Also you can Contribute Azure Provider Repo if you like. I develop the LogAnalytics provider which I wanted. This is my contribution pull request. When you send a pull request, people discuss and review it very gently and tell me how to improve the code. It was totally fun experience. I‚Äôd like to try to contribute Stream Analytics and CosmosDB this time. If you want to contribute it, you can refer my pull request, through the conversation, you can learn what is required to merging your pull request.
Also you can contrbute to write a module. For example, You can refer the module repo from this page.
I deploy EventHubs, Steram Analytics, and CosmosDB. In this case, I need to do these things.
Since, The hardest part was how to configure the Stream Analytics. We can‚Äôt find exact sample for EventHubs settings for ARM template. I try to configure these then try to download the template, I can‚Äôt find any settings for the Input/Output/Query part structure. However, we can refer two resources for this purpose.
I share the whole samples for deploying / configuring EventHubs, Stream Analytics, and CosmosDB. I download the ARM template part for StreamAnalytics and modify Input and Output part.
Terraform is very good tool to deploy SaaS/PaaS/Serverless resource to the Azure. It helps us to write human readable code with simple way. I‚Äôd like to contribute Stream Anaytics / CosmosDB provider to remove ARM parts of this solution.
Resources
Senior Software Engineer ‚Äî Microsoft
58 
58¬†
58 
Senior Software Engineer ‚Äî Microsoft
"
https://blog.cloudboost.io/serverless-the-next-level-of-abstraction-30f2003a49e3?source=search_post---------126,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
If you look at the history of software development, writing and maintaining software has been a very complicated & time consuming process. Making software development easier and faster by improving developer productivity literally saves companies thousands or millions of dollars annually and this is exactly the function that‚Äôs being optimised by many Cloud Vendors around the world.
Before we dive into what serverless actually is, let me give you a quick recap on how Cloud evolved in the last couple of decades and why it is the way it is today and lastly, why serverless is the next big thing.
To optimise for developer productivity and cost of running apps and services in the last decade ‚Äî cloud vendors have introduced IaaS, where companies don‚Äôt have to buy hardware to host their apps, they can ‚Äúrent‚Äù the hardware out from any of the cloud vendor and can only pay for what they use. This is called Infrastructure as a Service (IaaS for short) where cloud vendors provides virtual machines to these companies where they can ssh into and install and maintain their own OS, and can install any software and service on them. It saved companies a lot of money by not having to buy hardware physically, hire a ops team to maintain the server uptime, pay for energy to power and cool these machines, but you still had to install and maintain operating systems, make sure your server is secure by installing security patches and so forth.
So, In short IaaS is ‚ÄúI‚Äôll give you virtual machines and you can SSH in them, and install anything you like.‚Äù
Some of the best known IaaS are EC2, Azure Virtual Machines, Google Compute Engine, etc.
IaaS did improve a lot of productivity when compared to legacy enterprise IT, but it did took a lot of work to manage these virtual machines and maintain it (like installing patches, configuring firewalls, etc). Developers wanted a way to just write applications and give it to the Cloud Provider which would host it for them and they would not worry about OS‚Äôes, Security, etc. That‚Äôs where Platform as a Service (or PaaS for short) comes in. Machines are abstracted away from you and you cant SSH into them. All you can do is, upload your app and a cloud provider would run it for you. Cloud Provider would take care of installing and maintaining OS, patching it underneath, so you don‚Äôt have to and with every every abstraction, you lose a little control over your environment but gain an order of magnitude of productivity.
Some of the best known Platform as a Service today are Heroku, Amazon Elastic Beanstalk, Google App Engine, and more.
Think of serverless as an abstraction over PaaS. There are actually two types of serverless which I‚Äôll talk about briefly here :
Cost savings: One of the biggest benefits of serverless computing is that you only pay for the execution time of your code. In case of IaaS or PaaS you would be charged even if your application is idle whereas in serverless there is no concept of ‚Äúidle‚Äù resources and you are not charged if the function is not executed. This is especially helpful for applications that are only used a few times an hour, which means any dedicated hardware, VMs, or containers would be sitting idle for the majority of the time, and a user would be charged for underutilized resources. With serverless computing, you could build out an entire infrastructure and not pay for any compute resources until customers start using the application.
Scale: Scalability is also simple with a serverless architecture. If your code needs to scale, the platform will make copies of the function to handle the load. An example of this would be if you‚Äôre building a service like Yelp, then your peak demand is only during breakfast, lunch and dinner hours. So, the platform would automatically scale your code to thousands of instances automatically during your peak hours and would automatically scale it down when the demand subsides and you only pay for the time your code actually executes.
Developer Productivity: Serverless computing is ideal for teams that need to quickly develop, prototype, and iterate. Development is quicker since there aren‚Äôt any dependencies on DevOps. Code is usually single threaded which makes debugging easier. The build process is also broken down into smaller and more manageable chunks of code. This increases the number of changes that can be pushed through the CI/CD pipeline, resulting in faster deployment and much tighter feedback loop with users.
Less Administration and Ops: Most of the ops element of your infrastructure is eliminated. There are zero servers to manage, maintain, and scale.
Thank you for reading. I‚Äôm Nawaz Dhandala and I‚Äôm the founder of CloudBoost.io. CloudBoost is a serverless and a backend as a service company which does data-storage, search, realtime, and a whole lot more. CloudBoost is open source on GitHub under a liberal Apache 2 license. If you want to truly go server-less, you can also check out the managed offering here.
The Realtime JavaScript Backend.
15 
15¬†claps
15 
Written by
Founder, HackerBay.io
The Realtime JavaScript Backend.
Written by
Founder, HackerBay.io
The Realtime JavaScript Backend.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/google-cloud/a-to-z-of-google-cloud-platform-gcp-a-personal-selection-a-is-for-app-engine-and-api-s-311d408249f8?source=search_post---------127,"There are currently no responses for this story.
Be the first to respond.
App Engine is GCP‚Äôs PaaS .
There are lots of real cool things about App Engine and I‚Äôm only going to talk briefly about one of them here Features
I feel ‚Äúfeatures‚Äù reflects the philosophy of being the ‚Äúsimplest‚Äù cloud in that it just provides functionality you‚Äôd otherwise have to code or feed and water yourself.
These are mostly API‚Äôs to services that are used frequently for a lot of use cases. Some are in GA others in beta or alpha .
Consider basic Image manipulation such as resizing and reformatting . This is a common requirement so App engine provides an images API that makes it super easy. The Images service can accept image data directly from the app, or it can use data retrieved from Google Cloud Storage.
Caching that‚Äôs a super common requirement so App Engine provides memcache Those are examples of just two of the really useful features where you as the developer don‚Äôt have to spend time writing the functionality or looking after the service yourself. Basically you just consume it.
At the time of writing App Engine provided an impressive list of features .
Using features helps you deliver basic functionality quickly and integration with App Engine makes it super easy to start using the features .
It was when I first started playing around with App Engine it became obvious to me that features had a lot in common with API management systems only without the trendy label. ( A bit like Devops being nothing really new but once it got a label well..)
To understand why I‚Äôd be bold enough to stick my neck out and say that well you need to understand what I mean by API Management :
Well I reckon App Engine features meets that criteria.
A mechanism to allow the discovery of API ‚Äî Via the console. You can start at the features table and drill down into the feature . If client‚Äôs consuming then this is a contract between the application and the clients ( see Endpoints )
A documented API so easily consumed ‚Äî API is documented for supported languages: App Engine Python API‚Äôs , Google App Engine Java API , PHP App Engine API‚Äôs
Each feature also has a dedicated docs page for the supported language which shows how to consume the service and lists the quotas e.g the Images Python API Overview
A Gateway that secures access to the traffic between the APIs and its consumers and provides metrics on usage ‚Äî App Engine API‚Äôs have quotas . Authorisation and authentication requires having a GCP account to access . Cloud endpoints generate APIs and client libraries from an App Engine application.
Lifecycle Management to manage the process of designing, developing, deploying, versioning and retiring API‚Äôs ‚Äî Google develops & provides the API‚Äôs . Note: For third party supplied features you need to check with those suppliers
I don‚Äôt believe I‚Äôm being disingenuous with making a direct analogy !
Before I leave talking about App Engine‚Äôs features I just wanted to touch lightly ( okay one lightly the other not so) on two features I found particularly cool and happen to fit in with my API management viewpoint. URL fetch and Cloud endpoints . So yes I ‚Äòm going to sneak in the letter E here as Endpoints are actually called out as a GCP product!
URL Fetch
Well the name of the feature( service) here is pretty succinct. It‚Äôs a service that allows you to issue a http or https request and receive a response ! These can be other app engine applications or other applications on the web.
So not trivialising it at all it‚Äôs a way for your application to easily deal with http and https requests and responses.
The service has some rules around it to prevent recursive requests i.e no calling yourself and time outs so it‚Äôs not waiting for a response for ever. It also supports both synchronous and asynchronous calls.There are also quotas assigned.
Cloud Endpoints
This feature is super cool. As a way to improve developer productivity as it provides a way to generate APIs and client libraries from an App Engine application. You will probably come across this being referred to as an API backend which may have you scratching your head as to what exactly that means. A far better description of it I feel is as an API server for your application and indeed it is referred to as such in some of the docs . In a nutshell Cloud endpoints performs business logic and other functions for Android, iOS clients and JavaScript web clients. It provides access to App engine‚Äôs features ( I am pretty sure I am not a fan of the word features though way of describing the services available via App Engine) .
So if you‚Äôre still not clear as to what they are I have regurgitated the official docs for a succinct description of what Endpoints are and how they remove a level of lower level coding for basic functionality and thus allow you to focus on your usp:
‚ÄúCloud endpoints Create RESTful services and make them accessible to iOS, Android and Javascript clients. Automatically generate client libraries to make wiring up the frontend easy. Built-in features include denial-of-service protection, OAuth 2.0 support and client key management‚Äù
So what exactly do you need to do to create your own API server and application that uses it :
It‚Äôs all a little inception like as in my analogy App Engine features and Endpoints (which is a feature itself) can technically both be considered as API gateways/ servers.
Google Cloud community articles and blogs
20 
20¬†claps
20 
Written by
Chocolate addict - I have it under control really I do. I do stuff involving cloudy tech. Tweets my own so only me to blame, except for retweets.
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
Written by
Chocolate addict - I have it under control really I do. I do stuff involving cloudy tech. Tweets my own so only me to blame, except for retweets.
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@deeeet/practices-as-a-platform-engineer-2020-200fe6c8e996?source=search_post---------128,"Sign in
There are currently no responses for this story.
Be the first to respond.
deeeet
Jun 16, 2020¬∑5 min read
I‚Äôve been working as a platform engineer (platformer) for almost 5 years. In the previous company, I worked on the internal PaaS based on Cloud Foundry and, in the current company, I‚Äôve been working on the microservices platform based on Kubernetes.
If you‚Äôve done one thing for 5 years, you will have things that you take for granted as a matter of habit and become the basis of daily decision making, which is neutral from specific technologies. In this post, I wrote down these things as practices of platform engineers who build platform for developers. The things I listed below are not special. I think you‚Äôve heard or seen these things somewhere. These are just results from daily inputs or experiences with the team I‚Äôve been working.
Since they are just practices, you won‚Äôt be able to use them for 5 or 10 years and they should be updated when the trend or the world changes. This is just a record of 2020.
Principal YAML engineer at Mercari platform group. https;://twitter.com/deeeet
See all (24)
13 
13¬†claps
13 
Principal YAML engineer at Mercari platform group. https;://twitter.com/deeeet
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@garethr/platform-as-a-service-and-the-network-gap-817849715f0a?source=search_post---------129,"Sign in
There are currently no responses for this story.
Be the first to respond.
Gareth Rushgrove
Aug 11, 2013¬∑5 min read
I'm a big fan of the Platform as a Service (PaaS) model of operating web application infrastructure. But I'm a much bigger user and exponent of Infrastructure as a Service (IaaS) products within my current role working for the UK Government. This post describes why that is, and hopefully helps anyone else inside other large enterprise organisations reason about the advantages and disadvantages, and helps PaaS vendors and developers understand what I personally thing is a barrier to adoption in that type of organisation.
A quick word of caution, I don‚Äôt know every product inside out. It‚Äôs very possible a PaaS product exists that deals with the problems I will describe. If you know of such a product do let me know.
PaaS products make for the very best demos. Have a working application? Deployment is probably as simple as:
Your app has started to run slowly because visitors are flooding in? Just scale out with something like:
The amount of complexity being hidden is astounding and the ability to move incredibly quickly is obvious for anyone with experience of doing this in a more traditional organisation.
Even small systems are often being built out of many small services these days. Many large organisations have been up to this for a while under the banner of Service Orientated Architecture. I'm a big fan of this approach, in my view it moves operational and organisational complexity back into the development team where its impact can often be minimised by automation. But that‚Äôs a topic for another post.
In a PaaS world having many services is fine. We just have more applications running on the Platform which can be independently scaled out to meet our needs. But services need to communicate with each other somehow, and this is where our problems start. We‚Äôll keep things simple here by assuming communication is over HTTPS (which should be pretty typical) but I don‚Äôt think other protocols make the problem I have go away. The same problem applies if you‚Äôre using a SaaS database for example.
Over what network does my HTTPS internal service call travel? The internet? The internal PaaS vendor‚Äôs network? If the latter, is my traffic travelling over the same network as other clients on the platform? Maybe I'm running my own PaaS in-house. But do I trust everyone else in my very large organisation and want my traffic on the same network as other things I don‚Äôt even know about? Even if it‚Äôs just me do I want internal service traffic mixing with requests coming from the internet? And are all my services created equally with regards what they can and cannot access?
Throw in questions like: is the PaaS supplier running on infrastructure provided by a public IaaS suppliers who you don‚Äôt have a relationship with and you start to question the suitability of the current public PaaS products for building secure service based systems.
You might be thinking, pah, what‚Äôs the worst that can happen? If you work for a small company or a shiny startup that might be completely valid. If on the other hand you‚Äôre working in a regulated environment (say PCI) or dealing with large volumes of highly sensitive information you‚Äôre very likely to have to build systems that provide layers of trust, and to be doing inspection, filtering and integrity checking as requests flow between those layers.
Imagine that I have a service dealing with some sensitive data. If I control the infrastructure (virtualised or not, IaaS provided or not) I‚Äôll make sure that service endpoint isn‚Äôt available to anything that doesn‚Äôt need access to it via my network configuration. If I‚Äôm being more thorough I‚Äôll filter traffic through some sort of proxy that does checking of the content; It should be JSON (or XML), it should meet this schema, It shouldn‚Äôt exceed this rate, it shouldn‚Äôt exceed this payload size or response size, etc. That is before anything even reaches the services application. And that‚Äôs on top of SSL and maybe client certificates.
If I don‚Äôt control the infrastructure, for example when running on a PaaS, I lose some of the ability to have the network protect me. I can probably get some of this back by running my own PaaS on my own infrastructure, but without awareness and a nice interface to that functionality at the PaaS layer I‚Äôm going to lose lots of the benefits of running the PaaS in the first place. It‚Äôs nice that I can scale my application out, but if new instances can‚Äôt connect to the required backend services without some additional network configuration that‚Äôs invisible to the PaaS what use is that?
The question becomes; how to implement security layers within existing PaaS products (without changing them). And my answer is ‚ÄúI don‚Äôt know‚Äù. Yet.
SSL doesn‚Äôt help as much as you‚Äôd like to think here because if I‚Äôm an attacker what I‚Äôm probably going to attack is your buggy code rather than the transport mechanism. SSL doesn‚Äôt protect you from SQL injection or unpatched software or zero-day exploits. If the only thing that my backend service will talk to is my frontend application, an attacker has to compromise two things rather than just ignore the frontend and go after the data. Throw in a filter as described above and it‚Äôs really three things that need to be overcome.
I think part of the solution lies in exposing some of the underlying infrastructure via the PaaS interface. IaaS is often characterised as compute, storage and network. In my experience everyone forgets the network part. In a PaaS world I don‚Äôt want to be exposed to storage details (I just want it to appear infinite and pay for what I use) or virtual machines (I just care about computing power, say RAM, not the number of machines I‚Äôm running on) but I think I do, sometimes, want to be exposed to the (virtual) network configuration.
Hopefully someone working on OpenShift or CloudFoundry or Azure or Heroku or DotCloud or insert PaaS here is already working on this. If not maybe this post will prompt someone to do so.
Software developer, occasional sysadmin, general web, programming and technology geek and curator of Devops Weekly. Engineer at @puppetize. @gdsteam alumnus
9 
9¬†
9 
Software developer, occasional sysadmin, general web, programming and technology geek and curator of Devops Weekly. Engineer at @puppetize. @gdsteam alumnus
"
https://towardsdatascience.com/types-of-cloud-computing-952ae75e07c9?source=search_post---------130,"Sign in
There are currently no responses for this story.
Be the first to respond.
Giorgos Myrianthous
Nov 6, 2021¬∑4 min read
In one of my recent articles I discussed about the deployment models in Cloud Computing, namely private, public and hybrid models. Now apart from deployment models, it‚Äôs equally important to know the three different types of cloud‚Ä¶
"
https://precipitation.io/acronyms-bad-8b63c8d3bffb?source=search_post---------131,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
It‚Äôs time to drop IaaS, PaaS and SaaS as broad definitions for cloud. They create false equivalence, confuse the market and get hijacked by marketeers*.
Whilst the NIST Definition of Cloud Computing attempts to describe three delineated service models for cloud with clear boundaries, it unfortunately describes three delineated service models for cloud.
The problem of course in reality the actual service offerings from cloud providers span the boundaries of IaaS, PaaS, and SaaS.
The current confusion of definitions is often evident in the Container as a Service (CaaS) space where there doesn‚Äôt appear to be a clear definition of what CaaS is, never mind whether it sits in PaaS or IaaS, and the continual comparison to Function as a Service (FaaS) platforms.
We see vendors offering different services for the same core technology, with the differentiation being on the amount of management provided.
In the CaaS world is the difference between an IaaS CaaS and a PaaS CaaS just the amount of management? Is a PaaS CaaS just a more managed IaaS CaaS?
The definition of PaaS, ‚ÄúThe consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment‚Äù, is misleading because it does not describe the degree of control the consumer has, and nature of the application being deployed.
In the case of Azure Container Service (ACS), the IaaS CaaS, it doesn‚Äôt quite meet the PaaS definition as you some level of control of the network and storage, and doesn‚Äôt meet the IaaS definition, as you cannot run arbitrary code on it, but are limited to specific container cluster managers.
How does all of this delineate from a Functions as a Service (FaaS) platform that uses containers under the hood but doesn‚Äôt use it in it‚Äôs marketing material?
By the NIST definition, FaaS services could easily be described as a SaaS platform, though no-one tries to define it as such. You could call FaaS a SaaS CaaS as it‚Äôs just a more managed form of CaaS?
The CaaS IaaS PaaS SaaS identity crises is just a glimpse of why trying to create delineated definitions for overlapping service models just confuses the market.
We need to stop using IaaS, PaaS, and SaaS to define the services and platforms we use or deliver, but rather focus on more specific definitions that clearly highlight service boundaries rather than lazy acronyms.
Ant
*marketeer: Like a buccaneer, but with less swashbuckling, and more exaggeration of loosely grasped topics. Dresses like the cover of a Manning book.
When playing with clouds, expect to get wet‚Ä¶
13 
1
13¬†claps
13 
1
Written by
Figuring it out‚Ä¶
When playing with clouds, expect to get wet‚Ä¶
Written by
Figuring it out‚Ä¶
When playing with clouds, expect to get wet‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/microsoftazure/deploying-java-ee-apps-to-azure-part-1-e895284b46d1?source=search_post---------132,"There are currently no responses for this story.
Be the first to respond.
There are a multitude of options for cloud based application development ranging from traditional IaaS (Infrastructure-as-a-Service), PaaS (Platform-as-a-Service) and CaaS (Containers-as-a-Service) all the way to Kubernetes and Serverless (and probably some more which I might be missing!). Think of it as a spectrum rather than a ‚Äúone size fits all model‚Äù, with each option having its pros and cons. Ultimately, every scenario is unique and the final choice is driven by requirements ‚Äî but its always good to know that you have ‚Äúchoices‚Äù at your disposal!
This is the first of a series of blogs that will walk you through one of the options of running Java EE applications on Azure. We will follow the most basic approach for deploying our Java EE app to an application server which is set up in a Virtual Machine on Microsoft Azure along with the Azure Database for PostgreSQL service as the backend database. In essence, this is the combination of IaaS (Azure VM) along with a PaaS (managed PostgreSQL on Azure)
Other options such as containers and Kubernetes will be covered in upcoming posts
The example used in the blog post is a simple three-tier application that uses Java EE 8 specifications such as JAX-RS, EJB, CDI, JPA, JSF, Bean Validation. We will use the Payara Server to deploy the application and use PostgreSQL as the relational database.
During the course of the tutorial, we will cover:
Except for minor changes, the application used in this tutorial has been adapted from this project by Reza Rahman
You will need a Microsoft Azure account and the Azure CLI to work through the tutorial.
If you don‚Äôt have a Microsoft Azure account, go ahead and sign up for a free one! The Azure CLI is a cross-platform command-line experience for managing Azure resources ‚Äî please install it using these instructions.
Set your Azure Subscription ID using the Azure CLI which will be used for this tutorial.
To set your Azure subscription ID
Create a resource group that will contain all the services (resources) which you will create as a part of this tutorial. A resource group is like a logical container that holds related resources for an Azure solution. The resource group includes those resources that you want to manage as a group.
To create a resource group
Azure Database for PostgreSQL is a relational database service based on the open-source Postgres database engine. It‚Äôs a fully managed database-as-a-service offering which is available in two deployment options, as a single server, and as a Hyperscale (Citus) cluster
We will be using the single server option for the purposes of this tutorial
We will use the az postgres server createcommand to create a Postgres server instance on Azure. First, set up some of the server properties such as the name, admin user, etc.
For storage and SKU options, please refer to the documentation
And, then invoke the command to initiate the database instance creation:
The provisioning process will take a few minutes.
To check the details of the Postgres database instance you just provisioned, invoke az postgres server show command
You should get a JSON response. Please note down the value for the fullyQualifiedDomainName attribute as you will be using this to connect to the Postgres instance later.
It should be of the format: [AZURE_POSTGRES_DB_NAME].postgres.database.azure.com
We will use a Virtual machine on Azure to host the Payara JavaEE application server. To be specific, this will be a Ubuntu based Linux VM.
Let‚Äôs start by setting up the required information for the VM
We will use the az vm create command to create the VM instance
The VM provisioning will take a few minutes.
You need to get the public IP address of the VM. Do so using the az vm list-ip-addresses command
You will see a JSON response ‚Äî take a look at the publicIpAddresses section and note down the value of theipAddress property. Configure it as an environment variable as you will be using it in the subsequent steps
The Postgres database is not accessible by default. Use the az postgres server firewall-rule create command to create a firewall rule to explicitly allow the VM to access the Postgres instance. This will allow the JavaEE application deployed inside the VM to communicate with Postgres.
Payara Server is an open source application server derived from GlassFish that supports reliable and secure deployments of Java EE (Jakarta EE) and MicroProfileapplications in any environment: on-premise, in the cloud or hybrid.
Check out the project on GitHub or dive into its documentation to learn more!
SSH into the Linux VM you just provisioned using the username and VM IP
Enter the password once prompted. Once you‚Äôre logged into the Virtual Machine, proceed with the next steps.
Before installing the Payara server, we need to set up a few things such as JDK, etc.
We are using Payara server version 5.193.1 which is the latest at the time of writing this tutorial. The setup simply involves downloading and extracting the server zip file.
To confirm, run ls ~/payara5/
Start the server using asadmin
It will take a few moments for the server to boot up. You should see the following logs:
Now that we have the VM as well as Payara server up and running, we can now deploy our application.
Start by cloning the Git repository
The web.xml file (under javaee-on-azure-iaas/src/main/webapp/WEB-INF) needs to be updated with the JDBC URL for the Postgres database on Azure. This is present in the <url> attribute of the <data-source section and its format is as follows:
Here is the list of placeholders which form a part of the JDBC URL:
Set the required values
Simply use these commands to replace
Here is an e.g. of what the <data-source> section will look like:
The application is now configured. Let‚Äôs build it!
You should have the WAR file available. To confirm
As a final step in the application setup process, let‚Äôs download the JDBC driver for Postgres and add it to Payara server
We are using driver version 42.2.8
Add the JAR to Payara, simply invoke asadmin add-library
Finally, to deploy the WAR file, just copy it to the domain autodeploy folder
The deployment will take some time. In the meanwhile, you can track the logs using:
You should see log messages indicating successful deployment of the javaee-cafe application
It‚Äôs time to test drive the JavaEE app! To start off, we can access the application using a web browser. But, just like the Postgres instance, the virtual machine which hosts the Payara server along with the application is also protected by default i.e. you cannot access it from the public internet.
We need to create a firewall rule using the az vm open-port to access it from our local machine. We just need to expose port 8080 since that's the default HTTP port which Payara server uses
Use your browser to access http://[ENTER_VM_IP]:8080/javaee-cafe. You can use the UI to create, delete and see coffees.
The application also exposes a REST API for creating, deleting and listing coffees.
Create coffees
Get all coffees
You should see a JSON response listing both the coffee options you just added
Get a coffee by ID
Delete a coffee by ID
Notice that cappuccino is now deleted
Once you are done exploring the application, you can delete the resources. Since we used a resource group, it's easy executing a single command.
Please be aware that this will delete all the resources in the group which includes the ones you created as part of the tutorial (VM, Postgres etc.) as well as any other service instances you might have if you used an already existing resource group
You learned how to deploy a Java EE application to Azure using an app server deployed to a Virtual Machine along with a managed database offering for long term persistence.
As mentioned earlier, each option comes with its own pros and cons. In this case, you have complete control over your application, its deployment infrastructure, the way you scale it, etc. On the other hand, remember that managing the infrastructure, sizing it for your application, securing it, etc. is a set of responsibilities that you have to take on along with delivering core business value as a part of the app functionality.
The next part will dive into how to use a Docker container platform to deploy your Java EE applications. Stay tuned!
Any language.
101 
101¬†claps
101 
Any language. Any platform. Our team is focused on making the world more amazing for developers and IT operations communities with the best that Microsoft Azure can provide. If you want to contribute in this journey with us, contact us at medium@microsoft.com
Written by
Azure Cosmos DB at Microsoft | I like Databases, Go, Kubernetes
Any language. Any platform. Our team is focused on making the world more amazing for developers and IT operations communities with the best that Microsoft Azure can provide. If you want to contribute in this journey with us, contact us at medium@microsoft.com
"
https://medium.com/martinomburajr/building-a-go-web-app-from-scratch-to-deploying-on-google-cloud-part-6-deploying-our-go-app-on-cb2fe6f68ed2?source=search_post---------133,"There are currently no responses for this story.
Be the first to respond.
Between Tutorial #1 and this one we have created our Go application, deployed it on Google‚Äôs Platform as a Service (PaaS) offering i.e Google App Engine (GAE), we have deployed it on Google‚Äôs Infrastructure as a Service (IaaS) i.e Google Compute Engine (GCE) and we‚Äôve‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/hackernoon/simplifying-docker-management-with-exoframe-9275e92c7406?source=search_post---------134,"There are currently no responses for this story.
Be the first to respond.
Docker is an amazing tool. It can help you setup self-hosted PaaS, scale things, do Android CI and even develop for IoT.But even though Docker is a great tool, it has its own problems.
First of all ‚Äî it‚Äôs not that easy to use. Mainly because there are so many different flags you can use during pretty much every step. Even after using it daily for the past few years, I still have to open the manual to remember how to correctly forward ports or how to set resource constraints.
Then there‚Äôs a challenge of setting up an authentication, access control as well as ownership of the images and running containers. Right now you can setup authorization using Docker plugins, but it‚Äôs far from simple. And it doesn‚Äôt give you a way to define ownership. You can, of course, use labels or security opts to set the user. But you‚Äôd have to do that manually.
And that‚Äôs if you know how to use Docker. In our research group, we recently decided to migrate all our demos and services to Docker. Turns out it‚Äôs quite hard to teach people what Docker is and how to properly use it. And it‚Äôs even harder to make everyone set correct labels and security opts to make sure admins know e.g. who is responsible for container causing trouble.
And so I set out to create a better, simpler way of working with Docker.
Update: Exoframe beta is out! Simpler, faster, smaller and as user-friendly as ever.
The idea behind Exoframe is quite simple ‚Äî to help users tackle the aforementioned problems in a simple intuitive way with as little configuration as possible. Sort of, to give you a way to use it as a power armor to move those heavy docker containers around.
Exoframe consists of two parts: Exoframe server and Exoframe CLI.
Exoframe server is installed alongside your Docker on the remote server you want to use for deployment. It is essentially as a smart proxy for Docker remote API with authentication, access control and ownership features.
Exoframe CLI is installed on your local machine and is used for all the common Docker tasks like building and deploying images using Exoframe server API.
First, you will need to setup Exoframe server.Since your server should already be running docker, it‚Äôs quite easy to do:
This will start an Exoframe server, forward port 3000 to your host and init default Exoframe server config. Be sure to navigate to /path/to/exoframe-folder and adjust username and password in server.config.yml because default admin:admin pair is not exactly secure :)You can also configure additional server auth plugins (e.g. LDAP or your other corporate user DB) that can be used instead of config-based user list.
Done. The server is ready to work!
Next, you will need to setup Exoframe CLI on your local machine.Since Exoframe is written using Node.js, you will need to have Node.js (v6 or later) installed. Once you have it, simply execute npm install command to get Exoframe CLI:
Once install finishes, you can specify your server endpoint using the following command:
Then execute ‚Äúexoframe login‚Äù to authenticate on the server and you are ready to go!
Now let‚Äôs see it in action! We are going to create, build and deploy a simple static HTML project.You can find all the steps explained below in one simple screencast on asciinema:
asciinema.org
First, create a new folder and add a new index.html file that has some content, e.g.:
Then, execute ‚Äúexoframe build‚Äù and pick a name for your image (or just leave it as a default one):
At this point, Exoframe will automatically detect the project type and pick a suitable Dockerfile for it. Since we only have one index.html file, Exoframe reasons that it might be suitable for basic Nginx image.This detection is done using the templating engine. Templates are simple Node.js packages that provide a set of methods to detect if a project is suitable for them, ignore files, add type-specific labels and ask a user for additional input if required. The output of the template is a complete Dockerfile that is used to build a project.You can find an example of Nginx template that is used in this case on GitHub.
Once the build is finished, you can get list of your owned images and services using ‚Äúexoframe list‚Äù command:
Now that you have built a new image, let‚Äôs deploy it.Simply execute ‚Äúexoframe deploy‚Äù and you will get a list of available images to deploy ‚Äî no need to remember all of your image names:
Once you‚Äôve selected the image you want to deploy, Exoframe will ask what exactly do you want to do during the deployment ‚Äî do your want to forward ports, specify restart policy, etc?
In this case we only want to forward ports, so that‚Äôs what is selected in the screenshot above. After you hit enter, Exoframe will present you with additional inputs that will guide you through all of the selected actions, e.g. for ports input looks like this:
Note that Exoframe shows you inline how the port mappings should look and which of the ports is inside a container and on a host. As you can see, it also allows you to map multiple ports.
After hitting enter, you will see a message that says the image was successfully deployed. You can now see your new service in a list that we have already called before using ‚Äúexoframe list‚Äù:
As you can see, the list now includes running html-test service with full info about it ‚Äî forwarded ports, status, template, name.If you open your browser at http://your.domain you should see the static HTML you‚Äôd created.
Now that you‚Äôve seen that service works, let‚Äôs stop and remove it.You can use ‚Äúexoframe stop‚Äù command to stop your running services and ‚Äúexoframe rm‚Äù to remove stopped services. Once again, you don‚Äôt need to remember names of your services, if you don‚Äôt provide service name ‚Äî Exoframe will present you with an interactive list:
Exoframe also provides a way to interact with images from registries.Using ‚Äúexoframe pull <image>‚Äù will pull given image from docker registry.You can then get list of all locally available registry images by executing ‚Äúexoframe list public‚Äù command:
Deployment of the images from registry can be done by executing deploy command with an additional image argument, e.g.:
After that running services can be managed in the same manner as shown above.
Exoframe is still in its alpha stage and some features are missing here and there. But I‚Äôve been already using it to manage and deploy a set of demos on my own servers and it made my life a lot easier.
Exoframe is available now on GitHub. Free. Licensed under MIT.Any feedback you might have is highly appreciated.
Hacker Noon is how hackers start their afternoons. We‚Äôre a part of the @AMI family. We are now accepting submissions and happy to discuss advertising & sponsorship opportunities.
If you enjoyed this story, we recommend reading our latest tech stories and trending tech stories. Until next time, don‚Äôt take the realities of the world for granted!
#BlackLivesMatter
35 
2
Thanks to Ivan Ermilov.¬†
No rights reserved
¬†by the author.
how hackers start their afternoons. the real shit is on hackernoon.com.¬†Take a look.

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
35¬†claps
35 
2
Written by
Hi, I‚Äôm Tim! I talk about webdev, javascript and big data.
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Written by
Hi, I‚Äôm Tim! I talk about webdev, javascript and big data.
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/akropolis/polkahub-scalable-blockchain-infrastructure-5d5696fc0d60?source=search_post---------135,"There are currently no responses for this story.
Be the first to respond.
Web3 Foundation has awarded Akropolis PaaS solution a grant to continue its development. Please check announcement here:
medium.com
We are happy to re-introduce PolkaHub, a Web3Foundation grantee project by the Akropolis team. In this article, we will share what this product is about, how it benefits the Polkadot ecosystem, and most importantly, what problems does it solve.
Polkahub is a DevOps tool we wish existed when we started researching and building on Substrate.
New languages, frameworks, version control systems, databases, architectures, and other bleeding-edge technologies are gaining ground in the space. Especially in a fast-paced environment of the Web3 ecosystem. You need containers and microservices to support infrastructure work and be easily updatable.
Having launched our own Substrate-Based Chain since February 2019, we encountered the challenges that the rapidly changing web3 infrastructure brings with each upgrade.
We concluded back then, that keeping the infrastructure up to date becomes time-consuming and constantly requires attention. This delays the development process. Creating this PaaS solution will allow developers to fully focus on the development of their own Substrate-based chains or applications, rather than setting up and maintaining infrastructure.
Polkahub is a fast, scalable cloud infrastructure for Substrate based chains, a ‚ÄúPlatform-as-a-Service (PaaS) for Substrate Nodes‚Äù, inspired by Heroku. Heroku is a platform as a service based on a managed container system, with integrated data services and a powerful ecosystem, for deploying and running modern apps.
Polkahub aims to create a managed container system. The proposed system enables automatic updates and resource management for running nodes, additionally providing templates for launching Substrate based chains. It provides Substrate based chain developers with the ability to launch and manage network infrastructure using our command line utility and the ability to provide public node access, with a uniform standard for packaging and deploying applications to cloud infrastructure.
Substrate-based chain developers: use Polkahub to build serverless public node infrastructure. We offer the simplest way to deploy it with the git command. Additionally, through Polkahub, all the information needed for dApp developers (public node IP address, API specification, etc.) will be in one place, simplifying the onboarding of dApp developers to Substrate based chains.
dApp developers: find information, connect to public node, call contracts and so on via RPC/API/Sockets, by using the public node infrastructure powered by Polkahub.
Validators: node deployment made easy through this PaaS. The docker containers prepared by Substrate-based chain developers will be loaded into the Polkahub marketplace ‚Äî anyone who wants to become a validator can enter the marketplace, choose a Docker container and deploy it. PolkaHub creates an abstraction layer for node deployment for validators.
What benefits does it bring to the Polkadot ecosystem?
Polkahub has been presented (and demoed) at the DOTCon by our developers Alex Maz and Alex Gnatovskyi. As we received very positive feedback from the community, we decided to continue building the project, and make significant improvements. We would like to thank Web3 Foundation for supporting this initiative.
We will be ready to release PolkaHub in the near future ‚Äî we are aiming that, at the launch of the Polkadot mainnet, all developers in the ecosystem can use the platform and attract more people into the network.
Stay tuned for future updates!
Website: https://akropolis.io/
Twitter: https://twitter.com/akropolisio
Telegram: https://t.me/akropolis_official
Do you have any questions? Reach out through email team@akropolis.io or via Telegram.
The Financial Protocol for the Informal Economy
144 
144¬†claps
144 
Written by
Akropolis is a provider of decentralized finance products that curates sustainable yield generation strategies on multiple chains for DeFi users.
The Financial Protocol for the Informal Economy
Written by
Akropolis is a provider of decentralized finance products that curates sustainable yield generation strategies on multiple chains for DeFi users.
The Financial Protocol for the Informal Economy
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://faun.pub/docker-in-a-nutshell-ed2c05cfcfd5?source=search_post---------136,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/kiwicode/insight-saas-17-low-code-or-no-code-is-not-the-future-e022817c252?source=search_post---------137,"There are currently no responses for this story.
Be the first to respond.
We discussed PaaS in the last post ‚ÄòInsight: SaaS (16) PaaS‚Äô; tonight, we‚Äôll talk about the popular Low Code and No Code.
Low Code and No Code platforms are where applications can be built with little or no code. Users can rapidly create a bespoke App by dragging and dropping. The interface or business process generated by the user will be converted into a fixed code combination in these Low Code and No Code platforms, which will have a predetermined conversion algorithm. This will surely lengthen development time, but it has a number of difficult problems to overcome, so I‚Äôm not optimistic that Low Code or No Code will be a viable alternative to programming.
If you wish to entirely replace computer languages as a means of writing programs, you‚Äôll need an equivalent level of expressive capacity, which is unachievable for those dragging graphics. I‚Äôd want to use a very simple scenario as an example. The application contains two components: a switch and a button. The button is blue and clickable when the switch is turned on. When the switch is turned off, the button turns gray and is unable to be pressed.
A boolean variable must be set in the coding. The bool value can be changed by the switch. The Button becomes blue and clickable when the bool variable is true. It is turned to gray and not clickable when it is false. In the Low Code / No Code platform, it is difficult for you to complete the entry of this critical info by dragging and dropping. You can easily drag and drop the blue button and the gray button, but you cannot hook the switch to the button. The Low Code / No Code platform hides the information that they don‚Äôt want you to enter. The details in the programming are not absent; rather, it is automatically replaced. Low Code / No Code is convenient to use, however, flexibility is severely limited.
Alexander Ilg writes:
With low-code, you are a prisoner of the framework or tool you use.
Low Code and No Code can address the problem in some scenarios. Extending the game to indefinitely complex situations is doomed to fail. Low Code / No Code can also solve customer problems in a flexible manner, but it is constrained by the boundaries set by itself. It is unable to meet the rigorous customization requirements.
All Low Code / No Code programs are similar to black boxes. You have no influence over its internal quality. When you employ some platforms‚Äô conversion code snippet feature, you‚Äôll discover that these scripts can‚Äôt be simply transplanted into your project. Essentially, all of the codes for the Low Code / No Code platform‚Äôs visualization components are converted directly from the drawing. Engineers should not use this directly either.
Using low code to produce code that does not adhere to established best practices could violate an organization‚Äôs compliance measures.
And this kind of black box is still in its infancy. Adding some useful open source libraries to your Project is practically impossible. In order to accomplish rapid drag-and-drop customization, Low Code / No Code will muck with the internal code implementation, making it hard to connect other libraries. This is due to the Black box‚Äôs closed nature. You have no choice but to accept; you cannot participate in changing its output.
As a result, the company with the core positioning of Low Code / No Code is not very good. It has a few flaws:
Low Code / No Code is frequently used in SaaS firms‚Äô PaaS platforms. The positioning of the SaaS company is clear: it aims to answer a certain sort of client problem. These PaaS are natural extensions of the same scenario, with No Code and Low Code being particularly appropriate.
Is it possible that Low Code will solve the problem of expressiveness in the future without being as sophisticated as computer languages appear to be? To achieve this with the same degree of info, you must develop a new mode of expression that is distinct from human language.
Friends, be wary if you wish to develop the Low Code / No Code platform.
Merry Christmas! The next article ‚ÄòInsight: SaaS (18) Common pricing model for SaaS (part 1)‚Äô is published. Simply send me some claps and feedback if you enjoyed my article.
If you want to join our product ‚Äî Kiwicode (a code generation SaaS)‚Äôs waitlist, click here.
Let the computer program itself.
169 
169¬†claps
169 
Written by
Plan to build a Code Generation SaaS company in the US. Join the waitlist here ‚Äî https://www.kiwicode-service.com/waitlist
Create your app, and generate its code in Kiwicode. Kiwicode enables you to design Apps fast with our tools and turn it into a runnable code project.
Written by
Plan to build a Code Generation SaaS company in the US. Join the waitlist here ‚Äî https://www.kiwicode-service.com/waitlist
Create your app, and generate its code in Kiwicode. Kiwicode enables you to design Apps fast with our tools and turn it into a runnable code project.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@k33g_org/d%C3%A9ployer-un-runner-gitlab-sur-clever-cloud-2a804d00d1ab?source=search_post---------138,"Sign in
There are currently no responses for this story.
Be the first to respond.
Philippe Charri√®re
Jan 22, 2018¬∑4 min read
Clever Cloud (https://www.clever-cloud.com/) est une plateforme de type PaaS sur laquelle vous pouvez d√©ployer facilement vos WebApps par un simple git push de votre code source (cf. https://www.clever-cloud.com/doc/clever-cloud-overview/add-application/).
Mais vous pouvez d√©ployer autre chose que du code. Et en ce dimanche pluvieux, j‚Äôai d√©cid√© de d√©ployer un runner GitLab sur Clever Cloud. Un runner GitLab, c‚Äôest l‚Äôex√©cutable qui par exemple, va faire les builds de votre projet, va ex√©cuter les tests √† chaque commits‚Ä¶ et enfin qui va ‚Äúdiscuter‚Äù avec GitLab CI pour donner les r√©sultats de builds, tests, ‚Ä¶ √† la plateforme GitLab (GitLab.com ou votre propre instance).
Les possibilit√©s sont nombreuses. Mais aujourd‚Äôhui je vais me limiter √† un simple runner de type ‚Äúshell‚Äù qui va t√©l√©charger les d√©pendances de mon projet node.js et lancer les tests.
Voici un exemple de projet que vous pouvez utiliser:
https://gitlab.com/wey-yu/hello
Pour lancer les tests du projet il suffit de lancer la commande npm test
Pour activer l‚Äôint√©gration continue (la partie CI) dans votre projet GitLab, il vous suffit d‚Äôajouter un fichier .gitlab-ci.yml √† la racine de votre projet
C‚Äôest maintenant que nous allons avoir besoin d‚Äôun runner.
Allez dans les settings de votre projet et choisissez CI/CD puis d√©roulez la partie Runners settings (en cliquant sur le bouton Expand) et vous allez ainsi obtenir 2 param√®tres importants:
Donc notez bien ce token, il va vous servir dans la d√©finition de notre runner.
‚ö†Ô∏è Ensuite, tr√®s important, allez d√©finir un ‚ÄúPersonal Access Token‚Äù dans les settings de votre profil GitLab (et conservez ce deuxi√®me token quelque part).
Pour cr√©er mon runner sur Clever Cloud je vais utiliser un Dokerfile et un fichier de script shell que je d√©ploierais comme une application sur Clever Cloud. Donc, cr√©ez un r√©pertoire my-runner avec les 2 fichiers suivants:
Le Dockerfile va essentiellement servir √† installer le gitlab-runner et nodejs avec npm, puis lancer le fichier go.sh :
Et dans les settings vous verrez que votre runner est bien enregistr√©:
Maintenant, allez dans la rubrique CI/CD de votre repository, s√©lectionnez la sous-rubrique Pipelines:
Cliquez sur le bouton ‚ÄúRun Pipeline‚Äù. Vous allez ensuite pouvoir cr√©er un pipeline.
Donc cliquez sur le bouton ‚ÄúCreate Pipeline‚Äù. Cela va d√©clencher la cr√©ation du pipeline et le d√©marrer en commen√ßant par l‚Äôinstallation des d√©pendances:
En cliquant sur le job qui vous int√©resse (une √©tape du pipeline) vous obtenez le d√©tail de ce qui a √©t√© ex√©cut√© par le runner:
Dor√©navant, √† chaque fois que vous ‚Äúpousserez‚Äù des commits sur master le pipeline sera d√©clench√©.
Voil√†, c‚Äôest tout simple. Maintenant vous savez d√©ployer des runners immutables sur Clever Cloud üôÇ
TAM @GitLab | bots breeder @BotsGarden
44 
2
44¬†
44 
2
TAM @GitLab | bots breeder @BotsGarden
"
https://medium.com/@elbuo8/cheesy-ops-via-now-sh-4a9f16d352bf?source=search_post---------139,"Sign in
There are currently no responses for this story.
Be the first to respond.
elbuo
Oct 28, 2016¬∑2 min read
There is a wide spectrum of complexity for application deployments. Could be as simple as using a PaaS or rolling out your own solution which provides greater power (remember what uncle Ben used to say?). Such power allows you to design different deployment pipelines such as blue/green deployments.
Recently, I had the pleasure to use now to deploy a simple application. It got me thinking about the deployment pipelines I could build with it. I‚Äôll try to detail how to emulate blue/green deployments by using my personal website as an example.
To start, install the now CLI and a JSON CLI utility by running:
Then, proceed to provision a new token for the now CLI by visiting this page. Once you obtain it, export it to your environment by running:
There is support for Node.js applications as well as Docker containers. For the purposes of this demo, I‚Äôll will go with Docker. You can find the source and the Dockerfile that I‚Äôm going to be referring to here.
Now, lets get your domain set up. In your domain‚Äôs DNS settings, add a record similar to this:
If you have your token, the CLIs, your domain properly configured and a Dockerfile, we can get down to the fun part.
Whenever you deploy with now, a whole new deployment is provisioned and a new URL for it is generated. After N deployments, you will have N live versions of your app unless you start removing them. The URLs will be different for each one so if you were targeting a previous deployment, you have to change URLs to obtain the latest one. How can we automate this?
What is going on here?
You can run this N times, and if N times your app boots up successfully, your traffic will be redirected each time. You can configure your favorite CI to the script or simply execute it manually each time you need to update your app. Reverting would be as simple as:
There you have it. Cheap and easy (cheesy) blue/green deployments.
See all (290)
8 
Thanks to Christian Rodriguez.¬†
8¬†claps
8 
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/google-cloud/advantages-of-running-sap-on-google-cloud-2632a862feeb?source=search_post---------140,"There are currently no responses for this story.
Be the first to respond.
Google Cloud Platform (GCP) is certified to run SAP Applications, SAP Cloud Platform (PaaS), and SAP HANA. Read on to learn some highlights of what makes GCP different especially for SAP workloads.
Google Cloud offers per second billing and pay as you go for compute and storage and flexible innovative pricing and for all types of workloads and application use cases.Sustained usage discounts automatically apply up to a 30% discount for instances running for a full month. This is a great default value-add for standard workloads that will run for a undetermined amount of time.Committed usage discounts have no up front costs and offer up to a 57% discount on regular pricing in exchange for a 1 or 3 year commitment. This is most likely where you will want to be if you are considering running SAP on GCP. More on committed usage discounts here.Preemptible VM (pVM) instances are ideal for stateless, batch jobs and fault tolerant processing workloads. PVMs are discounted to about 80% of regular pricing.
Custom machine types allow you to select exactly how much vCPU and memory you need allowing you to break free from a predefined instance type at other vendors.GCP has the fastest instance startup time out of any cloud provider and unparalleled uptime for regions and zones.Performance is underpinned by the private distributed backbone network with over 100 global network point of presence throughout the world putting cloud locations closer to you. GCP has various flexible and quick turn up private interconnect and peering options for your internal mission critical applications, or use Cloud Identity-Aware proxy (Cloud IAP) for identity verification without the need of a VPN.
HANA and BigQuery (BQ) are two very unique data services and can be used together to handle hot, warm, and cold data tiers. Operating HANA DBs can be costly and usually require upkeep with variable OLTP and OLAP workloads. Infrequently accessed HANA OLAP data can be moved from in-memory to a data warehouse like BQ to provide more cost efficiency. BigQuery is pay as you go, regional, has cached queries, SQL query and easy integration. Use SAP Data Services to integrate BQ with HANA and display it all with Tableau or Data Studio to refine and reduce your HANA system footprint.
Do you have Google Analytics 360 running in your business? Use BigQuery for predictive analysis and better insight into your customers. Automate data flows several times a day and visualize with Google Cloud Data Studio. More here.
Google Cloud does not charge for agreements such as the business associate agreement (BAA) required for HIPAA compliance. Google Cloud holds common and uncommon compliance audits to protect clients and enable all industries to do more.
Google has a very unique approach to security working the past 15 years keeping customers safe on Gmail, search and ads. Everything is encrypted on the platform in transit and at rest at no extra cost. Defense at depth at each layer of the infrastructure and network stack. Read more in the Google security white paper.
In 2017 the public cloud is more secure than most customer owned on-premises data centers. More on Google Cloud security here.
Does your organization use G-Suite (Google Apps like Gmail, docs, or drive?) If so it is very easy to integrate Google Cloud projects and users with Google Admin in G-Suite. More here.
Its easy to try the Google Cloud Platform. Check the free tier program here. There is no up front cost or no commitment to try.
Do you work with a system integrator or partner? Google Cloud has partnerships with most major, regional, and boutique specialty SAP partners.
Don‚Äôt worry about deploying and managing instances or complex data warehouse clusters anymore. Focus on productive systems and getting profitable insights from your data. Nearly all services on Google Cloud are fully managed by default.
More info:
The Keyword Blog Post- SAP on Google Cloud Platform, Certifications and MoreSAP on Google CloudSAP HANA on Google Cloud
Google Cloud community articles and blogs
18 
18¬†claps
18 
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
Written by
Customer Engineer, Google Cloud. All views and opinions are my own. @mkahn5
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
"
https://medium.com/@bruntonspall/security-concerns-with-platforms-and-services-in-the-cloud-50837b8fbba0?source=search_post---------141,"Sign in
There are currently no responses for this story.
Be the first to respond.
Michael Brunton-Spall
Jul 2, 2018¬∑6 min read
When we talk about using SaaS or PaaS (or IaaS or even the new Serverless or FunctionAsAService, FaaS) it‚Äôs important that we understand that security concerns change.
Security concerns don‚Äôt change very much based on whether you are using a platform, or infrastructure or just services. They change based on the maturity of the solution and the maturity of the organisation you are using. There is some difference in where the shared responsibility line is drawn, but that‚Äôs not necessarily a primacy in security, as there are other concerns that matter.
To use an example, Amazon is a multi billion dollar company, and has a set of robust and audited security processes in place. Honest Bob‚Äôs Cloud is not, and probably does not. If we were to compare an AWS SaaS product vs Honest Bob‚Äôs IaaS offering, we wouldn‚Äôt naturally say that Honest Bob‚Äôs IaaS is more secure than the AWS SaaS just because it‚Äôs infrastructure and we have more control! To be honest, when we have more to control, sometimes we make security worse because there are many more ways to shoot our own foot.
The SaaS bucket is something into which we lump a variety of offering from a variety of vendors with massively different security implications. Does Office-365, a large productivity suite, have the same security implications as using a small service like MailChimp for our mailing list delivery? How about using Trello to track our cards? What about taking payments via Stripe?
Security assurance models haven‚Äôt kept up with this changing world. It used to be the case that when you outsourced to a vendor, it was a major deal, you could either get an integrator to manage it for you, or you did a lot of work to assess the security of the vendor. Security assurance is often still in this world, of assuming that you need to always ask questions about the physical location of the data center for every little service you manage.
With todays Azure marketplace or AWS marketplace, you can install a database as a service from a third party vendor with the click of a button, and the typical questions about ‚Äúis the data encrypted‚Äù, ‚Äúwhere are the admins located‚Äù etc are either too slow or not always appropriate for this new world
So what am I saying in essence?
If a service can be built on a market leading SaaS product, without customization or special relationships or need to maintain it, then we should use it where possible. Sending emails via Amazon SES, arranging video conferences via Appear.In, storing documents in Office 365 etc.
Where there is personal data involved, we need to be confident that the provider has robust security practices to protect that data. It is our liability if we select a bad provider, so we need to be more careful with those, but that confidence can come from someone with a data protection/security hat on looking at the service and agreeing ‚Äúyes this is common, meets the NCSC‚Äôs SaaS Security Principles and we think it‚Äôs acceptable‚Äù.
The more sensitive the data, or the more of it, the stronger a look we need to take. So for something like Trello, which holds very little personal data, sure, we‚Äôll check that they meet those principles above, and get on. For something hosting a database as a service, we might want a technical person working with a security person to give it a good looking at before we approve it, and we might want specific conditions on that, such as configuring it a certain way, or backing it up a specific way.
But at it‚Äôs essence, there is no fundamental security reason that you‚Äôd not use a SaaS if you‚Äôve already decided that you are willing to outsource your IT to the cloud for anything else. And since you should be using the cloud as your outsourced infrastructure provider, I‚Äôd argue you should always be preferring a SaaS solution where it‚Äôs possible.
When you use *any* outsourced service provision that is multi-tenanted, you have the possibility of the law enforcement seizing/viewing/intercepting your data because they are looking for one of the other tenants. This is worse with smaller providers, or providers who don‚Äôt protect against this with good client data segregation.
I‚Äôve never heard of it actually happening to a major service, and people like Amazon, Apple, Google, Microsoft and other major cloud providers tend to distribute content to devices in such a way that it‚Äôs mirrored (so the removal of a single server doesn‚Äôt reduce the availability), and additionally encrypt the contents so the possession of a single server won‚Äôt get them any data on it.
Secondly, even in the miniscule worst case, that the law enforcement have seized a server under a warrant because they believe that the information on it is relevant to a case, they are only authorised by the law to search the relevant parts of the machine, and they are not allowed to reveal contents that isn‚Äôt covered by the warrant. So we would not consider the device ‚Äúlost‚Äù or the data ‚Äúmade public‚Äù in most cases. We might have to report to the authorities that the data is no longer under our control, but it is under the control of somebody who is responsible to the same authorities.
I‚Äôve seen people suggesting that running your own PaaS on your own network keeps it safe, because it means that the data stays on the corporate network
The concept of networks being the ‚Äúsecurity boundary‚Äù is no longer the right model. When we are talking about data living within the cloud environment, the networking is all virtual, and considering it an extension of the core corporate network simply adds a lot of additional risks to the core network, and reduces all of the security features of the cloud networking stacks that we could use in future. This Armadillo or Castle metaphor for networks hasn‚Äôt been appropriate since network stacks got significantly more capable.
I recommend building separate networks for as small a ‚Äúzone‚Äù as is possible, and use ‚Äúidentity ‚Äù to create appropriately encrypted connections between the services as they need to talk to one another. This concept of ‚Äúidentity as the backplane‚Äù ensures that we can identify each server, identify the users of the server, and build a stack of proofs that are all signed from the base up. This means that we don‚Äôt simply trust that nobody is in the network, but we can assert and verify at all times that the connections between services have high authenticity, as well as use encryption to protect the data in transit.
When it comes to service style solutions, we can authenticate to the service, confirm that the connection is encrypted, and then we need to rely on their assertions about tenant separation. The best SaaS services will be doing the above, and searching for whitepapers or conference presentations from some of the SaaS providers out there will show how seriously they take security
Nerd, Geek, Father. <insert witticism here>
6 
1
6¬†
6 
1
Nerd, Geek, Father. <insert witticism here>
"
https://medium.com/@gmusumeci/how-to-deploy-an-azure-database-for-postgresql-using-terraform-a35a0e0ded68?source=search_post---------142,"Sign in
There are currently no responses for this story.
Be the first to respond.
Guillermo Musumeci
Aug 31, 2020¬∑3 min read
Azure Database for PostgreSQL is an enterprise-ready, fully managed community MySQL, delivered as a PaaS (Platform as a Service).
In this story, we will learn how to deploy PostgreSQL servers and PostgreSQL databases on Azure using Terraform.
About
Write
Help
Legal
Get the Medium app
"
https://architecht.io/kubernetes-201-with-cncf-director-dan-kohn-and-microsofts-gabe-monroy-e53cad7d489?source=search_post---------143,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
If you‚Äôre at all interested in application infrastructure and architectures, application containers and Kubernetes probably need no introduction. However, once you get below the surface of why you should care and what well-known technologies are good for, things can get a bit complicated.
This episode of the ARCHITECHT Show podcast tries to shed some light on the lower levels of ‚Äúcloud-native,‚Äù via interviews with Cloud Native Computing Foundation executive director Dan Kohn and Microsoft Azure container lead (and former Deis co-founder and CTO) Gabe Monroy. Kohn talks about a range of topics, including how the Cloud Native Computing Foundation functions, how its various projects work together and relate to the broader open source ecosystem, and how companies should think about consuming cloud-native technologies. Monroy discusses, among other things, the PaaS-like platform Deis built and why Microsoft acquired the company in April.
Keep reading for highlights from the podcast interviews with Kohn and Monroy, and scroll to the bottom (or click here) for links to listen to the podcast pretty much everywhere else you might want to.
This week‚Äôs episode brought to you by:
In the news segment, co-host Barb Darrow (Fortune) and I discuss Amazon‚Äôs non-compete lawsuit against a former exec, Intel‚Äôs veiled threat to would-be x86 emulators, and fun ‚Äî and hopefully useful ‚Äî AI research out of Microsoft and Facebook.
Here are some highlights from the interviews with Dan Kohn and Gabe Monroy, but anybody interested in the business models around Kubernetes and open source in general, or in the ecosystem of tools now surrounding Docker and Kubernetes, will want to listen to the whole thing. It‚Äôs a new space, but a large and evolving one that‚Äôs worth keeping up with.
‚ÄúI would describe it as our biggest and most important project, and so we‚Äôre definitely very focused on it and trying to support it. And then we have a number of other projects that are complementary to Kubernetes.
‚ÄúBut, I will say that we describe ‚Äòcloud-native‚Äô as being a terrain that‚Äôs newly getting mapped, and we think there‚Äôs many destinations to get there. Kubernetes has some competitors, particularly Mesos‚Äîthat‚Äôs hosted [by] Apache, and one of our members, Mesosphere, is a big backer of it‚Äîand Docker Swarm. And all of our technologies, like Prometheus, as an example, is a great monitoring app that works as well with Docker Swarm and with Mesos.
‚ÄúBut, certainly, if you look at the 10 projects that are now in CNCF, we would describe those as beginning to form something of a cohesive stack that is, and can be, a great open source platform for developing applications for years to come.‚Äù
architecht.io
‚Äú[T]he bigger vision for CNCF is that existing large enterprises with brownfield applications and startups with new greenfield applications‚Äîwhether they‚Äôre running it on their own hardware, bare metal or in the public cloud‚Äîwill say that they want to pick an open source platform to develop on to avoid being locked into any one vendor, and that CNCF‚Äôs set of technologies will be the one that they choose to do that, to deploy those applications.‚Äù
He added, later:
‚ÄúI think the cloud-native paradigm is saying that, ‚ÄòHere is one stack, one set of technologies, that you can move to that will rationalize all of those different investments, and give you a ton more flexibility in terms of your ease in moving between them.‚Äô And we‚Äôre also not saying, ‚ÄòOh, and you need to do a big bang, and have a flag day, and switch everything over.‚Äô
‚Äú‚Ä¶ I know a bank here in New York that threw together a little Kubernetes cluster on their own bare metal, and just had a couple small applications running on it, and had a great experience with it. Now they‚Äôre beginning to move more and more applications onto it, and also running Kubernetes in the public cloud, and looking at having some of those applications migrate up. So, we do try to have a path that makes it easy to dip your toe in, and then get wetter and wetter without even realizing it.‚Äù
architecht.io
‚Äú[M]y claim is that CNCF, by coming later, has looked at some of the predecessors of folks like OpenStack, but also the Apache Software Foundation and the IETF, the Internet Engineering Task Force, and our goal is to not replicate the mistakes of those other organizations ‚Äî instead to get to make entirely new mistakes. In particular, one of the ways that we‚Äôre most different from OpenStack is that we don‚Äôt come up with the projects ourselves and kind of promote them, or bless them. Instead, we‚Äôre going out and looking at existing open source projects, and trying to find the best-in-breed alternatives out there, and then requesting that they come in and join the foundation.‚Äù
‚ÄúPeople are certainly running Kafka on top of Kubernetes, and on top of these other technologies today. It so happens that we‚Äôre talking to a company, Apcera, who may be contributing a technology called NATS, which is essentially a Kafka competitor. So, I think in the bigger scheme of things, you definitely are seeing a trend of a lot of projects are looking at alternatives to the Java language, so that you don‚Äôt have to necessarily deal with the overhead in JVM and some of the annoyances and such. And, so, there‚Äôs definitely a push toward newer languages and, in general, kind of newer frameworks or approaches.
‚Äú‚Ä¶ Another example would be, say, Zookeeper out of Apache, versus etcd, which is widely used as one of the core technologies for Kubernetes ‚Ä¶
‚Äú‚Ä¶ [W]ith CNCF, we‚Äôre trying to glue together a set of technologies and say, ‚ÄòHey, we‚Äôre confident that our projects work well together, and also we think it‚Äôs a totally reasonable choice to swap out individual options for alternative open source projects, or maybe your own internal corporate project, or maybe a proprietary project from a vendor.‚Äô‚Äù
architecht.io
‚ÄúI feel like China today just has this classic example of a second-mover advantage, where, for many of these companies, they just didn‚Äôt have the couple decades of previous investment into proprietary technologies. And so they‚Äôre building up from scratch today, and looking at what the best practices are from around the world, and just able to say, ‚ÄòHey, open source is the way to go, we don‚Äôt want to lock into any vendor, we‚Äôre happy to take advantage of all this other work.‚Äô
‚ÄúAnd, what‚Äôs been fantastic to see is that, I think in earlier times they might‚Äôve just been a, ‚ÄòOK, we‚Äôre just going to consume this,‚Äô but as an example, Huawei actually has two of the committers on the Kubernetes project, and so they‚Äôve been a very early and big supporter of this. And we‚Äôre seeing the cloud companies do exactly the same thing, where all the companies are just moving so fast, and are finding that open source enables them to move more quickly.‚Äù
‚ÄúI think we actually created the original Deis project on GitHub as an answer to a lot of customers who were looking for, effectively, Heroku, but on their own servers. And so this is pre-Docker, we were trying to build that solution out for folks. It became pretty clear over time that container based technology was where we wanted to go. ‚Ä¶
‚ÄúSince then, we sort of took a look at different schedulers in the space and things like Mesos and Docker Swarm and Kubernetes were all things that we had built into the Deis PaaS product, this Heroku-style PaaS system, where users could at one point in the life of the Deis project, select between three different orchestrators. They could say, ‚ÄòWell I want to try Swarm, or I want to try Mesos or Kubernetes.‚Äô
‚ÄúAnd since those early days, we really start to see pretty big convergence around Kubernetes as being both the right technical solution on which to build a system like a PaaS. But also, the community started to develop pretty aggressively behind and line up pretty aggressively behind Kubernetes.‚Äù
architecht.io
‚ÄúPrior to the Microsoft acquisition, I spent a lot of my time in the field working with large customers who are in the midst of their Kubernetes journey. And one of the things I was finding is folks are kind of at the stage where they‚Äôre running a pilot [and] the pilot‚Äôs successful. But typically with a pilot, you select a pretty progressive part of your software team‚Äîfolks who maybe don‚Äôt have as much of a problem getting up to speed on things like Docker and Kubernetes.
‚ÄúBut when you go kind of say, ‚ÄòAlright. We‚Äôre done with the pilot. Let‚Äôs roll this out across the rest of the org,‚Äô well now you‚Äôve got to train 1,000 Java developers on how to use Docker and Kubernetes ‚Ä¶ It‚Äôs just a lot of conceptual overhead that folks are not comfortable getting up to speed with on their own.
‚ÄúAnd so Draft was really designed to answer that question: ‚ÄòI‚Äôm a developer, folks stood up the Kubernetes cluster and they‚Äôre asking me to target it with my new application. How do I do that without drowning in the Docker and Kubernetes documentation?‚Äô
‚Ä¶
‚ÄúSo it‚Äôs a really good answer to folks, and specifically the operations teams who are trying to expose Kubernetes to a large group of developers.‚Äù
architecht.io
‚ÄúI think what‚Äôs drawing people to put things like OpenStack on top of Kubernetes is actually very simple: Managing these VM-based systems without something like Kubernetes in the mix is incredibly complicated. You need to figure out how to do rolling deploys, how to do canaries, how to do intra-cluster service discovery. You have all the same problems you do with operating sort of more-traditional container-based applications as you do with operating an IaaS, the control plane for an IaaS.
‚ÄúAnd so by putting it into Kubernetes, and specifically into a Helm chart, you get this ability to do upgrades of these normally pretty brittle components. But they become much, much less brittle when they‚Äôre running on top of Kubernetes.‚Äù
architecht.io
‚ÄúMicrosoft‚Äôs been doing enterprise software for a long time. And as a result, we built up this incredible field organization and folks who have trusted relationships with people, even if they‚Äôre selling SharePoint licenses or whatever. As we move into the world of open source and container orchestration and things like that, companies still trust their Microsoft reps, that they‚Äôve been working [with] for years.
‚ÄúAnd so the way I look at is, it‚Äôs incumbent upon us to make this stuff really simple for folks in the Microsoft field so that we can help these customers out here who want to do the right thing. They want to, in a lot of cases, get on board with open source technologies like Docker and Kubernetes, things like that. But we‚Äôve got to make this stuff simpler‚Äîmuch, much simpler‚Äîin order to realize that dream.‚Äù
news.architecht.io
Enterprise IT interviews and analysis: AI, cloud-native, startups, and more
54 
54¬†claps
54 
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.bmannconsulting.com/the-new-hack-stack-5472252b35c7?source=search_post---------145,NA
https://medium.com/@gmusumeci/how-to-deploy-an-azure-database-for-mysql-using-terraform-c6ecb4c022e4?source=search_post---------146,"Sign in
There are currently no responses for this story.
Be the first to respond.
Guillermo Musumeci
Jun 1, 2020¬∑3 min read
Azure Database for MySQL is an enterprise-ready, fully managed community MySQL, delivered as a PaaS (Platform as a Service).
In this story, we will learn how to deploy MySQL servers and MySQL databases on Azure using Terraform.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@k33g_org/deploy-a-gitlab-runner-on-clever-cloud-367a3098e90a?source=search_post---------147,"Sign in
There are currently no responses for this story.
Be the first to respond.
Philippe Charri√®re
Jan 23, 2018¬∑4 min read
Clever Cloud (https://www.clever-cloud.com/) is a PaaS platform where you can easily deploy your WebApps with a simple git push of your source code (see https://www.clever-cloud.com/doc/clever-cloud-overview/add-application/).
But you can deploy something else than code. And on this rainy Sunday, I decided to deploy a GitLab runner on Clever Cloud. A GitLab runner is the executable that will make the builds of your project, will run the tests with each commits ‚Ä¶ and finally who will ‚Äúdiscuss‚Äù with GitLab CI to give the results of builds, tests, ‚Ä¶ to the GitLab platform (GitLab.com or your own instance).
There are a lot of possibilities. But today I will limit myself to a simple runner: a ‚Äúshell‚Äù runner, that will download the dependencies of my node.js project and run the tests.
Here is an example of a project that you can use:
https://gitlab.com/wey-yu/hello
To start the project tests just run the command npm test
To enable continuous integration (the CI part) in your GitLab project, just add a .gitlab-ci.yml file to the root of your project:
It is now that we are going to need a runner.
Go to the settings of your project and choose CI/CD, then scroll down the Runners settings section (by clicking on the Expand button) and you will thus obtain 2 important parameters:
So keep this token, it will be useful for the definition of our runner.
‚ö†Ô∏è Then, very important, you need to define a ‚ÄúPersonal Access Token‚Äù in the settings of your GitLab profile (and keep this second token somewhere).
To create my runner on Clever Cloud I will use a Dokerfile and a shell script file that I would deploy as an application on Clever Cloud.
So, create a my-runnerdirectory with the following 2 files:
The Dockerfile will basically be used to install the gitlab-runner and nodejs with npm, then run the go.shfile:
And in the settings you will see that your runner is well registered:
Now go to the CI/CD section of your repository, select the sub-section Pipelines:
Click on the ‚ÄúRun Pipeline‚Äù button. You will then be able to create a pipeline:
So click on the ‚ÄúCreate Pipeline‚Äù button. This will trigger the creation of the pipeline and start it starting with the installation of the dependencies:
By clicking on the job you are interested in (a step of the pipeline) you get the details of what has been executed by the runner:
From now, whenever you ‚Äúpush‚Äù commits to master branch, the pipeline will be triggered.
That‚Äôs it easy. Now you know how to deploy immutable GitLab runners on Clever Cloud üòÉ
TAM @GitLab | bots breeder @BotsGarden
21 
1
21¬†claps
21 
1
TAM @GitLab | bots breeder @BotsGarden
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/bryanyang0528/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-heroku-%E5%92%8C-flask-%E8%A3%BD%E4%BD%9C%E5%8F%B0%E5%8C%97%E5%B8%82u-bike-api-%E4%BA%8C-heroku-6dd185862474?source=search_post---------148,"There are currently no responses for this story.
Be the first to respond.
Heroku(https://www.heroku.com/) ÊòØ‰∏ÄÂÄãÈõ≤Á´Ø PaaS ÊúçÂãôÁ∂≤Á´ôÔºåÊÑèÊÄùÂ∞±ÊòØÂè™Ë¶Å‰Ω†ÊääÂØ´Â•ΩÁöÑÊáâÁî®ÊàñÁ∂≤Á´ô‰∏ü‰∏äÂéªÔºå‰∏çÂøÖÁÖ©ÊÉ±‰∏ªÊ©üË¶ÅÊÄéÈ∫ºÁ∂≠Ë≠∑‰ª•ÂèäË¶ÅÊÄéÈ∫ºÈÉ®ÁΩ≤ÁöÑÂïèÈ°åÔºéÂÄã‰∫∫Áî®ÈÅéÈ°û‰ººÁöÑÊúçÂãôÈÇÑÊúâ IBM ÁöÑ Bluemix (https://www.ibm.com/cloud-computing/bluemix/)Ôºå‰ª•Âèä Google ÁöÑ App Engine (https://cloud.google.com/appengine) ÔºéÂêÑÂÆ∂Âú®ÊúçÂãôÂÖßÂÆπÔºåÊìç‰ΩúÊñπÂºèÔºå‰ª•ÂèäÂÆöÂÉπ‰∏äÈÉΩÊúâ‰∏çÂêåÔºåÂ¶ÇÊûúÊ≤íÊúâÊôÇÈñìÂØ¶ÈöõÂéªÊë∏Ôºå‰πüÂèØ‰ª•ÂèÉËÄÉÈÄôÂÄãÊØîËºÉÁ∂≤Á´ôÔºö
ÂπæÂÄãÂÄã‰∫∫Ë™çÁÇ∫ÊØîËºÉÈáçË¶ÅÁöÑÊåáÊ®ôÔºö
Âü∫Êú¨Êìç‰Ωú
ÂÆòÊñπÊïôÂ≠∏ÈÉΩÂØ´ÂæóÂæàÊ∏ÖÊ•ö https://devcenter.heroku.com/articles/getting-started-with-python#introduction Â∞±‰∏çÂÜçÂè¶Â§ñÊí∞ÂØ´Ôºé
Ë®≠ÂÆöÊ™î
Heroku Ë∑üÂÖ∂‰ªñ PaaS ÊúçÂãô‰∏ÄÊ®£ÈÉΩÊúâËá™Â∑±ÁöÑË®≠ÂÆöÊ™îÔºåËÆìÂÆÉÁü•ÈÅìË¶ÅÊÄéÈ∫ºÂü∑Ë°åÁ®ãÂºèÔºé‰ª• Python ÁâàÊú¨‰æÜË™™ÔºåË®≠ÂÆöÊ™îÊúâÂÖ©ÂÄãÔºé
1.Procfile: web Ê®ôË®òÁî®‰æÜÂëäË®¥ Heroku Ë¶ÅÊÄéÈ∫ºÂü∑Ë°å‰Ω†ÁöÑ web ÊúçÂãôÔºéclock ÊòØÂè¶Â§ñ‰∏ÄÂÄã Heroku ÁöÑÊúçÂãôÔºåÈ°û‰ºº crontab ÁöÑÂäüËÉΩÔºé
2. requirements.txt: Python ‰ΩøÁî®ÊôÇÂ¶ÇÊûúÂÆâË£ù‰∫ÜÈùûÂü∫Êú¨ÁöÑÂ•ó‰ª∂ÔºåÂ∞±ÈúÄË¶ÅÁî®ÈÄôÂÄãÊ™îÊ°àÂëäË®¥ Heroku ÈÇÑË¶ÅÂè¶Â§ñÂÆâË£ùÂì™‰∫õÂ•ó‰ª∂Ôºé
ÈÄô‰∫õÂ•ó‰ª∂‰∏çÈúÄË¶ÅËá™Â∑±‰∏ÄÂÄã‰∏ÄÂÄãÂàóÔºåÂè™Ë¶ÅÂÜçÂ•ó‰ª∂ÂÆâË£ùÂ•ΩÂæåÔºå‰ΩøÁî® pip freeze > requirements.txt Êåá‰ª§Â∞±ËÉΩÂ∞áÂ•ó‰ª∂Ê∑ªÂä†Âà∞ requirements.txt Ë£°Èù¢Ôºé
‰ΩøÁî®ÂøÉÂæó
Data Solution Architect/ Engineer/ DataOps/ MLOps/ Agile/ Coach
3 
3¬†claps
3 
Written by
Ë≥áÊñôÁ∂ìÁêÜ‰∫∫ÔºåÂçîÂä©Ë≥áÊñôËûçÂÖ•‰ºÅÊ•≠ÔºåËá¥ÂäõÊñºËÆìË≥áÊñôÁôºÊèÆÊõ¥Â§öÂÉπÂÄº„ÄÇ
Data Solution Architect/ Engineer/ DataOps/ MLOps/ Agile/ Coach
Written by
Ë≥áÊñôÁ∂ìÁêÜ‰∫∫ÔºåÂçîÂä©Ë≥áÊñôËûçÂÖ•‰ºÅÊ•≠ÔºåËá¥ÂäõÊñºËÆìË≥áÊñôÁôºÊèÆÊõ¥Â§öÂÉπÂÄº„ÄÇ
Data Solution Architect/ Engineer/ DataOps/ MLOps/ Agile/ Coach
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jrodthoughts/google-cloud-ml-brings-a-unique-angle-to-the-machine-learning-cloud-d152dc42a0c7?source=search_post---------149,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jesus Rodriguez
Nov 16, 2016¬∑3 min read
Google Cloud Machine Learning (Cloud ML) is a new addition to the cloud machine learning market. While PaaS leaders such as AWS and Azure have released their ML stacks more than a year ago, Google Cloud certainly has taken its time to enter the space. However, the first version of the cloud ML service already provides some unique differentiators that can push it to a leadership position within that segment of the ML market.
Conceptually, Cloud ML can be seen as a native cloud service for hosting TensorFlow applications. Cloud ML provides an architecture based on concepts such as projects, models, versions and jobs that enables the implementation of really sophisticated ML applications.
Competition is Intense
Cloud ML is entering a very competitive market with incumbents such as Amazon and Microsoft leading the charge with very innovative offerings. Azure ML is Microsoft‚Äôs ML cloud service which offers some interesting technical capabilities such as visual model building and strong support fo rR and Python ML scripts. Similarly, AWS ML excels at the simplicity of its programming model and the strong support for advanced statistical methods.
Despite the initial traction of both Azure ML and AWS ML bot platforms have well-known limitations that constrains its usage to relatively simple ML scenarions. Today, is really complicated to build a sophisticated ML solutions using those services exclusively due to limitations in areas such as extensibility. support for custom algorithms, integration with on-premise data sources, etc. Google Cloud ML provides a unique model that addresses some of those limitation without sacrificing the simplicity of the programming model.
5 Factors that can Make Cloud ML a Winner
The TensorFlow Factor
TensorFlow is one of the most popular open source deep learning frameworks in the market. by leveraging Tensorflow, cloud ML allows developers to implement really sophisticated and highly extensible ML programs without investing in complex infrastructures.
The DeepMind Factor
Google‚Äôs DeepMind recently adopted TensorFlow as its underlying stack. The complexity of the AI problems that DeepMind is attacking is likely to translate into improvements for the TensorFlow stack and subsequently Cloud ML.
The AI API Factor
Google Cloud continues making steady progress on the AI space. The recent releases of capabilities such as natural language processing (MLP) APIs or Speech APIs are an example of the rapid growth in the Google Cloud AI ecosystem. Even though competitors such as Azure offer the same levels of AI and ML services as part of its platforms, other PaaS such as AWS and Bluemix are still trying to structure a cohesive platform for both types of capabilities.
The Hybrid Factor
As a side effect of using Tensorflow, Cloud ML customers can develope solutions completely on-premisee and deploy it and scale it in cloud environments. That llevelof symmetry is aabsentof other cloud ml stacks.
The Google Cloud Factor
Finally Cloud ML integration with unique Google Cloud services such as Datalab (self-service data science) or Bigquery enables and implementation of really robust ML solutions.
Google Cloud ML is a very young but also exciting addition to the cloud machine learning ecosystem. While Amazon, Microsoft and IBM still lead the field, Google Cloud ML has the potential of becoming a relevant solution in the space in a very short time.
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
3 
3¬†
3 
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
"
https://medium.com/@ZacharyJeans/salesforce1-a-platform-company-3ddf1094615a?source=search_post---------150,"Sign in
There are currently no responses for this story.
Be the first to respond.
Zachary Jeans
Dec 3, 2013¬∑3 min read
I quite literally did not use my MacBook Air one time all Dreamforce. Is that the biggest endorsement of Salesforce‚Äôs Salesforce1 move? Yes.
What is the genesis of Salesforce1?
Salesforce began 15 years ago with Marc Benioff‚Äôs vision to make business software as simple as pulling up the Amazon.com website to do a little shopping. At the time, business software took years to develop, months to roll out, and was updated with important modifications every couple years. It cost multiple millions of dollars. Salesforce.com slew that dragon with monthly pay as you go, per user per month pricing, and the the ability to update the core software with improvements as often as needed because it was hosted on the internet, not on a computer server on a company‚Äôs property. Thus, SaaS, Software-as-a-Service, was born, and grew to dominate the world‚Äôs CRM, Customer Relationship Management, space.
Over the last 15 years the simple ‚ÄòLead, Contact, & Account‚Äô Salesforce CRM has grown to include either a proprietary, a vendor solution, or an integration partner for every business process need.
Salesforce is shifting the business enterprise world forward again with the introduction of Salesforce1. This is the convergence of a couple key forces on the world. One, that the world is moving to a mobile first experience. Two, that Salesforce is battling the largest companies for existing and new market share.
‚ÄúAccording to a recently published mobile phone forecast from the International Data Corporation (IDC) Worldwide Quarterly Mobile Phone Tracker, worldwide smartphone shipments are expected to surpass 1.0 billion units in 2013, representing 39.3% growth over 2012.‚Äù Source
‚ÄúWhy can‚Äôt I run my company from my phone?‚Äù
In the mind of a billionaire, or a shopkeeper in Malawi, the question is the same. Mobile devices with the effective computing power and connectivity that rival desktops. The first computer that flashes across the eyes on a child in San Francisco is the same experience one is going to have in Mumbai ~ A mobile tablet or smartphone. If one can order takeout, a cab, buy movie tickets, & read or view a report on any subject in the world, why can‚Äôt a business owner do the equivalent in their business software? Salesforce is answering the question: You can.
Second, Salesforce is pushing into space currently owned by other global giants. It will face battles for its own core competencies, but also for new ones. Salesforce is positioning itself to win the businesses that will serve the next billion connected consumers. The connected world is about to double in the next decade, and Salesforce just doubled down. Think about that. And how are those folks from around the globe connecting to the internet? Through a social, mobile, cloud orientation.
Salesforce is meeting the convergence of the global move to engage internet through mobile devices and establishing itself as a platform company with Salesforce1.
‚ÄúI want us to play a small part in solving the water crisis together‚Äî donate to my campaign to dig a brand NEW well and provide #CleanWater to a village for LIFE!100% of everything we raise will directly fund water projects. ‚Äú http://my.charitywater.org/shortyaward-clean-water
Facilitating conversations around Salesforce, Leadership, and Travel, with a passion for NonProfits.
See all (3,307)
3 
3¬†claps
3 
Facilitating conversations around Salesforce, Leadership, and Travel, with a passion for NonProfits.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@diggen/service-as-a-service-2948ac99bf84?source=search_post---------151,"Sign in
There are currently no responses for this story.
Be the first to respond.
Diggen
Jan 15, 2016¬∑3 min read
First came PaaS then came Saas. But if we told you there is an additional SaaS in town? Service as a Service. That‚Äôs right! You might already be investing in software to enhance your business model and create new service revenue streams but do you know if you‚Äôre fully optimizing the use of that software? Are you aware that your teams may lack knowledge or aptitude for understanding the nuances of that software? This is where Service as a Service enters:
There‚Äôs a big gap between companies integrating technology to streamline business processes, spark collaboration, and fuel growth both internally and externally and the internal capabilities to execute these tools. For example, there are a variety of CRM tools, inbound marketing tools, link tracking tools, social listening tools, internal communication tools and the list goes on and on. The problem? Most these tools are all integrative and we end up on this never ending hamster wheel constantly trying to figure out which combination will help us be more productive and increase overall margins. The bigger problem? Most internal teams aren‚Äôt adept for understanding a vast majority of complicated tech tools and end up ‚Äòthrowing them away‚Äô so they can ‚Äòget back to work‚Äô.
This is where Service as a Service comes in. Let‚Äôs say your business is trying to increase productivity by integrating a CRM tool with an internal project management tool. (ie. Hubspot + Slack or Greenrope + Wrike). The challenges are you‚Äôre relying on your team to:
Service as a Service helps companies
The key to filling the gap is the expertise of an outsider to understand the ‚Äònitty gritty‚Äô, and recognize when the company isn‚Äôt optimizing tools, and will help them get the most value out of the tools they are using.
Automation is seen in email marketing, social media, prospect nurturing and much more. However automation isn‚Äôt always the answer. Before you automate, it‚Äôs crucial to understand the in‚Äôs and out‚Äôs of the manual process. For example, do you remember the Coca-Cola automated tweet campaign during the Superbowl that went horribly awry? Here‚Äôs what happened: in an attempt to engage with negative tweeters during the superbowl by automatically retweeting and turning it into #MakeitHappy, Gawker recognized the automation and exploited it.
The lesson to be learned: automation isn‚Äôt always the answer. So how does this fit in with the Service as a Service scenario? Simple. Most social media teams aren‚Äôt technology experts and most technology experts don‚Äôt understand the behavior taken place on social media. Having a middle man that can offer insight into both worlds, could save a company from a campaign that could backfire by understanding all the loopholes and nuances of ‚Äòwhere it could go wrong‚Äô.
Ultimately, if you‚Äôre going to spend time investing in technology, make sure to invest in optimizing the process and the people with the expertise as well.
Sources
http://www.networkworld.com/article/2293084/software/12-issues-you-need-to-know-about-software-as-a-service.html
http://searchcloudcomputing.techtarget.com/definition/Software-as-a-Service
http://www.computerworld.com/article/2516032/enterprise-applications/5-problems-with-saas-security.html
https://www.rickscloud.com/most-common-problems-with-the-adoption-of-saas-and-how-to-overcome-them/
http://www.businessnewsdaily.com/7838-choosing-crm-software.html
http://www.superoffice.com/blog/crm-software-statistics/
Diggen is a one stop shop marketplace for all consumer data sources. We help marketers be data driven integrating our middleware into their marketing tools.
15 
15¬†
15 
Diggen is a one stop shop marketplace for all consumer data sources. We help marketers be data driven integrating our middleware into their marketing tools.
"
https://medium.com/@devpicon/app-engine-creando-nuestro-primer-proyecto-6b754924a0a0?source=search_post---------152,"Sign in
There are currently no responses for this story.
Be the first to respond.
Armando Pic√≥n
Jan 24, 2016¬∑2 min read
App Engine es la opci√≥n PaaS (Plataforma como servicio) que Google nos ofrece para poner en l√≠nea nuestras aplicaciones web.
Antes de pasar a echarle mano al c√≥digo, vamos a necesitar crear un proyecto a trav√©s de la consola, para ello debemos seguir estos pasos:
Recursos:
üë®üèΩ‚Äçüíª Android Tech Lead @CornershopChile | üí¨ @GDGOpen organizer | üéô @CodalotDev Podcast host | üë®üèΩ‚Äç Lifelong learner Hola! Ol√°! Hi! üáµüá™ üáßüá∑ üá∫üá∏
See all (560)
3 
3¬†claps
3 
üë®üèΩ‚Äçüíª Android Tech Lead @CornershopChile | üí¨ @GDGOpen organizer | üéô @CodalotDev Podcast host | üë®üèΩ‚Äç Lifelong learner Hola! Ol√°! Hi! üáµüá™ üáßüá∑ üá∫üá∏
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@chamerling/or-1000-celebrate-278cab26dfe6?source=search_post---------153,"Sign in
There are currently no responses for this story.
Be the first to respond.
Christophe Hamerling
Jan 15, 2015¬∑1 min read
We started to work on the Open PaaS Enterprise Social Network exactly one year ago this month and we are now celebrating our 1000 JIRA issue (https://ci.open-paas.org/jira/browse/OR-1000).
According to average number of developers which is more or less around 4, this is a really great achievement. This past year also means millions of ideas, thousands commits and cups of coffee, hundreds liters of beer (per developer), tens broken builds (tons in fact) and a totally awesome project and product.
This is just the beginning, you can check our full stack javascript social network on https://ci.open-paas.org/stash/projects/OR/repos/rse/browse or https://github.com/linagora/openpaas-esn.
Cheers,
Lead Dev at @linagora
3 
3¬†
3 
Lead Dev at @linagora
"
https://medium.com/@ibmcloud/bendigo-and-adelaide-bank-use-secure-cloud-for-rapid-development-and-deployment-1dd01a3c04ec?source=search_post---------154,"Sign in
There are currently no responses for this story.
Be the first to respond.
IBM Cloud Stories
Sep 28, 2016¬∑3 min read
Private PaaS solution helps bank bring apps to market like an agile startup
Bendigo and Adelaide Bank wanted to be able to bring apps to market faster, with a desire to innovate like a startup. To achieve this goal, it turned to IBM‚Äôs platform of innovation. Its developer team can now create compelling new apps for both customers and employees, faster and cheaper than ever before, with IBM‚Äôs first ever localized Bluemix instance.
The bank uses the same open source technologies and approaches that more agile companies ‚Äî the disrupters ‚Äî do to bring products to market 20 to 100 times faster than traditional enterprises can.
Bendigo and Adelaide Bank chose IBM as its partner because IBM can bring resilient technologies to the regulated financial services industry, understands what the bank wanted to achieve, and acknowledged the importance of being able to actually get things to market, which are all critical considerations for the bank to be able to innovate.
IBM Bluemix offers the bank the ability to compose applications from a menu palette of services and solutions, like ingredients in a ‚Äúdigital kitchen.‚Äù A developer might pick and choose compute, network storage, analytics, mobile, social, and security components that IBM and third parties bring to the table, and cook up apps that are connected to back-end systems. The bank can reuse core transactions, add new functionality, and participate in the API economy.
For example, the bank used Bluemix to develop its Business Banker Application, a productivity app that helps its banking team take their business in the palms of their hands ‚Äî rather than in a bunch of manila folders ‚Äî when they‚Äôre visiting clients. This solution was delivered in just eight weeks after a two-day discovery workshop. Now the business bankers have real-time access to the information from the bank‚Äôs legacy systems while they‚Äôre on the road, on any mobile device. They have hooks into external third parties that provide information about industries, so they‚Äôre up to date with clients‚Äô businesses before they even walk into meetings.
The business bankers thought the app was fantastic, but mentioned that after meeting with the client they needed to take some notes and they‚Äôre in the car and don‚Äôt actually want to sit there and type on mobile phones or tablets nor do they want to pull over and write stuff down on paper. They wanted to know if there was anything that could be done. So the development team looked into Bluemix cognitive offerings and found a Watson speech-to-text service that could be implemented. Now the business bankers can record notes about their meetings and the Watson service will take the speech and translate it through to text.
At Bendigo and Adelaide Bank, IBM was able to bring executives, business people, and technical people together to help them speak the same language about composable services and understand that whether it‚Äôs art, music, cooking, or technology, there are ingredients that need to be put together in a way to create the magnum opus.
With all the stakeholders on the same page, the bank has undergone a digital transformation and created a startup within the enterprise. Using IBM Bluemix, all that needs to be done is pick, mix, and match to build the desired business outcome.
To learn more about Bendigo and Adelaide Bank visit http://www.bendigobank.com.au/public/
To read 2017 IBM Cloud Stories visit http://ibm.co/2iKoD4d .
See all (173)
25 
25¬†claps
25 
To read 2017 IBM Cloud Stories visit http://ibm.co/2iKoD4d .
About
Write
Help
Legal
Get the Medium app
"
https://architecht.io/microsofts-gabe-monroy-breaks-down-the-cloud-native-world-5744864b277d?source=search_post---------155,"In this episode of the ARCHITECHT Show, Gabe Monroy, head of product for cloud-native computing at Microsoft Azure, goes deep into the world of cloud-native computing. Monroy discusses his time in the PaaS space at Deis and EngineYard (and how that evolved into the container movement), and how the Kubernetes/CNCF communities are able to play nice with each other given all that‚Äôs at stake. He also discusses the art of building managed Kubernetes services, Microsoft‚Äôs GitHub acquisition, the role of serverless computing and more.
Scroll to the bottom (or click here) for links to listen to the podcast pretty much everywhere else you might want to.
This episode brought to you by:
news.architecht.io
Enterprise IT interviews and analysis: AI, cloud-native, startups, and more
2 
2¬†claps
2 
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
Written by
Founder/editor/writer of ARCHITECHT. Day job is at Pivotal. You might know me from Gigaom - way back in the day, now.
Once a site about next-gen enterprise IT and the people building it; now a place where Derrick Harris occasionally blogs about tech-related things.
"
https://codeburst.io/building-a-go-web-api-with-the-digital-ocean-app-platform-31f361b0f632?source=search_post---------156,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Recently, Digital Ocean announced that they‚Äôre entering the PaaS market with their new application platform. They‚Äôve hosted virtual machines (droplets) and Kubernetes based services for years, but now they‚Äôre creating a platform that‚Äôs a simple point and click to get an application up and running.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/dataseries/a-brief-history-of-container-war-i-little-whale-docker-56cbe91fcf7d?source=search_post---------157,"There are currently no responses for this story.
Be the first to respond.
Container is one of the most important cloud technologies. From traditional PaaS to docker. From Docker Swarm to Kubernetes, a lot seems happened just like overnight. This is how quickly the landscape could change in the technology world and this is how fascinating the technology world is. What we could learn from this short history? That is a good question!
"
https://medium.com/@krishnan/dissecting-application-platform-landscape-20d0a9676fb0?source=search_post---------158,"Sign in
There are currently no responses for this story.
Be the first to respond.
Krish
Apr 22, 2018¬∑2 min read
The application platform landscape has been confusing with various vendors using different terms such as CaaS, PaaS, Container Platforms and Application Platforms. In this blog post, we try to explain different terms and how it fits various application needs.
There is quite a bit of confusion in how the terms CaaS, PaaS, Container Platforms and Application Platforms are used. The confusion exist in the market and we want to use this post to clarify what these terms mean in the context of cloud native ecosystem. The difference between CaaS or PaaS and Container Platforms or Applications Platforms are nothing new. Even in the early cloud computing days, there were always two ways to build platforms to deploy applications, IaaS+ vs PaaS, The same distinction applies to the container world. It is about the level of abstraction (or the control) one wants to have and whether the organization is comfortable using the public cloud.
Container as a Service (CaaS) is a hosted container infrastructure that offers an easy way to deploy containers on an elastic infrastructure and it is offered as a public cloud service. CaaS is suitable in contexts where developers want more control over container orchestration. With CaaS, organizations can deploy complex applications on containers without worrying about the limitations of opinionated platforms like Heroku or Google App Engine. Think of CaaS as the elastic container infrastructure just like how IaaS was elastic VM infrastructure. If we draw a line with flexibility on the left and abstraction on the right for the container world, CaaS is on the left most side of the line.
These are public cloud services that are more container centric where the containers can be used to deploy application code and the dependencies. CaaS is for deploying applications when you want more control over the components of the applications.
Read the rest of the post at StackSense.io
Future Asteroid Farmer, Analyst, Modern Enterprise, Startup Dude, Ex-Red Hatter, Rishidot Research, Modern Enterprise Podcast, and a random walker
8 
8¬†
8 
Future Asteroid Farmer, Analyst, Modern Enterprise, Startup Dude, Ex-Red Hatter, Rishidot Research, Modern Enterprise Podcast, and a random walker
"
https://medium.com/@alibabatech/kubevela-releases-1-1-reaching-new-peaks-in-cloud-native-continuous-delivery-82f4b49b1757?source=search_post---------159,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Tech
Nov 17, 2021¬∑6 min read
Tags: KubeVela, Kubernetes, DevOps, CI/CD, Continuous Delivery, PaaS
By KubeVela Maintainers
Initialized by Alibaba and currently a CNCF sandbox project, KubeVela is a modern application platform that focuses on modelling the delivery workflow of micro-services on top of Kubernetes, Terraform, Flux Helm controller and beyond. This brings strong value added to the existing GitOps and IaC primitives with battle tested application delivery practices including deployment pipeline, across-environment promotion, manual approval, canary rollout and notification, etc.
This is the first open source project in CNCF that focuses on the full lifecycle continuous delivery experience from abstraction, rendering, orchestration to deployment. This reminds us of Spinnaker, but designed to be simpler, cloud native, can be used with any CI pipeline and easily extended.
Kubernetes has made it easy to build application deployment infrastructure, either on cloud, on-prem, or on IoT environments. But there are still two problems for developers to manage micro-service applications. First, developers just want to deploy, but delivering application with lower level infrastructure/orchestrator primitives is too much for them. It‚Äôs very hard for developers to keep up with all these details and they need a simpler abstraction to ‚Äújust deploy‚Äù. Second, application delivery workflow is a basic need for ‚Äújust deploy‚Äù, but it is inherently out of scope of Kubernetes itself. The existing workflow addons/projects are too generic, they are way more than focusing on delivering applications only. These problems makes continuous delivery complex and unscalable even with the help of Kubernetes. GitOps can help in deploying phase, but lack the capabilities of abstracting, rendering, and orchestration. This results in low SDO (software delivery and operation) performance and burnout of DevOps engineers. In worst case, it could cause production outage if users make unsafe operations due to the complexity.
The latest DORA survey [1] shows that organizations adopting continuous delivery are more likely to have processes that are more high quality, low-risk, and cost-effective. Though the question is how we can make it more focused and easy to practice. Hence, KubeVela introduces Open Application Model (OAM), a higher level abstraction for modelling application delivery workflow with app-centric, consistent and declarative approach. This empowers developers to continuously verify and deploy their applications with confidence, standing on the shoulders of Kubernetes control theory, GitOps, IaC and beyond.
KubeVela latest 1.1 release is a major milestone bringing more continuous delivery features. It highlights: ‚óèMulti-environment, multi-cluster rollout: KubeVela allows users to define the environments and the clusters which application components to deploy to or to promote. This makes it easier for users to manage multi-stage application rollout. For example, users can deploy applications to test environment and then promote to production environment.‚óèCanary rollout and approval gate: Application delivery is a procedural workflow that takes multiple steps. KubeVela provides such workflow on top of Kubernetes. By default, Users can use KubeVela to build canary rollout, approval gate, notification pipelines to deliver applications confidently. Moreover, the workflow model is declarative and extensible. Workflow steps can be stored in Git to simplify management.‚óèAddon management: All KubeVela capabilities (e.g. Helm chart deployment) are pluggable. They are managed as addons [2]. KubeVela provides simple experience via CLI/UI to discover, install, uninstall addons. There is an official addon registry. Users can also bring their own addon registries.‚óèCloud Resource: Users can enable Terraform addon on KubeVela to deploy cloud resources using the same abstraction to deploy applications. This enables cooperative delivery of application and its dependencies. That includes databases, redis, message queues, etc. By using KubeVela, users don‚Äôt need to switch over to another interface to manage middlewares. This provides unified experience and aligns better with the upcoming trends in CNCF Cooperative-Delivery Working Group [3]. That is the introduction about KubeVela 1.1 release. In the following, we will provide deep-dive and examples for the new features.
Users would need to deploy applications across clusters in different regions. Additionally, users would have test environment to run some automated tests first before deploying production to environment. However, it remains mysterious for many users how to do multi-environment, multi-cluster application rollout on Kubernetes. KubeVela 1.1 introduces multi-environment, multi-cluster rollout. It integrates Open Cluster Management and Karmada projects to handle multi-cluster management. Based on that, it provides EnvBinding Policy to define per-environment config patch and placement decisions. Here is an example of EnvBinding policy:
Below is a demo for a multi-stage application rollout from Staging to Production. The local cluster serves as the control plane and the rest two are the runtime clusters.
Note that all the resources and statuses are aggregated and abstracted in the KubeVela Applications. Did any problems happen, it will pinpoint the problematic resources for users. This results in faster recovery time and more manageable delivery.
Can you build a canary rollout pipeline in 5 minutes? Ask Kubernetes users and they would tell you it is not even enough to learn an Istio concept. We believe that as a developer you do not need to master Istio to build a canary rollout pipeline. KubeVela abstracts away the low level details and provides a simple solution as follows. First, installing Istio is made easy via KubeVela addons:
Then, users just need to define how many batches for the rollout:
Finally, define the workflow of canary, approval, and notification:
Here is a full demo:
In this KubeVela release we have built the cornerstone for continuous delivery on Kubernetes. For the upcoming release our major theme will be improving user experience. We will release a dashboard that takes the user experience to another level. Besides that, we will keep improving our CLI tools, debuggability, observability. This will ensure our users can self serve to not only deploy and manage applications, but also debug and analyze the delivery pipelines.
For more project roadmap information, please see Kubevela RoadMap.
KubeVela is a community-driven, open-source project. Dozens of leading enterprises have adopted KubeVela in production, including Alibaba, Tencent, ByteDance, XPeng Motors. You are welcome to join the community. Here are next steps:
First-hand & in-depth information about Alibaba's tech innovation in Artificial Intelligence, Big Data & Computer Engineering. Follow us on Facebook!
5 
5¬†
5 
First-hand & in-depth information about Alibaba's tech innovation in Artificial Intelligence, Big Data & Computer Engineering. Follow us on Facebook!
"
https://medium.com/@InnFin/the-man-who-predicted-the-financial-crash-in-2008-joins-the-board-of-the-company-who-will-predict-183efc301ba0?source=search_post---------160,"Sign in
There are currently no responses for this story.
Be the first to respond.
Innovate Finance
Oct 13, 2015¬∑3 min read
The man who predicted the Financial Crash in 2008 joins the Board of the company who will predict ‚Äî and hopefully prevent ‚Äî the next one.
London 13th October 2015 ‚Äî Simudyne, the developer of Providence, the revolutionary simulation platform-as-a-service (PaaS), today announced the appointment of Dr. Steve Keen to its Advisory Board. Dr. Keen, the famous post-Keynesian economist, author and founder of the Minsky simulation software project is one of the few who predicted the financial crisis of 2007‚Äì08.
‚ÄúI developed computer simulations that enabled me to successfully anticipate and warn of an impending serious economic crisis,‚Äô said Dr. Keen. ‚ÄúYesterday, the Nobel Memorial Prize in Economic Sciences, as usual, rewarded incremental work in economics when a wholesale shift is needed. I‚Äôm excited to become a Simudyne investor and Advisory Board member because I am confident that applications developed upon the Providence platform will facilitate that wholesale shift. Furthermore, Providence will be used to predict and mitigate future economic crises,‚Äù he continued. ‚ÄúTogether, we‚Äôll realise our vision that all critical decisions will be made with the aid of Simudyne‚Äôs technology.‚Äù
‚ÄúBy integrating Dr. Keen‚Äôs Minksy software into our Providence platform, we augment the intelligence of Governments, Central Banks, Hedge Funds and other financial institutions,‚Äù said Justin Lyon, Simudyne‚Äôs CEO. ‚ÄúHis long-standing relationships with leaders and policymakers across the US, UK and Australian financial sectors will be invaluable when they deploy our software as the operating system for managing their dynamic economies and organisations.‚Äù
In addition to his other roles, Dr. Keen is also a consultant to the hedge fund Asymmetric Return Capital, which harnesses market volatility to protect and grow wealth in a rapidly changing world. ‚ÄúCNBC publicised Simudyne‚Äôs collaboration with hedge funds and the combination of Dr. Keen‚Äôs expertise and technology has proven itself a powerful prediction engine for this market. We‚Äôre therefore thrilled to announce that it‚Äôs part of our Providence platform,‚Äù said Justin Lyon.
Mike Morgan, Simudyne‚Äôs COO welcomed Dr. Keen to the team, ‚ÄúI‚Äôm delighted that Dr. Keen is joining us. We will infuse his vision and foresight into our strategic execution and by integrating his technology into our platform we will further enhance its predictive power for hedge funds and other financial institutions.‚Äù
‚Äî END ‚Äî
Notes to Editors
For interviews with Dr. Steve Keen or Justin Lyon please contact;
Jan McGinley
jan.mcginley@simudyne.com
+44 (0)7834 223434
About Simudyne
Simudyne is the world‚Äôs leading next generation simulation software company. They empower business, government, military, law enforcement and civic leaders to solve highly complex problems that carry with them high levels of risk or reward. They leverage big data, simulation science and their powerful software to enable decision makers to build simulations of the real world to predict and test the future outcomes of their decisions and actions. Simudyne provides the platform of choice for those seeking to develop versatile, sophisticated, scalable simulation applications that help leaders solve complex problems and dramatically accelerate and improve decision-making by turning insight into foresight.
About Dr. Steve Keen
Dr. Keen is a Professor of Economics and Head of the School of Economics, Politics and History at Kingston University London. He is also a founding member of the hedge fund Asymmetric Return Capital. Dr. Keen is a prominent critic of conventional economics and he famously predicted the economic crisis of 2007‚Äì2008 because banks, debt and money play an integral role in his dynamic (as opposed to equilibrium) approach to economics. Dr. Keen‚Äôs controversial book, Debunking Economics, explains the many logical and empirical flaws in mainstream (and Marxian) economics without using mathematics. It has been translated into Chinese, French and Spanish. Dr. Keen also has more than 60 widely cited academic publications.
Innovate Finance is a convening voice for the UK FinTech industry, providing a single point of access for key industry influencers, regulators, tech and talent.
2 
2¬†
2 
Innovate Finance is a convening voice for the UK FinTech industry, providing a single point of access for key industry influencers, regulators, tech and talent.
"
https://medium.com/@cyril_lakech/quels-sont-les-impacts-du-as-a-service-pour-les-d%C3%A9veloppeurs-c92d0331411a?source=search_post---------161,"Sign in
There are currently no responses for this story.
Be the first to respond.
Cyril Lakech
Sep 5, 2016¬∑9 min read
De nombreuses entreprises, produits et √©quipes utilisent les services Cloud (PaaS ou SaaS), dits ‚Äúmanag√©s‚Äù, pour leurs d√©veloppements IT. Vous savez, ces services qui g√®rent automatiquement la scalabilit√©, le failover, la s√©curit√©‚Ä¶ et sans avoir √† g√©rer les serveurs n√©cessaires. Ils sont de plus en plus utilis√©s, si on en croit les croissances actuelles et √† pr√©voir dans ce domaine. Certains utilisent des solutions ‚Äúas a service‚Äù publiques, d‚Äôautres cr√©ent leur propre solution au sein de ‚Äúleurs‚Äù datacenters. De nombreuses personnes se mettent en ordre de marche pour que ce type de services soient utilis√©s. Mais qu‚Äôest ce que √ßa change pour les devs ? On a plusieurs fois √©voqu√© cette question.
Une comp√©tence sera particuli√®rement demand√©e dans les projets qui utilisent des services manag√©s; Il faut savoir cr√©er un √©difice qui r√©ponde aux besoins √† partir de briques connect√©es les unes aux autres, comme avec des LEGOs, sauf qu‚Äôon n‚Äôa pas de plan de montage et qu‚Äôon peut inventer nos propres briques. On avait d√©j√† cette mission avant quand il s‚Äôagissait de choisir une base de donn√©es, un framework web, un middleware‚Ä¶ Maintenant ces choix sont simplement plus fr√©quents parce qu‚Äôon d√©coupe plus souvent et ils sont √©galement plus nombreux car il y a encore plus de mani√®res diff√©rentes de faire. Le d√©veloppeur doit faire plus souvent des choix qui sont plus difficiles et plus complexes.
Pour chaque nouveau service √† d√©velopper, on se demande:
On a TOUJOURS eu ces questions √† se poser, bien avant l‚Äôarriv√©e du ‚Äúas a service‚Äù et du SOA. Mais avant, les r√©ponses √©taient souvent plus simples : on ajoutait le service au m√™me endroit que les autres. Classique. Maintenant, on a plus souvent tendance √† cr√©er plusieurs modules qui sont li√©s entre eux.
(Je ne juge pas le choix d‚Äôarchi; bien souvent une archi classique est satisfaisante, et il arrive que des projets soient complexifi√©s sans besoin r√©el, simplement pour apprendre et suivre le mouvement. Parfois une approche est plus adapt√©e, parfois c‚Äôest l‚Äôautre, parfois les 2. Peu importe.)
Du coup, l√† o√π on avait l‚Äôhabitude d‚Äôavoir un sch√©ma de fonctionnement bas√© sur quelques ‚Äúmonolithes‚Äù avec webapp, BDDs, load balancer, firewalls et 2‚Äì3 zones r√©seaux, maintenant on peut avoir des myriades de services interconnect√©s tel un final de feu d‚Äôartifice mais sur un sch√©ma Visio.
Cela complexifie donc l‚Äôarchitecture du SI mais c‚Äôest en contrepartie de certaines promesses de scalabilit√© automatis√©e, de taux de dispo √©lev√©s, de baisse de co√ªts ou de m√©t√©o plus cl√©mente (sisi).
Il faut donc √™tre √† l‚Äôaise avec l‚Äôarchitecture des services, ce qui n√©cessite de conna√Ætre certains principes d‚Äôarchitecture; le d√©veloppeur devient donc un peu plus architecte encore, voir un peu plus ops selon le contexte. Ce qui est certain, c‚Äôest que pour les d√©veloppeurs curieux, c‚Äôest une opportunit√© int√©ressante pour apprendre.
Le d√©veloppement devient plus complexe et n√©cessite plus de r√©flexion et de cr√©ativit√©. Le d√©veloppeur doit se former √† l‚Äôarchitecture!
Le m√©tier de d√©veloppeur comprends donc de plus en plus de t√¢ches d‚Äôint√©gration de services, car pour chacune des questions pos√©es pr√©c√©demment, les r√©ponses sont souvent diff√©rentes et c‚Äôest autant d‚Äôint√©grations sp√©cifiques √† mettre en place.
Pour chaque nouvelle solution as a service, il faut l‚Äôappr√©hender, se documenter, la tester pour la ma√Ætriser et pouvoir l‚Äôutiliser sur son projet. Il existe des dizaines (centaines) de fournisseurs avec pour chacun des dizaines (centaines) de services; il est quasi impossible de tous les suivre. Heureusement diront certains et malheureusement pour d‚Äôautres; souvent une entreprise utilise une petite partie de ces services disponibles, chez un ou deux fournisseurs. Au final, le dev doit, encore plus qu‚Äôavant, se tenir inform√© des √©volutions et des nouveaut√©s.
Il faut utiliser les SDKs et les APIs des diff√©rentes solutions pour les faire communiquer avec notre code. Les langages utilis√©s et compatibles ne sont pas forc√©ment les m√™mes que ceux avec lesquels on a l‚Äôhabitude de coder. Ponctuellement, un dev .NET peut se retrouver √† (re)coder en Python et un dev Java va se mettre √† coder en NodeJS. On a donc plus tendance √† utiliser diff√©rents langages dans un SI, on peut toujours avoir des langages qui sont majoritairement utilis√©s, mais on peut aussi avoir des briques d‚Äôint√©gration ou des modules complets cod√©s dans d‚Äôautres langages ponctuellement. Les connecteurs √† ses services sont souvent propri√©taires et proposent de nombreuses options et possibilit√©s qu‚Äôil faut ma√Ætriser √©galement. Le dev doit donc, encore plus qu‚Äôavant, √™tre capable de s‚Äôadapter aux SDKs et d‚Äôapprendre de nouveaux langages. Rien d‚Äôinsurmontable mais il va falloir changer un peu ses habitudes.
En contrepartie de ces contraintes, ces solutions nous apportent des services qui r√©duisent la charge de travail sur d‚Äôautres aspects. Par exemple, utiliser un service de d√©ploiement de Webapp en PaaS demande de comprendre son fonctionnement et son API, mais en √©change il permet de ne pas (trop) se soucier des aspects de scalabilit√© par exemple. Pas besoin de g√©rer le failover du serveur web. Pas besoin de (trop) stresser en cas de passage m√©dia dans l‚Äô√©mission Capital. Pas de probl√®me de d√©couverte √† chaud par le load balancer de l‚Äôarriv√©e de nouveaux noeuds dans le cluster. Bref, cela permet de signer un trait√© de paix entre les Devs et les Ops qui se m√®nent une guerre sans merci depuis des d√©cennies sans jamais se comprendre.
Le dev dans les nuages demande de ma√Ætriser diff√©rents nouveaux services et parfois diff√©rents langages. Cela demande du temps d‚Äôapprentissage suppl√©mentaire! En √©change, certaines probl√©matiques sont report√©es sur la responsabilit√© du fournisseur.
Le d√©veloppeur peut donc se concentrer sur le d√©veloppement applicatif comme on dit, mais c‚Äôest en d√©laissant ses connaissances de plus bas niveaux et en montant en comp√©tences sur les APIs sp√©cifiques des services manag√©s utilis√©s. C‚Äôest surement l‚Äôimpact le plus important sur le m√©tier de d√©veloppeur! Le futur?
Parfois le fournisseur de services peut √™tre interne voir, le d√©veloppeur peut √™tre son propre fournisseur de services manag√©s. Dans ces cas, c‚Äôest diff√©rent mais l‚Äôimpact sur le m√©tier est √©galement tr√®s important! On verra les impacts des diff√©rentes strat√©gies Cloud dans un autre article.
Avant d√©j√†, l‚Äôautomatisation √©tait importante pour la qualit√©; maintenant c‚Äôest devenu obligatoire! Pour cr√©er un nouvel environnement ‚Äúmanuellement‚Äù, avec des clics ou des lignes de commandes, cela peut n√©cessiter des heures en suivant une proc√©dure fastidieuse et source d‚Äôerreur. C‚Äôest ing√©rable. Forc√©ment, plus on a de services diff√©rents, plus leur installation va n√©cessiter d‚Äôactions diff√©rentes. Donc automatiser devient obligatoire et permet de cr√©er un nouvel environnement en peu de temps.
Il devient fortement d√©conseill√© de modifier manuellement un composant d‚Äôun environnement. Chaque environnement comprend de nombreux composants, si on les modifie manuellement, il est impossible de s‚Äôy retrouver. Il faut donc tout automatiser, pas seulement la cr√©ation des composants mais leur mise √† jour, leur remplacement ou tout autre changement d‚Äô√©tat.
Les environnements doivent le plus possible √™tre immutables, cad ne pas √™tre modifiables une fois cr√©√©s, on doit pr√©f√©rer leur suppression et recr√©ation plut√¥t que de les modifier. Plut√¥t que d‚Äôaller mettre √† jour les diff√©rentes instances de l‚Äôapplication avec une nouvelle version du code, on cr√©√©e de nouvelles instances qui viennent remplacer les pr√©c√©dentes puis on supprime les anciennes instances. Et un environnement doit pouvoir √™tre compl√®tement d√©truit et reconstruit en quelques minutes de mani√®re automatis√©e. Adieu les erreurs humaines manuelles, bonjour le debuging de provisonning automatis√©.
Par exemple, on peut automatiser le d√©ploiement avec Cloudformation chez AWS ou avec Terraform sur Google Cloud pour atteindre ce but ultime; la r√©g√©n√©ration totale de son SI en une commande ‚ù§
Le dev n√©cessite, encore plus qu‚Äôavant, d‚Äôautomatiser le d√©ploiement en utilisant des solutions dites d‚ÄôInfrastructure as Code.
Avant on r√©servait des ressources pour les environnements de d√©veloppement, ces ressources √©taient constamment disponibles et on les payaient donc tout le temps. Quel que soit l‚Äôusage des CPUs, des disques, du r√©seau le prix √©tait le m√™me.
Maintenant ces services sont factur√©s en fonction de leur utilisation r√©elle, en fonction du nombre d‚Äôappels en lecture ou en √©criture, en fonction de l‚Äôespace disque utilis√©, de la bande passante r√©seau consomm√©e. Certains services ne co√ªtent m√™me RIEN quand ils ne sont pas utilis√©s.
En th√©orie, cela permet de baisser les co√ªts des environnements de d√©veloppement. En pratique, comme le nombre de projets de d√©veloppement en cours explose avec la transformation num√©rique, c‚Äôest difficile √† v√©rifier :troll_face:
OK les co√ªts sont variables et non fixes, quel rapport avec le d√©veloppeur ?
En fonction de la strat√©gie cloud utilis√©e, dans le cas o√π l‚Äôon s‚Äôappuie sur des services PaaS publics par exemple, le d√©veloppeur peut avoir besoin de ressources chez le fournisseur pour d√©velopper et il ne peut pas forc√©ment tout faire fonctionner localement sur son poste de travail. (Ceci n‚Äôest pas applicable si vous pouvez tout faire fonctionner localement avec des conteneurs par exemple.)
Il existe souvent des SDK de d√©veloppement pour √©muler les services PaaS en local mais cela reste une √©mulation et ce n‚Äôest pas toujours le cas. Par exemple, pour DynamoDB, il vous faudra DynamoDB local pour coder sur la plage de Bali sans 4G. Pour un service utilisant API Gateway et les Lambdas par contre, vous pouvez utiliser serverless ou apex qui impactent un peu la mani√®re de d√©velopper.
Du coup, pour tester son code dans des conditions proches de la cible, le d√©veloppeur va r√©guli√®rement le d√©ployer sur un environnement d√©di√© rien qu‚Äô√† lui. Et chaque d√©veloppeur peut avoir besoin de le faire. Mais comme les co√ªts sont maintenant variables, il faut avoir conscience du co√ªt relatif aux actions qu‚Äôon r√©alise.
Si j‚Äôoublie de supprimer un environnement de dev pendant plusieurs jours et qu‚Äôil consomme du budget, √ßa peut faire d√©raper la facturation.
Si je fais un traitement long ou un tir de performance sur un environnement, la facturation va augmenter √©galement.
Le d√©veloppeur doit donc int√©grer cette notion du co√ªt variable des ressources dans son quotidien. Cela peut passer par des tableaux de bords de suivi des co√ªts qui est affich√© dans le bureau, en passant par des alertes en cas de d√©passement d‚Äôun seuil de consommation, ou une limitation de l‚Äôusage de certains services.
Outre l‚Äôaspect co√ªt, le nombre d‚Äôenvironnement peut facilement augmenter si on manque de rigueur. Quand on utilise uniquement son poste de travail pour d√©velopper, chacun en est responsable. Mais si chaque d√©veloppeur a son(ses) environnement(s) chez un fournisseur, il faut s‚Äôaccorder sur des r√®gles de fonctionnement pour s‚Äôy retrouver. D√©finir des r√®gles de nommage, des permissions, mettre en place des tags sur les ressources etc. Exactement ce qu‚Äôon faisait d√©j√† avant mais avec encore plus d‚Äôenvironnements √† g√©rer.
Le d√©veloppeur devient responsable des co√ªts de facturation induits et doit √™tre gestionnaire de ses environnements.
TL;DR: L‚Äôutilisation du as a service pour le d√©veloppeur modifie son quotidien en faisant appel √† ses comp√©tences d‚Äôarchitecture, d‚Äôint√©gration, d‚Äôautomatisation et en lui demandant plus de rigueur, de curiosit√© et de cr√©ativit√©. Des qualit√©s d√©j√† requises auparavant mais qui sont tout particuli√®rement n√©cessaires maintenant. L‚Äôentreprise doit se transformer en une √©cole permanente pour que ses d√©veloppeurs puissent suivre ces transformations. Le d√©veloppeur a plus de responsabilit√© et donc plus de pouvoir! :thug_life:
Suivez moi sur twitter @cyril_lakech ;-)
‚òÖ SaaS Director @qimaone ‚òÖ ex @axa @adeo @chtijug ‚òÖ Zoo Keeper ü¶¶ü¶Åüêßü¶äü¶Ü ü¶Ö#hiring
See all (264)
3 
Thanks to Antoine Leveugle.¬†
3¬†claps
3 
‚òÖ SaaS Director @qimaone ‚òÖ ex @axa @adeo @chtijug ‚òÖ Zoo Keeper ü¶¶ü¶Åüêßü¶äü¶Ü ü¶Ö#hiring
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/lol-weekly-list-of-lit/lol-issue-10-22-28-april-17-67e29be2916c?source=search_post---------162,"There are currently no responses for this story.
Be the first to respond.
Contents: 1. The Legal Rapist ‚Äî Simar Singh | (Slam Poem)2. Prateek Kuhad‚Äôs Tum Jab Paas by Prateek Kuhad | (Song, Video)3. The Anatomy of the Tortured Artist: Why ‚ÄúSad People‚Äù Create ‚Äî Isha Joshi ‚Äî (Recommended) | (Article)4. Feat of Pressure Cookers by Kritarth Srinivasan | (Stand Up Comedy)5. The Best Kind of Sleep | (Cartoon)6. A poem by Gursahiba Gill ‚Äî (Recommended) üíõ7. The Rhythm and Your Blues ‚Äî Abhimanyu Gurung (Poem | Recommended )üíõ
Pardon my Non Hindi Speaking Subscribers(you can watch the video though :))
fondlist.com
Excerpt
Full poem here:
Excerpt:
toomanypumpkins.wordpress.com
Until next Saturday! Bbye!
LOL is a weekly curation of poems, spoken word‚Ä¶
2 
2¬†claps
2 
Written by
I write poetry and short fiction. I meditate, code, dance, sing, play üèÄ, clean stuff. I‚Äôm a non sticky pan to events üç≥.
LOL is a weekly curation of poems, spoken word performances, essays, blog posts, visual and generative art, songs, visual jokes, patterns, humour and other articles, that I come across in a week. You can help curate with our chrome extension: http://bit.ly/2nFn1wa
Written by
I write poetry and short fiction. I meditate, code, dance, sing, play üèÄ, clean stuff. I‚Äôm a non sticky pan to events üç≥.
LOL is a weekly curation of poems, spoken word performances, essays, blog posts, visual and generative art, songs, visual jokes, patterns, humour and other articles, that I come across in a week. You can help curate with our chrome extension: http://bit.ly/2nFn1wa
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jrodthoughts/five-reasons-why-aws-is-going-after-office365-and-g-suite-4c374e4ac2b?source=search_post---------163,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jesus Rodriguez
Mar 4, 2017¬∑3 min read
AWS has been steadily expanding beyond its traditional IaaS-PaaS capabilities into business applications and not it seems to be ready to take those efforts to the next level. A few days ago, there were some reports that indicated that AWS has been working g on a new line of services for traditional information worker tasks such as word processing, presentations or spreadsheets. The initiative is a clear indication of AWS‚Äô intentions to compete with cloud rivals such as Microsoft and Google for the supremacy in the cloud productivity tools space.
AWS‚Äôs new line of services are far from being the only effort of the cloud gain in the business apps space. Last week, AWS announced Chime, a video-collaboration tool that rivals offers such as Skype for Business or Google Hangouts. WorkMail is another business centric service included in the AWS cloud.
Whether AWS‚Äô move was anticipated or not it still results fascinating. Here we have a company with over 60% domination in the cloud platform market expanding into a complementarily market vastly dominated by its two closes competitors in the cloud space. It doesn‚Äôt get any better than that. The move can be compared with Facebook‚Äôs audacious entrance in the messaging space or Google release of Home to compete with Amazon Alexa.
What could be triggering AWS‚Äôs decisions to go into productivity tools? How feasible are those plans? Here is part of my initial analysis:
1‚Ää‚Äî‚ÄäPreventive Measures
Office365 and G-Suite are two of the biggest assets that Microsoft and Google can use to disrupt AWS‚Äô domination in the cloud platform space. Both platforms are indirect channels for the commercialization of Azure and Google Cloud and AWS, obviously, intends to build that market.
2‚Ää‚Äî‚ÄäBuilding New Distribution Channels
Building on the previous point, Office365 and G-Suite count with millions of business as customers which provides an easier transition point to Azure or the Google Cloud platform. That channel is particularly important in large enterprise environments.
3‚Ää‚Äî‚ÄäBecoming Competitive via M&A
One aspect that I haven‚Äôt heard analysts consider is AWS‚Äôs capability to grow its productivity apps portfolio via acquisitions. At the end, a large percentage of the popular cloud business apps in the market are built on AWS. That position contrasts with Office365 and G-Suite‚Äôs grow that has been mostly based on in-house IP.
4‚Ää‚Äî‚ÄäThe Battle of Emerging Markets
I think is safe to assume that Office365 and G-Suite are going to remain the dominant cloud productivity suites in first-world markets such as North America, Europe or Australia. However, AWS is rapidly trying to consolidate its leadership position in emerging markets such as China, India, Middle East or Brazil in which a new business apps suite can be a great asset.
5‚Ää‚Äî‚ÄäNon-Developers Tools
Microsoft and Google have done a remarkable job expanding the capabilities of Office365 and G-Suite to non-developers. Tools such as Office365's Flow or PowerApps are great examples of this trend. Until now, AWS have remained exclusively an infrastructure and developer-centric platform but the new productivity apps and service can set the foundation for non-developer tools and solutions.
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
1 
1¬†
1 
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
"
https://medium.com/@alibaba-cloud/how-to-install-docker-ce-and-docker-compose-on-centos-8-3a45bb541415?source=search_post---------164,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Jan 22, 2020¬∑7 min read
Docker is a set of Platform as a Service (PaaS) products that uses operating system level virtualizations to deliver software in the form of containers. Docker CE (Community Edition) is the strip down version of Docker EE (Enterprise Edition). Docker CE is free and open source and distributed under Apache License 2.0.
In Red Hat Enterprise Linux (RHEL) 8 / CentOS 8, Support of Docker has been removed by the vendor. Whereas a new containerization platform libpod (Podman‚Äôs Container Management Library) has been introduced inplace of Docker.
However, we can still install Docker and it‚Äôs dependencies on CentOS 8 / RHEL 8 from third party yum repositories.
In this article, we are installing Docker CE and docker-compose on CentOS 8.
We have configured a CentOS 8 virtual machine with following specifications.
Connect with docker-01.example.com using ssh as root user.
Docker CE is available to download from Docker‚Äôs Official Website However, we can also install it from Docker CE yum repository.
Add Docker CE yum repository using dnf command.
Build cache for Docker yum repository.
After addition of Docker CE yum repository, we can now easily install Docker CE on CentOS 8 by using a dnf command.
Docker CE requires containerd.io-1.2.2‚Äì3 (or later) package, which is blocked in CentOS 8. Therefore, we have to use an earlier version of containerd.io package.
Install docker-ce with an earlier version of containerd.io using following command.
Enable and start Docker service.
Check status of Docker service.
Check Docker version.
Docker CE has been installed on CentOS 8.
Let‚Äôs put Docker into action by creating a simple container.
For this purpose, we are using official image of Alpine Linux from Docker Hub.
Pull Alpine Linux image from Docker Hub.
List locally available docker images.
Create and run a container using Alpine Linux image.
Additionally, we are installing docker-compose on our CentOS 8 server, so we can create and run multiple containers as a single service.
Download docker-compose package from GitHub.
Grant execute permissions to docker-compose command.
Check docker-compose version.
We have successfully installed Docker CE and Docker-Compose on CentOS 8. We have only explored the installation of Docker CE here
www.alibabacloud.com
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
2 
2¬†claps
2 
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@alibaba-cloud/integrating-distributed-architecture-with-cloud-native-best-practices-by-ant-financial-2d6c171c1891?source=search_post---------165,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Jul 7, 2020¬∑14 min read
By Yu Renjie, Product Expert of SOFAStack at Ant Financial
From February 19 to February 26, Ant Financial live streamed digital classes with the topic of ‚ÄúFight Against the ‚ÄúEpidemic‚Äù with a Breakthrough in Technologies‚Äù. Ant Financial invited senior experts to share their practical experiences of cloud native, development efficiency, and databases and answer questions online. They analyzed the implementation of the Platform-as-a-Service (PaaS) architecture in financial scenarios and the elastic and dynamic architecture of Alipay on mobile devices. In addition, they shared the features and practices of OceanBase 2.2. So far, we have compiled and posted a series of these speeches under the WeChat official account ‚ÄúAnt Financial Technology‚Äù (WeChat ID: Ant-Techfin). You are welcome to follow the account and read them.
In this blog, we‚Äôll be recapping the presentation by Yu Renjie, product expert of SOFAStack at Ant Financial, on the practices of building the cloud-native application PaaS architecture at Ant Financial‚Äôs digital classroom.
Hello, everyone. Welcome to Ant Financial‚Äôs digital livestreaming classroom. In February, we commercially released our Scalable Open Financial Architecture Stack (SOFAStack) on Alibaba Cloud. To allow more friends to know about the capabilities, positioning, and design ideas of this financial-grade distributed architecture, we will conduct a series of livestreamed classes to share them later. Today, we are going to share the topic of Practices of Building the Cloud-native Application PaaS Architecture. This topic focuses on the ideas of employing PaaS product capabilities in some financial scenarios that require steady innovations, to help you better connect PaaS products to the cloud-native architecture.
Through the development history of IT, cloud computing has been classified into Infrastructure as a Service (IaaS), PaaS, and Software as a Service (SaaS) for more than a decade. During the development of the entire cloud computing industry, it is obvious that enterprises have experienced three stages of cloud computing policies, that is, Cloud-based, Cloud-ready, and Cloud-native. The three stages changed due to the fact that businesses are becoming increasingly agile, requiring enterprises to shift their focus to upper layers by investing more energy and talent in the business logic and turning over the unfamiliar and increasingly complex infrastructure and middleware at lower layers to cloud computing vendors. In this way, professionals are able to focus on their professions.
This essentially further refines the social division of labor and complies with the law of the development of human society. In the era of cloud native, the container technology, service mesh technology, and serverless technology proposed in the industry are all intended to decouple business R&D from base technologies to make it easier to drive innovations both in businesses and base technologies.
Cloud native is an inevitable trend in the technology industry where businesses change rapidly. What substantively drives this trend is the container technology represented by the so-called cloud native, Kubernetes, and Docker. These essentially revolutionize application delivery modes. To truly implement the new application delivery mode advocated by the industry and communities in the actual enterprise environments, we need an application-centric platform that works throughout the lifecycle of application O&M.
In fact, there have been a lot of exchanges and materials for the keyword ‚Äúcloud native‚Äù in the community and the industry. They focus on best practices of Docker and Kubernetes, continuous integration and continuous delivery (CI/CD) of DevOps, the design of container network storage, optimizations on the integration with log monitoring, and so on. Today, we want to demonstrate the product value of building a PaaS platform on top of Kubernetes. Kubernetes is an excellent orchestration and scheduling framework, and the key contributor to standardize application orchestration and resource scheduling. In addition, Kubernetes provides a highly scalable architecture to help the upper layer customize various controllers and schedulers. However, Kubernetes is not a PaaS instance. The bottom layer of PaaS can be implemented based on Kubernetes. However, to truly use Kubernetes in production environments, you must supplement many capabilities at the upper layer, especially in the financial industry.
What are the challenges for implementing cloud native in production environments?
We have previously conducted some research and customer interviews. As of 2020, the vast majority of financial institutions had expressed a great interest in technologies such as Kubernetes and containers. Many institutions had built an open-source or commercial cluster for some non-critical businesses or in development and testing environments. Their motivations are simple. Financial institutions hope that this new delivery mode can help businesses evolve rapidly. However, in distinct contrast, it is evident that few of them dare to implement cloud-native architectures in core production environments. This is because financial business innovations are based on the premise of guaranteed stability.
Our team has summarized the preceding six challenges faced by Ant Financial in the process of serving internal businesses and external financial institutions. In fact, these challenges are also faced by our internal site reliability engineer (SRE) team. In the insights we will share today and in the future, we will gradually summarize and deepen product ideas to address these challenges.
One of the core ideas that we are going to share today is how we control application change risks at the product level. Around this topic, we will introduce the background of the ‚Äúthree measures‚Äù for application changes, the native deployment capability of Kubernetes, the extensions made to our products based on change requirements, and our open sourcing plans.
The so-called ‚Äúthree measures‚Äù indicate the requirements that application changes can be carried out in canary release mode, be monitored, and meet emergency needs. This is a redline rule for internal SREs at Ant Financial. All changes must comply with this rule, and this rule is mandatory even in the cases of minor changes or rigorous tests. To meet this rule, we have designed a variety of fine-grained release policies at the PaaS product layer, such as group release, beta release, canary release, and blue-green release. These release policies are similar to those used in conventional O&M. However, many container users find it difficult to implement them in Kubernetes.
Sometimes, due to demanding business continuity requirements, users are reluctant to accept the standard mode of the native Kubernetes model. For example, the canary release of a native deployment cannot be completely lossless or controlled on demand because we still lack control over pod changes and traffic governance by default. In view of this, we made customizations at the PaaS product level and extended custom resources at the Kubernetes level. In this way, we can still exercise fine-grained control over the entire release process in cloud-native scenarios, making the deployment, canary release, and rollback of applications in a large-scale cluster more graceful and in line with the ‚Äúthree measures‚Äù against technical risks.
Actually, the native deployment object of Kubernetes and the corresponding ReplicaSet have gradually been stabilized in several recent major versions. To put it simply, in the most common release scenario in Kubernetes, we declare the expected release mode and the definition of pod specifications by using the deployment object. When pods are running, we use the ReplicaSet object to manage the expected number of pods, in which case rolling release or recreation release is enabled by default.
The lower part of the preceding figure shows the rolling release of an application based on the deployment object. Here, we will not elaborate too much on that. Essentially, in the process, we specify a step according to O&M requirements, create a pod, and delete the old pod. In this way, we can ensure that there is always an available container that provides external services in the entire application version change and release process. In most scenarios, the deployment object is sufficient and the whole process is easy to understand. In reality, deployments are the most common in the Kubernetes system in addition to pods and nodes.
After reviewing the deployment object, let‚Äôs take a look at CafeDeployment, a CustomResourceDefinition (CRD) extension developed according to actual requirements. Cloud Application Fabric Engine (CAFE) is the name of our SOFAStack PaaS product line. We will briefly describe CAFE at the end of this article.
CafeDeployment has an important capability of perceiving the underlying topology. But, what does this topology mean? This topology knows the specific node to which we publish a pod and does not simply bind the pod to the node based on affinity rules, but can truly import relevant scenario information such as high availability, disaster recovery, and deployment policies into the entire release-centric domain model. To this end, we proposed a domain model called a deployment unit. It is a logical concept and is simply called a cell in the YAML file. In actual use, a cell can be used in different zones, different physical data centers, or different racks, all of which are centered on different levels of high availability topologies.
Let‚Äôs see the typical release process of a CafeDeployment that has perceived the underlying topology. We will demonstrate the process through the product console and command line later. This figure shows a fine-grained group release process that enables changes at the container instance level to be sufficiently controllable and support canary release. Specifically, each stage can be suspended, verified, resumed, or rolled back.
As shown in the preceding example, we want to release or change 10 pods and evenly distribute them into two zones to ensure high availability at the application level. In addition, we need to introduce the concept of group release in the release process. Specifically, each data center must release one instance first. After the verification is suspended, the data center can continue to release the next group. In this case, the beta group has 1 instance on each side, group 1 has 2 instances on each side, and group 2 has the remaining 2 instances on each side. In the actual production environment, we monitor the businesses and more dimensions when making major changes to a container, to ensure that every step meets expectations and passes verification. In this way, the fine-grained control at the application instance layer plays the important role of a break for online application release, allowing SREs to roll back an application in time, when needed.
Now that we‚Äôve described the entire fine-grained release process, let‚Äôs talk about the fine-grained traffic removal process. To ensure lossless release, we must gracefully remove the network traffic in both the north-south and east-west directions so that online services are not affected when a container is stopped, restarted, or scaled in.
The preceding figure shows the standard control procedure when a pod is released after being changed. The time sequence diagram includes the pod and its associated component controllers. The CafeDeployment mainly works with network-related components such as the service controller and LoadBalancer controller to redirect traffic and check traffic recovery for lossless release.
According to our command-based O&M practices in conventional O&M scenarios, we can run commands sequentially to perform atomic operations on each component to ensure that all inbound traffic and inter-application traffic are removed before we make the actual change. In contrast, in the cloud-native Kubernetes scenario, these complex operations are performed by the platform and SREs only need to run a simple statement. During deployment, we pass through the traffic components associated with the application, including but not limited to the Service LoadBalancer, RPC, and DNS, to the CafeDeployment, add the corresponding finalizers, and use ReadinessGate to identify whether the pod can carry traffic.
For example, when we want to update a specified pod in place under the control of the InPlaceSet controller, the InPlaceSet controller sets the ReadinessGate parameter to false. After perceiving the change, the associated components deregister their respective IP addresses sequentially to trigger actual traffic removal. After all related finalizers are removed, the system automatically updates the pod. After the new version of pod is deployed, the InPlaceSet controller sets the ReadinessGate parameter to true to sequentially trigger the loading of actual traffic to the associated components. The pod has been released only when the detected traffic types of the finalizers are consistent with that actually declared in the CafeDeployment.
Let‚Äôs go back to the PPT file. In fact, the CafeDeployment we just mentioned is a commercial product of CAFE. We have also developed some open-source projects in the community when commercializing the CAFE. Here, I would like to introduce the OpenKruise project, which we developed based on massive cloud-native O&M practices in the Alibaba economy. We open-sourced many Kubernetes-based automated O&M operations through standard Kubernetes extensions to supplement the capabilities that native workloads cannot provide. The project has resolved application automation problems in scenarios such as deployment, upgrade, elastic scaling, QoS adjustment, health check, and failover and recovery in Kubernetes.
Currently, the OpenKruise project provides a set of controller components. In particular, the UnitedDeployment can be considered as the open-source version of CafeDeployment. In addition to the basic replica retention and release capabilities, the UnitedDeployment provides the capability of releasing pods to multiple deployment units, which is one of the main features of CafeDeployment. Additionally, UnitedDeployment manages pods based on various workloads, currently including StatefulSet and OpenKruise AdvancedStatefulSet provided by the community. Therefore, the UnitedDeployment can inherit features of the corresponding workloads.
Wu Ke (Haotian, GitHub ID: wu8685), the key contributor to UnitedDeployment, comes from the SOFAStack CAFE team and has led the entire design and development process of CafeDeployment. Currently, we are working to incorporate more capabilities into the open-source version through standardized methods after carrying out massive verification on the capabilities. By doing this, we can gradually minimize the difference between the two versions.
Due to time constraints, that‚Äôs it for our detailed discussion of these technical implementations today. According to the previous description about the entire release policy of CafeDeployment, our key value proposition for product design is to provide a steady evolution capability while helping integrate emerging technology architectures into applications and businesses. Both conventional O&M systems represented by virtual machines (VMs) and cloud-native architectures for large-scale container deployment require fine-grained technical risk control and evolution towards the most advanced architectures.
The following example shows the containerization evolution route of a certain Internet bank. Since its foundation, the Internet bank has determined a distributed system where microservices are built on top of the cloud computing infrastructure. However, from the perspective of the delivery mode, the PaaS management model based on conventional VMs was initially adopted. From 2014 through 2017, developers had been deploying application packages to VMs through Buildpack. This O&M mode lasted for three years, during which we helped upgrade the architecture from the zone active-active mode to the mode with three data centers across two zones, and then to the unitized active geo-redundancy mode.
In 2018, as Kubernetes became more mature, we built a base at the underlying layer based on physical machines and Kubernetes. Meanwhile, we used containers to simulate VMs to containerize the whole infrastructure. However, service providers are unaware of this. We provided services for upper-layer applications through ‚Äúrich containers‚Äù by using pods that are located on top of the underlying Kubernetes. From 2019 to 2020, as the businesses developed, the requirements for O&M efficiency, scalability, migratability, and refined management drove us to evolve the infrastructure to a more cloud-native O&M system and gradually implement capabilities such as service mesh, serverless, and unitized federated cluster management.
Through productization and commercialization, we are open-sourcing the capabilities that we have accumulated for years. We hope to enable more financial institutions to quickly replicate the capabilities of the cloud-native architecture in the Internet financial business scenarios and create value for the businesses.
You may know about the unitized architecture and the elasticity and disaster recovery capabilities of the active geo-redundancy mode at Ant Financial from many channels. Here, I‚Äôll show you a figure, which is the abstract architecture of a solution that we are currently working on and are going to implement within months for a large bank. At the PaaS level, we build federated capabilities on top of Kubernetes, hoping that each data center has an independent Kubernetes cluster. This is because disaster recovery requirements cannot be met if we deploy a Kubernetes cluster across data centers and regions. Furthermore, the multi-cloud federated management capability also requires that we extend Kubernetes capabilities to PaaS-layer products, such as defining logical units and federation-layer resources. Ultimately, this builds a unitized architecture that covers multiple data centers, regions, and clusters. We have made a large number of extensions, including some federated objects at the federation layer in addition to the aforementioned CafeDeployment and ReleasePipeline. The ultimate goal is to provide unified release management, disaster recovery, and emergency management for businesses in these complex scenarios.
Now, I can finally explain the meaning of CAFE, which was mentioned much earlier. CAFE stands for Cloud Application Fabric Engine. It is the PaaS for cloud-native applications at Ant Financial‚Äôs SOFAStack. It not only provides the cloud-native capabilities standardized by Kubernetes, but also open-sources production-proven financial-grade O&M capabilities at the upper layer, including application management, release and deployment, O&M and orchestration, monitoring and analysis, disaster recovery, and emergency management. In addition, CAFE is highly integrated with the SOFAStack middleware, service mesh, and Alibaba Cloud container service for Kubernetes (ACK).
The differentiated application lifecycle management capabilites provided by CAFE include release management, disaster recovery, and emergency management, plus the evolving path to the unitized hybrid cloud capabilities. CAFE is the key base for the implementation of distributed architectures, cloud-native architectures, and hybrid cloud architectures in financial scenarios.
The last slide is actually the core theme today. The CAFE we described today is a part of the financial distributed architecture product SOFAStack. At present, SOFAStack has been commercially available on Alibaba Cloud. So, we welcome you to apply for a trial and discuss it further with us. For more information, search us online, follow the product link provided in this article, or go to the official website of Alibaba Cloud.
www.alibabacloud.com
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
1 
1¬†clap
1 
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/altoros-blog/a-car-app-in-6-months-mercedes-benz-daimler-gains-pace-with-cloud-foundry-1dba3380319?source=search_post---------166,"There are currently no responses for this story.
Be the first to respond.
With Cloud Foundry PaaS and microservices architecture, dreams of emission-free, self-driving, and connected vehicles and shared driving are becoming a reality. The blog post features a project of Daimler partnering with Pivotal to deliver a smart Mercedes-Benz app that takes car usage and servicing to a whole new level. Read the article to learn the details about the app, the development process, the achieved results, and plans for the future.
www.altoros.com
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
1 
1¬†clap
1 
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/altoros-blog/2016-2017-trends-industry-4-0-6edb7e635fb?source=search_post---------167,"There are currently no responses for this story.
Be the first to respond.
Bringing together cloud computing, PaaS, big data, Internet of Things, artificial intelligence, and even blockchain, Industry 4.0 can become the key to improving efficiency and profits in the manufacturing sector. The blog post investigates into the roots of the trend and gives some examples from practice of GE, IBM, and Ford to illustrate the current situation. The article also explores concerns about the future of manufacturing in the light of Industry 4.0 and IT development.
www.altoros.com
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
1 
1¬†clap
1 
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@rinormaloku37/hi-neven-5e3578eced87?source=search_post---------168,"Sign in
There are currently no responses for this story.
Be the first to respond.
Rinor Maloku
May 7, 2018¬∑1 min read
Neven C.
Hi Neven,
Thanks for taking the time to port the Microservices app to a PaaS solution, this enables everyone with Kubernetes knowledge to use the comparison to rapidly learn deploying their apps in PWS, and vice versa, enables all with PWS knowledge to see how we would solve this in Kubernetes.
Thanks for the feedback! Am planning to write articles that build on top of the base architecture to show other features of Kubernetes. Though was never really thinking about showing the Microservice application as PaaS in different CSP-s, that opened up like a myriad of opportunities :)
Am looking forward to read your article!
Rinor ;)
Join me and master one tool at a time @ https://rinormaloku.com
1 
1
1¬†
1 
1
Join me and master one tool at a time @ https://rinormaloku.com
"
https://medium.com/@InnFin/cloud-simulation-platform-vendor-s-latest-appointment-signals-the-end-for-rivals-246038f99e64?source=search_post---------169,"Sign in
There are currently no responses for this story.
Be the first to respond.
Innovate Finance
Oct 12, 2015¬∑2 min read
London, October 12th 2015 ‚Äî Simudyne, the developer of Providence, the revolutionary simulation platform-as-a-service (PaaS), today announced the appointment of Mike Morgan to the company‚Äôs board and leadership team as Chief Operating Officer. Mike joins Simudyne from Relayware, the SaaS partnering automation vendor he founded and led as CEO through a period of stellar growth following a successful career with tech giants, Compaq, HP and Sony. He will be responsible for Simudyne‚Äôs business operations including sales, marketing, finance and investor relations leveraging his years of experience as a software entrepreneur, non-executive director and advisory board member for many high-growth software companies in the UK and USA.
‚ÄúI‚Äôm thrilled to join the Simudyne team at this critical time‚Äù Mike said. ‚ÄúOur customers are investing heavily in technologies and services to derive insight from big data. They now seek foresight ‚Äî the means to develop and test their strategies in safe, virtual environments and make radically better decisions across their extended enterprises. Our competitors are legacy simulation software vendors and the developers of modelling tools that are totally unsuited to the task of deploying cloud-based sims at pace and scale. Decision makers now demand more and Providence delivers. I look forward to working with our growing network of partners to build the next generation of decision support software harnessing the power of simulation science and the scalability and performance of the cloud.‚Äù
Justin Lyon, Simudyne‚Äôs founder and CEO welcomed Mike to the team, ‚ÄúMike is a technology industry veteran and he has witnessed first-hand how powerful the PaaS model can be in supporting a collaborative approach in which application development, customisation and deployment are managed by domain experts within a partner ecosystem. His considerable experience in building high-performance indirect channels to market will be a tremendous asset to Simudyne.‚Äù Justin concluded, ‚ÄúOur technology is unique and our ability to serve any market, to help any customer to solve their most challenging problems and to consistently improve their decision-making by using customised solutions, developed and delivered by a network of experts is unparalleled. As a team, we look forward to realising our vision ‚Äî that one day, all critical decisions will be made with the aid of Simudyne technology.‚Äù
By the Simudyne Team
Innovate Finance is a convening voice for the UK FinTech industry, providing a single point of access for key industry influencers, regulators, tech and talent.
2 
2¬†
2 
Innovate Finance is a convening voice for the UK FinTech industry, providing a single point of access for key industry influencers, regulators, tech and talent.
"
https://medium.com/@eFileCabinet_57957/the-future-of-xaas-from-infrastructures-to-platforms-1b9d07f3a2b?source=search_post---------170,"Sign in
There are currently no responses for this story.
Be the first to respond.
eFileCabinet
Mar 30, 2017¬∑2 min read
The death of commodity IT services (like email) begins with IaaS, PaaS, SaaS, MaaS, CaaS, and culminates in XaaS. The following strengths and pitfalls to each portion of the SPI model can be ascertained through this lens, and in the following ways:
The IaaS strength resides in giving leeway to users to build as they please, offer shared control over processes, shared on premise and cloud functionality, the prevention of ‚Äúcloud bursting,‚Äù and also the offering of scalability. The weaknesses in the infrastructure model are that buyers feel they must rely too much on their IaaS provider to intervene when issues arise.
The strengths of the platform as a service model are speedy deployment, versatile configuration capacities, and virtually unparalleled performance assessment. Despite these benefits, the weaknesses still exist with the difficulty in integrating the technology with existing applications, software, and systems.
The strengths of this platform are the fact no tech expertise is required, very low-cost, great for small businesses, and reduced hardware dependence. It‚Äôs weaknesses, though minimal, can include input delays and exclusive dependence on the internet.
Monitoring as a service enables companies to move their monitoring tools to the cloud, which can eliminate the risks associated with downtime for output intensive companies or business cycles.
Communication as a Service lets workers and potential customers utilize business grade VoIP and VPNs (virtual private networks, as are typically found in healthcare clinics). As organizations grow in inter-connectivity and shared services, this component of XaaS will become especially prevalent.
In consideration of these technology models‚Äô respective strengths and weaknesses, Xaas will combine all of these elements, and only the future can tell how the strengths and weaknesses will eventually coincide with each other.
Although the SPI models are important, the impact of XaaS will tip the scale toward a massive paradigm shift in which technology is no longer considered a mere resource, but also a strategic imperative for ensuring business profitability in mass.
Hosting has become a cloudy topic with all these different acronyms, and is even further complicated by the addition of ‚Äúanything‚Äù or ‚Äúeverything‚Äù as a service to the sphere of interpretation.
Although these different delivery models culminate in XaaS, they are yet to reach the level of advent expected. One could argue, however, that these various cloud deployment models have always existed, and until recently were merely not compartmentalized as expected.
To begin your organization‚Äôs journey toward an XaaS world, begin with the right document management tools that solve common office problems today.
Originally published at www.efilecabinet.com on March 30, 2017.
Paperless Solution Provider - Over 156,000 users worldwide work smarter and more efficiently with eFileCabinet
1 
1¬†
1 
Paperless Solution Provider - Over 156,000 users worldwide work smarter and more efficiently with eFileCabinet
"
https://medium.com/@benbob/thanks-for-the-positive-comments-dan-deb3f487f9d3?source=search_post---------171,"Sign in
There are currently no responses for this story.
Be the first to respond.
Ben Fathi
Dec 16, 2018¬∑1 min read
Dan Keldsen
Thanks for the positive comments, Dan. Duct tape and chewing gum is definitely the right analogy for what passes as on-prem state-of-the-art.
I don‚Äôt think there‚Äôs a single answer when it comes to IaaS vs. PaaS vs. SaaS. They‚Äôre solving different problems and each is a viable solution for some subset of those problems. The equivalent question in the on-prem world would be to ask which is better: hardware, operating system, or application. Obviously, each has its own place in the stack.
My simple rule of thumb is always to opt for the highest level of abstraction available for the specific problem you‚Äôre trying to solve.
Former {CTO at VMware, VP at Microsoft, Head of Engineering & Cloud Ops at Cloudflare}. Recovering long distance runner, avid cyclist, newly minted grandpa.
1 
1
1¬†
1 
1
Former {CTO at VMware, VP at Microsoft, Head of Engineering & Cloud Ops at Cloudflare}. Recovering long distance runner, avid cyclist, newly minted grandpa.
"
https://medium.com/altoros-blog/bosch-connects-6-million-devices-with-pivotal-cloud-foundry-a45c6bfbf6c5?source=search_post---------172,"There are currently no responses for this story.
Be the first to respond.
Addressing specific needs in the Internet of Things domain, Bosch launched an IoT Cloud, making Bosch IoT Suite available as a PaaS. The blog post explores how the company made use of Pivotal Cloud Foundry to ensure scalability, compatibility with a range of IaaS providers, and accelerate development. In addition to the achievements and challenges, the article also features examples of innovative solutions ‚Äî built with Bosch IoT Cloud ‚Äî already available for connected cars, smart homes, etc.
Read the full article on our blog:
paas.ly
Stay in touch with the latest Altoros‚Äô updates, subscribe to our social accounts: Twitter, Facebook, LinkedIn, Reddit.
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/lexrus/serverless-%E7%AE%80%E4%BB%8B-7c9c5aa1fb82?source=search_post---------173,"There are currently no responses for this story.
Be the first to respond.
ÈöèÁùÄ PaaS„ÄÅBaaS„ÄÅSaaS ÁöÑÊµÅË°åÔºåÊúçÂä°Á´ØÂºÄÂèëÂíåÁª¥Êä§ÁöÑÂ∑•‰ΩúÂèòÂæóÊõ¥Âä†‰æøÊç∑ÔºåÂ§ßÈÉ®ÂàÜÂàõ‰∏öÂÖ¨Âè∏‰∏çÂÜçÈúÄË¶Å‰∏ìËÅåÁöÑËøêÁª¥ÔºåÊúçÂä°Á´ØÂºÄÂèë‰∫∫ÂëòÂç≥ËÉΩÊêûÂÆöÊó•Â∏∏ÁöÑÊúçÂä°Âô®Áª¥Êä§Â∑•‰Ωú„ÄÇËÄåËøëÂá†Âπ¥ÔºåÂÉè Parse„ÄÅFirebase„ÄÅCloudKit ËøôÁ±ªËøûÊúçÂä°Á´ØÂºÄÂèë‰∫∫ÂëòÈÉΩËÉΩÁúÅÊéâÁöÑÊñπÊ°àÊõ¥ÊòØÂèóÂà∞‰∏çÂ∞ëÂàõ‰∏öÂÖ¨Âè∏ÁöÑÈùíÁùê„ÄÇÂÅö‰∏Ä‰∏™ App ‰∏çÂÜçÈúÄË¶Å‰∏ÄÂ†Ü‰∫∫ÔºåËØïÈîôÁöÑÊàêÊú¨Â§ßÂ§ßÈôç‰Ωé„ÄÇ
ËÄåÂêÑÁßçÂÆπÂô®ÊäÄÊúØÁöÑ‰∏çÊñ≠ËøõÊ≠•ÔºåÂà©Áî®Ë≠¨Â¶Ç Docker ÂÆπÂô®ÂÆûÁé∞ËΩªÈáèÁ∫ßÁöÑÊúçÂä°Âô®ÂçïÂÖÉÔºå‰∏Ä‰∏™Êñ∞ÁöÑÊúçÂä°Á´ØÂΩ¢ÊÄÅÊ≠£Âú®ÊàêÂΩ¢ ‚Äî ‚Äî ServerlessÔºåÊàñÁß∞ FaaS (Functions as a Service)„ÄÇ‰∏ãÈù¢‰ªéÊàë‰∏™‰∫∫ÁöÑËßÇÊÑüÈöè‰æøËÅä‰∏Ä‰∏ãÊàëÁêÜËß£ÁöÑ Serverless„ÄÇ
Serverless ‰∏ªË¶ÅÂ∫îÁî®Ë°®Áé∞‰∏∫Ôºå‰∏öÂä°ÂäüËÉΩ‰ª• function ÂÆûÁé∞ÁöÑ endpoint ÁªÑÊàêÔºåÁî®Êà∑ËÆøÈóÆÊüê‰∏™ endpoint Êó∂ÂêØÂä®‰∏Ä‰∏™ÂÆπÂô®ÊâßË°å function ÂÜÖÁöÑÁ®ãÂ∫èÔºåÊâßË°åÁªìÊùüÂõûÊî∂Ëøô‰∏™ÂÆπÂô®ÔºåÊï¥‰∏™ËøáÁ®ãÂø´Ëá≥Âá†ÊØ´ÁßíÂ∞±ËÉΩÂÆåÊàê„ÄÇÂú®Êüê‰∫õÂ∫îÁî®Âú∫ÊôØ‰∏ãÔºåËÉΩÂæàÂ•ΩÁöÑ‰ª£ÊõøÊåÅÁª≠Âú®Á∫øÁöÑÊúçÂä°„ÄÇ
ÁõÆÂâçÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑ Serverless Ëß£ÂÜ≥ÊñπÊ°àÂΩìÂ±û‰∫öÈ©¨ÈÄäÁöÑ AWS Lambda Âíå Google Cloud FunctionÔºåÂêéËµ∑‰πãÁßÄ now.shÔºåÂè¶Â§ñËøòÊúâ‰∫õ‰∏≠Â∞èÂûãÁöÑÊúçÂä°ÂïÜÂ¶Ç Webtask„ÄÅhyper.sh Á≠â„ÄÇ
Ëøô‰∫õÊúçÂä°ÊúâÁ±ª‰ººÁöÑÊî∂Ë¥πÊîøÁ≠ñÔºöÊåâÈúÄ‰ªòË¥πÔºåÈ¢ùÂ∫¶ÂÜÖÂÖçË¥πÔºåË∂ÖÈ¢ùÂêéÊØèÊ¨°ËØ∑Ê±ÇËÆ°Ë¥π„ÄÇ
ÁõÆÂâçÊàë‰∫ÜËß£Âà∞ÁöÑ‰ΩøÁî®Âú∫ÊôØ‰∏çÂ§öÔºå‰ªé AWS Lambda Êèê‰æõÁöÑÂêÑÁßç‰ªãÁªçÊù•ÁúãÔºåÊàëËÑëË°•‰∏Ä‰∏ã Serverless ÈÄÇÁî®Âú∫ÊôØÔºö
1. ËøêÁÆóÂØÜÈõÜ ‚Äî ‚Äî Â¶ÇÂõæÁâáÂéãÁº©„ÄÅÊï∞ÊçÆÂàÜÊûê„ÄÇÂõ†‰∏∫‰ΩøÁî® Serverless ÊñπÊ°àÂêå‰∏ÄÁßíÈáåÂèØ‰ª•ËøêË°åÂçÉ‰∏ä‰∏á‰∏™ LambdaÔºåËÉΩËΩªÊòìÂÆûÁé∞‰º†ÁªüÊû∂ÊûÑÊó†Ê≥ïÂÆûÁé∞ÁöÑË∂ÖÂº∫Â§ÑÁêÜËÉΩÂäõÔºåÂπ∂‰∏îÂè™Âú®‰ΩøÁî®Êó∂Êî∂Ë¥π„ÄÇ
2. ‰∏∫ÂÖ∂ÂÆÉÊúçÂä°Êèê‰æõÁºñÁ®ãÊîØÊåÅ ‚Äî ‚Äî ‰æãÂ¶ÇÔºåÂΩì AWS DynamoDB Êï∞ÊçÆÂèëÁîüÂèòÂåñÊó∂ÔºåË∞ÉÁî® AWS Lambda ÁîüÊàê PDF Êä•Ë°®„ÄÇÂÜçÂ¶ÇÔºå‰∏∫ AWS API Gateway Êèê‰æõËá™ÂÆö‰πâÊùÉÈôêÈ™åËØÅËÑöÊú¨„ÄÇ
3. ÂÆöÊó∂‰ªªÂä° ‚Äî ‚Äî ‰ª•ÂæÄ‰ΩøÁî® cron ÁºñÂÜôÁöÑÂÆöÊó∂‰ªªÂä°ÂèØ‰ª•ÊîπÁî® AWS Lambda ÂÆûÁé∞ÔºåÂæàÊòéÊòæÁöÑÂ•ΩÂ§ÑÊòØ‰ªªÂä°‰∏çÊâßË°åÁöÑÊó∂ÂÄôÂÆåÂÖ®‰∏çÊî∂Ë¥π„ÄÇ
4. Áò¶ÂÆπÂô® ‚Äî ‚Äî Âõ†‰∏∫ AWS Lambda Êú¨Ë∫´Âü∫‰∫é Docker ÂÆπÂô®ÂÆûÁé∞ÔºåLambda ÊñπÊ≥ïË∑ëÂú® Amazon Linux AMI ‰∏≠ÔºåËôΩÁÑ∂ÂÆòÊñπÊîØÊåÅÁöÑÁºñÁ®ãËØ≠Ë®ÄÂè™Êúâ NodeJS„ÄÅJava„ÄÅPythonÔºå‰ΩÜÂÖ∂ÂÆûÂèØ‰ª•Áî® NodeJS ÁöÑ shim ËøêË°åÂ§ßÈÉ®ÂàÜËÉΩÂú® Linux ‰∏ãËøêË°åÁöÑÁ®ãÂ∫è„ÄÇ‰ª•Ëá≥‰∫éÊúâ‰∫∫Áî®Ëøô‰∏™ÁâπÊÄßÂÅö‰∫Ü LambCI ËøôÁßçËÑëÊ¥ûÂ§ßÂºÄÁöÑ Serverless CI ÊúçÂä°„ÄÇ
5. Êó†‰∫∫ËøêÁª¥ ‚Äî ‚Äî Serverless ÁöÑÊ†∏ÂøÉ‰ºòÂäøÂ∞±ÊòØ‰∏çÈúÄË¶ÅÁÆ°ÁêÜÊúçÂä°Âô®ÔºåËá™‰º∏Áº©ÁöÑÁâπÊÄßÂ¶ÇÊûúÁî®‰º†ÁªüÊñπÊ°àËß£ÂÜ≥‰ºöÁõ∏ÂØπÂ§çÊùÇÂæàÂ§ö„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶Å‰∏Ä‰∏™ÊúçÂä°‰∏∫‰Ω†Ë∑ëÂ•ΩÂá†Âπ¥ÔºåÊúüÈó¥ÂÆåÂÖ®‰∏çÈúÄË¶ÅÊãÖÂøÉÂÆÉÁöÑÊúçÂä°Âô®ËøêË°åÊÉÖÂÜµÔºåServerless ‰ºöÊòØÊúÄÂ•ΩÁöÑÈÄâÊã©„ÄÇ
ÂΩìÁÑ∂ Serverless ÁöÑ‰πü‰∏çÂ∞ΩÊòØ‰ºòÁÇπÔºåÂÆÉ‰πüÊúâ‰∏Ä‰∫õÂ±ÄÈôêÊÄßÊàñËÄÖËØ¥ÊòØÁõ∏ÂØπ‰º†ÁªüÊû∂ÊûÑÁöÑÁü≠ÊùøÔºå‰∏çËøá‰πü‰ªÖ‰ªÖ‰ΩìÁé∞Âú®Áé∞Âú®ÁöÑ AWS Lambda ‰∏äÔºåÁõ∏‰ø°‰ª•Âêé‰ºöÊúâÊîπÂñÑÔºö
1. ÁîüÂëΩÂë®ÊúüÁü≠ ‚Äî ‚Äî ‰∏Ä‰∏™ Lambda ÊúÄÂ§öÂè™ËÉΩË∑ë 5 ÂàÜÈíüÔºåÊâÄ‰ª•ÊÉ≥Áî®ÂÆÉË∑ë ffmpeg/mencode Êù•Â§ÑÁêÜÈ´òÊ∏ÖËßÜÈ¢ëÁöÑËØùÂæóÊÉ≥Âë®Âà∞ÔºåÂèØ‰ª•ËÄÉËôëÂàáÁâáÂàÜÊñ≠Â§ÑÁêÜÔºå‰∏çËøáÈÇ£Â∞±Â§çÊùÇ‰∫Ü„ÄÇ
2. Linux only ‚Äî ‚Äî ÊÉ≥ÂÅö‰∏Ä‰∏™ macOS ÁöÑ CI ÊúçÂä°ÁõÆÂâçÊòØ‰∏çÂèØËÉΩÁöÑ„ÄÇ
3. ËØ≠Ë®ÄÈôêÂà∂ ‚Äî ‚Äî Èô§‰∫Ü NodeJS„ÄÅJava„ÄÅPython ‰ª•Â§ñÔºåÂÖ∂ÂÆÉÁ®ãÂ∫èÈÉΩÂè™ËÉΩÈÄöËøá shim Êù•ËøêË°åÔºåË∞ÉËØïÁõ∏ÂØπÈ∫ªÁÉ¶„ÄÇ
4. ÈÉ®ÁΩ≤Êìç‰ΩúÁπÅÂ§ö ‚Äî ‚Äî ÈíàÂØπÁ¨¨Ëøô‰∏™ÈóÆÈ¢òÔºåÂ∑≤ÁªèÊúâ‰∏çÂ∞ëËß£ÂÜ≥ÊñπÊ°àÔºåÂ¶Ç Sparta„ÄÅApex„ÄÅWebtask„ÄÅServerless ÈÉΩÂú®ÁÆÄÂåñ Lambda ÈÉ®ÁΩ≤ÁöÑÂ∑•‰Ωú‰∏äÁªôÂá∫‰∫ÜÂêÑÁßçÁ≠îÊ°à„ÄÇËÄå now.sh ËÉΩÂú®Áü≠Êó∂Èó¥ÂÜÖÂèóÂà∞ÂºÄÂèë‰∫∫ÂëòÁöÑËøΩÊçßÔºåÊàëËßâÂæó‰∏Ä‰∏™ÂéüÂõ†Â∞±ÊòØÂÆÉÁÆÄÂåñ‰∫ÜÈÉ®ÁΩ≤„ÄÇÂ¶Ç‰ªäÂ§ßÂéÇÈÉΩÂú®ÂÅö‰∏Ä‰∫õÁÆÄÂåñÊìç‰ΩúÁöÑ CLI Â∑•ÂÖ∑ÔºåÂÉè AWS Amplify Â∞±ËØïÂõæ‰ªéÂ∑•ÂÖ∑ÈìæÂ±ÇÈù¢Âê∏ÂºïÊõ¥Â§öÁöÑÂºÄÂèë‰∫∫ÂëòÂä†ÂÖ•„ÄÇ
Áî±‰∫é‰∏äÈù¢ÊèêÂà∞ÁöÑËøô‰∫õÁâπÊÄßÔºåÊàëËßâÂæó Serverless Ëøô‰∏™Ê¶ÇÂøµÈùûÂ∏∏ÈÄÇÂêà App ÂºÄÂèë‰∫∫ÂëòÊ∑±ÂÖ•Á†îÁ©∂„ÄÇÂÆÉÂ∞±ÂÉèÊòØ‰∏Ä‰∏™Ê∞∏Ëøú‰∏ç‰ºöÂÄíÈó≠ÁöÑ Parse Cloud Function (ÂìáÔºåÈ°∫Ë∑ØÂêêÊßΩ Facebook ‰∫Ü~~)ÔºåÊàñËÄÖËØ¥ÊòØ‰Ω†Ë∫´Ëæπ 24 Â∞èÊó∂Âú®Á∫øÁöÑËøêÁª¥ÊúãÂèãÔºå‰∫¶ÊàñËØ¥ÊòØ‰Ω†ÁöÑÂºÄÊú∫ÊúÄÂø´ÁöÑ‰∏ÄÂè∞ÁîµËÑë(ÂÆûÊµãÁî® AWS Lambda ËøêË°å‰∏Ä‰∏™ Swift ÂÜôÁöÑ Hello World Âè™Ë¶Å 16ms)„ÄÇ
Âà∞Ê≠§Êñá‰ª∂ÊúÄÂêé‰∏ÄÊ¨°Êõ¥Êñ∞Êó∂‰∏∫Ê≠¢ÔºåÊàëÂÜôËøáÁöÑ AWS Lambda ËøòÈùûÂ∏∏Â∞ëÔºåÂè™ÂÆûÁé∞Ëøá‰∏Ä‰∫õËæπËßíÂäüËÉΩ„ÄÇÊàëÊõæÁî®Ëøá ApexÔºåÂú® AWS Lambda ‰∏äÁî® Go Êù•ÂÜô Serverless Á®ãÂ∫è„ÄÇ‰∏∫‰ªÄ‰πàÊ≤°Áî® Swift Âë¢ÔºüÂõ†‰∏∫ÊúçÂä°Á´ØÁöÑ Swift Â∫ìÂÆûÂú®Â§™Â∞ë‰∫ÜÔºåÁº∫ÁöÑËΩÆÂ≠êÂ§™Â§ö„ÄÇËÄå‰∏î Swift ‰æùËµñÁõ∏ÂØπËæÉÂ§öÔºå‰∏Ä‰∏™ HelloWorld.swift Ë¶ÅÂú® AWS Lambda ÈáåË∑ëËµ∑Êù•Â∑Æ‰∏çÂ§öÈúÄË¶Å 16MB ÁöÑÁ©∫Èó¥ÔºåÂêåÊ†∑ÁöÑ Go Âè™Ë¶Å 2MBÔºåËÄå‰∏î Go ÁöÑÂ∑•ÂÖ∑ÈìæÈùûÂ∏∏Âº∫Â§ß„ÄÇÂ¶ÇÊûúÊúâÂÖ¥Ë∂£Âú® AWS Lambda ÈáåËøêË°å Swift Á®ãÂ∫èÔºåÂèØ‰ª•ÂèÇËÄÉ ËøôÁØáÊñáÁ´†„ÄÇ
ÂñùËå∂„ÄÅÁúã‰π¶„ÄÅËÆ≤ÊïÖ‰∫ã
ÂñùËå∂„ÄÅÁúã‰π¶„ÄÅËÆ≤ÊïÖ‰∫ã
Written by
80 Âêé iOS ÂºÄÂèë | ‰∫åÊµÅÂâçÁ´ØÂºÄÂèë | ‰∏âÊµÅÁïåÈù¢ËÆæËÆ°Â∏à | ÊûúÁ≤â | Â•ΩÁà∏Áà∏
ÂñùËå∂„ÄÅÁúã‰π¶„ÄÅËÆ≤ÊïÖ‰∫ã
"
https://medium.com/@PicardParis/discovering-google-cloud-platform-e621ea3200d7?source=search_post---------174,"Sign in
There are currently no responses for this story.
Be the first to respond.
Laurent Picard
Mar 17, 2017¬∑2 min read
Google Cloud Next 2017 event was huge. Over 200 sessions (about 45 min each) are available, covering many subjects: IaaS, PaaS, Containers, Web Apps, APIs, Machine Learning, Databases, G Suite, Chrome, Android‚Ä¶ The momentum around Google Cloud Platform (GCP) is just impressive.
Over the 3 days, they had 100 announcements.
blog.google
Last but not least, Google is currently offering a $300 credit to get started with GCP for free.
cloud.google.com
Experimenting with Google Cloud Platform
Tech lover, passionate about software, hardware, science and anything shaping the future ‚Ä¢ ‚õÖ explorer at Google ‚Ä¢ Opinions my own ‚Ä¢ You can DM me @PicardParis
Tech lover, passionate about software, hardware, science and anything shaping the future ‚Ä¢ ‚õÖ explorer at Google ‚Ä¢ Opinions my own ‚Ä¢ You can DM me @PicardParis
"
https://medium.com/@pentacent/depending-on-your-use-case-you-could-actually-perform-hot-upgrades-with-docker-containers-353e88761eec?source=search_post---------175,"Sign in
There are currently no responses for this story.
Be the first to respond.
Philipp
Nov 16, 2017¬∑1 min read
Jan Stevens
Depending on your use-case, you could actually perform hot upgrades with Docker containers. After all, we‚Äôre still using OTP Releases, just packaged inside of a Docker container. I just wouldn‚Äôt recommend it because I find stateless deployments preferable. So instead you‚Äôd typically use techniques like blue-green deployment.
However, the use of Docker makes it extremely easy to deploy and orchestrate Elixir applications on PaaS systems which might be more important for some users.
I make software. Passionate about Elixir. User of C++, Ruby & JavaScript. Current project: https://www.dblsqd.com
1
1
I make software. Passionate about Elixir. User of C++, Ruby & JavaScript. Current project: https://www.dblsqd.com
"
https://arm.ag/dovec%C3%B4te-9c29cec04d82?source=search_post---------176,NA
https://medium.com/@alibaba-cloud/why-to-have-and-how-to-support-multi-cloud-environments-b8c3e35b8dbd?source=search_post---------177,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Feb 9, 2018¬∑4 min read
Public IaaS and PaaS clouds have existed long enough that they have become mainstream technologies. Many organizations have adopted a ‚Äúcloud first‚Äù IT model, in which the cloud is the default location for deploying new applications and services.
Given this trend, the focus on the cloud has largely shifted from cloud adoption to implementing multi-cloud deployments. This article explains why multi-cloud infrastructures are useful and how to implement them.
Although multi-cloud environments are undeniably more complex than single cloud environments, there are compelling reasons for adopting a multi-provider approach to the cloud. One such reason is that using multiple clouds allows organizations the flexibility to choose best-of-breed solutions. There are certain services that nearly all of the major cloud providers offer. For example, all of the major public cloud providers offer an object storage solution, a platform for hosting virtual machines, and a database service.
Whatever the service, there is a good chance that one provider will offer a better solution than the others. One provider might, for instance, have a better virtual machine platform, while a different provider may have a better storage solution. Using multiple providers gives you freedom of choice.
Just as operating in a multi-cloud environment gives you the ability to choose a best-of-breed solution from a number of competing services, multi-cloud environments also give you the ability to shop for the best price. You might find that one provider has the best price for database services, while a different provider has the best price for virtual machine hosting.
Security and redundancy also tend to be strong considerations when implementing a multi-cloud environment. As the old saying goes, you shouldn‚Äôt put all of your eggs in the same basket. An organization might, therefore, mirror a database to a different cloud provider, so that a copy of the data will remain available in the event that the primary cloud provider suffers an outage.
Likewise, multi-cloud usage can help to keep data secure (or private). Some organizations use erasure coding to stripe data across multiple cloud storage platforms. Very often, the data is written in such a way that no one single provider has a complete copy of the data. Instead, each cloud contains only fragments of data that are useless by themselves. Hence, if a cloud provider is compromised, it will be impossible for the hacker to read the organization‚Äôs data.
There are two main things that your organization will need in order to support a multi-cloud environment. First, you will need the appropriate staff resources. Each cloud service provider has its own way of doing things, and so expertise in one cloud environment does not necessarily translate to expertise with another.
Simply put, the members of your IT staff will need to have a good working knowledge of the cloud platforms that are being used. Not every IT staff member needs an intricate knowledge of every cloud platform, but the IT department should collectively have the knowledge required to support each cloud that is being used.
The second requirement is having a strategy for moving resources to a different cloud. There are actually two different considerations involved in this requirement. The first consideration involves the actual migration of data. The second consideration is being able to use the data once it is in its new location.
Obviously, there is no universal answer to these requirements, because each organization‚Äôs needs are different. When it comes to data migration, however, the best option is to check to see what types of data migration tools the public cloud provider makes available to its subscribers.
Alibaba Cloud provides a number of different tools for uploading and downloading data, which can be useful when implementing a multi-cloud architecture.
While you may not need every one of these tools, different tools are useful in different situations. Alibaba Cloud‚Äôs tools are listed at https://www.alibabacloud.com/help/doc-detail/51654.htm and are divided into two categories‚ÄìAlibaba Cloud DTPlus products and open source products. The Alibaba Cloud DTPlus products include tools such as Data Integration of DataWorks (a data synchronization tool), MaxCompute Client (a data uploading and downloading tunnel), and Data Transmission Service (DTS). DTS is a data migration tool that is designed to work with RDBMS, NoSQL, OLAP, and other data sources. The open source tools are available on GitHub and include Sqoop, Kettle, Flume, Fluentd, LogStash, and OGG.
There are a number of compelling reasons why it may be beneficial for an organization to adopt a multi-cloud strategy. When doing so, however, it is important to carefully assess the various public cloud providers in order to determine which providers will best meet the organization‚Äôs own unique needs. One of the best ways of assessing a cloud provider‚Äôs capabilities is to sign up for a free trial. Currently, Alibaba Cloud is offering a free trial at: https://www.alibabacloud.com/campaign/free-trial#free-products. This free trial includes $300 of credit, which you can use to explore Alibaba Cloud‚Äôs various cloud offerings.
Brien Posey is a Fixate IO contributor, and a 16-time Microsoft MVP with over two decades of IT experience. Prior to going freelance, Brien was CIO for a national chain of hospitals and healthcare facilities. He also served as lead network engineer for the United States Department of Defense at Fort Knox. Brien has also worked as a network administrator for some of the largest insurance companies in America. In addition to his continued work in IT, Brien has spent the last three years training as a Commercial Scientist-Astronaut Candidate for a mission to study polar mesospheric clouds from space. You can follow Posey‚Äôs spaceflight training at www.brienposey.com/space
Reference:
https://www.alibabacloud.com/blog/Why-to-Have-and-How-to-Support-Multi-Cloud-Environments_p325328?spm=a2c41.11219737.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@alibaba-cloud/backend-as-a-service-baas-for-efficient-software-development-6a7a142af477?source=search_post---------178,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Mar 15, 2018¬∑10 min read
First-generation cloud services, such as Alibaba Cloud IaaS and PaaS products, eliminate the need for managing servers and O&M systems by deploying cloud data centers. Backend-as-a-Service (BaaS) represents the second-generation cloud service platform. BaaS can further simplify and optimize cloud computing resources and provide all-in-one cloud services including development, O&M, and service management.
BaaS can package public cloud data center resources based on frontend application scenarios and provide them to developers through simple interface invocation. With those benefits, developers can focus on studying users, creating and designing app software, and developing mobile-end apps. This greatly simplifies the development procedure, development cycle and personnel, as well as capital investment while accelerating the launch of apps to the market. The objective for the development of the BaaS architecture is to solve business development efficiency problems. From this article, you can understand the development trends of current software development models.
With the proliferation of the Internet and the booming number of mobile-technology-based start-ups, the time for implementing an idea is as short as a few months. With intense competition, if a company fails to do so, other similar products may come out, which is true for O2O, Internet of Things and Internet finance. For entrepreneurs, launching products quickly, going through market tests and occupying the target market is undoubtedly a quick-action battle. To survive and thrive in such a competitive marketplace, you must run your business efficiently and effectively. Rooted in the furnace of the mobile internet, the BaaS architecture has gained importance.
For entrepreneurial developers, the priority is cost and efficiency. They normally lack technical accumulation, and they need to develop their businesses by proving their business models with low costs. In this context, cloud service providers become their best options.
When entrepreneurs‚Äô technical teams are trying to implement their architectures, they will be delighted to find that dedicated entrepreneurial technical companies are providing some of those required common features. Being open to developers as cloud services, these features can either provide certain portions of the required functionality or complete features. On this basis, the cloud service ecosystem is formed and can provide entrepreneurs with various technical services.
Let us assume that you are the CTO of an O2O entrepreneurial company and are considering developing a business platform from an O2O idea. In this age of the mobile internet, mobile app and web features are mandatory. You are likely to face the following challenges:
‚óèDeployment and maintenance of servers‚óèDevelopment of apps and websites‚óèDevelopment of backend servers‚óèPlatform functions like authentication and authorization, file storage, pushing and communication, mapping, payment, social sharing, verification and security, intelligent identification, searching, and user behavior analysis‚óèServices like Activity management
As a CTO, to overcome these challenges, you need to recruit backend, frontend, iOS, Android and O&M engineers. However, when trying to design and implement each of these features, you may find that some of these recruits are technically not sound. On the other hand, implementing these features independently and quickly requires high costs, time, and resources.
However, by researching the technical market, you can find that these basic services are already available as solutions from dedicated companies, so all you have to do is integrate those solutions to save development costs.
You can find entrepreneurial technical companies that provide dedicated services in almost every common functional area. With sharp business acumen, these technical companies can quickly respond to market needs, and this boosts the emergence of new technical architecture services. Entrepreneurs can directly utilize such rich solutions to meet their business needs and quickly develop product platforms for end users.
In fact, those entrepreneurial and technical platform companies are building a complementary relationship between themselves. While entrepreneurial companies are using the services from technical platform companies, the latter can obtain more data, and the former can obtain free and improved services. Through competitions, technical platform companies can enhance their services and offer developers a better development experience. This allows those companies to take the lead in their respective business fields.
In this mobile internet and cloud computing age, the technical platform companies can encapsulate certain features as services to acquire new users (in the form of developers). The strategy has resulted in the popularity of the BaaS architecture soaring in recent years.
Today, so many systems exist in Taobao‚Äôs technical departments, and we know little about their specific roles. To figure this out, we can go over those systems by using the domain layered model:
Surprisingly, we find that there are hundreds of systems supporting a relatively small number of services. By exploring those systems in depth, we can find the following major problems:
Here, you can easily see the waste of development and physical resources. Those systems have also become a huge burden that requires lots of effort and resources to maintain, upgrade, develop, run, and monitor. To perform code-level reconstruction on a software program that is complicated and difficult to maintain, you probably require architecture-level reconstruction to overcome the system-level complexity.
Alibaba Cloud‚Äôs developers have deep technical understanding as well as extensive practical industry experience in cloud technology. On the one hand, Alibaba Cloud has outstanding business scenarios that require excellent technical skills to maintain; on the other hand, internal developers have to go through highly intensive development practices, which make them come out on top.
While outsourcing internal systems, for example, to develop a new business system, Alibaba Cloud was able to determine some of the best practices that developers need to follow during different phases.
‚óèDevelopment phase:Developers need to consider how to design databases, separate databases, and tables, and ensure high security, concurrency, and performance. In this case, developers need to use the databases (MySQL and Hbase), message middleware (notify and metaq), cache (Tair), distributed invocation (HSF) and .J2EE.
‚óèMaintenance phase:Alibaba Cloud‚Äôs attitude towards system stability is that stability prevails over everything. During one recent promotion event, most development teams focused on ensuring system stability by reviewing system architecture and dependency strength and designing traffic limitation plans. Thus, high concurrency, system performance optimization, and JVM have also become strengths of Alibaba Cloud developers.
However, we must go over the following questions: Is it necessary for developers to master so many skills in developing business systems in addition to implementing business logic? Shouldn‚Äôt business system developers focus on developing business logic? Shouldn‚Äôt system stability and high backend concurrency performance be implemented by less advanced and professional teams, why does each development team have to do the same job? Is this the result of job division, planning or the technical architecture?
In Alibaba Cloud, there is a trend: after a certain period, technical system developers are prone to running businesses, and business system developers are prone to building platforms. On the one hand, this phenomenon reflects the developers‚Äô desire to promote themselves based on KPIs; on the other hand, this reveals their confusion about career development resulting from ambiguous objectives.
To be specific, business development teams need to meet business requirements while technical development teams need to provide various capabilities for business development and ensure underlying support services. Such architectural specificity ensures unambiguous assignment of responsibilities.
To solve problems of complexity, we need to learn from enterprise middleware software programs. For example, for traditional banking businesses, different internal systems can combine various standards such as EIP and ESB to work out complicated businesses together.
Software engineering draws many references from construction engineering. In the construction field, China Grand Enterprises is famous for constructing the Broad Pavilion overnight at the Shanghai Expo 2010.
Recently, China Grand Enterprises constructed a high-rise with 57 floors in 19 days. Their constructional renovation achievement demonstrates China‚Äôs progress in today‚Äôs world. Their achievement lies in the innovative construction method, namely constructing buildings by following the ‚Äústandard construction model.
If you can standardize and modularize your accumulative technical skills so that business teams can quickly utilize those skills, you will be able to gain the expected ‚Äúplatform‚Äù capabilities.
For Alibaba Cloud, its technical accumulation has formed a complete system from cloud infrastructure construction to middleware, to e-commerce systems.
This system covers almost all technical fields, and the accumulated skills can support the world‚Äôs largest e-commerce businesses. To solve current problems, it needs to review existing processes and ‚Äúmodularize‚Äù its capabilities in addition to combining those capabilities through ‚Äústandardization.‚Äù
In this way, Alibaba Cloud development teams can effectively develop separate capability modules while business systems can use these modules in the standard way.
Building a capability supermarket allows you to use refined market management to transform the development model from an open market to a modern supermarket. As we all know, supermarkets are bound to replace open fairs during urbanization development.
The reasons are simple. Essentially, supermarkets outshine open fairs due to their chain of operation, which features centralized procurement, distribution, and management. Centered around the linking system, chained supermarkets rely on the network of mass outlets, develop sales revenue based on the centralized procurement system, and make a logistic profit out of modern distribution centers. They route marketing information to the processing and manufacturing industry to develop OEM products and even form a supply chain to develop manufacturing profit. That is to say that chained operation expands standardization, routinization, and industrialization to the circulation domain to reduce costs dramatically while providing consumers with tangible benefits.
In this centralized management and standardization approach, chain operation can earn maximum scale and efficiency advantages. Similarly, business development teams should also learn from this modern supermarket operation model to improve work efficiency through centralized management and standardization.
Nowadays, uneven business development and technical planning have created a gap in Alibaba Cloud‚Äôs operation. By reviewing its internal development ecosystem, Alibaba Cloud found that different development teams develop based on separate department businesses, resulting in cases of repeated construction of resources. Technical and business departments cannot fully support and complement each other while they do not have a clear understanding of each other‚Äôs capabilities or overall market capabilities. This results in redundant workloads that create a similar situation to that of repetitive procurement in open markets. To solve this problem, we can take cues from modern supermarkets for their overall management and planning of operation models, layouts, stocks, and capabilities. In this way, it is possible to manage the responsibilities and capabilities of different development teams explicitly while ensuring close cooperation among them.
Metaphorically, capabilities are like products in a supermarket. You can purchase the required capabilities, while at the same time able to discard the unsalable ones. You can enhance salable capabilities, and avoid repetitive capabilities. You can also centrally plan categories of capabilities, with their utilization monitored and charged accordingly.
By doing this, you can formulate an effective mechanism with which a newly-developed capability will be available to all business teams, and it can undergo further development to meet the requirements. In this way, different development teams will not develop similar capabilities repeatedly, preventing wastage of resources. (For example, think about how many rule systems are there internally.)
By operating capability developers and consumers, one can create an efficient ecosystem to avoid resource wastage. By using the supermarket capability, consumers can understand all internal capabilities while capability developers can respond to market needs to develop required capabilities.
.
Legacy enterprise middleware uses enterprise integration systems to coordinate complicated business problems among multiple systems. Similarly, Alibaba Cloud‚Äôs business development also requires the coordination of its systems and needs to respond to complicated businesses quickly.
Many scenarios need data synchronization, such as the data synchronization between business systems and search systems and the data exchange between ODPS offline data and online data.
Currently, we achieve data interaction of these systems by custom APIs or scripts of specific systems. To develop such standards, developers need to understand each system‚Äôs APIs. Once those standards are ready, like enterprise integration, it will significantly lower the development threshold of developers and improve development efficiency.
Soon, the new tiers of the mobile internet cloud-computing era (UI, MBaaS, and platform) will replace the three-tier architecture of the J2EE time (presentation, middle and data service tiers).
With the new architecture, complicated business systems can become simple and loosely-coupled as well enable easy sharing of data and interfaces internally and externally.
As shown in the figure above, most of Alibaba Cloud‚Äôs development architecture stays in the tightly-coupled state, or it partially transforms into the SOA a;;rchitecture. Ideally, it needs to move to a third development architecture to meet complex business needs among systems in a simple, standard and interchangeable way.
Also, for business development teams, their development capabilities must align better with the frontend. In this way, those teams only need to retain JavaScript and RESTful APIs in their technology stacks while they can focus on understanding business models and logic to quickly build business systems and implement business innovations.
For backend teams, they need to focus on implementing platforms and services. To implement those services, they need to upgrade their development architectures from the J2EE era (such as MVC and RPC) to new architectures of the cloud era such as microservices, EDA and CQRS. They should enhance their understanding of system complexities and utilize servitization to meet the needs of business teams.
With the upgrade of those architectures, division of responsibility for development teams will have better definitions, for example:Development team -> frontend, interaction and business logicBackend team -> platforms, services, and stability
By building an optimum ecosystem around data for applications (businesses), developers and platforms, it is possible to share all developers‚Äô expertise and experience effectively. Further, all developers can review and follow the development of various businesses and the designing and implementation of architectures. Meanwhile, by developing development expansion and module standards, developers can take the initiative to submit their capability modules, which you can purchase through the platform ‚Äúcapability supermarket.‚Äù
This article looked at some of the development trends of current software development models. We discussed how the adoption of the Internet and mobile technologies has revolutionized the business ecosystem, with entrepreneurs able to implement their ideas quickly by leveraging services of technical platform providers. We also looked at certain challenges that are likely to come in our way, and finally discussed some recommendations by Alibaba Cloud on overcoming these challenges.
Reference:
https://www.alibabacloud.com/blog/Backend-as-a-Service-(BaaS)-for-Efficient-Software-Development_p519851?spm=a2c41.11292175.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
"
https://medium.com/@IBMDeveloper/3-factors-for-successful-open-source-contributions-19c4bd36d979?source=search_post---------179,"Sign in
There are currently no responses for this story.
Be the first to respond.
IBM Developer
May 16, 2019¬∑2 min read
Open source software is eating the world, with numerous projects that cover a breadth of technologies, from IaaS to PaaS to CaaS to Serverless, AI, and more.
With so many projects and so much technology, getting started in open source can be overwhelming. What project should you work on? How do you open source your own code? How do you make your project meaningful for customers? In this blog post, I share the three key aspects that you should pay attention to when contributing to open source.
Since 2012, I have worked in various open source communities and on many different open source projects, including OpenStack, Mesos, Kubernetes, Itsio, Kubernetes Federation V2, Knative, cluster-api, even becoming a maintainer for some of those projects.
The image above shows my journey in open source. It‚Äôs important to note that with every open source product that I worked on, IBM now has a product or clients using it. My open source contributions, product integrations, and clients moved me to the position of an open source maintainer.
Along my journey in open source, I have learned a few things along the way that I think will help if you are planning to contribute or already contributing to open source.
Read the full blog post on IBM Developer.
Originally published at https://developer.ibm.com.
Open source, code patterns, tutorials, meet-ups, challenges, mentoring, and a global coding community ‚Äî all in one place.
See all (6,456)
Open source, code patterns, tutorials, meet-ups, challenges, mentoring, and a global coding community ‚Äî all in one place.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/altoros-blog/2016-2017-trends-smart-cities-510f32f410ba?source=search_post---------180,"There are currently no responses for this story.
Be the first to respond.
Backed up by technologies such as PaaS, artificial intelligence, and IoT, smart cities have grown to hit the top 5 IT trends in 2016‚Äì2017. The blog post discusses the concept of a smart city, exploring whether it can be expanded to a smart nation and what this expansion might raise in case of misuse. You will also find examples of how Smart Cities projects transformed the life of the world‚Äôs largest cities.
www.altoros.com
Driving digital transformation with cloud-native platforms, blockchain, ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Written by
Altoros provides consulting and fully-managed services for cloud automation, microservices, blockchain, and AI&ML.
Driving digital transformation with cloud-native platforms, such as Kubernetes and Cloud Foundry. Helping to disrupt industries with blockchain and ML/RPA.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@rakiabensassi/thanks-for-sharing-this-piece-anna-3e37f9448b1e?source=search_post---------181,"Sign in
There are currently no responses for this story.
Be the first to respond.
Rakia Ben Sassi
¬∑Apr 11, 2021
Anna Geller
Thanks for sharing this piece, Anna! But if it's just an answer to the YouTuber's video that you've mentioned then it's a generalization to say ""Many engineers don't understand serverless.""
Also, the presence of many paradigms like cloud, native cloud, containers, Kubernetes, Docker, virtual server, PaaS, serverless, ... may make it not easy to understand ""Serverless"" and what differentiates it from other similar concepts.
I hoped to find out in this article more explanation about this last point than a concentration on just the ""cold start"" and latency issue which was not my reason to want to understand serverless. So instead of ""seeing software architectures from a single angle,"" my reason was ""I want to see and understand the big picture"", I want to know why serverless instead of container, or instead of PaaS, etc.
Join a community for smart, curious people and get my new posts in your inbox.

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
Senior Software Engineer, TechLead, Speaker | Psychology & Creativity Enthusiast „ÉÑ I write about engineering, technology, and leadership - https://webenius.com
About
Write
Help
Legal
Get the Medium app
"
https://bartlorang.com/the-cloud-is-taking-over-and-why-you-should-apply-to-techstars-cloud-f6562f131d3b?source=search_post---------182,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
The cloud is taking over everything. Whether it‚Äôs PaaS, IaaS, APIs, virtualization, security, infrastructure or hosting ‚Äî everything is being built for (and in) the cloud.
The power of the cloud is real, and it‚Äôs here. Currently there is an enormous market opportunity for cloud infrastructure businesses. For proof, just look at Rackspace and Amazon AWS ‚Äî both enormously successful cloud infrastructure businesses and growing like weeds. There‚Äôs also SendGrid (for email delivery), Twilio (cloud-based communications) and UrbanAirship (powering mobile apps).
We‚Äôre obviously big believers in the cloud. At FullContact, we‚Äôre building a comprehensive suite of cloud-based APIs to manage contact information and ultimately solve the world‚Äôs contact information problem. (Fun fact: the original company name of FullContact was even ‚ÄòCloudCenter.‚Äô)
As a result of this powerful shift towards the cloud, the folks at TechStars have created TechStars Cloud.
If you‚Äôre a cloud-based startup, you should apply to TechStars Cloud. Why? As I‚Äôve written about previously, TechStars empowers entrepreneurs through incredible mentorship. And TechStars recently sweetened the pot by adding $100K of additional financing from an awesome group of investors.
So don‚Äôt delay, you‚Äôve got until November 7th to get your application in. And if you need any advice or help on your application, hit me up at bart@fullcontact.com ‚Äî I‚Äôm more than happy to help!
Originally published at https://bartsblogsite.wpengine.com on October 31, 2011.
Musings on life, business and the universe from a lifelong
Written by
Dad, Husband, and Co-Founder of @FullContact and @v1vc ‚Äî Lifelong Entrepreneur and Investor.
Musings on life, business and the universe from a lifelong investor and entrepreneur
Written by
Dad, Husband, and Co-Founder of @FullContact and @v1vc ‚Äî Lifelong Entrepreneur and Investor.
Musings on life, business and the universe from a lifelong investor and entrepreneur
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/technology-hits/what-is-the-cloud-exactly-5dbf6583308?source=search_post---------183,"There are currently no responses for this story.
Be the first to respond.
For most people, the Cloud dries up in a set of acronyms, a pile of technologies that moves data and jobs away.
The scenario worsens when considering how most of the consulting offering is written: nonsensical‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jeffjarvis/worried-261c3c65d375?source=search_post---------184,"Sign in
There are currently no responses for this story.
Be the first to respond.
Top highlight
Jeff Jarvis
Sep 19, 2016¬∑2 min read
A week ago, I registered voters in Bethlehem, PA, as a Hillary volunteer (I am a known partisan). I came away more worried than ever about this election. I became even more worried when I read this from The Times‚Äô Upshot: ‚ÄúWhy the Whole Trump-Clinton Election Could Probably Just Be Held in Pennsylvania.‚Äù This is why I‚Äôm going to spend every weekend moment I can between now and Nov. 8 in Pennsylvania.
Bethlehem is no Allentown but it is a city that steel built and it has two major colleges. With a heritage of labor and academics, this town should be thick with my fellow travelers. But after spending an afternoon in front of the library registering voters, I saw well more than a few Republicans, some of whom said without hesitation, secrecy, or shame that they were voting for Trump. I saw some enthusiastic Clinton voters who also told me they were afraid to put Hillary bumper stickers on their cars (what does this say about the state of civility and political discourse in America?). I met some shrugging Hillary voters. And I met many people ‚Äî including many young people ‚Äî who said they weren‚Äôt voting. I left depressed.
With only 49 days until the most momentous election in my long lifetime, I‚Äôm concerned that the campaign is still all about Donald Trump: he‚Äôs all Trump talks about, of course, and he‚Äôs all Clinton is allowed to talk about because he‚Äôs all media talks about. He‚Äôs nucking futs and anyone who‚Äôs not futs knows that already.
What the campaign needs to do in the remaining days is (1) have Hillary talk about her plans and qualifications, (2) show us the real, human Hillary we never get to see, and ‚Äî most important ‚Äî (3) show us the enthusiastic Hillary supporters who are never heard from to give those voters who are afraid of showing off their bumper stickers cover.
On Sunday this week, I went to the opening of Clinton‚Äôs New Jersey campaign headquarters with Cory Booker. It was more than jammed with eager Clinton backers ‚Äî 1,200 signed up and most of them were lined up on the street. I repeat: These are the voices we do not hear in media. These are the voices the campaign needs to showcase.
Blogger & prof at CUNY‚Äôs Newmark J-school; author of Geeks Bearing Gifts, Public Parts, What Would Google Do?, Gutenberg the Geek
See all (1,521)
78 
14
78¬†claps
78 
14
Blogger & prof at CUNY‚Äôs Newmark J-school; author of Geeks Bearing Gifts, Public Parts, What Would Google Do?, Gutenberg the Geek
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@pkerrison/pizza-as-a-service-2-0-5085cd4c365e?source=search_post---------185,"Sign in
There are currently no responses for this story.
Be the first to respond.
Paul Kerrison
Sep 1, 2017¬∑3 min read
Recently I was trying to describe the various types of cloud services available for modern IT deployment. Like many, I resorted to an analogy ‚Äî the ever popular ‚ÄúPizza as a Service‚Äù.
"
https://medium.com/@claudiopro/getting-started-with-kubernetes-via-minikube-ada8c7a29620?source=search_post---------186,"Sign in
There are currently no responses for this story.
Be the first to respond.
Claudio Procida
Jul 24, 2016¬∑6 min read
Kubernetes is an open-source production-grade container orchestration system for automating deployment, scaling, and management of containerized applications.
This tutorial is a simplified version of the Kubernetes Hello World Walkthrough, which uses minikube to run your service on a local Kubernetes cluster instead of Google Container Engine, so that you won‚Äôt need a cloud platform at all.
This tutorial uses Mac OS X, but the reader can easily follow on a different OS using the command flavors as noted in the various sections.
if the command returns an output, you‚Äôre good to go. Here‚Äôs the output on my machine:
If you‚Äôre on Linux, you would run instead:
In order to validate our deployment and check that everything went well, let‚Äôs start the local Kubernetes cluster:
We can inspect the cluster for running pods:
‚Ä¶and cluster nodes:
The minikube project on GitHub offers a quick start demo which uses a pre-built Docker image hello-minikube. Since we started the minikube cluster already, we can skip the first step:
Now, let‚Äôs run the built-in hello-minikube pod. This will create a deployment for the pod:
We can inspect the pods and the deployments to verify these have been updated with the following commands:
In order to access the hello-minikube service, we must first expose the deployment to an external IP via the command:
Note we must use the type=NodePort because minikube doesn‚Äôt support the LoadBalancer service. We can check if the service was exposed by listing services:
Now we can either curl the service from the CLI, or hit it via the browser. In order to figure out its external IP address and port, we can use the command:
Note you can figure out the IP address, which is mutable and controlled by VirtualBox, via the command minikube ip, or inspecting the output of ifconfig:
Once we‚Äôre done with the hello-minikube service, we can delete its deployment and service, in order to free up resources, and verify they were in fact deleted:
This last example is a bit more complex and requires the creation of a small node server, build it into a Docker image with a Dockerfile, and run it in Kubernetes.
Let‚Äôs create a simple node project hello-node:
Let‚Äôs create a simple http server that returns a Hello World! response:
Let‚Äôs edit the Dockerfile to declare this image will use node 4.4, and the container will run the service by executing the server.js file:
Before issuing any Docker commands, let‚Äôs set the Docker environment. Similarly to running eval $(docker-machine env), we generate Docker environment variables for the minikube runtime using the command minikube docker-env:
Now, let‚Äôs build the image. This will take some time, as it will fetch images for dependencies like node 4.4 from the Docker hub. Once finished, you‚Äôll have a new Docker image ready to deploy (note the trailing dot `.` in the command: this tells Docker to build the current directory):
Now we can deploy the hello-node pod to our local Kubernetes cluster via kubectl:
As before, we must expose the deployment to an external IP address and port in order to access it via curl:
Victory! We have successfully written, built, and deployed a simple node service as Docker image to our local Kubernetes cluster :-)
This toy project is just a starter to become productive with Kubernetes locally, before you start publishing pods to your cloud platform environment and incur in charges. It allows you to make your first baby steps without fear of scaling down your credit, while you run your experiments.
Let‚Äôs not forget to delete the service and deployment for hello-node, and shut down the minikube cluster once finished:
Thanks for reading through this tutorial! Let me know if you found it useful in the comments ;-)
Full stack web developer with a keen interest for the open web platform, privacy, security, and IoT. Former Amazonian, former IBMer. All views my own.
610 
14
Some rights reserved

610¬†
610 
14
Full stack web developer with a keen interest for the open web platform, privacy, security, and IoT. Former Amazonian, former IBMer. All views my own.
"
https://medium.com/hackernoon/stop-spending-engineering-effort-solving-problems-you-dont-have-8d18584f4d2a?source=search_post---------187,"There are currently no responses for this story.
Be the first to respond.
This post comes from a place of frustration. I apologise in advance.
If you are writing a web app ‚Äî a great web app, a fantastic web app, THE BEST EVER WEB APP ‚Äî you do not need a container orchestrator. You need a PaaS. You do not need 5 different ways to deal with rolling out new versions of your app. You do NOT need to be able to configure and tweak your database. Do not manage your own database! You do not need etcd. For everything that is holy: do not install consul. You do not have these problems. These are not your problems. Do not buy yourself these problems.
Here‚Äôs a quick cheatsheet to help you avoid these things:
Look. You‚Äôre writing a web app. Put your data in a service someone else maintains. If you‚Äôre using Amazon, RDS seems good. Or, if you‚Äôre using Cloud Foundry (on BlueMix or PCF or GCP or wherever), bind a database service (mysql is fine).
Now, what you have left is a simple, stateless web app. Let the platform deal with packaging and upgrading that app. Your app doesn't have state and is a simple web app so this is easy.
Please, don‚Äôt create a custom rollout strategy or (are you kidding me now?) a ReplicationController, don‚Äôt build a ‚Äúdocker compose file‚Äù or a ‚Äúpod‚Äù with redis and mysql in it, or an ‚Äúoperator‚Äù to deal with upgrading it. Don‚Äôt use chef or puppet unless you‚Äôre ordering food or performing in a children‚Äôs show (why are you reading this?). Push simple web apps. Use a platform that makes that easy. This should be easy.
Don‚Äôt manage production databases. Use a service provided, scaled and maintained by someone else. Use a service BACKED UP by someone else. Worry about changing this when this becomes a real problem for you (Hint: you will know when this is you). Again, any good platform will make this easy.
Are you trying to give me a heart attack? Do not do this. You‚Äôre writing a web app. You‚Äôre a small business or a large business and you‚Äôre writing a web app for all that is holy do not invest time in service discovery. Do not run etcd. Do not run zookeeper. Do not run consul. Consul is great if you need to manage a distributed micro-service system. You do not need to do this. Don‚Äôt do this. Just push your damn web app to a damn platform, OK? Ok.
Write a simple web app instead. Thank me later.
Hacker Noon is how hackers start their afternoons. We‚Äôre a part of the @AMIfamily. We are now accepting submissions and happy to discuss advertising & sponsorship opportunities.
To learn more, read our about page, like/message us on Facebook, or simply, tweet/DM @HackerNoon.
If you enjoyed this story, we recommend reading our latest tech stories and trending tech stories. Until next time, don‚Äôt take the realities of the world for granted!
#BlackLivesMatter
117 
8
117¬†claps
117 
8
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Written by
IBMer & PM of Cloud Foundry‚Äôs Container Engine ‚ÄúGarden‚Äù & ‚ÄúEirini‚Äù CF/Kubernetes Integration project. Fan of PaaSes. (Words and thoughts his own, only his own)
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
"
https://medium.com/@andrewsmedina/4-anos-de-tsuru-69e1e8bc1f22?source=search_post---------188,"Sign in
There are currently no responses for this story.
Be the first to respond.
andrews medina
Nov 2, 2016¬∑5 min read
Tudo come√ßou h√° mais de 4 anos atr√°s, quando a globo.com formou uma equipe com o objetivo de criar uma ferramenta para diminuir o tempo que uma aplica√ß√£o leva para entrar em produ√ß√£o.
Naquela √©poca, a maior parte das equipes fazia um deploy a cada duas semanas, n√£o havia uma forma padronizada para deploy e provisionamento das m√°quinas das aplica√ß√µes. Isso atrapalhava o cronograma e adicionava um custo no desenvolvimento dos projetos.
Eu acreditava que n√£o era necess√°rio fazer uma ferramenta para permitir que o deploy fosse feito a qualquer momento de forma f√°cil e simples.
Eu pensava que padronizar os scripts de deploy seria o suficiente e achava tamb√©m que n√£o conseguir√≠amos convencer as pessoas a mudarem a forma de fazer release de aplica√ß√µes. E que fazer isso n√£o valia a pena.
Eu estava errado‚Ä¶
Naquela √©poca cada time tinha uma aplica√ß√£o em produ√ß√£o, elas eram monol√≠ticas e um dos motivos disso era o deploy ser custoso. Quando o deploy tornou-se algo r√°pido e simples foi natural as equipes criarem projetos menores. Apenas com ‚Äúscripts mais r√°pidos‚Äù seria insano controlar a quantidade de aplica√ß√µes que temos hoje em produ√ß√£o (~800 apps).
Em mar√ßo de 2012 come√ßamos usando um PaaS que existia na √©poca, mas ele n√£o suportava v√°rias linguagens de programa√ß√£o que us√°vamos e tinha v√°rios problemas com performance. Enviamos v√°rios ‚Äúpull requests‚Äù para esse projeto adicionando suporte a mais linguagens de programa√ß√£o e adicionando integra√ß√£o com CloudStack mas nenhum ‚Äúpull request‚Äù foi aceito. Esse PaaS tinha parceiros comerciais e as mudan√ßas enviadas n√£o faziam parte do objetivo do projeto. O c√≥digo era aberto, mas o projeto n√£o.
Resolvemos ent√£o criar uma ferramenta com algumas premissas como alicerce:
Usamos as id√©ias boas do PaaS que est√°vamos usando, como a simplicidade da command line interface, e come√ßamos a fazer os componentes internos.
O tsuru do in√≠cio era bem diferente do que existe hoje.
Para conseguir ter o m√≠nimo funcionando no menor tempo poss√≠vel, come√ßamos utilizando o Juju. Usando as f√≥rmulas gen√©ricas do Juju (charms) foi simples provisionar aplica√ß√µes de diferentes plataformas.
Mas com o Juju cada unidade de processamento rodava em uma m√°quina virtual. A cada deploy as depend√™ncias e configura√ß√µes das unidades eram alteradas uma a uma, e para adicionar uma unidade nova era necess√°rio criar uma m√°quina virtual nova e replicar as configura√ß√µes das unidades equivalentes. Os deploys n√£o eram ‚Äúreproduz√≠veis‚Äù e adicionar unidades era uma opera√ß√£o lenta.
Devido a esses problemas come√ßamos a pensar em uma forma mais r√°pida e consistente de provisionar as aplica√ß√µes. Existiam algumas alternativas e entre elas usar linux containers foi a melhor op√ß√£o, o lxc possibilita o isolamento l√≥gico entre as aplica√ß√µes, mas compartilha o mesmo kernel, tornando o ‚Äúboot‚Äù de uma aplica√ß√£o bem r√°pido. Mas para ir por esse caminho ter√≠amos que resolver v√°rios problemas, como gerenciamento de redes e de disco dos containers. Felizmente nessa √©poca nasceu o Docker.
O Docker trouxe um ecossistema que simplificou o uso de containers, permitindo a cria√ß√£o de containers baseado em imagens e um reposit√≥rio para armazenar e distribuir essas imagens. Como o Docker resolvia todos os problemas foi natural a escolha dele como ferramenta para provisionar as aplica√ß√µes.
E assim nasceu o tsuru da forma como ele existe hoje, tornando poss√≠vel colocar uma aplica√ß√£o em produ√ß√£o em minutos:
Uma das coisas que mais gosto do tsuru √© a forma como a equipe do projeto trabalha. Ela tem como prioridade o produto/cliente e as pessoas que trabalham para fazer o projeto ter sucesso.
Com isso a equipe sempre manteve os usu√°rios do tsuru pr√≥ximos, conseguindo organizar e priorizar as features para resolver o que era mais importante para o cliente, criando assim um projeto que as pessoas gostassem de usar.
Colocar as primeiras aplica√ß√µes em produ√ß√£o com tsuru foi dif√≠cil, a maioria n√£o estavam preparadas para um ambiente baseado em cloud computing. Antes do tsuru eram utilizadas m√°quinas f√≠sicas com uma quantidade de mem√≥ria e processadores grande, escrever aplica√ß√µes para rodar em muitas m√°quinas n√£o era algo comum. Mostrar como desenvolver uma aplica√ß√£o para ter mais de 100 unidades dessas aplica√ß√µes rodando foi um dos maiores desafios quando as equipes come√ßaram a usar o tsuru.
Realizamos v√°rios workshops mostrando como cada equipe poderia usar o tsuru, falando sobre 12 factor e sobre as vantagens de ter uma arquitetura escal√°vel.
Outro desafio foi operar as aplica√ß√µes. Criamos v√°rias features para facilitar a visualiza√ß√£o do que est√° acontecendo com a aplica√ß√£o como dashboard com m√©tricas, agrega√ß√£o de logs e automatizamos alguns procedimentos de recupera√ß√£o das aplica√ß√µes. No tsuru quando uma unidade fica indispon√≠vel outra √© criada automaticamente para substituir a que est√° com problemas.
No √∫ltimo trimestre de 2013 entrou o primeiro projeto em produ√ß√£o e hoje v√°rios projetos como o cartola, globoplay e globosat play usam tsuru.
Com mais de 3 anos em produ√ß√£o na globo.com o tsuru possibilita mais de 300 deploys por dia, desde aplica√ß≈çes internas at√© aplica√ß≈çes com picos de 300k de acessos simult√¢neos.
H√° alguns meses lan√ßamos a vers√£o 1.0.0, com ela versionamos, estabilizamos e padronizamos a HTTP API do tsuru.
Foi uma longa jornada. Mas ap√≥s anos em produ√ß√£o, com aplica√ß√µes com mais de 300k de usu√°rios simult√¢neos, j√° era hora de estabilizar a API. dando a seguran√ßa que a API 1.0 n√£o mudar√° e as mudan√ßas ser√£o lan√ßadas em novas vers√µes da API.
Quando come√ßamos a usar Docker n√£o existia nenhum orquestrador de containers e hoje existem v√°rios softwares open source que resolvem muito bem esse problema como o Mesos/Marathon, Kubernetes e Docker Swarm. Come√ßar a usar esses orquestradores em vez de manter um orquestrador pr√≥prio √© o pr√≥ximo objetivo e ap√≥s isso o pr√≥ximo passo √© ter suporte a filesystem persistente e roteamento tcp, com isso tornando poss√≠vel o deploy de aplica√ß√µes como Spark, Tensorflow e etc.
Mas, na minha opini√£o o maior desafio do tsuru √© tornar a sua instala√ß√£o e atualiza√ß√£o t√£o simples quanto subir uma aplica√ß√£o no tsuru.
Isso j√° est√° √° caminho.
Se voc√™ curtiu conhecer a hist√≥ria do tsuru e quiser saber mais sobre o projeto ou contribuir com o projeto, voc√™ pode olhar nosso reposit√≥rio no github ou conversar com a gente no gitter.
Software Engineer at Jusbrasil
See all (485)
109 
4
109¬†claps
109 
4
Software Engineer at Jusbrasil
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/architectural-patterns/12-factor-app-uygun-geli%C5%9Ftirme-nedir-61645e68f114?source=search_post---------189,"There are currently no responses for this story.
Be the first to respond.
√ñl√ßeklenebilir SaaS uygulamalar yazabilmek i√ßin 2012 yƒ±lƒ±nda Heroku‚Äônun kurucularƒ±ndan Adam Wiggins tarafƒ±ndan ortaya atƒ±lmƒ±≈ü bir manifestodur.
Codebase kaynak kod ve dosyalarƒ±n y√∂netimini saƒülayan ara√ßtƒ±r. √ñrneƒüin: Git, Subversion, Mercurial vb..
Uygulamanƒ±zƒ±n dev, staging, production olsun bir tane Codebase i√ßersinde olmasƒ±. Environment ile ilgili config bilgilerinin ilgili environment ortamƒ±nda bulunmasƒ±.
Staging ortamƒ±na commit edilmemi≈ü dev geli≈ütirmeleri veya production ortamƒ±na commit edilmemi≈ü staging geli≈ütirmeleri olabilir. T√ºm bu versiyonlara ait kodun tek bir codebase √ºzerinden kontrol edilebilmesi gerekmektedir.
Projenizin baƒüƒ±mlƒ±lƒ±klarƒ±nƒ±, baƒüƒ±mlƒ± olduƒüu diƒüer k√ºt√ºphaneleri projenizin i√ßerisine statik olarak eklememek, a√ßƒ±k bir ≈üekilde bir dosyada belirterek ve bir paket y√∂neticisinin ilgili baƒüƒ±mlƒ±lƒ±klarƒ± getirmesini saƒülatarak ger√ßekle≈ütirmelisiniz. Bunun i√ßin farklƒ± dillere y√∂nelik farklƒ± paket y√∂neticileri bulunuyor.
Bu sayede Codebase i√ßerisindeki bir dosyada baƒüƒ±mlƒ±lƒ±klarƒ±nƒ±zƒ±n ismini, versiyonunu tutmanƒ±z yeterli.
Projenize ait konfig√ºrasyon bilgilerini kodunuzun i√ßerisinde statik olarak tutmayƒ±n. √á√ºnk√º test, staging, prod veya ba≈üka bir durum i√ßin ortamƒ± klonlandƒ±ƒüƒ±nda Bu konfig√ºrasyon bilgilerinin g√ºncellenmesi gerekecektir. Konfig√ºrasyon bilgileri;
Bu tip konfig√ºrasyon bilgilerinin env variable olarak saklanmasƒ±. Kodun ortamdan baƒüƒ±msƒ±z olmasƒ±nƒ± saƒülayacaktƒ±r.
Arka planda √ßaƒürƒ±lan servisleri mikro-servis olarak kullanmasƒ±. Bir kaynak olarak kullanƒ±lmasƒ±. ƒ∞lgili kaynaƒüa eri≈üebilmek i√ßin gerekli DNS adresinin ve Credentials bilgisinin yeterli olmasƒ±. En √∂nemli terimlerden birisi Loose Coupling olmasƒ±
Bu sayede sistemin arkaplanƒ±nda kullanƒ±lan servisleri kod deƒüi≈üikliƒüi yapƒ±lmadan sadece konfig√ºrasyon g√ºncellemesi ile deƒüi≈ütirilebilir.
Build, Relase ve Run i≈ülemlerinin birbirinden ayrƒ±lmasƒ±. Deployment ara√ßlarƒ±, otomasyon ara√ßlarƒ±nƒ±n bu i≈üleri birbirinden ayƒ±rarak t√ºm s√ºre√ßleri olu≈üturmasƒ± beklenir.
Stateless (State tutmayan) process geli≈ütirin. State veya veri tutma ihtiyacƒ±nƒ±z var veritabanƒ± gibi stateful backend servislerinde bu bilgileri tutun. Bu sayede 1..n Process uygulamanƒ±zƒ± √ßalƒ±≈ütƒ±rabilirsiniz. Burada bellekte tutulan sticky session yerine bunlarƒ± Redis/Memcached saklayarak servis olarak kullanmak Process sayƒ±nƒ±zƒ± kolay bir ≈üekilde arttƒ±rabilmenizi saƒülar.
Servislerin dƒ±≈üarƒ±ya port binding sayesinde belli URL ve portlar √ºzerinden eri≈üilebilir hale gelmesi. Bu sayede istediƒüiniz servise bu IP ve Portlar √ºzerinden eri≈üebilirsiniz.
M√º≈üteri Servisi https://192.162.12.16:5555
√úr√ºn Katalog Servisi https://23.123.15.17:5000
√áalƒ±≈üan process √∂l√ßeklendirilme ihtiya√ßlarƒ±na g√∂re e≈ü zamanlƒ± ≈üekilde tasarlanmasƒ± ve duruma g√∂re klonlanmasƒ± ve restart edilebilmelidir. Bu sayede Req/Resp y√ºk √ßoƒüaldƒ± ise Web mod√ºl√º i≈üleme kƒ±smƒ±nda bir gecikme var is Worker mod√ºl√º √∂l√ßeklendirilebilecektir (Yatay √∂l√ßeklendirme).
Servisler hƒ±zlƒ± ≈üekilde ba≈ülatƒ±labilmeli ve kapatƒ±labilmelidir. Servislerin tek kullanƒ±mlƒ±k olu≈üturulup yok edilebilmelidir. Bunun maliyeti olduk√ßa d√º≈ü√ºk olmalƒ±. Docker/Container yapƒ±larƒ± bunlara uygun √∂rneklerdir. Aynƒ±sƒ± AWS Lambda ortamƒ± i√ßinde s√∂yleyebiliriz.
Geli≈ütirme ve Canlƒ± ortam arasƒ±nda olu≈üacak bo≈üluƒüu(gap) kapatmayƒ± ama√ßlar. Bu bo≈üluklar/farklƒ±la≈ümalar neden ortaya √ßƒ±kar ?
Geleneksel Uygulama ile Twelve-factor App arasƒ±ndaki olmasƒ± istenen farklarƒ± a≈üaƒüƒ±da listelemi≈ü.
Loglarƒ± dosyaya statik yazƒ±lan bir log c√ºmleleri olarak tutmak yerine. Daƒüƒ±tƒ±k sistemde event-stream olu≈üturularak ba≈üka servislerin bunlarƒ± yakalayƒ±p, g√∂r√ºnt√ºlemesi, debugging, √ºzerinde arama yapabilmesine izin veren Hadoop, ElasticSearch sistemlerinin kurulu olmasƒ±nƒ± bekler.
√á√ºnk√º sistemin ger√ßek zamanlƒ±/ge√ßmi≈üe y√∂nelik g√∂r√ºnt√ºlemenin en iyi y√∂ntemi log tur.
Tek seferlik yapƒ±lan admin ve y√∂netim g√∂revlerinin scriptler ile ger√ßekle≈ütirilmesi. √ñrneƒüin.
Bu yazƒ±nƒ±n devamƒ± veya yazƒ± grubundaki diƒüer yazƒ±lara eri≈ümek i√ßin bu linke tƒ±klayabilirsiniz.
Architectural Patterns
108 
108¬†claps
108 
Written by
Senior Frontend Developer at Thundra
Architectural Patterns
Written by
Senior Frontend Developer at Thundra
Architectural Patterns
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://itnext.io/edge-focused-compact-kubernetes-with-micropaas-%CE%BCpaas-k3s-k3os-and-rio-6f7d758e19f1?source=search_post---------190,NA
https://medium.com/clouddon/modern-ai-stack-ai-service-consumption-models-f9957dce7b25?source=search_post---------191,"There are currently no responses for this story.
Be the first to respond.
If you are a developer developing new AI capabilities or LOB applications/ services leverage AI capabilities, you have various tools at your disposal. A necessary and sufficient collection of such tools can be visualized as the Modern AI Stack.
Artificial Intelligence (AI) refers to the tools and techniques that enable machines/ software to exhibit intelligence. Machine Learning (ML) refers to a subset of AI that enables a computing system to learn with data, without the need to be explicitly programmed. Artificial Neural Networks (ANN) are computing units inspired by neural networks of animal brains, that form the core of machine learning systems.
It is interesting to note that techniques/ algorithms used for AI haven‚Äôt changed in the past 20+ years. However, the tools have. If you were an AI researcher just ten years ago, you had to write code to build and train your neural networks. Not anymore. Gone are the days when you have to build such stack from scratch ‚Äî now you have ML platforms, libraries, computing, and data platforms readily available as software platforms. Some of these capabilities are also available as a service that you can consume directly. This post provides an overview of such a stack and different consumption models available to consume AI capabilities as a Service.
Modern AI Stack consists of two components ‚Äî infrastructure and developer environment.
Infrastructure refers to the tools, platforms, and techniques used to run store data, build and train AI/ ML algorithms, and the algorithms themselves.
Developer Environment refers to the tools that assist in developing code to bring out AI capabilities.
LOB applications and services are technically not part of the AI Stack. They derive value from the AI Stack.
Compute
Compute refers to the raw computational power required to run AI/ ML algorithms. One has a wide choice of physical servers, virtual machines, containers, specialized hardware such as GPUs, cloud-based computational resources including VMs, containers, and Serverless computing.
Data
Data makes an important component of machine learning system. Just like how one is made of what one eats, machine learning is only as good as the data it is trained with. One has a wide choice of data platforms ‚Äî structured and non-structured databases, big data platforms, managed databases, and cloud-based databases.
Machine Learning Algorithms
Machine learning algorithms are of three categories ‚Äî supervised, unsupervised and reinforced, with more choices of algorithms under each category.
Supervised Learning refers to learning to find the best fit function that maps input data to output data, based on training data of input-output pairs. Learning continues until a desirable accuracy on the training model is obtained.
Unsupervised Learning refers to learning to find the best match from an unknown category of data that was not encountered before (‚Äòunlabeled‚Äô data).
Reinforced Learning refers to learning based on trial-and-error.
Machine Learning Platform
Machine Learning Platforms/ frameworks provide necessary capabilities to enable one to develop ML capabilities. Such platforms usually accept different types of sources of training data, provides a choice of training algorithms, and support multiple programming languages. Commonly used ML platforms include Apache MXNet, TensorFlow, Caffe2, CNTK, SciKit-Learn¬π, and Keras¬≤.
Libraries
You have a variety of libraries at your disposal ‚Äî whether to leverage advanced mathematical operations (NumPy), or to add specific cognitive capability, such as computer vision (OpenCV), language translation (OpenNMT), etc. Particularly, if you are building cognitive services, say smart video surveillance services, you can use these libraries along with ML platforms.
IDE
Whether you are developing ML models or applications/ cognitive services that leverage underlying ML platform‚Äôs capabilities through APIs, you will be developing a good amount of code. An IDE would make your job easier.
There is a variety of integrated development environments (IDE) available for you, such as PyCharm, Microsoft VS Code, Jupyter, MATLAB etc. It is to be noted that IDEs for AI/ ML may not have the advanced debugging capabilities one is used with procedural or object-oriented programming languages.
Visualization
As we noted above, data makes an important component of machine learning. Naturally, data visualization plays an important role. One could argue that it is not an essential component of AI Stack, but given the importance of the datasets, we consider it to be an important part of AI Stack. Visualization choices include MATLAB, Seaborn, Facets, or data analytics platforms such as Tableau.
Workflow
We include workflow tools in the AI Stack as they make sharing, collaboration, and automation much easier. As more developers start leveraging AI/ ML capabilities, developer collaboration becomes more important. A variety of workflow automation tools are available, such as Jupyter, Anaconda, GitHub, VSTS etc.
Public cloud service providers are making more AI/ ML capabilities available as a service. This removes the need for having the entire stack deployed/ implemented from scratch. Such capabilities are also available at different levels of abstractions, enabling one to consume at the level that one prefers. As of now, AI/ ML services can be consumed through following ways.
AI Stack
This is the reference consumption model where every infrastructure component (ML platform, algorithms, compute, and data) is deployed and managed by the user. The user builds, trains, and deploys ML models. The user is also responsible for installing and managing all components of the developer environment.
This model is analogous to the consumption of on-prem/ private cloud services.
AI-aaS
AI-aaS refers to AI infrastructure services being offered by the services providers that one can consume directly. In this model, one continues to use their models, algorithms, types of data stores, compute resources as they would do with the AI Stack model. But they don‚Äôt install or manage the infrastructure components. They can leverage ML capabilities that are available as a service (Google Cloud ML Engine, Amazon ML), along with IaaS for compute and data requirements.
This model is analogous to the consumption of IaaS capabilities. Naturally, you will see a lot of Lift & Shift :).
Managed AI-aaS
It turns out that it is not trivial to build and train ML models. When ML models get complex, managing the supporting compute/ datastore is also not trivial.
Wouldn‚Äôt it be better if there is an easy way to train ML models? Wouldn‚Äôt it be better if compute resources are automatically allocated/ managed as the model requires? In short, wouldn‚Äôt it be more efficient if the developer can just focus on getting value out of ML without having to worry about the underlying infrastructure?
Managed AI-aaS services such as Google Cloud AutoML, Amazon SageMaker, Azure ML Studio belong to this category. They make it easier to consume ML by removing these pain points.
This mode is analogous to consuming Managed IaaS capabilities.
Cognition-aaS
Cognition-aaS refers to the consumption model where advanced cognitive capabilities themselves are available as a service. For example, if one has to build a video surveillance application, one can consume video recognition capabilities that are offered as service (Amazon Rekognition Video, Google Vision, Azure Compute Vision, etc). There is no need to build these capabilities using computer vision libraries and ML.
With such cognitive capabilities being readily available, an application developer can focus on business logic without having to worry about the underlying AI infrastructure components at all.
Last year, I had postulated that
Cognitive computing capabilities available as a service will double approximately every year
With more Cognition-aaS capabilities getting enabled by service providers and niche players adding more cognitive capabilities to the mix (Xoom.ai, Grammarly), this trend will continue.
Cognition-aaS is analogous to consuming PaaS capabilities. I am not seeing this as SaaS category as some might do, because, these capabilities are not complete solutions like a SaaS offering would be¬≥.
Recommendations
Choose the right consumption model based on your application needs and in-house ML expertise.
If you want total control and everything in-house, choose AI Stack/ On-Prem.
If you want to build/ train ML models, but don‚Äôt want the overhead of managing ML platform/ underlying infrastructure components, choose AI-aaS.
If you want to leverage ML capabilities, but don‚Äôt want to manage infrastructure components, choose Managed AI-aaS.
If you would like to just focus on the business value, choose Cognition-aaS.
CloudDon - catalyzing modern enterprise IT transformations
243 
1
243¬†claps
243 
1
CloudDon - catalyzing modern enterprise IT transformations
Written by
Research Director, IDC. Irreverential Yogi; Single Dad; Son; Brother.
CloudDon - catalyzing modern enterprise IT transformations
"
https://itnext.io/building-a-kubernetes-based-platform-focus-on-progressive-delivery-the-edge-and-observability-3a702e0c19a7?source=search_post---------192,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Kubernetes has been widely adopted as a container manager, and has been running in production across a variety of organisations for several years. As such, it provides a solid foundation on which to support the other three capabilities of a cloud native platform: progressive delivery, edge management, and observability. These capabilities can be provided, respectively, with the‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/cloud-and-servers/serverless-architecture-faas-2e5804ececd9?source=search_post---------193,"There are currently no responses for this story.
Be the first to respond.
√ñncelikle bildiƒüimiz Bulut Hizmetlerini sƒ±ralarsak.
On-Premises: Yazƒ±lƒ±mlarƒ±nƒ±zƒ±n sizin veya firmanƒ±n bilgisayarlarƒ±na y√ºklendiƒüi kƒ±sƒ±mda t√ºm katmanlarƒ±n sorumluluƒüu sizin ekibinizin √ºzerindedir. Bir sistem ekibiniz olmasƒ± gerekir. Bu sistem ekibi sunucularƒ±, veritabanlarƒ±nƒ±, g√ºvenliƒüi, network‚Äô√º bilmesi ve kurmasƒ± gerekmektedir. Veritabanƒ±nƒ±n yedeklerinin alƒ±nmasƒ±nƒ± saƒülamasƒ±, i≈ületim sisteminin g√ºncel s√ºr√ºmlerinin y√ºklenmesini saƒülamasƒ± gerekmektedir. Ayrƒ±ca sistem ekibinin JVM, dll, plugin gibi yazƒ±lƒ±mƒ±n ihtiyacƒ± olan Run-Time sisteme kurmalarƒ± gerekmektedir.
Infrastructure As A Service: Size bulut √ºzerinden sanal Compute, Storage, Networking satƒ±ldƒ±ƒüƒ±, kiralandƒ±ƒüƒ± bulut hizmeti olarak d√º≈ü√ºnebilirsiniz. Bilgisayar, Disk ve Network kartlarƒ± almak yerine bunlarƒ± Sanal olarak bulut ‚Äôtan kiralayƒ±p √ºzerine istediƒüiz i≈ületim sistemini kurup yolunuza devam edebilirsiniz.
Platform As A Service: Bulut √ºzerinde direk bir java, ruby, node uygulamasƒ± geli≈ütirmek istiyorsunuz ve i≈ületim sistemi, network, sunucu gibi sistemler ile uƒüra≈ümak istemiyorsunuz, Sadece uygulamanƒ±zƒ± geli≈ütirmek ile uƒüra≈üƒ±yorsunuz sonrada uygulamanƒ±zƒ±n run-time dosyalarƒ±nƒ± ilgili platforma atƒ±p √ßalƒ±≈ümasƒ±nƒ± saƒülƒ±yorsunuz. (Tomcat, Jetty, Django, Express vb‚Ä¶)
Software As A Service: Uygulamalarƒ±n bulut‚Äô tan hizmet vermesine SaaS denir. Kullanƒ±cƒ±lar ve geli≈ütiriciler sadece uygulama aray√ºzlerine eri≈üebilir. Bu servisler belli domain(Alanlarda √∂zelle≈ümi≈ütir) sizi bu domain detaylarƒ±ndan kurtararak size hizmet satar. Genelde her ay veya yƒ±llƒ±k √∂deme y√∂ntemi ile i≈üler . √ñrneƒüin Authentication uzmanla≈ümƒ±≈ü Auth0, ƒ∞leti≈üim‚Äôde uzmanla≈ümƒ±≈ü Twillo, veya √ñdeme i≈ülemlerinde uzmanla≈ümƒ±≈ü Stripe bu t√ºr SaaS hizmetlerinden bazƒ±larƒ±dƒ±r.
Peki FaaS hizmeti ne oluyor. FaaS Managed Servisleri birbirine tutkal gibi baƒülayacak olan sadece Functions yazarak i≈ülemlerinizi halledebildiƒüiniz bir ortam sunuyor. Sizin yazdƒ±ƒüƒ±nƒ±z Fonksiyon yeri gelince (ilgili event/olay ile) tetiklenerek ilgili i≈ülemlerinizi ger√ßekle≈ütiriyor.
A≈üaƒüƒ±daki resimde g√∂r√ºleceƒüi gibi IaaS ‚Üí PaaS ‚Üí FaaS doƒüru ilerlerken ye≈üil alanlar artmƒ±≈ü yani , y√∂netim sorumluluƒüu Cloud Provider √ºzerinde duruyor, bu bir anlamda iyi sizin √∂l√ßeklendirme, g√ºvenilir ki vs‚Ä¶ y√∂netme sorununuz ortadan kalkƒ±yor , fakat ba≈üka bir problem var giderek Provider daha √ßok baƒüƒ±mlƒ± hale geliyorsunuz.
BaaS (Backend As A Service), MBaaS ise (Mobile Backend As A Service) bulut hizmetidir. Bir web veya mobil uygulama geli≈ütirirken hƒ±zlƒ± bir ≈üekilde uygulama ortamƒ±nƒ± hazƒ±rlamak yerine Third Party provider ‚Äôlardan faydalanarak uygulamanƒ±zƒ± geli≈ütirmenizi saƒülayan bulut hizmetleridir. Authentication, Database, Messaging, Analytics vb.. servisleri hazƒ±r olarak kullanmanƒ±zƒ± saƒülar.
A≈üaƒüƒ±da bahsettiklerim size nasƒ±l bir App geli≈ütirmeniz gerektiƒüini kendi Backend yapƒ±larƒ± ile nasƒ±l entegre olabileceƒüini anlatan saƒülam Kod √úretme altyapƒ±larƒ± ve √∂rnek dok√ºmanlarƒ± bulunmaktadƒ±r.
Biraz daha derine inerek Eventlere takƒ±labilen Fonksiyonlarƒ± Function As A Service olarak sunacak Provider‚Äô lar √ßƒ±kmaya ba≈üladƒ±.
Bunlar provider kendi ortamlarƒ±nƒ±n eventlerine baƒüƒ±mlƒ± fonksiyonlar olu≈üturmanƒ±zƒ± saƒülayarak kendi i√ßerisinde sunduklarƒ± servisler √ºzerinde programlama yababilecek, servisleri birbirine baƒülayabilecek altyapƒ±yƒ± kurmu≈ü oldular.
Serverless mimari demek;
anlamƒ±na geliyor.
PaaS servisleride benzer bir ama√ßla √ßalƒ±≈üƒ±r. Server kurma, y√∂netme, √∂l√ßeklendirme, g√ºvenlik maliyetlerinden sizi kurtarƒ±p sadece uygulamanƒ±zƒ±,i≈ü mantƒ±klarƒ±nƒ±zƒ± kurmanƒ±za odaklamanƒ±zƒ± saƒülar.
PaaS ile FaaS arasƒ±ndaki farkƒ± a≈üaƒüƒ±daki Twitter‚Äôdaki a≈üaƒüƒ±daki post √∂zetlemi≈ü aslƒ±nda
FaaS Hakkƒ±nda Makaleler
http://martinfowler.com/bliki/Serverless.htmlhttp://martinfowler.com/articles/serverless.html
FaaS Frameworkleri
https://github.com/serverless/serverlesshttps://github.com/apex/apexhttps://github.com/lambadaframework/lambadaframework
Email g√∂nderme, Kuyruk sistemi, Media transcoding, Loglama, Makine √ñƒürenmesi ve yazƒ±lƒ±m ile ilgili genel ihtiya√ßlar t√ºm projelerde benzerlik g√∂stermektedir. Bu kƒ±sƒ±mdaki i≈ü mantƒ±klarƒ±nƒ± tekrar tekrar kodlamak veya sunucu kurup ayaƒüa kaldƒ±rmaya gerek yoktur. High Available, Scalable ve Fault-Tolerant bir sistemi AWS App Service olarak sunmaktadƒ±r. Serve-less kƒ±smƒ±nda yer alan temel servislerden bahsedecek olursak.
Lambda: Sunucu olmadan farklƒ± runtime kod √ßalƒ±≈ütƒ±rmayƒ± saƒülar. (Event ile tetiklenir)
APIGateway: REST API olu≈üturmanƒ±zƒ±, Lambda ile Entegrasyonlarƒ±n yapƒ±lƒ±p i≈ü mantƒ±klarƒ±nƒ±n i≈ületilmesini , Request/Response trafik y√∂netimi , yetkilendirme, g√∂r√ºnt√ºleme , API versiyonlamayƒ± kontrol edip y√∂netmenizi saƒülar.
StepFunctions: Server-less akƒ±≈üƒ± orkestra etmenizi saƒülar, i≈ületilmesinin √ßok uzun s√ºren par√ßa par√ßa i≈ülerin zincir ≈üeklinde fonksiyonlarƒ±n √ßaƒürƒ±lmasƒ± ve sistemin state ve koordinasyonunu saƒülar
DynamoDB: Server-less uygulamalar i√ßin kalƒ±cƒ± Managed NoSQL veritabanƒ± saƒülar.
S3: Server-less Web uygulamalarƒ± i√ßin Object storage ve Web sayfayalarƒ± i√ßin key/value ≈üeklinde objeleri tutabilme ve bu kaynaklara HTTP ile eri≈üebilme imkanƒ± sunar.
ElasticSearch: Log analitiƒüi, full-text arama, g√∂r√ºnt√ºleme(monitoring) saƒülayacak arama motoru ve analitik ara√ßlar saƒülar.
AppSync: Managed GraphQL servisi saƒülar. DynamoDB, ES, S3 √ºzerinden g√ºvenli, ger√ßek zamanlƒ± GraphQL √ßalƒ±≈ütƒ±rmayƒ± saƒülar.
SQS: Managed Kuyruk Servisi
SNS: Managed pub/sub mesaj servisi , async event notification, mobile push notifications
Kinesis: Real-time streaming verisini basit ≈üekilde toplama, i≈üleme ve analiz etmeyi saƒülar. Amazon Kinesis Data Analytics, bu stream √ºzerinde SQL √ßalƒ±≈ütƒ±rmanƒ±sƒ± saƒülar.
Firehose: Verinin yakalanmasƒ±, d√∂n√º≈üt√ºr√ºlmesi, Kinesis Data Analiytics, S3, Redshift, ES ger√ßek zamanlƒ± olarak y√ºklenmesini saƒülar.
Cognito: Basit bir ≈üekilde kullanƒ±cƒ± giri≈üi, √ºyelik, Serverless uygulamalar ile veri senkronizasyonu saƒülar. Ayrƒ±ca kullanƒ±cƒ± havuzlarƒ± ile Facebook, Google, Amazon sistemleri ile giri≈ü imkanƒ± sunar.
CloudFront: Web uygulama i√ßerikleri ve verilerinin u√ß/istemci makinelere daha yakƒ±n olacak ≈üekilde az gecikme ve hƒ±zlƒ± veri transferi saƒülayacak CDN hizmetidir.
CloudWatch: AWS Servisleri ile ilgili t√ºm sistem metriklerine , uygulama seviyesi log, kendi olu≈üturabileceƒüiniz KPI, metric , dashboard ve alarmlar olu≈üturmanƒ±zƒ± saƒülar.
X-Ray: Serverless ve microservis yapƒ±larƒ±n olu≈üturduƒüu distributed tracing ve service map g√∂r√ºnt√ºleyip, problem olu≈üturan kƒ±sƒ±mlarƒ± tespit etmenizi saƒülar.
SAM: AWS Cloudformation Serverless uygulamalarƒ± deploy i√ßin √∂zellemi≈ü bir extension‚Äôƒ±dƒ±r. Bu sayede serverless uygulamalar CLI √ºzerinden daha basit ve otomatik olarak kurulabilir.
Bu yazƒ±nƒ±n devamƒ± veya yazƒ± grubundaki diƒüer yazƒ±lara eri≈ümek i√ßin bu linke tƒ±klayabilirsiniz.
AWS, Azure, OpenStack
160 
1
160¬†claps
160 
1
Written by
Senior Frontend Developer at Thundra
AWS, Azure, OpenStack
Written by
Senior Frontend Developer at Thundra
AWS, Azure, OpenStack
"
https://medium.com/@robertdouglass/launching-magento-cloud-in-vegas-4f0daff812de?source=search_post---------194,"Sign in
There are currently no responses for this story.
Be the first to respond.
Robert Douglass
Apr 16, 2016¬∑5 min read
A Selfie-mentary about my first Imagine conference
TL:DR; My selfies didn‚Äôt win the ginormous TV, but I finished the 10k run and we launched Magento Cloud.
This is a story about setting ambitious goals to challenge you and make you grow. I set three big challenges for myself for my first Magento Imagine conference, and striving to achieve these challenges unleashed great rewards beyond what I had expected, even if I didn‚Äôt win a flat-screen TV.
When I learned I would be attending Magento Imagine, the main annual event hosted by Magento Commerce, I decided to sign up for the 10 kilometre ‚ÄúImagine a Big Dam Run‚Äù that is organised as a community event the day prior to the main conference. 10k is a real challenge for me ‚Äî I had to train for months to gain the confidence that I‚Äôd actually cross the finish line, and the run was actually longer, and harder, than expected. I had to take motivation from some of the more experienced runners to keep going.
I was at Imagine with my company, Platform.sh, to participate in the most significant product announcement Magento have made since they were sold by Ebay eight months ago. Magento were announcing the launch of an ambitious cloud offering for Magento merchants, based on my company‚Äôs technology. Nobody outside of a tight circle of partners knew this, though, on the day of the run.
The run was an out-and-back-again course; we‚Äôd run to the Hoover Dam, spend a moment gawking at its scale and pondering the achievement of such a thing, and then run back.
Participating in the run was a great decision that already started paying off during the bus ride to the site. I met some fascinating people, like the Gene team who were also launching a new product, and whose character and charisma would get featured in the Magento highlights video (see below). My running partners on the way to the dam were Magento CEO Mark Lavelle and Strategy Dude Mark Lehnard, the very people who had been driving the Magento Cloud launch. We enjoyed the mutual suspense of the impending announcement, still unknown to most of the other runners, and we definitely helped each other keep going with the run, which somehow seemed even longer than advertised. This moment was captured nicely by the conference photographer (see below, far left).
I also got to spend some time running with Scott Dahlgren, a former colleague, whose Blackfire.io product is the code profiling tool in Magento Cloud. He too was relishing the secrecy and suspense of the upcoming announcement, and without his encouragement, I would have struggled to finish the run. Thanks, Scott!
For Platform.sh, launching Magento Cloud is a big deal. Every bit of the technology that we‚Äôve been developing over the past three years is at play inside of the Magento Cloud product, from the fast-cloning on-demand development environments, the triple-redundant and highly scalable production clusters, to the accounts management and help desk solutions that we use for our own Platform.sh customer base. Working with Magento over the past months in preparation of the launch is easily the most exhilarating and challenging project our team has undertaken, and we arrived in Vegas already quite proud of the way we‚Äôd come together as a team to deliver this solution.
We brought 8 people to Las Vegas, and for the keynote and big announcement we sat with the team from Blackfire.io. Our collective hearts were pounding much like the drum corps that was the opening act for the keynote. Only after the announcement, when I went to congratulate Mark Lavelle on the keynote address, did I see the photo of us from the Hoover Dam run on the big backdrop screen for the keynote presentation. I know a selfie opportunity when I see one!
One of the sponsor companies for Magento Imagine, Robofirm, was running a competition: whoever took the best selfie featuring their robot mascot would win a ginormous TV. Challenge accepted! I used the selfie-challenge as a way to meet people at the Magento Imagine conference, and even though my selfie wasn‚Äôt selected as the winner, and I won‚Äôt be taking home any 65 inch TV, I‚Äôve made many new friends to whom I am bound in eternal selfie-dom. Here is a selection of the selfies (each one is worth the TV in my opinion).
One final treat awaited me; the day after the conference, the utterly excellent Magento marketing team published a highlight video which perfectly captures the energy of the conference, and lavishes praise and admiration on my efforts as a Selfie-mentarian. See below.
Christina Jones will sing Kimiko Ishizaka‚Äôs songs about saving love: https://christinajones.com
See all (1,414)
42 
2

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
42¬†claps
42 
2
Christina Jones will sing Kimiko Ishizaka‚Äôs songs about saving love: https://christinajones.com
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@arschles/cloud-native-comes-with-new-challenges-ca9c22dbbb7?source=search_post---------195,"Sign in
There are currently no responses for this story.
Be the first to respond.
Aaron Schlesinger
Dec 20, 2017¬∑4 min read
On the last day of KubeCon 2017 in Austin, I tweeted that we‚Äôve moved on from asking whether to run our apps on Kubernetes, to asking how best to do so.
We‚Äôre so clearly past the early adopter/hobbyist phase in our community.
Popularity and buzz aren‚Äôt hard to come by these days, and neither is adoption. The ‚Äúbig three‚Äù cloud providers were all in the sponsorship hall, with plenty more companies looking to get in on this cloud native thing.
With all this adoption comes innovation, and we have plenty of that too.
This was the year of the service mesh, and there are at least two major players in that space ‚Äî with more on the way.
If service meshes weren‚Äôt enough, I recently wrote a post about solving service dependencies for cloud native apps as well, so that‚Äôs coming too.
All these innovations are solving big problems that folks have in production, but we‚Äôre forgetting something: ease of use.
It‚Äôs damn near impossible for someone new to Kubernetes to figure out how to get started. Hours of research and study are the price of admission to be in the cloud native club, and it shouldn‚Äôt be that way.
Let‚Äôs break down the challenges we have in cloud native applications:
The community has met lots of these challenges by building new stuff. It‚Äôs a Cambrian explosion of systems and tools to help build and manage cloud native apps.
But we don‚Äôt tell anyone how to put everything together to actually build an app.
Tons of folks at KubeCon had the same question: ‚Äúhow do I get my code into production?‚Äù
I have my go-to tool to put things together ‚Äî Helm ‚Äî but it‚Äôs rudimentary. Other people have their tools as well. But we as a community don‚Äôt even have good recommendations on how to put things together. You start with a Kubernetes and then what?
The standard answer is to learn all this stuff:
And then, you can figure out for yourself how to get your code tested, built into an image, and onto your cluster.
We need to delete that big ass list above and make it simple to get your code onto your cluster.
We need to build a system to make it easy for everyone to ‚Äúdo Kubernetes‚Äù
We need a system that would run in Kubernetes and would figure things out for you, so at least you could get started in a weekend.
If you‚Äôre new, you could get going fast. If you‚Äôre already in production, you could still customize this thing and improve your workflow.
Here‚Äôs what the system needs to do:
Yea, there are tons of features in that list. That‚Äôs on purpose.
But here‚Äôs the magic of our community: there‚Äôs something already built for every bullet point in that list. We‚Äôre putting those pieces together here, and the point is to make decisions on how they should fit.
This system is not an invention, it‚Äôs an extraction.
We‚Äôre gonna take strong opinions on how apps should look, on how tools should be configured, and how developers should develop in our cloud native world.
We even have prior art to draw on:
Look at how our ecosystem is growing now. I talked about the sponsor hall at KubeCon 2017 and how much momentum we have. We‚Äôre going to be 10 times as big in 5 years.
Imagine KubeCon being held at a 30,000 person convention center in 5 years.
And the way we‚Äôre going to get there is in large part by bringing in newcomers with opinionated frameworks like this one.
I can‚Äôt wait.
Credit to Mark Bates for the ‚Äúnot an invention, it‚Äôs an extraction‚Äù idea. You can see the wonderful talk in which he introduced the idea here.
Gopher, containerizer, and Kubernetes-er
59 
5
59¬†
59 
5
Gopher, containerizer, and Kubernetes-er
"
https://blog.getambassador.io/enabling-full-cycle-development-4bf81abd7955?source=search_post---------196,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Cloud computing and container orchestration frameworks provide an excellent foundation for deploying and running modern software applications. However, in order for these technologies to support the move towards ‚Äúfull cycle development‚Äù ‚Äî where developers take increased ownership from idea to delivery ‚Äî there are several requirements that must be met for both the development and platform/SRE personas. Many teams design and build a platform in order to support these requirements, often using Kubernetes‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@nutanix/the-rise-of-anything-as-a-service-xaas-the-new-hulk-of-cloud-computing-5eca37c2ff02?source=search_post---------197,"Sign in
There are currently no responses for this story.
Be the first to respond.
Nutanix
Apr 26, 2017¬∑3 min read
Cloud Computing, as we see it today, has seen a tremendous evolution in the service segments ‚Äî right from the dawn of Software-as-a-Service (SaaS) to Infrastructure-as-a-Service (IaaS) and Platform-as-a-Service (PaaS), and now Anything-as-a-Service (XaaS).
Analysts forecasted that the global XaaS market will grow at a CAGR of 38.22% between 2016‚Äì2020. Besides the typical SaaS, IaaS, and PaaS offerings discussed, there are other ‚ÄòAs-a-Service(aaS)‚Äô offerings too. For instance, Database-as-a-Service, Storage-as-a-Service, Windows-as-a-Service, and even Malware-as-a-Service.
No doubt the ‚ÄòCloud-driven aaS‚Äô era is clearly upon us and cloud computing remains the top catalyst for all these services‚Äô growth. The converse holds true too.
In the words of Amarkant Singh, Head of Product, Botmetric, ‚ÄúThe persuasive wave of cloud computing is affecting every industry and every vertical we can think of. Thanks to all of its fundamental models ‚Äî IaaS, PaaS, and SaaS plus the latest XaaS, cloud has brought in democratization of infrastructure for businesses. Talking about XaaS. It is the new hulk of the cloud computing and is ushering in more of ready-made, do-it-yourself components and drag-and-drop development.‚Äù
The XaaS model was born as a result of the elasticity that the cloud offers. More so, the XaaS provides an ever-increasing range of solutions that ultimately gives businesses the extreme flexibility to choose exactly what they want tailored for their business, irrespective of size/vertical.
Recently, Stratoscale asked 32 IT experts to share their insights on the differences between IaaS, PaaS and SaaS and compiled an exhaustive Op-Ed report IaaS/PaaS/SaaS: The Good, the Bad and the Ugly[1]. Among these experts, Amarkant too has penned few lines for the report.
Here are the excerpts from the article:
‚ÄúMore companies across the spectrum have gained trust in cloud infrastructure services, pioneered by AWS. While IaaS provides a high degree of control over the cloud infrastructure, it is very-capital intensive and has geographic limitations. On the other hand, PaaS comes with decreased costs but offers limited scalability.
With its roots strongly tied to virtualization, SOA and utility/grid computing, SaaS is gaining more popularity. More so, it is gaining traction due to its scalability, resilience, and cost-effectiveness.
According to a recent survey by IDC, 45% of the budget organizations allocate for IT cloud computing is spent on SaaS.
As organizations move more of their IT infrastructure and operations to the cloud, they are willing to embrace a serverless/NoOps model. This marks the gradual move towards the XaaS model (Anything as a Service), which cannot be ignored.
XaaS is the new hulk of the cloud computing. Born due to elasticity offered by the cloud, XaaS can provide an ever-increasing range of solutions, allowing businesses to choose exactly the solution they want, tailored for their business, irrespective of size/vertical. Additionally, since these services are delivered through either hybrid clouds or one or more of the IaaS/PaaS/SaaS models, XaaS has tremendous potential to lower costs. It can also offer low-risk infrastructure for building a new product or focusing on further innovation. XaaS embracement has already gained traction, so the day is not far when XaaS will be the new norm. But at the end of the day, it all matters on how cloud-ready a company is for XaaS adoption.‚Äù
Each expert has an idiosyncratic perspective to what, where, when, and why XaaS. For few, it stands for everything-as-a-service and refers to the increasing number of services delivered through cloud over the Internet. For few it is anything-as-a-service. Techopedia quotes it as a broad category of services related to cloud computing and remote access where businesses can cut costs and get specific kinds of personal resources. Different perspective, different views, but one goal: Putting cloud in perspective.
Read what other experts are deliberating on XaaS on Stratoscale‚Äôs Op-Ed article ‚ÄòIaaS/PaaS/SaaS ‚Äî the Good, the Bad and the Ugly.‚Äô[1]
Share your thoughts in the comment section below or give us a shout out on either Facebook, Twitter, or LinkedIn. We would love to hear what‚Äôs your take on XaaS.
[1] Stratoscale, 2017, ‚ÄúIaaS/PaaS/SaaS ‚Äî the Good, the Bad and the Ugly.‚Äù
We make infrastructure invisible, elevating IT to focus on the applications and services that power their business.
21 
1
21¬†
21 
1
We make infrastructure invisible, elevating IT to focus on the applications and services that power their business.
"
https://medium.datadriveninvestor.com/what-exactly-is-knative-252ec94e4de7?source=search_post---------198,"There are currently no responses for this story.
Be the first to respond.
Knative is a serverless framework that is based on Kubernetes and was announced and developed by Google. One important goal of Knative is to establish a cloud-native and cross-platform orchestration standard. Knative implements this serverless standard through integrating the creation of container or function, workload management and auto scaling, and event models. In addition to Google, major contributors to the Knative community include Pivotal, IBM, and Red Hat. PaaS providers such as CloudFoundry and OpenShift are also actively making contributions to the Knative community.
Before Knative was developed, many serverless solutions had already been available in the community. These included Kubeless, Fission, OpenFaaS, and Apache OpenWhisk. In addition to these open-source solutions, major cloud providers also offered equivalent FaaS products, such Amazon Web Services‚Äôs Lambda, Google Cloud‚Äôs Functions, Microsoft‚Äôs Azure Functions, and Alibaba Cloud‚Äôs Function Compute.
www.datadriveninvestor.com
Deploying business code to a serverless platform requires source code compilation, deployment, and event management. However, both open-source solutions and FaaS productions from public cloud providers all involve different implementation methods. The lack of uniform standards has caused some market fragmentation, with each available solution posing the possible risk of being bound to a specific solution provider.
Also, the lack of uniform standards and market fragmentation caused many other additional issues. For cloud providers, it is difficult to allow their users to migrate to the cloud in a serverless manner. And for PaaS providers, they find it hard to build a general-purpose PaaS platform for their users. However, to the aid of these difficulties, Google initiated the Knative project together with companies such as Pivotal, IBM, and Red Hat.
The following diagram shows the collaborative effort that lead to the Knative system:
Source: Knative GitHub repo
According to this diagram, you can see that with Knative:
The overall serverless framework of Knative consists of three core components:
Now, let‚Äôs discuss these components in more detail.
The Build component is mainly responsible for obtaining source code from the code repository, compiling code into images and then pushing them into the image repository. All these operations are performed in Kubernetes Pods.
The Eventing component has a complete set of design implementations targeting serverless event-driven mode. These features include the connection to external event sources, event registry, event subscription, and event filtering. The event model can effectively make event producers and consumers decoupled and independent. Any producer can generate events before active event consumers start. Any consumer can listen to events before active producers start.
The Serving component is responsible for managing workloads and provide external services. The most important feature of Knative Serving is autoscaling (both up and down to zero). Another important feature of Serving is phased release.
You can say that, even though Knative is implemented on top of Kubernetes, this does not mean that all Kubernetes features can also be used in Knative. The reason for this is because that Knative is specifically designed for serverless scenarios, such as scenarios in which only one Container can be included in a Pod, and only on Port can be included in a Container. More related details will be described in follow-up articles.
Knative builds on Kubernetes to support serverless orchestration, and also is implemented based on Istio to enable features including service connection, route management and phased release. Knative is built on the existing cloud native basis and therefore has a large community base. Knative is positioned to create a large stir in the market once it was published as an open-source project thanks to the following reasons:
In this blog, we have described the background of the birth of Knative, issues expected to be solved by Knative, core concepts, and the advantages of Knative. In a series of follow-up articles, we will continue to describe the use of Knative and analyze its internal implementations.
Author: Dong Dao, Technical Expert at Alibaba Cloud Intelligence Department
www.alibabacloud.com
empowerment through data, knowledge, and expertise.
140 
140¬†claps
140 
Written by
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
empowerment through data, knowledge, and expertise. subscribe to DDIntel at https://ddintel.datadriveninvestor.com
Written by
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
empowerment through data, knowledge, and expertise. subscribe to DDIntel at https://ddintel.datadriveninvestor.com
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/t-t-software-solution/%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87-azure-app-service-%E0%B8%9F%E0%B8%A3%E0%B8%B5-%E0%B9%83%E0%B8%99-10-%E0%B8%99%E0%B8%B2%E0%B8%97%E0%B8%B5-e3a5c25ef749?source=search_post---------199,"There are currently no responses for this story.
Be the first to respond.
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Azure Cloud Service ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö Paas ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡∏à‡∏∞‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á web application ‡πÅ‡∏•‡∏∞ web api ‡πÅ‡∏ö‡∏ö ‡∏á‡πà‡∏≤‡∏¢‡πÜ‡∏ú‡πà‡∏≤‡∏ô Azure ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
2. ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà my.visualstudio.com
3. ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠3.1 ‡∏ü‡∏£‡∏µ Azure 300$ 1 ‡∏õ‡∏µ (25$ ‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)3.2 ‡∏ü‡∏£‡∏µ Pluralsight (‡πÄ‡∏ß‡πá‡∏õ Learning Centre) 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏°‡∏µ‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡∏µ‡πÜ‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å‡πÜ‡∏Ñ‡∏£‡∏±‡∏ö)3.3 ‡∏ü‡∏£‡∏µ Azure App Service (‡∏Å‡∏î‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡πÅ‡∏ï‡πà‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡πà‡∏∞ 1‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
4. ‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Tool >> Azure App Service >> Use it free
5. ‡∏à‡∏∞‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å App ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó, ‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Web App
6. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å MVC Template
7. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Account ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏û‡∏±‡∏Å‡πÉ‡∏´‡πâ Azure ‡∏™‡∏£‡πâ‡∏≤‡∏á Web ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡∏ñ‡πâ‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏û
8. ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡πâ‡∏Ñ‡∏∑‡∏≠
8.1 Link ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Web ‡∏ó‡∏µ‡πà‡∏û‡∏∂‡πà‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á
8.2 Link ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Azure
8.3 Edit Code ‡∏ú‡πà‡∏≤‡∏ô Visual Studio Code ‡πÑ‡∏î‡πâ online ‡πÄ‡∏•‡∏¢
8.4 Download sample code ‡∏•‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ
8.5 Download Azure Publish Profile ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ deploy web ‡∏ú‡πà‡∏≤‡∏ô Visual Studio ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤
8.6 Git
9. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏õ
10. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Azure Portal
11. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Edit code online
12. ‡∏ú‡∏° ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Web API ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÇ‡∏î‡∏¢‡∏Å‡∏î Previous ‡πÅ‡∏•‡πâ‡∏ß ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏•‡∏ö web app ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
13. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å API APP
14. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å API To Do List
15. ‡∏´‡∏ô‡πâ‡∏≤ Web API
16. ‡∏Å‡∏î using the Swagger UI, ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏Ç‡∏≠‡∏á Swagger UI ‡∏û‡∏£‡πâ‡∏° list ‡∏Ç‡∏≠‡∏á Web API ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ^ ^
17. ‡∏ó‡∏î‡∏•‡∏≠‡∏á ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å service GET /api/ToDoList
18. ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏à‡∏∞‡πÑ‡∏î‡πâ web api ‡πÅ‡∏ö‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ‡πÑ‡∏ß‡πâ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°
‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏° ‡πÉ‡∏ô Medium ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏°‡∏≤ ‡∏ì ‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏ô‡∏≤‡∏¢‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
https://www.tt-ss.net/
26 

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
26¬†claps
26 
Written by
Development Manager, Web Developer with ASP.Net, ASP.net Core, Azure and Microsoft Technologies
Web developers with ASP.Net, MSSQL, Azure working in Remote Office 100%
Written by
Development Manager, Web Developer with ASP.Net, ASP.net Core, Azure and Microsoft Technologies
Web developers with ASP.Net, MSSQL, Azure working in Remote Office 100%
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/understanding-as-a-service-uaas/revisiting-rocks-thrown-at-the-cloud-12-months-later-and-a-goodbye-to-rosling-959ad608698f?source=search_post---------200,"Sign in
There are currently no responses for this story.
Be the first to respond.
Stephen Cummins
Feb 14, 2017¬∑5 min read
‚ÄúThe idea is to go from numbers to information to understanding.‚ÄùHans Rosling
I didn‚Äôt write ‚ÄòThrowing Rocks at the Cloud‚Äô twelve months ago for investors,, but anyone (with significant funds to invest) who took my advice would have made a fortune. I wrote it to accelerate the righting of a wrong. At the time a lot of caveman gloating over the apparent market woes of superior competitors threw boomerangs disguised as rocks at the sky. I wrote it to counter comments and articles using pseudo-analysis for misinformation and other ill-gotten gains. The market had gone haywire and some of the best SaaS (Software as a Service) companies on the planet were being pulverised for no sensible reason. And of course the least sophisticated came out of the woodwork making all sorts of declarations about their ‚Äòenterprise class‚Äô software. The on-premise enterprise-class brigade still painting pictures of the turn of the millennium.
‚ÄúBy a lie a man throws away and, as it were, annihilates his dignity as a man.‚Äù William Shakespeare
The goal was not investment advice, but if you had acted on my guidance this day 12 months ago by investing evenly across the 6 recommended stocks, you‚Äôd have made a 108% return on your investment. You would have made 34% on the worst performing stock. 236% on the best one.
From the original article:Those with the highest revenue growth rates suffered the largest price drops ‚Äî these include New Relic, Zendesk, Hubspot, Marketo, Demandware and Tableau. This indicates a current market going through a phase where emotion trumps reason.‚Äù I also pointed out the same disconnect between other metrics like customer satisfaction, profit levels and cashflow. I explained that these 6 companies were amongst the brightest stars in our industry.
So let‚Äôs see if I was right when I said the market reaction was nonsense in the case of these 6 companies in particular.
Marketo (formerly MKTO) sold for 236% of its valuation 110 days after I published the article. Demandware (formerly DWRE) was acquired by Salesforce for $2.8B 108 days later. It‚Äôs market price effectively went from 29.34 to 74.97 i.e. a 156% gain. Zendesk (ZEN) opened today at 27.36. It was valued at 15.09 at the time of publishing. That‚Äôs an 81% gain. Hubspot (HUBS) opened at 57.65 this morning ‚Äî versus 32.22 twelve months ago. That‚Äôs a gain of 79%. New Relic (NEWR) opened at 22.13 the day I published this article. Today it opened at over 36.00. A 63% gain. Tableau (DATA) opened at 54.04 this morning. It opened at 40.25 12 months ago. A far more modest, but still very healthy 34% gain.
Based on these results, the average gain over the last 12 months for the 6 specific companies highlighted in the article was 108%. As I value integrity, I will not name the cavemen who were gleefully throwing rocks at their competitors.
Thus far I have yet to make an incorrect prediction about a software company. And I‚Äôve made a ton of big calls publicly. There‚Äôs no chance that this situation will last forever, but I suspect my strike rate will remain high. I make these predictions based on reliable data focused on relevant parameters, logic and experience. In that order. And even more importantly, I listen carefully to people who approach things similarly. I could not have written that article without people like Tomasz Tunguz and trustworthy data driven platforms like G2Crowd.
The spirit of the original article:Certain words seem to carry an air of rationality with them. A word like ‚Äòcorrection‚Äô is a word. Nothing else. Market falls become memes in a billion bottles. We read all sorts of things into them while ignoring the sea of data all around us ‚Ä¶. Data is a bell that is ringing the death nell of aggressive old school vendors and legacy software companies that refuse to take their head out of the sand. Non born-in-the-cloud software behemoths can talk about cloud til the cows come home. However, it‚Äôs only the ones that wed cloud-related brand equity with cloud-related reality that will survive, and perhaps even thrive ‚Ä¶ Software can process data far more efficiently than humans and can be unbiased. Subject matter experts in the future will be built with ones and zeros to curate, analyse and interpret crowd sourced data. As software eats the world, data will usurp humans as la Bocca della Verit√† (mouth of truth). And the sound of crashing glass will only be a fading memory.
Our ability to convert data into understanding (Understanding as a Service) will eventually make human predictions virtually irrelevant. And that‚Äôs how it should be. In the meantime, be careful who you listen to.
I‚Äôd like to dedicate this piece to the late (and very great) Hans Rosling, former Professor of Global Health at Stockholm‚Äôs Karolinska Institutet (possible the world‚Äôs most innovative medical university). A rare and highly advanced human who championed global understanding and empathy for all ‚Äî especially the poor who are the forgotten members of his species. If you are new to Rosling and interested in data as a source of truth and understanding, I urge you to watch some of his Ted Talks. In an Age of Unreason it feels like we cannot afford to lose people like that. Rosling‚Äôs vision spanned the globe and his data driven visualisation of the success of healthcare projects helped move billions of dollars from Bill Gates‚Äô pocket to productive projects in the developing world. Rosling‚Äôs dataset really did change Gates‚Äô mindset. He was one of the first truly great humans of the 21st century.
‚ÄúHans was a great champion for the world‚Äôs poorest, and for clear thinking.‚ÄùBill Gates
‚ÄúI have a neighbour who knows 200 types of wine. He knows everything. He knows the name of the grape, the temperature and everything. I only know two types of wine ‚Äî red and white. (Laughter) But my neighbour only knows two types of countries ‚Äî industrialised and developing. And I know 200, I know about the small data.‚ÄùHans Rosling
‚ÄúWhat‚Äôs so funny ‚Äòbout peace love and understanding?‚ÄùElvis Costello
written by Stephen Cummins ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî
If you found this interesting, then please press the applause symbol for as many claps as you feel it deserves! And ‚Ä¶1. Listen to me interview the greatest founders in the world on the14 Minutes of SaaS podcast ‚Ä¶ you can listen to it wherever you listen to podcasts:14 Minutes of SaaS on Spotify / Apple podcasts / Google podcasts / TuneIn / Stitcher2. Follow me on social networks you use: @Stephen_Cummins and @14MinutesOfSaaS and my LinkedIn profile
CEO & Founder @AppSelekt. Host @14MinutesOfSaaS podcast. @SaaSMonster MC & Keynote speaker @CollisionHQ & @WebSummit. Run 2 biggest @salesforce Linkedin groups.
See all (138)
504 
504¬†claps
504 
Stephen Cummins writes about trends and observations in the world of SaaS and Deep Tech
About
Write
Help
Legal
Get the Medium app
"
https://engineering.99x.io/is-aws-lambda-just-another-platform-as-a-service-7c7a1998e786?source=search_post---------201,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Its more than 3 years since AWS has introduced Lambda Service back in 2014. So lets ask what is AWS Lambda from Wikipedia.
AWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of the Amazon Web Services. It is a compute service that runs code in response to events and automatically manages the compute resources required by that code. ~ Wikipedia
Many people wonder what is so special about Lambda Service since there were many Compute Services available even before Lambda such as Google App Engine, Heroku & etc. One can say, Lamda is Function as a Service(FaaS) not a Platform as a Service (PaaS). Again the same question repeats, what so special about Lambda?
Other Public Clouds, also started providing similar services such as Google Cloud Functions, Azure Functions & etc. and some of the capabilities I discuss here about Lambda are applicable to those as well.
One of the major differences with Lambda compared to Traditional Platform as a Service is that, its event driven where the code is and its container is not running unless its invoked.
Ok so does that mean upon invocation, it requires to first start the container and then run the code at the same time? Yes and not only that, the underlying container also needs to load the code before execution.
So probably the first question comes to your mind is ‚ÄúIs it fast enough?‚Äù The real answer is, it depends.
Although Amazon improved its performance to a reasonable level by reusing Containers for consecutive invocations (Search for AWS Lambda COLD Start and HOT Start), still there are several factors you need to look towards before using Lambda which governs its performance.
So ideally it is recommended to keep the Lambda code simple (Less size) and allocate reasonable amount of memory (Amazon not only allocates memory upon memory selection, it also matches with CPU performance) for the execution.
If the function is not invoked frequently you can deploy a strategy to keep the Lambda function HOT by invoking within 5 minutes interval and surpassingly it won‚Äôt cost you much. There are couple of ways to achieve this.
Another major difference with AWS Lambda compare to a Platform as a Service is its true function nature. You can connect Lambda functions to many services in AWS building rich workflows without the trouble in managing a EC2 instance. You can connect Lambda with S3, SNS, API Gateway, DynamoDB, Kinesis and etc. also allowing to connect different services together.
When using AWS Lambda, you will be paying for only the execution of milliseconds for each function although the pricing for each time block changes depending on the amount of memory you allocate. This vastly different from paying an hourly fee or a fix amount for using a Platform as a Service.
The Lambda free tier includes 1M free requests per month and 400,000 GB-seconds of compute time per month.
You are charged for the total number of requests across all your functions. Lambda counts a request each time it starts executing in response to an event notification or invoke call, including test invokes from the console.
Pricing Reference: AWS Lambda Pricing Details Page
This will be really useful in implementing an API using AWS Lambda. Since the number of consumption reduces when newer versions available, this will reduce the cost for consumption for older APIs and naturally ends up to zero when all the consumers migrates to the newer versions.
The scalability model with Lambda is significantly different from Platform as a Service. Since Lambda function container provisioned upon invocation (When an event is received), it is also possible to scale out when number of events increases.
Q: Is there a limit to the number of AWS Lambda functions I can execute at once?
No. AWS Lambda is designed to run many instances of your functions in parallel. However, AWS Lambda has a default safety throttle for number of concurrent executions per account per region (visit here for info on default safety throttle limits).
By default, AWS Lambda limits the total concurrent executions across all functions within a given region to 1000. For instructions on how to increase that limit.
Scaling Reference: AWS Lambda FAQs
However it is important to understand that Lambda scaling doesn‚Äôt work in the same way for different event sources. So do good enough research before designing your solution for scalability.
Have you ever wonder what will happen, if a Lambda function fails upon execution throwing an Error?
This is one of the important aspects of Lambda where you can externally configure the function to use fallback strategy to send the event payload to SNS or SQS allowing to take further decisions on how to handle the situation after certain number of retries.
Creating impactful digital products, together!
31 
31¬†claps
31 
Written by
Solutions Architect and a Content Specialist. For more details find me in Linkedin https://www.linkedin.com/in/ashanfer/
Headquartered in Sri Lanka, 99x is a technology company co-creating well-engineered, innovative digital products for the Scandinavian market. ‚Äã
Written by
Solutions Architect and a Content Specialist. For more details find me in Linkedin https://www.linkedin.com/in/ashanfer/
Headquartered in Sri Lanka, 99x is a technology company co-creating well-engineered, innovative digital products for the Scandinavian market. ‚Äã
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@auth0/building-serverless-apps-with-aws-lambda-1e1c5dd8f4cc?source=search_post---------202,"Sign in
There are currently no responses for this story.
Be the first to respond.
Auth0
Jul 20, 2016¬∑1 min read
Lambda is a Function-as-a-Service (FaaS) platform provided by Amazon Web Services(AWS). Lambda is tightly integrated into the AWS ecosystem and allows developers to build microservices that easily interact with other AWS services. For example, we can create a Lambda function that is executed every time a user signs up through the AWS Cognito service or we can trigger a Lambda function after a file is uploaded to S3. Combining Lambda with the API Gateway, we can build microservices that can be accessed from outside the AWS ecosystem.
A few weeks ago we showed how you can build serverless apps with Webtask. Today, we are going to recreate our Serverless Stories app with AWS Lambda. The goal of this article is to showcase how you can build serverless apps with AWS Lambda and to compare and contrast the differences between Lambda and Webtask.
Read More
Identity Is Complex, Deal With It. Auth0 is The Identity Platform for Application Builders.
12 
12¬†
12 
Identity Is Complex, Deal With It. Auth0 is The Identity Platform for Application Builders.
"
https://levelup.gitconnected.com/moving-away-from-aws-and-onto-heroku-d84852b9884d?source=search_post---------203,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
In the fall of 2018, I decided it was time to put my application design and development knowledge to use in order to provide a modernized solution for my mother-in-law‚Äôs small business. Her business is designed to help find living accommodations for those relocating to the southeast part of the United States. Since the weather is warm there throughout the entire year, her clientele typically are seeking a nice climate for‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://itnext.io/enabling-full-cycle-development-four-core-cloud-platform-capabilities-8670e5a4cd04?source=search_post---------204,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Cloud computing and container orchestration frameworks provide an excellent foundation for deploying and running modern software applications. However, in order for these technologies to support the move towards ‚Äúfull cycle development‚Äù ‚Äî where developers take increased ownership from idea to delivery ‚Äî there are several requirements that must be met for both the development and platform/SRE personas. Many teams design and build a platform in order to support these requirements, often using Kubernetes as a foundation. This platform must focus on offering self-service functionality, and it must support four core capabilities: container management, progressive delivery, edge management, and observability.
In part one of this series we covered the topic of ‚ÄúWhy Cloud Native?‚Äù in detail. This article will explore the new dev/ops requirements, outline the four core platform capabilities, and provide guidance on avoiding common antipatterns when building an application platform.
When adopting a cloud native approach, developers need to be able to run through the entire SDLC independently. And they need to do this with speed and with confidence that they are adding value to end-users (and not causing any unintended negative impacts). Developers want to build and package applications within containers, and rely only on self-service interfaces and automation (provided by the platform team) to test, deploy, release, run, and observe applications in production.
This rapid feedback loop supports developers in becoming more customer-focused. This enables more functionality to be delivered, with the goal of providing more verifiable value to end users in a repeatable manner.
Platform teams need to capable of providing three primary functions:
The foundational goals of continuous delivery are focused on being able to deliver functionality to end users in a manner that is as fast and as stable as the business requires. Creating a supportive platform is vital to this, and so is creating an effective developer experience (DevEx) for interacting with the platform via tools and APIs.
Bringing together all of the requirements discussed so far results in four core capabilities that a cloud native platform must provide: container management, progressive delivery, edge management, and observability management.
This is the ability to manage and run container-based applications at scale and on a variety of infrastructures. Developers should be able to perform these operations in a self-service manner that can easily be automated and observed. This capability must also allow the platform team to set policies around access, control, and auditability.
This capability is focused on supporting the creation of pipelines that enable the automated build, verification, deployment, release, and observability of applications by developers. This capability should also support platform teams in centralizing the codification and verification of quality and security properties.
Effective edge management should enable the self-service release of new functionality by developers. It should also support centralized configuration of sane defaults, such as TLS enforcement and rate limiting for DDoS protection, and the decentralized configuration of other cross functional requirements associated with traffic management, such as authn/z, retries, and circuit breaking.
This capability should support the collection and analysis of end user and application feedback directly by developers and the platform team. This allows product teams to iterate against business goals and KPIs, and supports the platform team in observing and managing infrastructure and ensuring their service level objectives (SLOs) are met.
At first glance, providing a platform that provides all of the four capabilities may appear relatively simple. However, there are a number of platform antipatterns which have been discovered over the recent history of software development. Whether an organisation buys a cloud native platform or builds this one sprint at a time, there are a number of common mistakes that must be avoided.
Many early attempts at creating a platform within an organization were driven by a single operations team without collaboration with the development teams. The ownership of these platforms tended to be centralised, the design work done upfront, and the resulting platforms were typically monolithic in operation. In order to use the platform, developers had to communicate with the operations team via tickets to get anything done, e.g. deploy artifact X, open port Y, and enable route Z.
These platforms often only supported limited ‚Äúcore‚Äù use cases that were identified as part of the upfront design process. Problems often emerged when developers wanted to design and deploy more modular systems, or implement new communication protocols. For example, as developers embraced the microservices architectural style, they frequently exposed more APIs at the edge of the system. They also adopted multiple protocols for applications: REST-like interactions for resource manipulations operations, WebSockets for streaming data, and gRPC for low-latency RPC calls
As developers moved away from the one-size-fits-all specifications, this increasingly meant raising more and more tickets for the operations team. The combination of the high cost of handoffs and the frequently inadequate (or slowing changing) platform meant that developers could not release software at the speed that the business required. Often this led to development teams taking matters into their own hands.
The failure of the centralized platform design and ownership model led to a swing in the opposite direction. Independent service development teams began building their own micro-platforms. This often manifested itself with coarse-grained access points being exposed at the edge of the system that forwarded all end-user requests to one of several development team-managed reverse proxies or API gateways. Developers had full control over these endpoints. However, inter-team collaboration was often low. Individual services were often configured to use third-party authentication and authorization services, leading to authentication sprawl. The capability to support availability and reliability goals were implemented in an ad hoc manner via language-specific libraries.
This failure mode led to lots of teams reinventing the (subtly different) wheel. Even popular open source libraries, such as Netflix‚Äôs Hystrix circuit-breaker, were reimplemented subtly differently across various language platforms. The fragmentation meant that it was difficult to ensure consistency of availability, reliability, and security. And because all of these features were baked-into each application, each team had to use a different workflow to deploy, test, and observe their applications. This lack of common developer experience often caused additional challenges.
Cloud native technologies also fundamentally altered the developer experience. Not only are engineers now expected to design and build distributed service-based applications, but their entire development loop has been disrupted. No longer can developers rely on monolithic application development best practices, such as checking out the entire codebase and coding locally with a rapid ‚Äúlive-reload‚Äù inner developer loop. They now have to manage external dependencies, build containers, and implement orchestration configuration (e.g. Kubernetes YAML). This may appear trivial at first glance, but this has a large impact on development time.
If a typical developer codes for 360 minutes (6 hours) a day, with a traditional local iterative development loop of 5 minutes ‚Äî 3 coding, 1 building i.e. compiling/deploying/reloading, 1 testing inspecting, and 10‚Äì20 seconds for committing code ‚Äî they can expect to make ~70 iterations of their code per day. Any one of these iterations could be a release candidate. The only ‚Äúdeveloper tax‚Äù being paid here is for the commit process, which is negligible.
If the build time is incremented to 5 minutes ‚Äî not atypical with a standard container build, registry upload, and deploy ‚Äî then the number of possible development iterations per day drops to ~40. At the extreme that‚Äôs a 40% decrease in potential new features being released. This new container build step is a hidden tax, which is quite expensive.
Many development teams began using custom proxies to either automatically and continually sync their local development code base with a remote surrogate (enabling ‚Äúlive reload‚Äù in a remote cluster), or route all remote service traffic to their local services for testing. The former approach had limited value for compiled languages, and the latter often did not support collaboration within teams where multiple users want to work on the same services.
In addition to the challenges with the inner development loop, the changing outer development loop also caused issues. Over the past 20 years, end users and customers have become more demanding, but also less sure of their requirements. Pioneered by disruptive organisations like Netflix, Spotify, and Google, this has resulted in software delivery teams needing to be capable of rapidly delivering experiments into production. Unit, integration, and component testing is still vitally important, but modern application platforms must also support the incremental release of functionality and applications to end users in order to allow testing in production.
The traditional outer development loop for software engineers of code merge, code review, build artifact, test execution, and deploy has now evolved. A typical modern outer loop now consists of code merge, automated code review, build artifact and container, test execution, deployment, controlled (canary) release, and observation of results. If a developer doesn‚Äôt have access to self-service configuration of the release then the time taken for this outer loop increases by at least an order of magnitude e.g. 1 minute to deploy an updated canary release routing configuration versus 10 minutes to raise a ticket for a route to be modified via the platform team.
With the motivations for enabling full cycle development presented, the four capabilities of a cloud native platform defined, and a number of antipatterns highlighted, what‚Äôs next? The answer is designing and building an effective platform to support the teams and workflow. For an organisation that is moving to cloud in 2020, this platform is likely to be based on a technology that has fast become the de facto vendor-agnostic computing abstraction: Kubernetes. We‚Äôll cover this in more detail in the next article.
To learn more about enabling these shifts at your organisation, click here to download our whitepaper ‚Äú4 Essential Elements of Kubernetes Platform‚Äù.
I‚Äôll publish part 3 of the series next week. Until then, I would be very keen to hear your feedback and comments.
ITNEXT is a platform for IT developers & software engineers‚Ä¶
41 
41¬†claps
41 
Written by
Director of DevRel @ambassadorlabs | News Manager @InfoQ | Chair @QConLondon | Biz-Dev-Ops
ITNEXT is a platform for IT developers & software engineers to share knowledge, connect, collaborate, learn and experience next-gen technologies.
Written by
Director of DevRel @ambassadorlabs | News Manager @InfoQ | Chair @QConLondon | Biz-Dev-Ops
ITNEXT is a platform for IT developers & software engineers to share knowledge, connect, collaborate, learn and experience next-gen technologies.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@chanakaudaya/enterprise-software-architecture-where-to-run-your-software-9d14c56d13ad?source=search_post---------205,"Sign in
There are currently no responses for this story.
Be the first to respond.
Chanaka Fernando
Jul 30, 2019¬∑6 min read
Enterprise software landscape has evolved from running batch jobs in mainframe computers to run a SaaS application from your mobile phone to onboard an employee. The software you run within the enterprise needs to be carefully selected and architected. The role of an enterprise software architect has become more prominent and important in the era of cloud computing and data privacy regulations. You have to consider many different aspects when designing an enterprise software architecture. Here are some of the key factors you need to put your close attention to.
If we consider all the above mentioned factors, it is evident that we cannot have the best of all always. We have to compromise some features to support the other. Let‚Äôs try to understand the software which is running on the enterprise in more detail.
Everything starts with the bits and bytes running on a set of electronic circuits which we called as hardware. From that point onwards, there are a plethora of software components that hide the complexity of the bits and bytes and abstract it away for various users based on their knowledge and expertise and expectations. There are many organizations who offer different levels of enterprise software capabilities as cloud services or ‚Äúas a Service‚Äù offerings. Here are some of the common cloud services offered as services that are fully hosted and managed by the respective vendors.
The figure below showcases how each of these components are layered up.
As depicted in the above figure, there are various cloud offering available in the market which can help you to delegate your responsibilities of IT infrastructure maintenance to a third-party technology vendor. Depending on the requirements and the capacity of your IT staff, you can select the best possible abstraction layer. Here are some ways on how you can decide which cloud abstraction is better suited for your enterprise.
In addition to the above mentioned categorization, there are some other offerings coming through to simplify the IT operations within enterprises. One such approach is ‚ÄúServerless‚Äù platforms where they run your programs for you in the cloud as and when necessary instead of running them all the time in the case of a PaaS or PCF. Another cloud offering that is getting popular these days is ‚ÄúIDaaS‚Äù which is ‚ÄúIdentity as a Service‚Äù which provides various Identity and Access Management capabilities as a cloud offering. Another such service is ‚ÄúMBaaS‚Äù which expands to ‚ÄúMobile Backend as a Service‚Äù which will provide you a platform to run your mobile backends for various mobile applications running on different platforms.
Here is a list of vendors under each layer which are available in the market.
The original content of this article can be found at the below GitHub repository.
github.com
üìù Read this story later in Journal.
üë©‚Äçüíª Wake up every Sunday morning to the week‚Äôs most noteworthy stories in Tech waiting in your inbox. Read the Noteworthy in Tech newsletter.
Engineer | Author | Speaker | Associate Director @ WSO2
28 
28¬†
28 
Engineer | Author | Speaker | Associate Director @ WSO2
"
https://medium.com/@RyanKroonenburg/this-is-a-great-insight-on-serverless-and-the-different-options-available-for-any-enterprise-beb6a7eb4c41?source=search_post---------206,"Sign in
There are currently no responses for this story.
Be the first to respond.
Ryan Kroonenburg
Feb 2, 2017¬∑1 min read
Terren Peterson
This is a great insight on serverless and the different options available for any enterprise! As you know from our keynote at SECON, A Cloud Guru is passionate about serverless architecture and always looks forward to Capital One‚Äôs engagement at ServerlessConf. We‚Äôve really enjoyed interacting with the amazing engineers at Capital One during our serverless workshops. To reflect the current state of modern Cloud Service Models, A Cloud Guru has updated our platform to now offer courses for DynamoDB, Lambda and a course on AWS Certified Big Data Specialty (which goes in-depth in to RedShift). We are looking forward to seeing everyone from Capital One in Austin on April 26‚Äì28 at ServerlessConf! Keep being awesome Cloud Gurus!
See all (121)
9 
9¬†claps
9 
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/google-cloud/experimenting-with-google-cloud-platform-441da66154ba?source=search_post---------207,"There are currently no responses for this story.
Be the first to respond.
Google offers a $300 credit to get started with GCP for free. It‚Äôs time to experiment.
What‚Äôs needed to sign up for the trial:
Once set up,
Deploying a serverless env in minutes with GCP
Google Cloud community articles and blogs
8 
8¬†claps
8 
Written by
Tech lover, passionate about software, hardware, science and anything shaping the future ‚Ä¢ ‚õÖ explorer at Google ‚Ä¢ Opinions my own ‚Ä¢ You can DM me @PicardParis
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
Written by
Tech lover, passionate about software, hardware, science and anything shaping the future ‚Ä¢ ‚õÖ explorer at Google ‚Ä¢ Opinions my own ‚Ä¢ You can DM me @PicardParis
A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@mauridb/azure-functions-dapper-and-sql-server-json-to-store-form-data-f95a2c9f3c12?source=search_post---------208,"Sign in
There are currently no responses for this story.
Be the first to respond.
Davide Mauri
Feb 6, 2017¬∑4 min read
Recently we had to setup a couple of contact form pages to allow users to register to the App 2.0 Beta program (now RTM) or to tell us which of the products we launched at CES 2017 they are interested into.
Such kind of request are quite frequent and usually, from a developer perspective, they are the worst thing someone can ask. They are boring to architect, boring to write, boring to test. Still, business and marketing needs and love them.
So how to satisfy this requirement in the fastest and easiest way, but still delivering high-quality and easy to maintain code, while also keeping an eye on integrating the data with the existing environment?
Given that we are on Azure, one option was Azure DocumentDB. No need to define a schema upfront and it is usable just using REST so the UX developer could do anything on its own, just using JQuery. Azure DocumentDB can also be queried using a SQL language, so extracting data from it wouldn‚Äôt have been a problem.
But at the end, I decided to go another way. All our data, after swimming in a Data Lake are saved in a Azure SQL database where we heavily rely on its column-store features. So having an additional database to integrate was something that would have made the solution a bit more more complex than the simplest possible one. The famous quote
everything should be made as simple as possible, but no simpler
is what drives all my architectural decisions, so I wasn‚Äôt really happy about going with Azure DocumentDB.
With the additional fact that there are no really good tooling around Azure DocumentDB yet, I started to look for alternatives. The obvious alternative, aside from saving data into a blob, which was not on option since that would have been too simple, because it doesn‚Äôt offer any querying capability, was to use Azure SQL.
With Azure SQL you have great tooling (SQL Server Management Studio and now also the online query editor), we already have all knowledge in house, but surely the fact that it doesn‚Äôt allow to use just REST to read and write data was, again, something that wasn‚Äôt making me really happy.
Beside that, Azure SQL seemed to be the perfect option. JSON is now natively supported, so there is no problem to store data without a strictly enforced schema.
Since we‚Äôre already using SQL Azure, we wound‚Äôt even have to spend any additional cent for it. The only problem to solve was that you can‚Äôt use Azure SQL directly via JQuery.
The missing link ‚Äî the REST interface ‚Äî can easily be created using Azure Functions and a microORM like Dapper. Thanks to the serverless nature of Azure Functions all it‚Äôs need are the few lines of code to get the HTTP Request Body that contains the contact form ‚Äújsonifyied‚Äù data and store into the SQL Azure database.
The created Azure Function gets called each time an HTTP Request is done, using an HTTP Trigger. Here the function.json file that defines the function bindings:
and the function full code is here:
Such additional layer is also a welcome addition since it allows to inject some additional validation checks and business if needed.
I‚Äôve used a Stored Procedure here for better decoupling, and it does just a simple insert, with some additional checks.
It also turns some JSON data into columns, to make querying even easier.
Dapper helps to make interacting with SQL Azure a breeze (two, yes two, lines of code to open the connection and write to SQL azure), so all simplicity requirements are finally met. No more impedance mismatch. No more.
Given the existing external factors (resources, knowledge, integration) the simplest solution but not simpler has been achieved.
Without any existing factors I would probably have chosen Azure DocumentDB. But as an afterthought, I still have the gut feeling that SQL Azure would have been better in the long term (for example I can connect Marketing Manager‚Äôs Excel directly to the SQL Azure, something that I cannot do yet with DocumentDB)‚Ä¶so maybe SQL Azure would be my choice onve again. After all software is made to serve people, and this should drive at least 50% (if not more) of the architectural choices, IMHO.
Since I joined Sensoria I‚Äôve moved to work on the cloud 100% of my time. And the more I work on the cloud, the more it is clear to me that serverless and simplicity (which means, implementation-wise: microservices) is the way to go. Efficiency is increased so much in this way that it‚Äôs really worth the effort, and embracing PaaS clearly becomes an obvious choice.
Data Geek, Storyteller, Developer at heart, now infiltrated in Azure SQL product group to make sure developers voice is heard loud and clear. Heavy Metal fan.
46 
2
46¬†
46 
2
Data Geek, Storyteller, Developer at heart, now infiltrated in Azure SQL product group to make sure developers voice is heard loud and clear. Heavy Metal fan.
"
https://medium.com/scalable/integrating-platform-services-with-pivotal-cloud-foundry-1fe2ff410c26?source=search_post---------209,"There are currently no responses for this story.
Be the first to respond.
Pivotal CloudFoundry (PCF) is a Platform as a Services (PaaS) solution originally developed by VMWare and later moved to Pivotal Software Inc, a joint venture by EMC, VMWare and General Electric. PCF is the commercial version of the open source Cloud Foundry solution which includes additional commercial features such as the operations manager, enterprise services, extensions, support, docs, etc. The following diagram illustrates its component architecture in detail:
In contrast to Kubernetes, OpenShift, DC/OS and Docker Swarm, which are considered as today‚Äôs most widely used open source container cluster management platforms (CCMP), PCF architecture is quite complex and considerably heavy to deploy. For an instance, a typical PCF production deployment would require nearly fifty virtual machines for installing its management components whereas Kubernetes would only require three instances. Moreover, PCF‚Äôs own infrastructure management component; BOSH, BOSH‚Äôs wrapper component; Operations Manager, the OS image and server runtime abstractions; Stemcells and Buildpacks, it‚Äôs own container runtime; Diego, PCF router, are some of the Pivotal specific components that users may need to learn when they start using PCF. Moreover, as I found the community support for these components are comparatively low and at the same time it may require a considerable amount of time and effort for troubleshooting deployment issues.
Nevertheless, if you are just getting started with PCF, PCF Dev can be used for setting up a lightweight PCF environment on a local machine using VirtualBox. This can be used for trying out the basic features of PCF including deploying applications using Docker and Buildpacks, configuring routing, integrating with services, etc. It is important to note that PCF Dev does not include BOSH and Operations Manager. If required BOSH Lite can be installed separately on VirtualBox and Operations Manager is only available on complete PCF installations on AWS, Azure, GCP, VMWare vSphere and OpenStack.
At WSO2 we did couple of evaluations on deploying WSO2 middleware on PCF (without using BOSH/Operations Manager) and found a collection of technical limitations in year 2016 related to exposing multiple ports, service discovery, container to container communication, TCP routing, separating out external and internal routing, etc. Very recently, we started doing another evaluation and found that PCF supports integrating such services iteratively at four different levels depending on how integrations need to be implemented, where service instances need to be deployed and how service instances need to be managed. This article explains details of those four levels and when to use each:
This is the most simplest way of integrating platform services with PCF. Any software product can be integrated with PCF with this approach using its API without having to implement any extensions or resources to deploy the software on PCF itself. Once integrated, applications running on PCF will be able to bind to a service and programmatically read service information such as API URL and credentials via environment variables. Afterwards applications will be able to consume the service with the given configurations. For an example if a RDBMS is need for applications, it can be registered as an user provided service in PCF as follows:
Afterwards, applications can bind to the above service as follows:
This might be the best approach for getting started with a PCF service integration. It would be less time consuming, and may not require implementing any extensions. Nevertheless, it might be worth to note that the only advantage of using this approach would be the ability to inject service configurations to a collection of applications via a central PCF feature without having to do it by manually injecting environment variables to each application. Otherwise, the same can be achieved without using PCF services.
In level 2 with brokered service approach, an extension API needs to be implemented according to PCF Service Broker API for the integration. Unlike in level 1, this approach does not directly expose software product‚Äôs API with applications, rather the following service broker API resources would mapped to the services provided by the product:
For an example, if the platform service is a RDBMS; the create service instance API resource could create a new tenant in an existing database server, the bind an application to a service instance API resource could create a new database in the above server, the unbind an application from a service instance API resource could delete the created database and so forth. The service broker API can be implemented in any language and deployed on PCF as another application. The software product can run outside PCF while ensuring routing between the two environments.
For an example once a service broker API is implemented for a third party software it can be deployed on PCF using a Docker image:
Afterwards, the service broker can be registered in PCF by executing the following commands:
Finally an application can bind to the above service via the following command:
At WSO2 we implemented a Service Broker for WSO2 API Manager using this approach for providing API Management services for microservices deployed on PCF. The service broker API was implemented in Ballerinalang and it can be deployed on PCF using Docker. Refer the README.md and the source code in the above repository for more information. The main advantage of level 2 over level 1 would be the ability to automate the service functionality binding with the applications without having to implement logic in the applications for specifically invoking the product API.
Level 3 is much similar to level 2 except that third party software is also deployed on PCF using a PCF Tile together with its brokered service API. A PCF Tile provides a packaging model and a deployment blueprint for executing software installations on PCF by creating virtual machines, containers, managing configurations, networking, routing, etc. It is designed to be deployed via the Operations Manager and once deployed it will generate a BOSH release and execute the deployment via BOSH. Pivotal provides a tool called PCF Tile generator for implementing tiles by generating the required folder structure and the tile definition.
Tiles allow software to be deployed on infrastructure platforms supported by BOSH either using virtual machines or Docker. It provides features for defining resources configurations (CPU, memory, disk), routing rules for load balancing, dependencies between tiles for installing dependent components, BOSH errands (scripts) for executing deployment commands including pre and post validations, etc. Since managed services only create one deployment of the given software at this level, this approach might only be suitable if multi-tenancy is supported by the third party software itself or if tenancy is not needed at the PCF context.
The main feature provided at level 4 is the ability to create single tenant, dedicated deployments of third party software for each service binding. If PCF is used in multi-tenant mode and if the third party software does not support multi-tenancy, an integration at level 4 would be needed for creating separate deployments for each PCF organization or space. Unlike in level 2 and 3, in level 4 a service adapter will need to be implemented using the On-Demand Services SDK. As shown in figure 5, On-Demand Broker (ODB) handles all interactions between the Cloud Foundry and BOSH. ODB make use of the service adapter for handling service specific tasks.
PCF provides four different levels for integrating platform services with applications running on PCF. At the initial level, third party software products can be directly integrated with PCF using product API without having to implement any extensions. At level 2, a service broker API needs to be implemented for mapping product functionality to service binding workflow. At this level the given software can be run outside PCF and would not need any deployment automation specific to PCF. At level 3 both service broker API and the software product will be deployed on PCF using CF Tiles. Here the software product will only have one deployment for all service instances. At level 4, each service instance will get a dedicated deployment of the third party software providing multi-tenancy with isolated deployments.
Industry best practices for implementing scalable‚Ä¶
58 
58¬†claps
58 
Written by
Engineer at Google
Industry best practices for implementing scalable enterprise applications
Written by
Engineer at Google
Industry best practices for implementing scalable enterprise applications
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://becominghuman.ai/real-time-speech-recognition-for-communication-apps-a459543425d?source=search_post---------210,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
Voximplant is being used by a number of developers and businesses around the world for different real-time communication apps and services. Automation was always important and became even more popular lately with serious progress in machine learning / neural networks. We‚Äôve been waiting for high-quality speech recognition as a cloud service for a long time as many other companies, since if connected to Voximplant it could enable a lot of new services that can be built and extend the functionality of already existing ones. That‚Äôs why when Google announced their Google Speech API we immediately started working on the integration, and it took us a while to finish its first version, which is now available to all Voximplant developers.
www.eventbrite.com
Since Voximplant empowers developers with JavaScript API to control calls running via the platform in real-time we could create flexible and powerful API for speech recognition on top of that. It can be used for call transcription and streaming recognition for both commands (specified in a dictionary by developer) and freeform speech interpretation that uses a very large grammar, and was trained by Google on large data volumes.
For example, the following code enables call record transcription:
language parameter tells the system what language should be recognized, 80 languages are supported out-of-the-box at the moment.
Call records transcription is a very useful service, but it‚Äôs something you can do with other platforms as well by sending audio call records to the recognition endpoint offered by Google or some other vendor. In our case when developer tells VoxEngine that call should be transcribed ‚Äî Voximplant records audio not only in mp3 format, but also stores RAW audio data which is then used for transcription what significantly improves the quality of the recognition result. Our backend processes the audio, feeds it to the recognition endpoint, processes the recognition result and stores it, after that the result is accessible via HTTP API (see transcription_url param).
And some streaming recognition examples:
The script above has dictionary specified [‚ÄúYellow‚Äù, ‚ÄúGreen‚Äù, ‚ÄúRed‚Äù, ‚ÄúBlue‚Äù, ‚ÄúWhite‚Äù, ‚ÄúBlack‚Äù], ASR will be detecting this words much better (with higher confidence) than anything else , but it still will recognize other words and phrases. For 100% freeform recognition developer needs to change
asr = VoxEngine.createASR(ASRLanguage.ENGLISH_US, [‚ÄúYellow‚Äù, ‚ÄúGreen‚Äù, ‚ÄúRed‚Äù, ‚ÄúBlue‚Äù, ‚ÄúWhite‚Äù, ‚ÄúBlack‚Äù]);
to
asr = VoxEngine.createASR(ASRLanguage.ENGLISH_US);
What if I need to recognize what person is saying for a long time, not just word or phrase, but sentences or even paragraphs? Of course, that‚Äôs also possible! Just don‚Äôt stop sending media from a call to ASR after SpeechCaptured event:
Since Voximplant session can communicate with external backend in real-time it‚Äôs easy to create your own voice bot. Voximplant will handle speech recognition (using ASR), speech synthesis (using TTS) and send/receive data to/from the bot‚Äôs backend. You can make a simple bot even without communication with external backend, but then this bot won‚Äôt be too smart :)
Here is an example of VoxEngine scenario:
Combining the power of VoxEngine and real-time speech recognition developers can implement number of different useful apps and scenarios. Feel free to register your free Voximplant developer account and start using nextgen cloud communication platform today.
Latest News, Info and Tutorials on Artificial Intelligence‚Ä¶
16 
1
Watch AI & Bot Conference for Free¬†Take a look.
16¬†claps
16 
1
Written by
CEO/Co-founder VoxImplant/Zingaya
Latest News, Info and Tutorials on Artificial Intelligence, Machine Learning, Deep Learning, Big Data and what it means for Humanity.
Written by
CEO/Co-founder VoxImplant/Zingaya
Latest News, Info and Tutorials on Artificial Intelligence, Machine Learning, Deep Learning, Big Data and what it means for Humanity.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@enginunal/bulut-mimarisinin-temelleri-111489c61fd7?source=search_post---------211,"Sign in
There are currently no responses for this story.
Be the first to respond.
Engin UNAL
Jan 31, 2018¬∑7 min read
Bulut servislerinin kullanƒ±cƒ±ya √∂zel olarak sunulmasƒ±dƒ±r. Sunulan kaynaklar diƒüer kullanƒ±cƒ±larla payla≈üƒ±lmaz, kullanƒ±cƒ± kendisine sunulan bulut servislerinin √∂l√ßeklenebilirlik, elastiklik gibi √∂zelliklerini kullanƒ±rken kontrol ve uyarlanabilirlik √∂zelliklerine de sahip olur. √ñzel bulut servisleri IaaS ve Paas modeli ile saƒülanabilir. Iaas, Servis Olarak Altyapƒ±(aƒü,depolama..) ve PaaS, Servis Olarak Platform(i≈ületim sistemi, web sunucusu, veritabanƒ± sunucusu‚Ä¶) anlamƒ±na gelmektedir.Dahili veya kurumsal bir bulut olarak da adlandƒ±rƒ±lan √∂zel bulut, ≈üirketlere barƒ±ndƒ±rƒ±lan bilgisayar altyapƒ±sƒ± √ºzerinden √∂zelle≈ütirilmi≈ü kaynaklardan saƒülanan ek kontrol ve √∂zelle≈ütirme sayesinde, i≈ületmelerin self-servis, √∂l√ßeklenebilirlik(scalability) ve elastikiyet(elasticity) gibi genel bir bulutun pek √ßok avantajƒ±nƒ± saƒülar
Internet √ºzerindeki sunucular ile saƒülanan ve herkese a√ßƒ±k olan bulut hizmetidir. Genel bulut, bir hizmet saƒülayƒ±cƒ±nƒ±n sanal makineler (VM‚Äôler), uygulamalar veya depolama gibi kaynaklarƒ±, internet √ºzerinden herkese a√ßƒ±k hale getirdiƒüi standart bulut bili≈üim modeline dayanƒ±r.Sunulan hizmetler kullanƒ±cƒ±lara √ºcretsiz veya √ºcret kar≈üƒ±lƒ±ƒüƒ± saƒülanabilir. Kullandƒ±ƒüƒ±n kadar √∂de modeli de uygulanmaktadƒ±r. √ñzel bulutlarƒ±n aksine, genel bulutlar firmalarƒ± ≈üirket i√ßi donanƒ±m ve uygulama altyapƒ±sƒ± satƒ±n almak, y√∂netmek ve bakƒ±m yapmak zorunda kalmaktan kurtarabilir ‚Äî bulut hizmeti saƒülayƒ±cƒ±sƒ± sistemin t√ºm y√∂netim ve bakƒ±mƒ±ndan sorumlu tutulur.
Melez bulut, genel bulut ile √∂zel bulut arasƒ±nda veri ve uygulamalarƒ±n payla≈üƒ±lmasƒ±nƒ± saƒülayarak bulut ortamƒ±nƒ± entegre eder. En kƒ±sa ifadeyle, kurum i√ßi kaynaklarƒ±n gelen bulut kaynaklarƒ±yla b√ºt√ºnle≈ütirilmesidir.Genellikle, melez bulut, bir genel bulut hizmetinin ve kurum i√ßi bir √∂zel bulutun kombinasyonunu ifade eder; Bununla birlikte, melez bulutlar, farklƒ± saƒülayƒ±cƒ±lar tarafƒ±ndan saƒülanan genel bulutlardan veya bulut ile geleneksel IT‚Äônin bir kombinasyonundan olu≈üabilir. Aslƒ±nda, geleneksel IT altyapƒ±sƒ±nda mevcut sistemlerin bir genel bulut hizmeti ile birle≈ütirildiƒüi bir kurulum ≈üu anda hibrit bulutun en yaygƒ±n kullanƒ±mƒ± halidir.Melez bulut kullanmak, yalnƒ±zca ≈üirketlerin bilgi i≈ülem kaynaklarƒ±nƒ± √∂l√ßeklendirmesine olanak tanƒ±makla kalmaz aynƒ± zamanda kƒ±sa s√ºreli talep artƒ±≈ülarƒ±nƒ± kar≈üƒ±lamak i√ßin b√ºy√ºk sermaye harcamalarƒ± yapma ihtiyacƒ±nƒ± ve i≈üin daha hassas veri veya uygulamalar i√ßin yerel kaynaklarƒ± ayƒ±rmasƒ± gereksinimini ortadan kaldƒ±rƒ±r.
Bu konuyla ilgili a≈üaƒüƒ±daki g√∂rsel ile ba≈ülayalƒ±m. IaaS, PaaS ve SaaS ile ilgili olan bu g√∂rsel a≈üaƒüƒ±daki anlatƒ±m √∂ncesi bir fikir verecektir.
Tek tek IaaS, PaaS ve SaaS maddelerine ge√ßmeden √∂nce konuyu basitle≈ütirmek adƒ±na yakƒ±n zamanda okuduƒüum bir yazƒ±daki √∂rnekle ba≈ülamak istiyorum.Tek ba≈üƒ±na, altyapƒ±(IaaS) kullanƒ±≈ülƒ± deƒüildir ‚Äî orada sadece duran ve birisinin belirli bir sorunun √ß√∂z√ºm√ºnde √ºretken olmasƒ±nƒ± bekleyen bir yapƒ±dan ba≈üka bir≈üey deƒüildir. √úlkedeki ula≈üƒ±m sistemini d√º≈ü√ºn√ºn. T√ºm bu yollar in≈üa edilmi≈ü olsa bile, insanlar ve e≈üyalarƒ± ta≈üƒ±mak i√ßin araba ve kamyon olmadan kullanƒ±≈ülƒ± olmazlar. Bu benzetmede, yollar altyapƒ±ya(IaaS), arabalar ve kamyonlar ise altyapƒ±nƒ±n √ºzerine oturan ve insanlarƒ± ve e≈üyalarƒ± ta≈üƒ±yan platformdur(PaaS). E≈üyalar ve insanlar ise teknik alanda yazƒ±lƒ±m(SaaS) ve bilgi olarak d√º≈ü√ºn√ºlebilir.
IaaS, bilgi i≈ülem, depolama, aƒü olu≈üturma ve diƒüer kabiliyetleri Internet √ºzerinden sunmanƒ±n bir y√∂ntemidir. IaaS, ≈üirketlerin temel bulut altyapƒ±sƒ±nƒ± satƒ±n almak, y√∂netmek ve desteklemek zorunda kalmadan web tabanlƒ± i≈ületim sistemlerini, uygulamalarƒ± ve depolamayƒ± kullanmalarƒ±nƒ± saƒülar. IaaS platformlarƒ±nƒ±n en pop√ºler √∂rnekleri Amazon Web Hizmetleri (AWS) ve Microsoft Azure‚Äôdur. Kullanƒ±cƒ±lar, genel ortam i√ßin bir IT operasyon y√∂netimi konsolu olarak hizmet veren Web tabanlƒ± bir grafik kullanƒ±cƒ± aray√ºz√º kullanarak, bu altyapƒ±yƒ± kendi ba≈ülarƒ±na y√∂netebilirler. Altyapƒ±ya API eri≈üimi bir se√ßenek olarak sunulabilir.En kƒ±sa ifadeyle IaaS, kullanƒ±cƒ±lara depolama, aƒü olu≈üturma, sunuculara ve buluttaki diƒüer bilgi i≈ülem kaynaklarƒ±na √ºcret kar≈üƒ±lƒ±ƒüƒ± eri≈üim saƒülayan servistir.Kullanƒ±cƒ±, kendi ihtiya√ßlarƒ± doƒürultusunda CPU, RAM ve Depolama miktarƒ±nƒ± belirler ve bu √∂zellikleri saƒülayan bir VM(virtual machine)‚Äôi servis saƒülayƒ±cƒ±dan satƒ±n alƒ±r. Bu VM alƒ±ndƒ±ktan sonraki adƒ±mlarda i≈ületim sistemi bakƒ±mƒ± ve y√∂netimi, servis konfig√ºrasyonu kullanƒ±cƒ± tarafƒ±ndan ger√ßekle≈ütirilir.
PaaS, IaaS‚Äôe ek olarak yazƒ±lƒ±m, geli≈ütirme ara√ßlarƒ±, i≈ü zekasƒ± (BI) hizmetleri, veritabanƒ± y√∂netim sistemleri gibi sistemler de i√ßerir. Yazƒ±lƒ±m lisanslarƒ±, uygulama altyapƒ±sƒ±, geli≈ütirme ara√ßlarƒ± ve diƒüer kaynaklarƒ± satƒ±n alma ve y√∂netme zorunluluƒüundan kurtarƒ±r. Bu hizmetler bulut saƒülayƒ±cƒ±sƒ± tarafƒ±ndan verilmektedir.PaaS, geli≈ütiricilerin internet √ºzerinden uygulamalar ve hizmetler olu≈üturmasƒ±na izin veren bir platform ve ortam saƒülar. PaaS, SaaS‚Äôtan daha d√º≈ü√ºk bir seviyede √ßalƒ±≈üƒ±r ve temel olarak yazƒ±lƒ±mƒ±n geli≈ütirilip daƒüƒ±tƒ±labileceƒüi bir platform saƒülar. PaaS saƒülayƒ±cƒ±larƒ±, altta yatan sunucu donanƒ±m ve aƒü altyapƒ±sƒ±nƒ± bakƒ±mƒ± ve sunucularla uƒüra≈üma zorluƒüunu √ºstlenir ve kullanƒ±cƒ±lara sadece i≈ü tarafƒ±na odaklanmayƒ± saƒülayan bir ortam sunar.
SaaS, yazƒ±lƒ±mƒ±n bulutta barƒ±ndƒ±ƒüƒ± ve internet √ºzerinden eri≈üildiƒüi bir abonelik tabanlƒ± modeli ifade eder. Basit√ße web veya bir API aracƒ±lƒ±ƒüƒ±yla eri≈üilen bulut tabanlƒ± uygulamalar olarak tanƒ±mlanƒ±r.Depolama ve i≈üleme i≈ülemlerini bulut sunucularƒ±nda ger√ßekle≈ütirilir ve servise eri≈ümek ve kullanmak i√ßin olduk√ßa basit ve yaygƒ±n bir istemci (genellikle bir web tarayƒ±cƒ±sƒ±) kullanƒ±lƒ±r. Hizmet saƒülayƒ±cƒ±sƒ±, donanƒ±m ve yazƒ±lƒ±mƒ± y√∂netir ve hizmet s√∂zle≈ümesi ile uygulamalarƒ±nƒ±zƒ±n ve verilerinizin kullanƒ±labilirliƒüini ve g√ºvenliƒüini saƒülar. Web tabanlƒ± email hizmetleri, sosyal medya, web tabanlƒ± m√ºzik dinleme hizmeti veren uygulamalar SaaS‚Äôe √∂rnek olarak verilebilir.
Container, bir uygulamanƒ±n kodunu, yapƒ±landƒ±rmalarƒ±nƒ± ve baƒüƒ±mlƒ±lƒ±klarƒ±nƒ±, tutarlƒ±lƒ±k, verimlilik, √ºretkenlik ve s√ºr√ºm denetimi i√ßin yapƒ± ta≈ülarƒ± olarak paketleyen bir sanalla≈ütƒ±rma(virtualization) y√∂ntemidir. Container, yazƒ±lƒ±mƒ±n payla≈üƒ±lan bir i≈ületim sisteminde izoleli olarak √ßalƒ±≈üabilen bir bi√ßimde paketlenmesinin bir yoludur. VM‚Äôlerin aksine, container bir i≈ületim sistemi paketlemez; yalnƒ±zca yazƒ±lƒ±mƒ± √ßalƒ±≈ütƒ±rmak i√ßin gereken k√ºt√ºphaneler ve ayarlara ihtiya√ß vardƒ±r. Bu, yazƒ±lƒ±mƒ±n nerede konu≈ülandƒ±rƒ±ldƒ±ƒüƒ±na bakƒ±lmaksƒ±zƒ±n yazƒ±lƒ±mƒ±n daima aynƒ± ≈üekilde √ßalƒ±≈üacaƒüƒ±nƒ± garanti eder.Container teknolojisi ile uygulamalarƒ±n deploy edilmesi √ßok daha kolay ve VM‚Äôe g√∂re √ßok √ßok hƒ±zlƒ±dƒ±r. Continuous Integration gibi yazƒ±lƒ±m geli≈ütirme s√ºre√ßlerinde geli≈ütiricilerin otomasyona baƒüladƒ±ƒüƒ± derleme ve test s√ºreci sonrasƒ±nda yayƒ±n s√ºreci gelmektedir, yayƒ±n(deployment) s√ºrecinin sorunsuz ger√ßekle≈ümesi √ßok √∂nemlidir. √úretilen ve test edilen bir yazƒ±lƒ±mƒ±n kullanƒ±cƒ±nƒ±n deneyimine sunulma a≈üamasƒ±nda kullanƒ±cƒ±nƒ±n i≈ülerini kesintiye uƒüratmadan deployment tamamlanmalƒ± ve bu i≈ülemler hatasƒ±z ger√ßekle≈ümelidir. Container‚Äôlar bu alanda da √∂nemli kolaylƒ±k getirmi≈ütir ve kullanƒ±mlarƒ± yaygƒ±nla≈ümaktadƒ±r.Konteynerlar bir konteyner engine √ºzerinde √ßalƒ±≈üƒ±r ve bu container engine a≈üaƒüƒ±daki i≈ületim sisteminden baƒüƒ±msƒ±z olarak √ßalƒ±≈üƒ±r, alttaki yapƒ±nƒ±n VM veya fiziksel bir makina olmasƒ±nƒ±n √∂nemi yoktur. Konteynerlar i√ßin end√ºstri standardƒ± Docker olarak s√∂ylenebilir. √áoƒüu b√ºy√ºk platform Docker engine desteƒüine sahiptir ve Docker imajlarƒ±nƒ± bu engine √ºzerinde √ßalƒ±≈ütƒ±rmaktadƒ±r. Bu imajlara Dockerfile ismi verilir ve Dockerfile i√ßerisinde konfig√ºrasyon tanƒ±mlarƒ±, uygulamalar, servisler vb gerekli t√ºm ≈üeyler bulunur.
Diyelim ki uygulamamƒ±z b√ºy√ºyor ve tek bir blok olarak giderek daha fazla fonksiyon eklemeye devam ettik. Uygulama √ßok fazla CPU ve RAM t√ºketen ve y√∂netimi neredeyse imkansƒ±z bir hale gelmeye ba≈üladƒ±. Bu durumda ne yapmak gerekir? Uygulamamƒ±zƒ± daha k√º√ß√ºk par√ßalara ayƒ±rmaya karar verir ve her biri belirli bir g√∂rev veya fonksiyon i√ßin sorumlu daha k√º√ß√ºk b√∂l√ºmlere yani mikroservislere(microservices) ayƒ±rmaya karar veririz.ƒ∞≈üte bu durumda bir ihtiya√ß daha ortaya √ßƒ±kƒ±yor o da Konteyner Orkestrasyonu(Container Orchestration), konteynerlarƒ±n otomatik olarak d√ºzenlenmesi, koordinasyonu ve y√∂netimi anlamƒ±na gelir. Bir uygulama i√ßin bir den √ßok container kullanƒ±labilir ve bu container‚Äôlar arasƒ±nda uyumun saƒülanmasƒ± i√ßin container‚Äôlarƒ±n y√∂netilmesi, yayƒ±nlanmasƒ±, konfig√ºrasyonu i≈ülemlerinin ger√ßekle≈ütirilmesi bu ≈üekilde olmaktadƒ±r. √ñrnek tool olarak Kubernetes verilebilir.
Bulut kaynaklarƒ±na eri≈üimde kimlik y√∂netimi ve kullanƒ±lan hesaplarƒ±n korumasƒ± √∂nemli konulardan biridir. √ñrneƒüin y√∂netici hesabƒ± t√ºm kaynaklara, servislere eri≈üim hakkƒ±na ve t√ºm kullanƒ±cƒ±larƒ±n yetkilerini belirleme onlarƒ± blok etme hakkƒ±na sahiptir ve g√ºvenliƒüi bu nedenle olduk√ßa √∂nemlidir. Bu g√ºvenliƒüi saƒülamak i√ßin bazƒ± noktalara dikkat etmek gerekir. Bunlar:
‚Ä¢ ≈ûifre g√ºvenliƒüi≈ûifrelerin tahmin edilememesi i√ßin ≈üifre belirlemede akƒ±lda kalan veya tahmin edilebilen ≈üifreler yerine i√ßinde b√ºy√ºk k√º√ß√ºk harf kombinasyonu ve rakam i√ßeren daha karma≈üƒ±k ≈üifreler kullanƒ±lmalƒ±dƒ±r. Brute Force gibi ≈üifre kƒ±rma ataklarƒ±na kar≈üƒ± g√º√ßl√º ≈üifrelerin belirlenmesi √∂nemli bir g√ºvenlik konusudur.
‚Ä¢ √áok fakt√∂rl√º kimlik doƒürulama (Multi Factor Authentication)Hesabƒ±nƒ±za g√ºvenli bir ≈üekilde eri≈üilmesine yardƒ±mcƒ± olmak i√ßin kullanƒ±lƒ±r ve hesaba giri≈ü i≈ülemini her biri farklƒ± bir fakt√∂r kategorisinden doƒürulayarak kullanƒ±cƒ±yƒ± tanƒ±mlama i≈ülemidir.
‚Ä¢ Ko≈üullu Eri≈üim (Condition Access) ve Sahtekarlƒ±ƒüƒ± Algƒ±lama(Fraud Detection)Ko≈üullu eri≈üim, kullanƒ±cƒ±lara konum, aygƒ±t ve uygulama d√ºzeyinde i√ßeriƒüe dayalƒ± kontroller saƒülayan ilkeler tanƒ±mlaya imkan veren y√∂ntemdir. √ñrneƒüin bir kullanƒ±cƒ±nƒ±n belirlenen IP‚Äôler dƒ±≈üƒ±nda ba≈üka bir IP aralƒ±ƒüƒ±ndan baƒülanmasƒ± engellenebilir. Fraud Detection, sahtekarlƒ±k veya hile ile sisteme girmeye √ßalƒ±≈üanlarƒ±n algƒ±lanmasƒ±dƒ±r. √ñrneƒüin bir kullanƒ±cƒ± kendi hesabƒ±na ilk giri≈üi T√ºrkiye,ƒ∞stanbul‚Äôdan yapmƒ±≈ü ve bu i≈ülemden be≈ü dakika sonra ƒ∞ngiltere‚Äôden giri≈ü yapmaya √ßalƒ±≈ütƒ±ƒüƒ±nƒ± d√º≈ü√ºnelim. Bu i≈ülem ≈ü√ºpheli olarak kabul edilip Fraud Detection kurallarƒ± ile algƒ±lanƒ±p bloklanabilir.
Yukarƒ±da saydƒ±ƒüƒ±m g√ºvenlik √∂nlemlerine yenileri de eklenebilir fakat ne kadar √∂nlem alƒ±nƒ±rsa alƒ±nsƒ±n bu bir sistemin tamamen g√ºvenli olduƒüu anlamƒ±na gelmez. Her zaman birilerinin bir y√∂ntem veya a√ßƒ±k bulup sisteme eri≈üme imkanƒ± olabileceƒüi olasƒ±lƒ±ƒüƒ± g√∂z ardƒ± edilmemelidir.Olasƒ± sƒ±zmalara veya saldƒ±rƒ±lara maruz kalƒ±nan durumlarda sistemin i≈üleyi≈üinin devamƒ±na y√∂nelik de bazƒ± √∂nlemler geli≈ütirilmelidir. √ñrneƒüin bir bulut ortamƒ±nda admin hesabƒ±nƒ±n yaratƒ±lan t√ºm ortam √ºzerinde tam yetkisi vardƒ±r. Uygulamalarƒ±n ve servislerin tek ortamda olduƒüunu ve bunun bir admin ile y√∂netildiƒüini varsayalƒ±m. Admin hesabƒ± ile ilgili bir sorun ya≈üandƒ±ƒüƒ±nda t√ºm ortamƒ±n √ßalƒ±≈üamaz hale gelmesi s√∂zkonusudur. Buna kar≈üƒ± uygulamalarƒ±n ve servislerin farklƒ± ortamlara daƒüƒ±tƒ±lmasƒ±, birbirini yedeklemesi ve bu ortamlarƒ±n farklƒ± admin hesaplarƒ±yla y√∂netilmesi daha g√ºvenli olacaktƒ±r. Bu ≈üekilde bir hesap ile sorun ya≈üandƒ±ƒüƒ±nda sistemin diƒüer ortamlardan ayaƒüa kalkarak devamlƒ±lƒ±ƒüƒ±nƒ±n saƒülanmasƒ± daha saƒülƒ±klƒ± olacaktƒ±r.
Rol tabanlƒ± eri≈üim kontrol√º (Role Based Access Control ‚Äî RBAC), kullanƒ±cƒ±larƒ±n rollerine dayalƒ± olarak bilgisayar veya aƒü kaynaklarƒ±na eri≈üimi d√ºzenleyen bir y√∂ntemdir. √ñrneƒüin bulut sisteminde bir y√∂netici hesabƒ± ve veritabanƒ± i≈ülemleri yapan ba≈üka hesaplar olsun. T√ºm bu hesaplara aynƒ± haklarƒ± verip t√ºm kaynaklara eri≈üimi a√ßmak g√ºvenlik riskleri olu≈ümasƒ±na yol a√ßar. Bunun yerine kullanƒ±cƒ±lara ve y√∂neticilere gerektiƒüi kadar ve gereken √∂l√ß√ºde hak verilmeli ve bu haklarƒ±n sistemde nasƒ±l bir risk olu≈üturabileceƒüi √∂nceden analiz edilmelidir.
Diƒüer adƒ±yla Servis Olarak Fonksiyonlar (Functions as a Service ‚Äî FaaS). √ñncelikle belirtmek gerekiyor ki bu serverless isimlendirmesi kullanƒ±lmasƒ±na bakƒ±lmamasƒ± gerekiyor, √ß√ºnk√º bu konu tamamen serverlar √ºzerinde ge√ßiyor ve onlara baƒüƒ±mlƒ±. Bu nedenle ba≈ülƒ±ƒüƒ±n verdiƒüi √∂nyargƒ±yƒ± yazƒ±nƒ±n ba≈üƒ±nda kƒ±rmak √∂nemli. Serverless programming bulut servis saƒülayƒ±cƒ±sƒ±nƒ±n sunduƒüu fonksiyonlar ile ger√ßekle≈ütiriliyor.
√ñnemli √º√ß nokta var: ‚Ä¢ Sunucularƒ±n geli≈ütiriciden tamamen soyutlanmasƒ±, yani geli≈ütiriciler sunucu ile ilgili herhangi bir bilgiye sahip olmak zorunda deƒüil. Kullanƒ±lan altyapƒ± i√ßin bir √ºcretlendirme yok.‚Ä¢ T√ºketim ve √ßalƒ±≈ütƒ±rma temelli faturalandƒ±rma, sunucunun alanƒ±,performansƒ± fiyatta belirleyici deƒüil. Fiyat ne kadar √ßalƒ±≈ütƒ±rƒ±ldƒ±ƒüƒ± ile ilgili √ºcretlendirme var.‚Ä¢ Olay g√ºd√ºml√º ve anƒ±nda √∂l√ßeklenebilir olan servisler. Bulut platformunun sunduƒüu fonksiyonlar, API ve hizmetler kullanƒ±lƒ±yor. Kodlama olay g√ºd√ºml√º ve stateless yazƒ±lƒ±yor. Yazƒ±lan kodun verimi √ºcretlendirmeyi de doƒüal olarak etkiliyor.
Olay g√ºd√ºml√º sistemler i√ßin yeni bir mimari kalƒ±ptan bahsediyoruz. Bu nedenle, sunucu i√ßermeyen i≈ülevler genellikle diƒüer hizmetler arasƒ±nda baƒülayƒ±cƒ± olarak veya olay odaklƒ± bir mimaride kullanƒ±lƒ±r. Kƒ±sa √∂m√ºrl√ºd√ºr, durum bilgisi tutmaz, mevcut hizmetlerinizden veya √º√ß√ºnc√º parti kaynaklardan faydalanƒ±r, bir ka√ß saniye i√ßinde i≈üini yapar.Sunucusuz bilgi i≈ülem, kod √ßalƒ±≈ütƒ±rma i≈üleminin, geleneksel uygulama geli≈ütirme ve sunuculara daƒüƒ±tma y√∂ntemi yerine tamamen bir bulut saƒülayƒ±cƒ±sƒ± tarafƒ±ndan y√∂netildiƒüi bir mimaridir. Geli≈ütiricilerin, kod daƒüƒ±tƒ±rken sunucularƒ± y√∂netmek, hazƒ±rlamak ve korumak i√ßin endi≈üe duymamalarƒ± anlamƒ±na gelir.Daha √∂ncesinde bir geli≈ütirici, ne kadar depolama ve veritabanƒ± kapasitesi gerekiyor bunu tanƒ±mlamak zorundaydƒ± ve toplam s√ºre√ß bu nedenle yava≈ülamaktaydƒ± fakat bu y√∂ntemle bu tip endi≈üelere gerek duyulmamaktadƒ±r.
Sunucusuz uygulamalar olu≈üturmak, uygulama geli≈ütiricilerinin bulut veya lokaldeki sistemin y√∂netilmesi ve √ßalƒ±≈ütƒ±rƒ±lmasƒ± ile ilgilenmek yerine uygulama geli≈ütirmeye odaklanabileceƒüi anlamƒ±na gelir. Bu azaltƒ±lmƒ±≈ü y√ºk, geli≈ütiricilerin √∂l√ßekli ve g√ºvenilir √ºr√ºnler geli≈ütirmek i√ßin daha fazla zaman ve enerjiyi √ºr√ºne ayƒ±rmalarƒ±nƒ± saƒülar.Bu hizmeti veren hizmet saƒülayƒ±cƒ±larƒ±n √∂rnek √ºr√ºnleri, AWS Lambda, Azure WebJobs, IBM OpenWhisk, Google Cloud Functions olarak sƒ±ralanabilir.
Engin √úNAL
Software Engineer
27 
27¬†claps
27 
Software Engineer
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@jrodthoughts/the-blockchain-as-a-service-is-coming-to-a-cloud-near-you-1d5ccb214b91?source=search_post---------212,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jesus Rodriguez
Feb 24, 2016¬∑3 min read
The bitcoin blockchain is becoming one of the most exciting enterprise software technologies of this decade and now is becoming available as part of popular platform as a service(PaaS) technologies. In recent weeks, both IBM and Microsoft have announced the availability of private blockchain as a service (BaaS) technologies as part of the Azure and Bluemix cloud respectively.
The blockchain is popularly known as the technology that powers the infrastructure of the bitcoin cryptocurrency. From a functional standpoint, the blockchain provides a decentralized, time stamped, ordered record of all transactions in a Bitcoin network that can be verified at any time. These simple capabilities represent the first practical answer to profound computer science problems based on the trust of nodes in a decentralized network.
Despite the popularly if bitcoin, most experts are convinced that the opportunities around the blockchain are exponentially larger that the market developed by popular crypto-currency. Industries like legal, asset management, decentralized B2B, trade settlement and many others are starting to be disrupted by the blockchain. To become mainstream, the blockchain requires general programming models and distribution mechanisms included in popular software development platforms. Enter the world of the blockchain as a service (BaaS).
The emergence of blockchain based programming platforms such as Ethereum or Eris Industries allows the creation of software solutions powered by the blockchain. However, the provisioning, scalability and maintenance of private blockchain environments is far from being an easy endeavor. This problem gets even worse if we consider that high scale applications are likely to leverage multiple blockchains for different tenants, geographies etc. From some perspective, the magic of the blockchain relies on the model for storing and querying data and not on the infrastructure behind it.
To address those challenges, companies like Microsoft and IBM have started including blockchain capabilities as part of their PaaS offerings. This model allows developers to provisioning, scale and operate blockchain environments without being concerned about the underlying infrastructure. Additionally, devops will leverage a consistent and familiar PaaS management experience to operate blockchain solutions.
A few days ago, IBM announced the availability of its blockchain as a service (BaaS) solution as part of which includes devops services as part of IBM Bluemix. IBM also announced the open source availability of the Hyperledger project which attempts to make the blockchain completely open source and availability to enterprise developers.
Microsoft has also actively working in a BaaS initiative as part of the Azure PaaS. Recently, Microsoft announced a partnership with Consensys to enable Ethereum as part of Azure environments. Since then, Microsoft has been very active adding some of the top blockchain solution providers in the market to its BaaS partner network.
The BaaS model represents a very important step towards the mainstream adoption of blockchain technologies. Even though IBM and Microsoft will be the first to admit that BaaS is still highly experimental, we can already see some of the tangible benefits of this model such as the following:
IBM and Microsoft are leading the charge in the adoption of BaaS architectures. Based on the popularity of blockchain technologies, we should expect popular PaaS providers like AWS, Google and Salesforce to quickly join the movement. Making BaaS a first class citizen of mainstream PaaS technologies will only help to increase the adoption of the blockchain as one of the building blocks of enterprise applications.
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
13 
13¬†
13 
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
"
https://medium.com/@jrodthoughts/some-thoughts-about-private-blockchains-747ebfa7fef0?source=search_post---------213,"Sign in
There are currently no responses for this story.
Be the first to respond.
Jesus Rodriguez
Jul 11, 2016¬∑3 min read
In recent months, private blockchains have emerged as one of the most popular trends within the blockchain ecosystem. The challenges in the existing bitoin‚Äôs blockchain infrastructure as well as the rapid raise of movements like the blockchain as a service (BaaS) have contributed to the relevance of the private blockchain movement. Additionally, new software and services companies that are focusing exclusively in the implementation of private blockchain solutions.
While there are many arguments in favor of private blockchain models, there are no lack of detractors. The public vs. private blockchain debate is certainly one of the most interesting developments in the current blockchain community. From that perspective, the adoption of blockchain technologies can be categorized in three main groups:
¬∑ Public Blockchains: A public blockchain is open for read access to any application. In general, public blockchains are considered to be fully decentralized. The most notorious example of this model is the blockchain that powers the bitcoin crypto-currency.
¬∑ Private Blockchains: A private blockchain restricts the write permissions to a single organization and read permissions to an authorized group of third parties.
¬∑ Consortium Blockchains: A consortium blockchain is a blockchain infrastructure controlled by a set of nodes or organizations. This model is becoming a favorite in highly regulated industries such as finance or healthcare.
In some scenarios, consortium blockchains can be seen as a specific type of private blockchains. Undoubtedly, both models are attempts to address the limitations of the public blockchain. While these blockchain models have many apparent benefits, they also introduce plenty of challenges. Many detractors of the private blockchain model often compare it with the private network models that predated the emergence of the internet. In any case, there are plenty of arguments in favor or against the private blockchain movement. Instead of fueling this debate, I thought it would be interesting to summarize some observations about private blockchains that are relevant in the current state of the market.
The private blockchain ecosystem is currently experience an explosion in the number of tools, frameworks and complete platforms that enable the implementation of blockchain-powered applications. From that perspective, the experience for developers building applications for private blockchains is very sophisticated compared to the public blockchain model.
Most of the successful consumer and B2C solutions powered by the blockchain are currently relying in public models. Some examples might include decentralized eCommerce platform OpenBazaar or blockchain-base remittance app Abra. This type of solutions has helped to test public blockchains in highly scalable industry scenarios.
The BaaS model has been a tremendous validation of the private blockchain ecosystem. With companies like Microsoft, IBM and Amazon launching BaaS initiatives, millions of developers can now leverage private blockchain infrastructures in their favorite cloud platform. More importantly, BaaS provides the private blockchain with a most needed scalable and global infrastructure.
There are more private blockchains that we can keep track of. That level of fragmentation is hurting the portability and interoperability of blockchain solutions. Not to mention that selecting a private blockchain platform is becoming a nightmare for most organizations.
Private and consortium blockchain are a more popular option to build industry specific solutions. From that perspective, private blockchains are easier to extend and customize to support standards or specific components required in industry solutions.
Despite its recent popularity, private blockchains haven‚Äôt been tested in highly scale applications like bitcoin. From that perspective, the private blockchain model still needs a few year of evolution before it can process a volume of transactions compared to the public blockchain. However, is not crazy to think that public blockchains will remain a favorite of consumer or B2C solutions while private blockchains will be mostly adopted in industry specific or private enterprise
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
12 
12¬†
12 
CEO of IntoTheBlock, Chief Scientist at Invector Labs, I write The Sequence Newsletter, Guest lecturer at Columbia University, Angel Investor, Author, Speaker.
"
https://medium.com/@stephen_cummins/hi-harry-1739fddff30a?source=search_post---------214,"Sign in
There are currently no responses for this story.
Be the first to respond.
Stephen Cummins
Mar 17, 2017¬∑4 min read
Stephen Cummins
Hi Harry
Thank you very much for the positive feedback and the great question. The goal of the article was to ‚Äúdemystify the AppExchange and it‚Äôs numbers‚Äù. The reason its mysterious is that it‚Äôs almost like a detective story working it out as the sources are varied ‚Äî declared financials, slideshares in the public domain, public quotes by senior Salesforce people, Dreamforce presentations/videos, the live data on the AppExchange itself, historic data (for trends) etc. And at the end of the article I quoted Descartes who said ‚Äú‚ÄùPerfect numbers like perfect men are very rare.‚Äù The goal was to finally give people a feeling for the scale of things and the trends. For example almost everyone thought that the number of apps being added to the marketplace was accelerating. In fact the rate of addition was steady for a few years, but the average revenue from apps was accelerating considerably. The vast majority of the data was published or calculated and extrapolated from published data. Where an assumption is made, I point that out. The article was written 14 months ago. Almost all of the stats were derived from publicly available financial data (Salesforce being a publicly traded company on the NYSE). Some of the data comes from public statements by Salesforce personnel. That has since been redesigned, but for example you can see as I type that there have been 4,420,699 installs from the debut of the AppExchange until the moment I write this .A lot of the other stats are calculations based on financial data. For example salesforce breaks out where it gets its revenue from, we know how many installs there are and we know what percentage of the apps are free etc etc. Sometimes we can‚Äôt get things exact, but you can make smart estimates that will certainly be close to the right figure. The idea of the article is to give people an idea of the scale, trajectory and evolution of the AppExchange. Not to be precise ‚Äî although much of the data happens to be precise. For some reason nobody had ever done this before and I felt people needed to get an idea of the scale of things. A lot of the data was from a live dashboard-like piece on the homepage of the AppExchange. Here‚Äôs an example of something that is easy to extrapolate: ‚ÄúThe rate of app downloads is not accelerating. However the average value of those downloads is accelerating fast. By the end of September 2013 app downloads had hit 2 million. It took another 19 months until the close of April 2015 to hit 3 million downloads. And it has taken nearly 9 months to hit 3.5 million. Hence the numbers are stable, and from that we can extrapolate that current downloads are 666,000/annum.‚Äù The one big assumption I made was to guess what percentage of downloads were free apps (but I‚Äôm transparent about that in the article). ‚Äú$1.5B annual revenues / (660K downloads x 56% paid apps) =approx $4,000. However if we make a reasonable assumption that that freebies are downloaded 4X as much as paid apps, that would push the download ratio from 50 : 50 to 80 : 20 and that leaves the average AppExchange transaction value at $10,ooo. This assumption is difficult to get correct (even approximately) and is by far the biggest leap in this article, but it‚Äôs not unreasonable. Just consider how often the Salesforce 1 mobile app, all the various packaged dashboards and other cool stuff from Salesforce labs are downloaded. All free.‚Äù My career in Salesforce spanned over a decade and I run and scale the 2 fastest growing LinkedIn SaaS groups in the world (Salesforce.com and Salesforce Evolution) and if I don‚Äôt attend the presentations for investors when in Dreamforce, I watch the videos or look at Slideshares from Dreamforce (another source of data)‚Äî so I obviously have a good feel for the numbers. When projecting into the future I drew upon public statements by senior Salesforce staff e.g. ‚ÄúNeeracha Taychakhoonavudh (Salesforce‚Äôs SVP of Partner Programs) says Salesforce will boost AppExchange revenues 5X over the next 5 years. Let‚Äôs assume they‚Äôll take the same average cut. The data tells us that app download rates are neither increasing nor decreasing (yes it does!), but we know revenues are accelerating at a clip. If Taychakhoonavudh‚Äôs estimate is correct and all other trends and assumptions hold, then the data tells us that the value of the average transaction to a vendor will be $8,500 x 5 = $42,500.‚Äù And of course I quoted from IDC‚Äôs detailed projections on the Salesforce economy.
Regarding the assumption in one of the calculations, there‚Äôs good reason to believe I might be in the ballpark. I make predictions all the time about SaaS, and about Salesforce in particular. So far every prediction has been accurate. That won‚Äôt last forever (I‚Äôll inevitably get stuff wrong), but there‚Äôs reason to believe that the strike-rate will probably remain high. You can see a lot of the predictions in these articles:
https://www.linkedin.com/in/stephencumminsappselekt/recent-activity/posts/
I really hope this helps to further clarify things.
All the Best, Stephen Cummins
CEO & Founder @AppSelekt. Host @14MinutesOfSaaS podcast. @SaaSMonster MC & Keynote speaker @CollisionHQ & @WebSummit. Run 2 biggest @salesforce Linkedin groups.
111 
111¬†
111 
CEO & Founder @AppSelekt. Host @14MinutesOfSaaS podcast. @SaaSMonster MC & Keynote speaker @CollisionHQ & @WebSummit. Run 2 biggest @salesforce Linkedin groups.
"
https://medium.com/@jameshamann/cloud-computing-service-types-3da6998a7a11?source=search_post---------215,"Sign in
There are currently no responses for this story.
Be the first to respond.
James Hamann
Nov 24, 2017¬∑3 min read
These days most people refer to things being in The Cloud but what does this actually mean? A general, high-level definition is the delivery of hosted services over the internet. Email, calendars, todo lists, photos, pretty much everything fits into that description. Think Google Drive backing your photos up or iCloud backing your iPhone up, both of these keep your data in stored in the cloud. This makes it easy to access your stuff across all of your devices. There are, though, a few different levels to cloud computing.
This is the outermost layer of the types, typically targeted at the end customer. The provider makes their application available through a web-browser, mobile app or dedicated desktop app, which is powered by cloud infrastructure. Lets use Google Sheets as an example here. The benefits provided to the consumer include the ability to create, edit and update spreadsheets from anywhere, with multiple users able to edit at one time.
This is the middle layer of our pyramid, typically used by developers. Here a developer can deploy their app, written in whatever language they‚Äôve chosen, to a pre-configured cloud infrastructure. The developer doesn‚Äôt deal with the configuration of the servers, databases or operating systems. Instead they are able to deploy their app with ease and speed. Let‚Äôs use Heroku as an example here. The benefits provided to the developer is quick, easy deployment with minimal hassle. You can push a rails app live within minutes, it allows for rapid prototyping and gives developers the ability to deploy an app without needing to worry about things like server configuration.
This is the final layer, where all the nuts and bolts lie. This level is typically used by sysadmins who would be charge of provisioning servers and deploying application builds. From here you‚Äôre able to completely configure everything, from operating systems and network settings. Lets use AWS‚Äôs EC2 instances as an example here. From the EC2 console when deploying a new instance you‚Äôre able to choose from a wide range of AMI images. When your instance is setup, you can SSH in and configure it in anyway you see fit. This gives the user huge levels of customisation and flexibility, which is important if you‚Äôre running apps that require very specific needs.
The diagram below provides a visual representation of each level.
Beyond this there are further abstractions like DaaS (Data/Desktop as a Service), STaaS (Storage as a Service) and SECaaS (Security as a Service). These are quite specific, focused in particular sectors and not as commonly known as the main three mentioned above.
As always, thanks for reading, hit üëè if you like what you read and be sure to follow to keep up to date with future posts.
Software Developer https://jameshamann.com
11 
11¬†
11 
Software Developer https://jameshamann.com
"
https://medium.com/@MorpheusData/how-did-mongodb-get-its-name-7acc0f16d389?source=search_post---------216,"Sign in
There are currently no responses for this story.
Be the first to respond.
Morpheus Data
Apr 15, 2016¬∑3 min read
Example of a MongoDB query. Source: MongoDB.
MongoDB was originally developed by MongoDB, Inc., which at the time (2007) was named 10gen. The company was founded by former DoubleClick founders and engineers, specifically Dwight Merriman, Kevin P. Ryan, and Eliot Horowitz.
At first, 10gen wanted to build an open-source platform as a service. The company wanted all of the components of its software to be completely open-source, but could not find a database that met their needs and provided the type of scalability needed for the applications they were building.
The platform 10gen was working on was named Babble and was going to be similar to the Google App Engine. As it turned out, there wasn‚Äôt a big market for Babble, but both users and non-users of Babble agreed that the database 10gen had created to accompany the platform was excellent and would be happy to use it on its own.
While originally simply dubbed ‚Äúp‚Äù, the database was officially named MongoDB, with ‚ÄúMongo‚Äù being short for the word humongous. Given the input 10gen had received about MongoDB, the company decided it would indeed be best to scrap the Babble project and release MongoDB on its own as an open-source database platform in 2009.
By 2012, 10gen had been named number nine on ‚ÄúThe Next Big Thing 2012‚Äù published by the Wall Street Journal and had 6 offices located in various parts of the world. In 2013, 10gen renamed itself to MongoDB, Inc., wanting to make the strong association with its popular primary product.
As time went on, MongoDB moved up the ranks to become the most popular type of database for document stores, and the fourth most popular database system overall. It is used by other highly successful companies like eBay, Abobe, LinkedIn, Foursquare, McAfee, Shutterfly, and others.
It is also used by software developers as part of the MEAN stack, which includes MongoDB (database), Express (web app framework), AngularJS (MVC JavaScript front-end framework) and NodeJS (platform for server-side apps). Part of the popularity of this stack is that JavaScript and/or JSON/BSON notation can be used across all members of the stack, allowing developers to easily move through and develop within each piece of the stack.
The MEAN stack. Source: modernweb.
All in all, MongoDB can be an excellent choice for a database for your applications, especially if you deal with large amounts of data that will continually expand over time! What‚Äôs more, a new-age platform as a service (PaaS) solution can not only help you get more than you ever thought possible from your MongoDB, but help you save time, money and IT/DevOps sanity.
Easy, infrastructure-agnostic cloud application management. 1 Click provisioning. Automatic monitoring, logging, alerting. Pure awesome.
3 
3¬†
3 
Easy, infrastructure-agnostic cloud application management. 1 Click provisioning. Automatic monitoring, logging, alerting. Pure awesome.
"
https://medium.com/hackernoon/developerweek-2018-biggest-names-in-development-industry-part-1-fea8cb0785d8?source=search_post---------217,"There are currently no responses for this story.
Be the first to respond.
We always keep an eye on big industry events and of course we could not ignore the DeveloperWeek 2018 that recently took place in Oakland, California. DeveloperWeek is the largest world expo in the industry of development and it focuses on the cutting-edge technologies and innovations. The list of past event hosts and supporters includes such names as Google, Facebook, IBM, Yelp and other industry giants. So it‚Äôs obviously interesting to have a look at the names that were listed among 2018 award winners and see what makes these companies so outstanding.
Make money your friend again
For the users, AirTM is a cloud USD account that enables them to deposit or withdraw local currency to and from their account. It also allows easily sending or receiving dollar payments and overall is a fast and easy way to make and receive dollar payments.
What‚Äôs left behind the scenes is the fact that AirTM basically runs on bitcoin and that‚Äôs what makes it so cool. The trustworthy cashiers who process the users‚Äô deposits and transactions are all bitcoiners and they convert bitcoin to USD in their Uphold account. As a result, AirTM greatly increased the demand for bitcoin in all markets where AirTM operates and the number keeps growing. Besides, AirTM positively affects bitcoin adaptation and that‚Äôs the reason the team won its award.
JavaScript Charts designed to be embedded and integrated
AnyChart is a graphics software development company that provides wide array of products that are used by the world leading companies such as Oracle or 3M. The company offers data visualization solutions like charts, graphs and many more.
AnyChart is a light weight JavaScript library that‚Äôs been out there since 2003. Company‚Äôs main products are AnyChart, AnyStock (real-time data-streaming charts), AnyMap and AnyGantt (for Gantt charts). And considering the impressive number of AnyChart clients and their flexible and efficient products, no wonder the company received the award for best innovation in JS technology.
Your personal leadership coach
Butterfly is an employee pulse survey and management coaching software designed to transform managers at all levels into exceptional leaders. Butterfly helps modern organizations gather regular employee feedback that drives actionable insights and builds stronger leaders and more transparent cultures.
A pioneer in AI-powered management coaching, Butterfly‚Äôs self-learning technology uses real-time team feedback to deliver customized leadership training and content to managers on an ongoing basis.Companies like GE, Citibank, Jet.com, Ticketmaster and Ogilvy rely on Butterfly to grow leaders and build stronger, happier teams.
Butterfly recently closed its seed funding round of $2.4 million with backing from Daphi (lead), Precursor, Tectonic Capital and notable angel investors. In 2017, the Webby Awards, the internet‚Äôs highest honor, named Butterfly as one of the top 5 platforms in its category.
Digital Transformation suite
Built.io positions itself as ‚Äúcloud-based API-first enterprise suite‚Äù and it offers digital products and solutions to the most innovative companies, including the ones from Fortune 500. Speaking about Built.io Flow, it is an integration-as-a-service platform for APIs that is aimed at connecting people and businesses.
Built.io Flows allows quick integration of your business apps, automation of recurrent tasks and elimination of manual processes. It increases business efficiency, offers IoT utilization and is recognized as great tool for any business ‚Äî so you may want to pay attention to it as well.
Vulnerability prevention dream team
Checkmarx well played on one of the biggest issues of modern IT world ‚Äî application security testing. There was a gap between the vision of app security specialists and developers (first ones see it as a necessity while second ones consider it a burden) and Checkmarx developed a solution that is both time-saving and delivering value.
The issue with app security lies in the fact that app security should start right from the development stage and many developers simply lack the necessary skills. Codebashing is integrated into the CxSAST UI and when developer encounters any security vulnerability, Codebashing allows immediately activating the necessary learning lesson and getting back to work with new knowledge on how to solve the issue.
In Part 2 and Part 3 I will continue our overview of DeveloperWeek Awards so stay updated and subscribe to our news to keep up with the latest news from the world of developing!
Written by Natalia Kukushkina
#BlackLivesMatter
41 
how hackers start their afternoons. the real shit is on hackernoon.com.¬†Take a look.

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
41¬†claps
41 
Written by
Collection of posts from those who build Dashbouquet https://dashbouquet.com/
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Written by
Collection of posts from those who build Dashbouquet https://dashbouquet.com/
Elijah McClain, George Floyd, Eric Garner, Breonna Taylor, Ahmaud Arbery, Michael Brown, Oscar Grant, Atatiana Jefferson, Tamir Rice, Bettie Jones, Botham Jean
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@juarezjunior/oracle-blockchain-cloud-service-introduction-463e4777ad3c?source=search_post---------218,"Sign in
There are currently no responses for this story.
Be the first to respond.
Juarez Junior
Oct 18, 2018¬∑3 min read
Blockchain is considered as the new backbone of what is defined as the Web 3.0 ‚Äî the new world computer ‚Äî a network that will be able to add more intelligence to our business processes in form of smart business contracts ‚Äî and by means of that it will change computer networks as we know them.
Gartner has reported that Blockchain‚Äôs business value-add will grow to slightly over $360 billion by 2026, then surge to more than $3.1 trillion by 2030. In relation to Europe, IDC has reported that the European Blockchain spending and adoption will grow to $3.5 Billion by 2022.
So given all such forecasts and the associated business opportunities, a number of companies have started to investigate how they can leverage the Blockchain technology in order to modernize, transform or even disrupt their business models.
Beyond the business aspects of Blockchain, the technology itself is somehow complex. There are many open-source options that can support a Blockchain solution, however they are hard to operate so the consideration of a Blockchain as a Service (BaaS) platform is a strategy that makes sense as it can help a business to accelerate its Blockchain strategy and the solutions required by its business vertical and specific market niche.
Companies need not only understand how Blockchain works but also select the right Blockchain technologies, networks and platforms in order to achieve the required results. The underlying IT governance required by a Blockchain solution is comprised by many different software, cloud and DevOps components and not only that, non-functional requirements such as interoperability and integration are real challenges, not to mention that security is critical requirement. So the right platform choice is a mandatory and crucial step in order to have solutions that result in successful implementations of Blockchain technology.
Oracle has a BaaS service as part of its cloud PaaS services ‚Äî the Oracle Blockchain Cloud Service.
The Oracle Blockchain Cloud Service is an enterprise grade, pre-assembled, open and open standards based Blockchain platform. Its underlying framework is based on Hyperledger Fabric, a project that has been developed under the Linux Foundation umbrella.
Oracle is offering a rock solid BaaS platform, where all the underlying platform and IT governance complexities including security, backups, failover, high-availability, decentralization, consolidation of metrics and monitoring among many enterprise features and other non-functional requirements are properly addressed as required. So the Oracle Blockchain Cloud Service is the perfect PaaS service and platform required for your successful Blockchain adoption efforts and strategy aligned with the common requirements of enterprise, B2B Blockchain systems.
I strongly advise you to get more information about the Oracle Blockchain Service by checking the links below. With such resources you will be able to fully understand the Blockchain related benefits and the big picture of it as aligned with the requirements of B2B solutions.
In the next blog posts, you‚Äôll have a series called Blockchain App Development Series, where I‚Äôll explain the technical aspects and advantages of our Oracle Blockchain Cloud Service in detail, how to create your Blockchain network, configure it, deploy and instantiate your smart contracts (also known as chaincodes in Hyperledger‚Äôs terminology).
Transforming the Enterprise with Oracle Blockchain Cloud Service
Oracle Blockchain Cloud Service
11 Things to Know about Oracle Blockchain Cloud Service
Rethink Trust 2018: Joost Volker, Making Enterprise Blockchain a Reality
Oracle Launches Enterprise-Grade Blockchain Cloud Service
Give it a try! Get Started with Oracle Cloud for Free!
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
See all (3,278)
55 
55¬†claps
55 
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@voximplant/augmenting-zoom-functionality-with-voximplant-part-2-webrtc-call-in-15ff39086b91?source=search_post---------219,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alexey Aylarov
Aug 15, 2017¬∑2 min read
In previous post I wrote about adding PSTN call-in and call-out capabilities to Zoom with SIP connector enabled (that seems much cheaper and more efficient than Premium Audio package). In this post I‚Äôm going to write how to enable browser-based call-in functionality without any download/installation required. It can be rather convenient if you are inviting somebody, who doesn‚Äôt want to install Zoom, to your meeting. We will use Voximplant Web SDK for that. The SDK is WebRTC-enabled, it should work well in Chrome and Firefox at the moment (since both support H.264 video codec required for interop with Zoom)
Same as in my previous post
I‚Äôm assuming that you have already read the previous post :) Let‚Äôs get down to VoxEngine scenario development:
This scenario passes our call from Web SDK to Zoom SIP Connector and changes SDP a little to have the right H.264 packetization mode in place. Web SDK is used to build a simple web app that lets specify Zoom conference number and choose the closest region.
In addition to the call itself other Voximplant features can be used, for example, replacing
VoxEngine.easyProcess(e.call, call);
with
VoxEngine.easyProcess(e.call, call, function(call1, call2) {
call1.record({ video: true });
call2.record({ video: true });
});
will enable video streams recording, or adding transcribe param to record function will enable speech-to-text transcription of saved audio data, etc.
Feel free to try the web app by yourself (don‚Äôt forget that Zoom SIP Connector is required to make it work) https://demos02.voximplant.com/zoom/
CEO/Co-founder VoxImplant/Zingaya
4 
1
4¬†
4 
1
CEO/Co-founder VoxImplant/Zingaya
"
https://medium.com/@marutitech/how-salesforce-can-make-your-startup-lean-9fdb58303d7e?source=search_post---------220,"Sign in
There are currently no responses for this story.
Be the first to respond.
Maruti Techlabs
May 20, 2016¬∑3 min read
Small team, tight budget, inefficient task management and lack of human resource management tool. These are the common features of a startup or growing team. The business might be earning a decent amount of revenue but nonetheless losing more than expected due to lack of management and execution planning. As the business expands it needs proper tools to manage the daily workflow otherwise it is bound to crumble soon. The solution comes in the form of automation tools. As these businesses might not have the capabilities to develop in house tools, Salesforce offers an excellent platform to build customized automation tools.
Salesforce is ranked No. 1 in the Forbes list ‚ÄòThe World‚Äôs Most Innovative Companies‚Äô. The core components of Salesforce are cloud computing, workflows, communities, collaboration, and analytics. These can be applied to many areas of the enterprise. Also businesses are building custom apps beyond pure CRM to suit their needs. Salesforce.com‚Äôs multi-tenant architecture allows for optimization of computing resources resulting in savings and significant gains in efficiency for global enterprises even over applications deployed on private clouds.
Salesforce has proved its ability to achieve global deployment. It has also expanded its global support network. It employs faster, multi-channel and predictive support to resolve issues and provide a satisfying experience to customer. Moreover Salesforce.com publishes real-time statistics on system performance and security.
Salesforce gives the flexibility to design applications that respond with greater customer insight and intelligence across different devices. Partnering with analytics driven enterprises such as Anaplan and Host Analytics, Salesforce is trying to enable every business user to take a more dynamic, data-driven approach to business planning and performance management.
As all opportunities are updated in Salesforce CRM, businesses analyse from where sales are coming in and subsequently forecast for next periods. It also helps in targeting of prospective customers. They no longer have to update Excel spreadsheets and mail their forecasts to their managers. Their managers will be happy as well ‚Äî they can edit the forecasts without needing additional spreadsheets. Trend analysis can also be performed to accurately define a strategy to achieve business goals.
Salesforce can cater to every segment of business because of it‚Äôs flexibility and customization potential. User can create new objects, extend existing ones and define relationship between those objects. Salesforce integrates well with different business models because of its ability to provide report and analytics that are tailored to the specific needs of its users. Salesforce being a cloud based system allows accessibility to employee from anywhere, thus providing operational flexibility.
Salesforce offers a wide array of textual and visual resources to suit the user preference. Salesforce posts educational and informative blogs and article; it routinely does educational webinars; its own YouTube channel complete with videos covers a full spectrum of topics, and it also publishes a thoroughly comprehensive web-accessible user guide. Moreover Salesforce employs an excellent, knowledgeable, and customer-oriented service team to solve any doubts.
The AppExchange is a marketplace of easy to access, download, and install apps made by other users. This concept shows the rapid innovation and competitive positioning of Salesforce. The Apps provides users with more resources, options and expandable functionality. Additionally the AppExchange is a place of new ideas and capabilities that are being developed and fine tuned at a swift pace, giving businesses powerful tools to reach new heights. This helps businesses to have awareness about the customer preference and build deeper relationships.
Salesforce being essentially Platform as a Service(PaaS) model provides the flexibility to customize its modules to suit the business needs. There are many process management and automation tools available in Salesforce.
The frequently used modules are explained in this section.
If you resonated with this article, please subscribe to our newsletter. You will get a free copy of our Case Study on SMS-Bot Powered by Artificial Intelligence.
The article was originally published at the Maruti Techlabs.
We are a digital product development company and your guide on the digital transformation journey.
See all (335)
3 
3¬†claps
3 
We are a digital product development company and your guide on the digital transformation journey.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@aheadcrm/iot-becomes-outcome-orientated-with-sap-leonardo-finally-a49e1f874704?source=search_post---------221,"Sign in
There are currently no responses for this story.
Be the first to respond.
Thomas Wieberneit
Jan 12, 2017¬∑3 min read
On January 10, 2017, SAP announced a bundling of their IoT portfolio of initiatives to focus on business outcomes instead of technology while combining the set of emerging products and solutions under the brand name Leonardo ‚Äî as in Leonardo Da Vinci, one of the most forward looking artists and innovators ever. This announcement substantiates SAPs commitment to invest two billion Euro in IoT over the next 5 years.
The new portfolio will combine adaptive applications, big data and connectivity as packaged line-of-business solutions, covering a range of topics. It bases upon a rebranded ‚Äî and repackaged(?) HANA Cloud Platform, enhanced by the micro services for machine learning that were announced earlier and which I covered here. This enhanced platform is now called SAP Cloud Platform.
As per a blog post accompanying the Leonardo announcement, the high level architecture of SAPs new offering looks like below and covers, besides a set of existing applications
Leonardo High Level Architecture ‚Äî Source: SAP
Leonardo is accompanied by a jump-start enablement program to accompany this initiative. This program includes introductory pricing and is intended to help organizations identify and validate IoT pilots and use cases, including expert staffing and using design thinking methodologies, thus easing the first IoT steps. Of course there will be a launch event to bring together customers, partners, and experts, showcasing innovations and strategies.
According to Tanja Rueckert, EVP Digital Assets and IoT SAP with Leonardo connects ‚Äúthings with business processes [‚Ä¶] and with people‚Äù.
This was long overdue.
Overdue not only from SAP, but from any and every vendor. IoT is a means, not an end!
As Brent Leary very recently said in a podcast with SearchCRM, IoT is still trying to make its way to provide value for businesses. This is imho due to the IoT market being vendor- and technology driven. SAP now takes the lead in tightly integrating technology into business process, and to show a clear path to business value. This fits neatly into the core of SAPs overall value proposition as an enterprise software company and it nicely combines numerous technologies and services that have been developed by SAP in the past years into a holistic piece that can deliver business value. I see this mainly as a rebranding instead of something net new, although there are some new pieces to this solution portfolio. This is also a bit of a concern. SAP now needs to keep up the momentum and deliver new intelligent, IoT based business solutions.
What is interesting is the (important) combination of IoT and machine learning, which is mentioned only in the blog post, and which has the potential to make a real difference, e.g., when it comes to distributed intelligence.
As a final word of caution, SAP only announced introductory promotional pricing. This means that there are still important open questions about pricing overall, which should be a worry for customers.
However, overall this is good news for customers, as with this portfolio of services and technology every IoT investment can be tied to a business case and then business value. I expect that other big vendors
SAP clearly takes a thought leadership position here, if not a technology leadership position.
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
See all (1,289)
9 
9¬†claps
9 
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@juarezjunior/oracle-iot-cloud-service-application-development-basics-9cbe11ce951c?source=search_post---------222,"Sign in
There are currently no responses for this story.
Be the first to respond.
Juarez Junior
Aug 2, 2018¬∑9 min read
Recent reports by Forrester and IDC about the IoT (Internet of Things) market and adoption concluded that first, IoT now reached a point where it is moving from experimentation to business scale and second, worldwide technology spending on the Internet of Things will reach $1.2 Trillion in 2022.
The Oracle IoT Cloud Service is a managed Platform as a Service (PaaS) cloud-based offering that helps you to connect your IoT devices to the cloud, analyze data from those devices in real time and integrate your data with enterprise applications, mobile applications, micro services, web services or with other Oracle Cloud Services.
This tutorial shows the quick steps required to configure an IoT application on Oracle Internet of Things (IoT) Cloud Service, register a cloud-side device as well as activate the device.
It also explains how to code a simple client-side device application as well as how to use the device provisioning file that you can download from the cloud service to connect to your IoT application.
1) Access the Oracle IoT Cloud Service
Before you begin, we assume that you have:
¬∑ Access to an instance of Oracle IoT Cloud Service. In case you need to provision your IoT CS instance first, you can check the related blog post: Oracle IoT CS ‚Äî How to Create the IoT Enterprise Service Instance.
¬∑ A computer with a Java development environment (required to run the sample code) or any other programming language development environment of your choice (C, C++, Javascript, Python, others) and a web browser;
¬∑ Familiarity with basic Oracle IoT Cloud Service management console operations.
In a web browser, enter the URL for your Oracle IoT Cloud Service instance. Normally the URL has the following form: https://myinstance-myidentitydomain.iot.us.oraclecloud.com
Enter your user ID and password, click Sign-In and after the successful logon process the main screen is shown as below:
2) Create the IoT application (OracleIoTApp)
Follow the steps below to create your IoT application and provide the required information as described below.
From the main screen, select the hamburger user interface component at the top right corner of your screen (the one inside the red square below). You will see the right side actions bar with Home as the default, selected menu option.
Select Applications -> Browse Applications and click the Create Application button. You will see a popup window.
Enter the required information and click the Create button.
¬∑ Name: OracleIoTApp
¬∑ Description: Sample IoT App
You will see that your application is now created.
3) Create the Device Model
The next step is to create the Device Model. Select Applications -> OracleIoTApp -> Device Model and click the button with the plus (+) sign so that you can add a new device model.
Enter the following values in the Details section:
¬∑ Name: OracleIoTDeviceModel
¬∑ Description: Sample Device Model for Oracle IoT App
¬∑ URN: urn:test:oracleiotappsample (the URN will be used in the client Java code shortly)
In the Custom Attributes section, click the Add (+) button.
Enter the following values:
¬∑ Name: messagefromiotdevice
¬∑ Description: This attributes stores the string message from the Java device
¬∑ Type: String
¬∑ Writable: Checked (checkbox)
Click OK and then click Save. The attribute is saved and the Device Model page will show the device.
4) Register a device
The next step is to register a device. Select the hamburger user interface component at the top right corner of your screen again.
Then select Devices -> Registration -> Single Registration -> Register Single.
On the Register Single Device page, enter the following values and click Register:
¬∑ Activation ID: ORACLEIOTCSDEVICE
¬∑ Activation Secret: SampleSecret
¬∑ Name: OracleIoTDevice
¬∑ Manufacturer: Sample Oracle Device Manufacturer
¬∑ Serial Number: 123456789
¬∑ Model Number: Oracle-2018
On the confirmation page, enter a password for the provisioning file in the File Protection Password input field and confirm your password in the Confirm Password input field.
After that click Download Provisioning File button and save the file as you will need to use it in the Java client code.
Take note of the Activation ID which is the same as the Provisioning File Name and the File Protection Password because you‚Äôll need these values to activate the device from the Java client code.
4 ) Implement the Java Client Device by using the IoT Cloud Service Java API
Now you can implement the Java Client Device and leverage the IoT Cloud Service Java API to simulate and integrate an IoT device, then send a message from it to our cloud-side IoT Cloud Service application and device configurations.
The Java code sample below has only the bare bones of an implementation that will allow you to perform a couple of crucial steps:
a. Activate the Device ‚Äî the device is activated by the client-side, there‚Äôs no option available in the cloud console for that;
b. Test your configurations as well as make sure that your communication channel is working properly, that is, validate the network path as well as validate both the IoT device configuration on both the client and cloud sides along the bi-directional communication.
We‚Äôll send a message from the IoT device (client-side) to our IoT Cloud service, and the retrieve the same message from the cloud-side so that the entire network round trip and communication can be validated.
In order to implement the device client simulation you need to leverage one of our existing IoT client libraries and APIs. There are many available such as Java, C, C++, Javascript, POSIX, Android, iOS and even a REST API.
The example below uses the Java library and you can download the libraries here.
Regarding the Java code, you can check the full Javadocs documentation for the related API on the link below.
Java SE Device Virtualization API Reference for Oracle Internet of Things Cloud Service Client Software Library
You can use any Java IDE to create the Java project and implement the code. As an example you can use and Eclipse Java project. Note it is only a plain old Java project with no tricks or additional details at all. Just remember that as usual you will need to download the JAR files from the link below and include them on your Java classpath (lib directory).
So without further ado, let‚Äôs implement the Java client device. The code is very basic and self-explanatory as it has all the comments that explain the different parts and steps regarding our Java IoT client device implementation.
5 ) Test and validate our IoT scenario - Java IoT device (client-side)
We can now test and validate it all: the device simulation and IoT Cloud Service configurations. It will allow us to test the end to end, bi-directional IoT interaction and communication.
Again remember that our cloud side device configuration is activated by the client side request, not with with the selection and configuration of an option on the cloud side ‚Äî there‚Äôs no option available on the console / GUI for that at all.
So on the Java code, we have this code excerpt below for that:
Note that after the first communication the device will change its status to an Activated one as expected.
Run the Java application on Eclipse. Right click any area in the Eclipse code editor, then select Run As -> Java Application.
Provided that everything is OK regarding your Java project and the network path (firewalls, proxies, others) you will see the output below on the Eclipse‚Äôs console tab:
Let‚Äôs explain the logged messages above.
First, we send the message from the Java IoT device client to our cloud service:
Then provided that our message is sent from the Java IoT client to our Oracle IoT Cloud Service application, we can then retrieve the cloud IoT endpoint ID:
The output is:
Then we do almost the same as before but now for the device model ‚Äî and remember that we created a custom model during the configuration steps:
The output is:
Here then we retrieve the same message (and its contents) we sent so that we can validate the bi-directional communication:
The output is:
6) Test and validate our IoT scenario ‚Äî Oracle IoT Cloud service (cloud-side)
On the Oracle IoT Cloud Service side, we can now check the IoT device messages on the Oracle IoT Cloud Service side.
Select the hamburger user interface component at the top right corner of your screen once again and then select Devices -> Alerts and Messages.
You will see the screen below where you can see the details for the message received.
You can run the Java IoT client program again and see more that more messages will be received and confirmed as below.
One last thing. Note that as usual you can use the Java Debugging perspective, set your breakpoints as well as introspect the Java code on the client side in order to further analyse and understand the communication scenario.
That‚Äôs it! I hope this blog post helped you understand how easy it is to develop IoT applications by leveraging the features of our Oracle IoT Cloud Service, combined with the available IoT application client APIs.
Give it a try! Get Started with Oracle Cloud for Free!
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
6 
6¬†
6 
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
"
https://medium.com/@juarezjunior/oracle-iot-cloud-service-how-to-create-the-iot-enterprise-service-instance-2d9bb7e46d1e?source=search_post---------223,"Sign in
There are currently no responses for this story.
Be the first to respond.
Juarez Junior
Aug 12, 2018¬∑6 min read
This tutorial shows the quick steps required to provision an Oracle IoT Cloud Service instance.
It uses the Cloud Stack approach that‚Äôs a great and easy way to provide all the services and dependencies you may need for your Oracle IoT Cloud Service instance.
The Cloud Stack approach is interesting because it provides several standard out-of-the-box templates that accelerate your task as well as hide you from all the underlying complexities.
Templates transparently isolate you from the dependencies and required version matches that you would need to check and guarantee in order to have the proper services instances along their proper versions provisioned.
In case you want to learn more about the Oracle Cloud Stack approach and the available templates, please check this Oracle by Example quick guide ‚Äî Getting Started with Oracle Cloud Stack.
So without further ado, let‚Äôs create our IoT Cloud Service instance.
From the main screen, select the hamburger user interface component at the top right corner of your screen (the one inside the red square below). You will see the right side actions bar with Dashboard option as the default, selected menu option.
Click on Services and scroll down until you see the IoT Enterprise menu list option and then select it.
You will see the Oracle Internet of Things Cloud ‚Äî Enterprise page with the instances list (it‚Äôs still empty, no IoT service instances yet).
Here as quickly explained before, we have the option to create the IoT instance and provide all its dependencies manually one by one, or use the Oracle Cloud Stack approach, which is the easiest and less error prone way.
So let‚Äôs select the Oracle Cloud Stack option. Click on the tiny hamburguer user interface (UI) component on the top right corner (besides the Welcome! label, you will see the expanded drop down menu as shown below:
Scroll down to its last option, Cloud Stack, and select it. You will be taken to our Oracle Cloud Stack page.
Select the Templates tab, type IoT in the search input field and click the search icon or hit ENTER to find the IoT stack template.
You will see the results as below. Click the Oracle-IoT-Enterprise option from the results list just to see its contents.
Then you can see the compositions of our IoT-Enterprise stack with both the IoT Service topology (and its dependencies) as well as the IoT Enterprise stack template specification in YAML format.
YAML is a human-readable data serialization language. It is commonly used for configuration files.
In case you do not know what YAML is want to learn more you can check its site and documentation here.
You can export / save the specification in case you want, just click export for that. Anyway, that‚Äôs just to provide more clarify regarding the Oracle Cloud services that are part of our IoT Enterprise stack.
Let‚Äôs resume with the IoT instance provisioning process. Click Done and the previous templates list page will be shown again.
Select the (+) icon on the far right at the end of the Oracle-IoT-Enterprise option in order to start the effective instance creation steps based on our selected template.
Now you can click Next.
You will see the confirmation page.
In case you want you can also download the instance information in JSON format. In case you‚Äôve never heard about JSON, it stands for JavaScript Object Notation.
It is a lightweight data-interchange format that‚Äôs easy for humans to read and write as well as also easy for machines to parse and generate. It‚Äôs becoming one of the de-facto standards for modern architectures, solutions and MicroServices. You can check more about JSON here.
Just click the icon with the arrow down as shown above and the JSON file will be downloaded.
Now you can just click the Confirm button and your instance creation process will be started as shown below.
That‚Äôs it! Now you know how easy it is to provision an instance of our IoT Service! I hope you can build great things with the Oracle IoT Cloud Service!
Give it a try! Get Started with Oracle Cloud for Free!
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
See all (3,278)
2 
2¬†claps
2 
Azure Developer Relations Lead @ Microsoft. Invite me to speak about #Blockchain #IoT #AI #Java #Python #EmergingTechnologies #DevRel ü•ë
About
Write
Help
Legal
Get the Medium app
"
https://koukia.ca/remote-profiling-in-azure-web-apps-and-api-apps-a1689c42a8c0?source=search_post---------224,"Today I‚Äôm going to show you how to do Remote Profiling on an Azure Web App or Azure API App or a WebJob.
This scenario happens a lot when you see weird behavior (Slow performance) in your service in a certain environment and you want to know why but it is Production environment or pre production and you don‚Äôt want to attach a debugger to stop other users but you just want to check what is happening there.
There are different ways to do Remote Profiling in Azure Web Apps and for today I‚Äôm just showing the simplest approach‚Ä¶
"
https://medium.com/@waxzce/why-isn-t-there-a-free-tier-in-clever-cloud-65709d45ea56?source=search_post---------225,"Sign in
There are currently no responses for this story.
Be the first to respond.
Quentin ADAM
May 17, 2015¬∑2 min read
Do you know that hosting is one of the nastiest business out there? Hardware, bandwidth suck up huge amounts of money and energy. But some hosting companies want to give it for free, forever. And people keep asking me ‚Äúdo you have a free plan?‚Äù
The problem is quite basic. Hosting the web‚Äôs ‚Äúhello world‚Äù applications for zero money is not a sustainable business model. Most of all, we should really ask ourselves: is it really useful to humanity? The problem with free offerings is that it‚Äôs killing product value: nobody really takes care of a free product.
At Clever Cloud, we have built a great platform. We‚Äôve worked with developers to help them build great applications, be more efficient, and sustain huge traffic surges without stress.
Our job is not to host unfinished side projects.
Hosting the web‚Äôs ‚Äúhello world‚Äù applications for zero money is not a sustainable business model. Most of all, we should really ask ourselves: is it really useful to humanity?
Since free tier costs money, who really pays for it? Loyal and paying customers, of course. And that‚Äôs just not fair. I prefer to say: our price is the right price. We are not making you pay for a poor marketing idea. If you are not ok with our price, don‚Äôt worry.
We can always agree on something: just email us at sales@clever-cloud.com.
But the problem about free tier goes even deeper: this poor marketing strategy is lowering the overall customer perception of PaaS. What doesn‚Äôt have a price doesn‚Äôt have any value, and the idea that PaaS provides no value is a deeply entrenched misconception. This is one of the reasons the PaaS market has taken so long to emerge.
Sure, we help open-source projects, charity, media and other projects by giving them free hosting. If you think your project deserves it, just send me an email: quentin.adam@clever-cloud.com.
Post Scriptum: I‚Äôm really happy to see Heroku changing their point of view on this and slowly nerfing their free trial offer. The industry, and the web in general, can only benefit from it.
Originally published at www.clever-cloud.com on April 14, 2015.
CEO @clever_cloud PaaS cloud computing company. We industrialize IT management to help developer to be happy and efficient and make organizations move fast.
3 
1
3¬†
3 
1
CEO @clever_cloud PaaS cloud computing company. We industrialize IT management to help developer to be happy and efficient and make organizations move fast.
"
https://medium.com/@alibaba-cloud/installing-alfresco-community-edition-on-centos-2162e79d5527?source=search_post---------226,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Sep 3, 2018¬∑7 min read
By Arslan Ud Din Shafiq, Alibaba Cloud Tech Share Author. Tech Share is Alibaba Cloud‚Äôs incentive program to encourage the sharing of technical knowledge and best practices within the cloud community.
Alfresco Community Edition is an open source Enterprise Content Management (ECM) software for managing the contents of an enterprise. Alfresco Community Edition is one of the software products of Alfresco. It is developed for Windows and Unix operating systems. It is written in Java, and PostgreSQL is used for storing its database. Alfresco is used within an enterprise for managing its various systems and digital assets such as videos, documents, images, and records. WebDAV, CIMS, SMB, and FTP can be used for accessing the file repository of hosted Alfresco.
With Alfresco, many enterprise challenges can be addressed, including displaying important information at one place and keeping track of employee performance. For getting the advantages of community-driven development, Alfresco Community Edition could be the best option for your enterprise.
When talking about availability and scalability, Alfresco does have some limitations. For instance, the community edition of Alfresco does not support clustering. The quality assurance and the bug fixes are also limited. However, Alfresco Community Edition provides enterprises of different levels with ease of managing their content and non-critical business process. It is easy to use and the source code of the Community Edition is also publicly available.
As a developer, I prefer the services of Alibaba Cloud to deploy Alfresco. Alibaba Elastic Compute Service (ECS) is highly scalable and flexible. You can upgrade the hardware resources anytime when required. Alibaba Cloud can also provide you technical support and assistance in order to launch any of your system.
Alfresco does not restrict its installation to any specific operating system (OS). You can use any operating system (OS) of your choice; however, the installation steps would vary according to the choice of operating system.
In this tutorial, we will be installing and configuring Alfresco Community Edition on an Alibaba Cloud Elastic Compute Service (ECS) instance with CentOS 7.
The installer package for Alfresco is easily available on their official website. This installer package by Alfresco contains all the programs required to execute Alfresco Community Edition on your Operating System. The LibreOffice plugin require some dependencies that needs to be installed.
Perform the following installations by entering the relevant commands:
Install fontconfig
Install libSM
Install libICE
Install cups-libs
Install libGLU, cairo, mesa-libGL-devel
After completing all the above installations, remove Postfix or MTA from the machine with the command:
Nano editor is used to edit different files. It helps you in editing files easily. We will be using this editor for editing a few files, so downloading it on prior basis makes it easy for us to continue with the configurations and editing processes. Here‚Äôs the command to install the editor.
We are now all set to install Alfresco on our ECS instance.
The next step is to download the latest Alfresco installer via its official page. It is recommended to use the installer that is provided by the official Alfresco website, as it will not get you in trouble due to bugs or other errors during or after installation of Alfresco.
This downloading process may take a while, and after it is saved, it will generate a message of saving the installer package. This installer package requires certain execution permissions. The following command will provide it with the necessary permissions.
We can now install the Alfresco Community Edition easily. Execute the following command to start the installation process.
After running the command, you will be prompted to select an installation language. Select the installation language by entering the respective number for your preferred language. After the language selection, it asks you to select the installation type. For installing the application with default configurations, you should select the ‚ÄúEasy Install‚Äù method.
You will then be prompted to select a folder to install Alfresco community. Select /opt/alfresco-community, which is the default location for installing Alfresco. Continue with the default folder by pressing Enter.
You will need to specify a password for the Alfresco Content Services administrator account. This will be the credential that you will be using for accessing the Alfresco services, after they are installed, by using the administrative ID and password. After setting up a password, select ‚ÄòY‚Äô for installing it as a service.
Right after the Alfresco is installed, it asks ‚ÄòView Readme File?‚Äô. Select ‚ÄòY‚Äô and the server should start immediately with the following output.
You can also launch your application right away, as the installer has already provided the start-up service.
You need to get the Alfresco service enabled for it to start automatically at boot time. You can do this with the following command:
By default, the Tomcat server starts on port 8080. To check the working status of Alfresco server, the port 8080 needs to be allowed through the system firewall. This will be done by the firewall settings mentioned with details at the end of this tutorial.
Go to a browser and log on to http://47.90.214.177:8080/share/ where 47.90.214.177 is my public IP. Remember to replace it with yours. Upon loading this, you will be shown Alfresco‚Äôs landing page.
By default, Tomcat server runs on port 8080. Here we are going to use Nginx as a reverse proxy for the application to be easily accessible through the standard HTTP and HTTPS ports. We will also be configuring Nginx for using an SSL generated with Let‚Äôs Encrypt free SSL.
Now, install Nginx server.
We will be starting the web server along with enabling it to automatically start at the boot time.
Next, you need to configure your reverse proxy. All we need to do is to create a new block file in Alfresco.
Here softpedia.xyz is the public domain name, replace it with yours. The next thing is that we shall be populating this file with the following code.
Save the modified changes and close the file. Now we are done with the necessary changes made for the configuration.
Restart the server to save your configuration and for the changes to take effect.
Now go to http://softpedia.xyz/share/page/ (or your own domain name) and access the various services of Alfresco Community Edition. Use credentials that you provided during the installation process of Alfresco.
Alfresco Community Edition is now accessible through the domain name, easily. You can now use the amazing services provided by this application by giving the authenticated administrative credentials.
If you have activated firewalls, you will have to define a rule in Alibaba Cloud security group for your cloud server to add exception for port 80/TCP and 443/TCP. You can enable these ports while creating ECS instance, but in case if you have forgotten to unblock these ports, you can follow the procedure below.
By default, these ports are blocked by the firewalls. Also, we need to add port 8080 for accessing the Alfresco. To do this, go to your Elastic Compute Service section. Click on More for the ECS you are using for Alfresco and click Security Group Configuration.
Click on Configure Rules and then click on Quickly Create Rules.
Add the configurations as shown in screenshot below and click OK.
Reference:
https://www.alibabacloud.com/blog/installing-alfresco-community-edition-on-centos_593922?spm=a2c41.11954966.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
See all (24)
101 
101¬†claps
101 
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/lightspeedindia/this-fourth-wave-of-indian-enterprise-software-startups-is-world-class-5c16a654acc2?source=search_post---------227,"There are currently no responses for this story.
Be the first to respond.
[Published on Yourstory.com]
India‚Äôs enterprise software industry has been slowly bubbling since the 1980s but has generally failed to deliver a large number of high impact, high value companies. We do have some companies that everybody talks about ‚Äî iFlex, Tally, Zoho ‚Äî but these are far and few between. I believe that we are seeing a new scalable wave of enterprise software companies coming out of India and there is a potential to deliver several high impact companies over the next decade. Here at Lightspeed Venture Partners, leveraging our global strength in enterprise technologies, we see opportunities to partner with companies that are cloud-native and have cracked a global market ‚Äî examples of current active categories in India are CRM, analytics/big data, marketing automation and infrastructure.
India‚Äôs enterprise software industry has to be looked at separately from the outsourcing/BPO firms like Genpact, Cognizant, Tata Consulting Services and Infosys. Starting in the 1980s and early 1990s, this services industry is now mature and at scale.
Separate from the outsourcing/BPO industry, India‚Äôs enterprise software industry (or ‚Äúproducts‚Äù as it is called by many here in India) has evolved from the 1980s to now in what I think can be divided into four waves, coinciding somewhat with three trends: 1) enterprise software moving from desktop to client-server to cloud; 2) evolution of Indian industry post 1991 liberalization; and 3) increased experience of Indians at successful US product companies.
WAVE 1
The first wave of software products came along in the late 1980s/early 1990s ‚Äî the focus was desktop products for business accounting. Companies in this wave include Tally Solutions (still the undisputed leader in SME accounting software in India), Instaplan, Muneemji and Easy Accounting.
WAVE 2
This generation of software products emerged in the 1990s as projects within outsourcing firms or from internal services arms of larger corporates. Infosys launched Finacle. Ramco Systems launched its ERP. And Citibank launched CITIL which became i-Flex. Other notable companies included 3i Infotech, Cranes Software, Kale Consultants, Newgen Software, Polaris Financial Technologies, Srishti Software and Subex.
I remember attending CEBIT in Hanover in 1989 when many of these Indian software and consulting companies were first introduced to Europe.
The late 1990s saw a wavelet of ASP (application service provider) startups in India, most of which got crushed after the dotcom bust.
WAVE 3
The 2000s saw on-premise India-first companies such as Drishti-Soft, Eka Software, Employwise, iCreate Software, iViz, Manthan Systems, Quick Heal Technologies, Talisma (for which I did some initial product management work while at Aditi Technologies) and Zycus get started. This was the era of 8‚Äì10% GDP growth in India which lasted till about 2010. Many of these companies had a direct sales model. After India, they generally expanded into the global South (Africa, Middle East, SE Asia, Latin America) where they found similar customer requirements and little competition from Western software companies. Bootstrapped in their earlier years, some of these companies grew over several years and have broken through to $25 million+ in annual revenue. Key verticals have traditionally been BFSI (banking, financial services and insurance), telecom, retail/FMCG (fast-moving consumer goods aka CPG in the US) and outsourcing/BPO.
Having been around for over a decade, some of these companies generally face the challenge of migrating to the cloud, upgrading user experience to modern Web 2.0 levels, and expanding addressable markets beyond the global South to the US and Europe. We have seen some of these companies get venture funded, typically at much later stages in their go-to-market relative to US-based software companies. Several of these companies have received funding in the past couple of years, ostensibly to ‚Äúgo international‚Äù and ‚Äúgo cloud,‚Äù not an easy task, especially when done together.
WAVE 4
Starting in around 2010, a new wave of cloud-native companies were launched, perhaps following the slowdown in India‚Äôs economy and the growth/acceptance of SaaS as a delivery model and as a sales model in the US. These companies have grown and now could power beyond the $10M/year revenue glass ceiling. The reason for the scale potential being higher for this cloud-native wave is the cracking of efficient online sales channels to reach markets globally.
Why this decade? Because there is an increased willingness of companies around the world to search for and buy software products online. There is now a large pool of founders who have worked at global enterprise product companies (e.g. Indian offshore development centers or in Silicon Valley itself with companies like SAP, Oracle, Google, Microsoft, Adobe) and have experience in product management, marketing and sales. And finally, there has been a dramatic reduction in the capital required to bootstrap enterprise software companies. Everybody uses AWS and software from other startups to get started. It‚Äôs quite meta.
Wave 4 companies have the opportunity to break through the barriers that previously relegated Indian enterprise software companies to selling to the global South. We have seen Atlassian (Australia), Zendesk (Denmark) and Outbrain (Israel) do this move to Western or global markets. Zoho is an Indian company that is rumored to be at $100 million per year revenue scale ‚Äî they have been part of many of the waves I have described.
This cloud-native wave, I believe, can be divided into two dimensions. One dimension is the platform/tools companies versus workflow automation (applications) companies. The other dimension is India-first companies versus the global-first companies. We see opportunities in all four quadrants, each having its own challenges. We are interested in looking at companies in all these segments, with a bias toward companies which have reached some scale ($1M ARR) and are going after large addressable markets with aggressive sales & marketing execution.
[Please note this is not a comprehensive list of companies nor a view on which companies we admire or not]
Global-first companies coming out of India have started to crack or have cracked the online sales model, using SEO, SEM, content marketing and telesales. They are typically going after mature segments where buyers are typing keywords into Google at a high rate. This online selling model results in an SMB and mid-market customer base. In many cases, founders may have to move to the US to pursue direct enterprise sales. It‚Äôs worth noting that scale markets are not necessarily all in the US ‚Äî companies could get built with a general global diffusion of customers, perhaps with help from resellers.
I see India-first companies typically going after newer high-growth companies in India (e.g. ecommerce, retail) and startups. Some go after Indian arms of multinationals (MNCs). This is a reasonable early adopter market to cut a product‚Äôs teeth on, but has limited ability to scale. Of the newer crop of India-first companies, very few go after large enterprises in India ‚Äî there are exceptions like Peelworks and Wooqer. The model here generally is SaaS as a delivery model but not SaaS as a sales model (ie direct sales, not self-service). Many software companies are essentially verticalized.
We continue to see a few high-ticket, high touch direct sales enterprise software companies which are global-first, including companies like Cloudbyte, Druva, Indix, Sirion Labs and Vaultize. Many of these start out with teams in both Silicon Valley and India or transplant themselves to the Valley over time. I think this will continue to happen but we will not see the explosion here that we are seeing in the number of companies utilizing low touch online sales models. I see several high-impact companies coming out of these direct sales enterprise software startups as well.
I think this dichotomy between India-first and global-first companies is interesting and makes India a distinctly different type of investment geography, different from Israel (which has very small domestic market where tech companies move to the US very quickly), different from China (which mostly has domestic market focused startups and very little enterprise software) and different from the US (which is primarily domestic-focused in $500B enterprise tech industry in the early years of most startups). In terms of investor and founder interest, the pendulum may also swing back and forth between these two models as the Indian economy grows, sometimes at high speed, sometimes at a snails pace.
[With input from the team at iSPIRT and several of the companies mentioned above].
Tomorrow, built today.
5 
1
5¬†claps
5 
1
Written by
Venture capital investor at Lightspeed India Partners.
Tomorrow, built today.
Written by
Venture capital investor at Lightspeed India Partners.
Tomorrow, built today.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/redpixie-news/api-economy-28e04467b1b6?source=search_post---------228,"There are currently no responses for this story.
Be the first to respond.
There are more than 15,000 APIs, or Application Program Interfaces, available for public use today. The rapid growth of the API economy has led to a wave of new companies entering the scene, from businesses that curate API directories, like PublicAPIs, to API brokers, such as Stateless, who can advise other companies on the best APIs for them.
The benefits that they bring to a business are also very significant:
Though the race is already on for companies to participate in the API economy, there can still be success for those lagging behind. With iOS 10, Apple has finally opened Siri up to developers with a public API, and WhatsApp Messenger and Uber have already leapt at the opportunity to integrate.
If you‚Äôre not making use of APIs in your business, you‚Äôre missing out on a massive slice of potential revenue. Here‚Äôs how to get in on the action:
First off, there‚Äôs no use trying to get a foothold in the API economy if your business, employees or customers won‚Äôt benefit from it yet. You should only set about creating an API if it will improve customer satisfaction, help you stand out from the competition, improve productivity, cut costs, increase sales or grow your business. That might not be today, but keep eyes and mind open for the future.
While APIs are relatively easy to create, and if you don‚Äôt have the in-house developers there are plenty of companies that can help, you don‚Äôt want to take on more than you can handle.
Start small and iterate often. As with any kind of project, you will learn things along the way, whether from experience or via feedback, that take you in a different and often better direction.
Consider integrating your API with an aggregator such as Zapier or IFTTT to make it easier for people to take advantage of it.
You don‚Äôt want to restrict your creativity by applying rules and limits early on, but a good plan should act as a homing beacon for a valuable end product. An API design plan should factor in:
When you‚Äôve got your API portal set up, you should present clear brand guidelines and any legal conditions or copyright notices for developers. If you‚Äôve spent the time, money and resources creating your API, you‚Äôll want to ensure that others use it in the way you want and that you get the credit.
While the legal stuff is never the fun part of any project, understanding your rights and clearly outlining the responsibilities of third-party users is important.
APIs are a way for firms to extend their reach into a new market, maintain a competitive advantage and even gather valuable data for predicting consumer behaviour.
For more and more companies, getting in on the API economy is a key step towards obtaining strategic value in an incredibly competitive environment. If you‚Äôre not prepared to take part in the race, you‚Äôre not going to win.
info.redpixie.com
See more at www.redpixie.com/blog or http://www.linkedin.com/company/redpixie
We help organisations challenge the status quo and achieve‚Ä¶
3 
1
3¬†claps
3 
1
Written by
RedPixie go beyond technology. Building and managing Azure hybrid cloud solutions for the financial sector.
We help organisations challenge the status quo and achieve breakthrough business results with Cloud, HPC, data science, fintech and big data.
Written by
RedPixie go beyond technology. Building and managing Azure hybrid cloud solutions for the financial sector.
We help organisations challenge the status quo and achieve breakthrough business results with Cloud, HPC, data science, fintech and big data.
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@priyeshp18/2-3-setup-hasura-local-development-27af3b034335?source=search_post---------229,"Sign in
There are currently no responses for this story.
Be the first to respond.
Priyesh Patel
Jun 18, 2017¬∑1 min read
The following video will walk you through the setup process of Hasura Local Development.
Visit this link and follow along with the screen-cast.
drive.google.com
Oracle VirtualBox is a virtualization tool. One can create Virtual Machines(VM) to test different softwares or Operating Systems without affecting their daily Machine‚Äôs state.
Next
medium.com
I am a Computer Science graduate student ‚Äî University at Buffalo. Looking for full-time opportunities.
13 
13¬†
13 
I am a Computer Science graduate student ‚Äî University at Buffalo. Looking for full-time opportunities.
"
https://medium.com/@aheadcrm/salesforce-acquires-mulesoft-a-defensive-move-d4510dab18d8?source=search_post---------230,"Sign in
There are currently no responses for this story.
Be the first to respond.
Thomas Wieberneit
Mar 22, 2018¬∑4 min read
On March 20, 2018 Salesforce announced the signature of a definitive agreement to acquire Mulesoft for a whopping 6.5 billion USD ‚Äî whopping because the 2017 Mulesoft revenues have been at just $296.5 Million, albeit with a $1 billion target for 2021.
The press release states that ‚Äútogether, Salesforce and MuleSoft will accelerate customers‚Äô digital transformations, enabling them to unlock data across legacy systems, cloud apps, and devices to make smarter, faster decisions and create highly differentiated, connected, customer experiences.‚Äù
Mulesoft is recognized by Gartner as a leader in the 2017 Enterprise Integration Platform as a Service Quadrant.
As I have stated repeatedly before, most recently here, the enterprise software market is engaged in something that can be called a platform war. There are a few big players and some emergent players in the enterprise software market, and then we have a number of companies that come from the infrastructure side of the house.
Business applications get commoditized. Therefore the platform becomes crucial in a battle for dominance.
And it is not a given that there will be a dominance.
Looking at the 4 big software vendors, Microsoft, Oracle, Salesforce, and SAP, they all have different legacies, strengths and weaknesses. They share one weakness, which is that their core business is in a mainly saturated enterprise market.
All of them want and need to play their strengths, while mitigating their weaknesses in order to become the dominant player.
Looking at Salesforce, one of its key strengths is the brand. Right or wrong, pretty much the first name that comes to mind when thinking CRM is ‚Ä¶ Salesforce. And sure, Salesforce builds good, sometimes even great, software, based on a strong business model. And where there is a need, the company is strong enough to buy leading players, like ten days ago Cloudcraze and now Mulesoft.
There are some weaknesses or risks, though:
This acquisition is a defensive move ‚Äî a strong one, but still a defensive one. It fortifies the position while enabling Salesforce to address some of its challenges that I laid out above.
For Salesforce it is necessary, even mandatory, to be able to seamlessly integrate into the application systems of other vendors. CRM and the plethora of applications around, is not and never will be the core application any company on this planet runs. It is important, yes, but an ERP is more important.
Salesforce is not an ERP company.
Salesforce is closer to the saturated enterprise end of the market than to the underserved SMB end of the market.
Salesforce does not have the wide and powerful access to data that the core competition has. And data nowadays is truly King.
Salesforce has strong, very strong, competition.
Salesforce is clearly aware of all this.
And then it cannot be denied that currently there is a need to connect applications that live in different clouds.
Besides becoming the default plumbing between applications that are built on the Salesforce platform(s) and acquired applications that are not, Mulesoft can become the foundation for a platform of platforms that bolsters the claim of ease of integration.
The first three challenges above can clearly get addressed by Mulesoft. How big an opportunity (or threat, if this was a competitive bid) Salesforce sees can get estimated by the price the company is willing to pay.
But the main reason for the acquisition seems to be around the word data. In the words of Benioff: ‚ÄúTogether, Salesforce and MuleSoft will enable customers to connect all of the information throughout their enterprise, across all public and privat clouds and data sources ‚Ä¶‚Äù. This statement clearly not only addresses first party data but also third party data and hints into connecting to social media. Identity, profiles, and of course consents, are a main topic here. Will we see a CIAM acquisition next?
The company is clearly playing a combination of ‚Äòbest of integration‚Äô with ‚Äòbest of breed‚Äô game. The integration part ring fences the application part, while making them more attractive with its ability to dig into data.
And oh, it also helps with the price point.
Really, a strong move.
Strong enough?
Time will tell.
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
See all (1,289)
3 
3¬†claps
3 
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@bdougie/i-really-love-that-you-went-into-detail-on-your-approach-in-getting-your-serverless-app-with-a-95074e90bd50?source=search_post---------231,"Sign in
There are currently no responses for this story.
Be the first to respond.
Brian Douglas
Oct 7, 2016¬∑1 min read
Ben Orozco
I really love that you went into detail on your approach in getting your serverless app with a combo of free/low priced tools. I personally believe this is the way to go for side projects and small applicasitons
I know you are getting push back on calling this Serverless, but have you heard of JAMstack, this approach is falls in line with what you have written.
I also host a podcast on the subject if you ever want to come on and chat about this, feel free to reach out.
All day I dream about GitHub and live in Oakland, CA
3 
1
3¬†
3 
1
All day I dream about GitHub and live in Oakland, CA
"
https://medium.com/scalable/how-to-deploy-wso2-middleware-on-cloud-foundry-3b50291734e2?source=search_post---------232,"There are currently no responses for this story.
Be the first to respond.
Cloud Foundry architecture, highlights, drawbacks & steps to deploy WSO2 middleware
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://koukia.ca/microsoft-windows-azure-webjobs-and-how-to-keep-them-awake-16283c28f19f?source=search_post---------233,"What are your thoughts?
Also publish to my profile
There are currently no responses for this story.
Be the first to respond.
In case you have come across Microsoft Azure WebJobs (if not you can take a look at what it is here) you know that they are basically background processes that you want to run them on a Azure hosted website, and you can make them to run continuously, on demand or based on a specific schedule.
In our latest project we had a WebJob in our Azure website that was supposed to listen to some messages on Azure Service Bus (ASB), so based on that we were expecting to run a process continuously so that it can listen to bus messages‚Ä¶
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@odsc/what-is-ipaas-and-why-should-your-business-care-7f2d2ad8a223?source=search_post---------234,"Sign in
There are currently no responses for this story.
Be the first to respond.
ODSC - Open Data Science
Jul 22, 2019¬∑4 min read
AI, cloud computing, and massive data. It‚Äôs getting beyond the capability of most companies and organizations to host and manage the type of infrastructure needed to build and deploy models. Integration Platform as a Service (iPaaS) could be the answer to in house computing and security issues.
Cloud integration is complicated, and security is faring even worse in most in-house solutions, putting companies at considerable risk. To build security and tackle computing issues, businesses are turning to Platform as a Service integration services to handle their needs.
[Related article: Why Your Business Needs Edge Computing]
Integration platforms give organizations the infrastructure to build and deploy in the cloud without having to manage the hardware or middleware itself. It reduces the load on in-house storage solutions but doesn‚Äôt require the organization to sacrifice capability.
You have an established in-house infrastructure; I know. However, with the Agile culture of tech and development, how much time are you spending making sure that in-house solution still works? Here are a few of the benefits of moving to iPaaS:
Unfortunately, this is a relatively new service concept, so some of the full capability hasn‚Äôt been realized yet. A report put out by Gartner regarding this new service outlines the three areas iPaaS effectively addresses, so one way to begin the process is to identify one of these in-house pain points to choose your service.
E-commerce or B2B integration allows you to deploy products on customer-facing models. On the B2B side, iPaaS solutions allow your organization to connect with partners regardless of what kind of legacy systems they‚Äôre using. Integration can happen smoothly, and in some cases, in just a few hours.
On the E-commerce side, you‚Äôve got flexible, fast integration even as your services change. You can enact hybrid solutions for a suite of products that move from customer acquisition to follow up, enable messaging, and capture analytics.
The future is in cloud applications. Your in-house system is a security risk, bogs down your talent with menial maintenance, and can‚Äôt sprint. Cloud integration platforms transfer your legacy systems to secure, flexible environments in the cloud and maintain their infrastructure so that your team is free to create, deploy, and evaluate.
ESBs are great for vertical scale, but iPaaS could soon be a viable alternative for horizontal scale or an alternative altogether. iPaaS already has the upper hand with data governance and multi-tenancy, so it‚Äôs just a matter of time before this cloud-based solution outperforms the traditional in-house capability of ESB.
On the SOA side, you can now use iPaaS to handle your API issues while maintaining an on-premises SOA for low latency, mission-critical projects. While iPaaS may not be a replacement, it can certainly speed up your iterations within your existing SOA. If you‚Äôve got the capability, however, it may be a good move to change to iPaaS altogether depending on how you address the benefits listed above.
[Related article: What are MLOps and Why Does it Matter?]
In reality, iPaaS has been around for a few years, but our cloud capabilities have only just caught up with the iPaaS potential. As these systems get more efficient and sophisticated, they have the potential to answer some of the most pressing concerns with cloud integration and leaving behind on-premises legacy systems.
In reality, we‚Äôre moving away from having on-premises solutions anyway. Security risks are too great for all but the largest enterprises to handle on-site, and as we‚Äôre passing the Moore‚Äôs Law line, organizations will need more storage and computing power than can be housed locally. Because products are niching down, and hybrid solutions are becoming the norm, iPaaS could be the glue that holds everything together.
Original post here.
Read more data science articles on OpenDataScience.com, including tutorials and guides from beginner to advanced levels! Subscribe to our weekly newsletter here and receive the latest news every Thursday.
Our passion is bringing thousands of the best and brightest data scientists together under one roof for an incredible learning and networking experience.
See all (95)
6 
6¬†claps
6 
Our passion is bringing thousands of the best and brightest data scientists together under one roof for an incredible learning and networking experience.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@manningbooks/secrets-management-with-terraform-6b73ba30d4e?source=search_post---------235,"Sign in
There are currently no responses for this story.
Be the first to respond.
Manning Publications
¬∑Jan 11, 2021
In case you missed this stream, here it is! Have a look.
Subscribe to our Twitch channel here: https://www.twitch.tv/manningpublications

By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices.
Medium sent you an email at  to complete your subscription.
51¬†claps
51 
Follow Manning Publications on Medium for free content and exclusive discounts.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/pressing-words/4-saas-trends-to-watch-in-2018-22f365b26ef?source=search_post---------236,"There are currently no responses for this story.
Be the first to respond.
It wasn‚Äôt all that long ago that you bought software on a CD-ROM and someone from IT had to install it on your computer for you. In recent years, however, more and more businesses have moved away from this on-premises software model in favor of web-based software-as-a-service (SaaS) solutions.
In fact, according to BSCG research, 64% of small and medium businesses now rely on cloud-based technology to drive growth and boost their productivity. Additionally, 88% of businesses say they are considering investing in new SaaS solutions in the next 2‚Äì3 years.
While SaaS has been around for more than a decade now, it only reached maturity as once-resistant legacy software providers (take Microsoft and Oracle, for example) finally abandoned their outdated pricing, licensing and delivery models in favor of SaaS and cloud subscriptions, joining companies like Salesforce and Slack.
Worldwide, SaaS spending is on the rise ‚Äî and is predicted to increase at an exponential rate. According to recent data by Gartner, final data for 2016 shows that SaaS revenue was far greater in 2016 than expected, reaching $48.2 billion. Last year SaaS revenue was projected to grow 21% to reach $58.6 billion, and grow to $71.2 billion in 2018, $84.8 billion in 2019 and reach $99.7 billion in 2020.
What‚Äôs driving this rapid growth? Convenience. SaaS saves organizations from having to install and run software on their own computers and in data centers, saving time, money and resources. There are also many other reasons that SaaS makes sense for businesses: flexible payments via subscriptions, scalable usage, and automatic updates and support.
In addition to SaaS maturing, there has also been growth in vertical SaaS solutions. Back in the late 1990s when Salesforce emerged as one of the first SaaS companies, horizontal solutions addressed general industry-agnostic business processes, such as CRM and accounting. With vertical SaaS, we‚Äôre now seeing a growing number of cloud solutions that provide industry-specific solutions that are not adaptive to other industries.
So what does 2018 hold for SaaS? While it‚Äôs not easy to predict what‚Äôs likely to happen in the future for such a dynamic market, there are some trends that are impacting the growth of SaaS this year.
With the emergence of Amazon Alexa, Google Home and even Apple‚Äôs Siri over the past few years, these once infant technologies are finally growing up as the personal assistance space gets more competitive.
In fact, Amazon is investing big in the Echo and Alexa, the virtual assistant that goes with it: More than 5,000 people now work just on Alexa, according to David Limp, Amazon‚Äôs senior vice president of devices and services.
Interestingly, the Alexa team is paying close attention to how people are using Alexa. Limp said the team is tracking how people use their devices over time and as new popular uses emerge, a new ‚Äúsingle-threaded leader‚Äù is assigned to develop that aspect of the product. For example, when the team noticed people were using their Echoes as timers, this use got a team leader.
Chatbots are also becoming more prevalent, helped along by Google‚Äôs investment in the area. Last year, the search giant acquired API.ai, a bot management startup. And this year, Google launched a new service called Chatbase, which provides analytics and suggestions for how to ‚Äúfix‚Äù bot experiences to make them better for users.
The technology is finally evolving past the novelty stage and we‚Äôre now seeing chatbots being integrated into existing platforms like Slack and Facebook‚Äôs Messenger. As TechCrunch explains, ‚ÄúThese [services] tap into innovations in areas like natural language processing and machine learning to provide information and much more to users in a chat messaging format ‚Äî a new way for users to interact with organizations and apps.‚Äù
While Google has mostly missed the boat on dominating AI in social media, it‚Äôs pushing forward with its Google Cloud services and integrating AI into its apps to help people work more efficiently. Using machine learning to aggregate vast amounts of data, Google has reached a point where apps can prompt users to open files at certain times of the day, and Google Calendar can automatically find the best time for office meetings.
While these advancements in artificial intelligence are hugely exciting, it‚Äôs important to note there are growing concerns as it becomes more predominant in technology advancement.
Smartphones are an everyday part of our lives and our work, whether we‚Äôre invoicing clients using Freshbooks while on-the-go, joining a Skype call with colleagues who live in five different time zones, or accessing files via Dropbox or Google Docs.
Nearly half (43%) of small business owners use a smartphone as their primary device to run their operations, which is increasing the demand on the SaaS industry for mobile apps and ‚Äúmobile first‚Äù solutions.
Customer demands and expectations have driven this change ‚Äî we all expect everything to be available online, especially the younger generation of workers who have grown up using smartphones and expect to use them at work.
With worldwide sales of mobile phones still surging ‚Äî Gartner predicts they‚Äôll reach 2.1 million in 2019 ‚Äî businesses that don‚Äôt prioritize cloud and mobile will be left behind.
Neumob, now part of Cloudflare, summed it up succinctly by saying the game has changed when it comes to SaaS in a mobile app world:
‚ÄúThe continued trend toward the mobilization of virtually everything is fast converging with a profound surge in the adoption of software-as-a-service (SaaS) applications. The impact of Mobile-SaaS convergence is that organizations of all sizes are leveraging new, critical mobile applications that maximize employee productivity and spur business growth.‚Äù
There are three big obstacles for SaaS mobile apps according to the newly acquired Cloudflare team: user experience, development efficiency and app performance. These challenges will likely further steal the focus of companies next year due to the fact each of these obstacles has a huge impact on user retention in ‚Äúmobile first‚Äù countries, as well as in the U.S. and Western Europe.
Just as word of mouth can help encourage adoption of a product, online reviews and testimonials can make or break an app. Just check out the Apple Store or Google Play Store for evidence of this. If an app is slow or difficult to use, users will simply delete it from their phones. But if an app is fast and performs well, users will happily leave a glowing review, encouraging other users to download the app.
As SaaS companies grow and reach a certain level of adoption and maturity, the focus shifts from customer acquisition to customer retention. This has led to the rise of platform-as-a-service (PaaS), allowing companies to expand on their original product and enable customers to choose add-on apps and services.
One example is Salesforce and its Force.com platform, which is designed to simplify the development and deployment of cloud-based applications and websites. Another example is Hubspot, which is introducing collaborative spaces inside its CRM and task management tools.
In the WordPress space, WPMU DEV looks ripe to evolve into a PaaS. Originally a development company that sold single plugins, WPMU DEV switched to a SaaS membership model a few years ago and has since rapidly grown its suite of tools, including security, performance, optimization, backup and site management API services.
These are just a few example of SaaS providers that are focusing on providing PaaS to their customers, the ultimate goal being to take hold of the market in their niche. As more and more SaaS companies mature, we‚Äôll see a greater number focusing on PaaS in the years to come.
Security will continue to be an ongoing issue for SaaS, especially as GDPR comes into play and regulations on privacy are increased. As smartphone adoption continues to increase, it provides multiple points of entry for security breaches, exposing personal and enterprise networks alike. On top of this, remote workers expose companies to unencrypted wifi networks that are more vulnerable to hackers, something our Security team at Pagely makes sure to prevent.
Writing for Computerworld, security manager Mathias Thurman explains how shadow IT and and the ‚Äúconsumerization of IT‚Äù are a threat to corporate data. Employees at his company use more than 90 cloud-based SaaS apps ‚Äî and those are the apps that he knows of. While many of the apps are corporate-sanctioned, meaning they‚Äôve been through a selection process and identified as secure, Thurman says other apps, like GitHub and Skype, are ‚Äúunsanctioned but tolerated.‚Äù
However, he said sometimes, he discovers employees are using apps only after he is invited to collaborate:
‚ÄúAn engineer introduced [a] free app to our network and was using it to share some fairly sensitive information regarding security weaknesses in our product. Although his intentions were good and the tool got the job done, it was a security nightmare. Authentication? Nonexistent. Encryption? Same story. The app uses http instead of https, and worst of all, everything shared to it gets indexed by Google, meaning it can be discovered by anyone.‚Äù
Smart service providers are making it their mission to serve up best in class security solutions, like our Secure WordPress Hosting at Pagely. For example, Pagely developed PressArmor, a security architecture that hardens and protects our network, hardware, and WordPress applications with a primary focus is on prevention and the mitigation of risk to clients. As such, it‚Äôs part of our promise to our customers that security is a given when they use our product.
If there‚Äôs one takeaway from this article, it‚Äôs this: SaaS companies are embracing innovation and change ‚Äî knowing they can‚Äôt rely only on first-generation SaaS strategies if they want to keep growing. This year SaaS is set to become even more personalized as artificial intelligence continues to evolve and help solve people‚Äôs problems, mobile apps become even more relied upon for business productivity, and SaaS companies provide more secure solutions for customers.
We make light of some buzzword trends, but at Pagely it‚Äôs our job to stay connected and aware of where our community is headed.
Originally published at pagely.com.
Handpicked articles covering the business side of WordPress.
2 
2¬†claps
2 
Written by
We help big brands scale WordPress. https://pagely.com
Handpicked articles covering the business side of WordPress. To submit your own story, visit: https://pagely.com/guest-post-form/
Written by
We help big brands scale WordPress. https://pagely.com
Handpicked articles covering the business side of WordPress. To submit your own story, visit: https://pagely.com/guest-post-form/
Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more
Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore
If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home. It‚Äôs easy and free to post your thinking on any topic. Start a blog
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@TheDigitalTP/how-to-choose-an-iot-platform-aec49134e47?source=search_post---------237,"Sign in
There are currently no responses for this story.
Be the first to respond.
The Digital Transformation People
Oct 15, 2018¬∑8 min read
So, you‚Äôve investigated IoT and come up with some ideas of where it could help your business. Hopefully, you‚Äôve done a high-level business case which indicates this should be worth pursuing. All good steps but at some point, you will need to get into the enabling technology.
Perhaps you want to run a proof of value exercise, look at a larger scale pilot or if you‚Äôre feeling brave enough to initiate a large-scale investment. Here within lies one of the major challenges. Search for IoT and you will uncover a wealth of different vendors making all kinds of claims for their technology. Where do you start? Who should you talk to? You can‚Äôt talk to them all.
Selecting your IoT technology ‚Äî no one does it all
So, assuming you are looking to get a competitive edge in your market and want to move now, what should you look for when selecting your IoT technology?
First you need to be aware you are unlikely to get it all from one vendor. The companies that manufacture sensors are unlikely to be the same that provide wireless networking services or that are highly experienced in enterprise-class cloud software applications.
One thing we have learned in the last 20 years is to avoid building large proprietary business solutions. These end up with a very high cost of ownership, leave the customer beholden to the vendor and do not provide agility expected by the business. The current trend is to look for open, extensible, platforms. These aim to provide core functionality but (in theory) are easily integrated with other technologies to reduce implementation time, cost and risk. In IoT this aspect is very important, given the range of technologies required to create a usable solution, it is not just a ‚Äúsoftware‚Äù play.
The market has at least matured enough that there are several highly capable platforms on which you can develop your specific business solution(s). None of them is perfect but this approach will allow you to manage and grow your solution as the vendor develops new capabilities and resolves deficiencies.
All the recommendations below are based on a number of ‚Äúprinciples‚Äù, those necessary for any modern business when selecting IT:
What to look for?
Below are listed some of the important IoT platform features you need to look for:
A flexible, distributed architecture. One of the key benefits of IoT is the ability to provide compute capabilities at the most effective point in the process. This may be on the device itself (perhaps to reduce network traffic, provide real-time control or allow limited ‚Äúoffline operation‚Äù when network availability isn‚Äôt guaranteed), it may be on a local compute ‚Äúnetwork‚Äù device filtering data from numerous devices, it may be on a cloud-based service providing advanced analytics and actioning historical insight or centralised device management or different compute may occur at each of these stages.
For example:
As compute capability, storage, power management and networking capabilities improve you need to be able to easily move compute loads within the architecture, without being locked to the original model. This will allow the solution to scale easily for other workloads, provide agility to the business (for the inevitable change requests) and reduce the cost of ownership.
The interface for managing the architecture needs to be visual for ease of operator understanding and control but should have suitable governance controls so that changes are properly considered before deployment and can be propagated in a controlled manner (e.g. per room, floor, factory, office, region, country etc).
Open standards. You don‚Äôt want to be constrained by proprietary standards. This will (at some point) limit the real-world data you can capture, increase the cost of ownership and limit the business agility of the solution. Just look at customers who were ‚Äúlocked‚Äù into large-scale ERP implementations in the 90‚Äôs and 00‚Äôs, who are still paying a fortune in support and maintenance and yet cannot easily move to lower cost, more agile alternatives.
Note that ‚Äúopen‚Äù doesn‚Äôt necessarily mean ‚Äúopen source‚Äù but do ensure that any platform exposes its functionality via easy to use API‚Äôs and ideally is hosted with a PaaS (Platform as a Service) model so you can just use the bits you need.
In most scenarios, you will want to integrate the data and insight from your IoT solution into action. The ‚Äúvehicle‚Äù for this action could be an existing ERP or CRM platform or a field service solution tasked with ensuring the right engineer turns up at the right time, with the right skills, tools and parts to get the job done on the first visit.
System integration used to be the ‚Äúnever-ending rope‚Äù in terms of time and cost but advances in cloud-based API management have made this task easier than it used to be.
Device management. There is a large difference between doing a lab PoC with 10 devices and implementing a global solution which could have 100‚Äôs of thousands of devices or more. Consider:
With this in mind, the importance of security will only grow as IoT solutions start to take on critical workloads. It is something that must be the solution design from the start and not added as an ‚Äúafterthought‚Äù once the rest has been built. An overarching model needs to be developed covering every component in the chain.
Advanced analytics. Collecting real-world data and managing those devices is a good start but unless you can build real-world data models and derive actionable insight you will show little value to your business stakeholders.
Advanced analytics includes:
These approaches can allow your business to respond quickly (and in many cases automatically) to real-world events and/or allow you to predict when an important or critical event is likely to occur (for example, machine failure) so its effect can be mitigated (for example, perform preventative maintenance outside core operating hours).
Note that it is perfectly feasible to source your analytical toolset from a different vendor than that providing your device management and data collection capability but there are some advantages of maintaining analytics within the same vendor product set.
An existing partner ecosystem. I have already indicated that most IoT solutions will involve multiple vendors. Having a pre-built ecosystem will make it easier, quicker and cheaper to deploy your solution as integration will have been pre-tested and (ideally) certified on your chosen platform, helping to reduce ‚Äúbuck passing‚Äù when the inevitable issues occur.
Look for user groups where you can meet other customers who have already made deployments and where you can learn ‚Äúbest practice‚Äù. Finally, think about what kind of field service is available for the installation or repair of devices that are not working. Again, when deploying devices at large scale this will be important to ensure continuity and quality of service.
Getting It Done
A final point to consider is whether you build a team in-house to design, implement and deploy, or whether you get some external help.
At one extreme you can engage a top-4 consultancy or global System Integrator. Many will struggle to provide you with value for money or quick results, they have too much internal bureaucracy and process and one could argue are more interested in billing ‚Äúbodies‚Äù for as long as possible. Also, check what they have actually done for customers and you‚Äôre not fooled by fancy marketing.
Building your own team keeps control in-house but skilled and experienced people are expensive, not that easy to find and time is ticking.
An alternative would be to blend options, augmented by a boutique consultancy with members that have ‚Äúbeen there and done that‚Äù to advise throughout the process, including platform selection. As with anything new, getting started in the right direction is critical.
Typically, these have very experienced practitioners, are substantially cheaper than high-end consultancies and will get things done with your agenda and outcomes top of mind.
Originally published at www.thedigitaltransformationpeople.com on October 15, 2018.
Helping you discover the what, how and who of digital transformation. We‚Äôve built a network of incredible people who can help you make a success of yours.
See all (1,331)
5 
5¬†claps
5 
Helping you discover the what, how and who of digital transformation. We‚Äôve built a network of incredible people who can help you make a success of yours.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@bryantchou/sell-shovels-not-entire-homes-b03dbbee2588?source=search_post---------238,"Sign in
There are currently no responses for this story.
Be the first to respond.
brryant
Feb 9, 2017¬∑2 min read
When you walk into a Home Depot, you see everything a carpenter needs to build a home from scratch. But one thing they don‚Äôt sell? A pre-made home.
There‚Äôs a growing trend of developers who are starting PaaS (platform as a service) companies, and it‚Äôs alarming to me how quick developers jump at the opportunity to build services for other developers. As Slava Akhmechet points out in his excellent RethinkDB post mortem:
Developers love building developer tools, often for free. So while there is massive demand, the supply vastly outstrips it. This drives the number of alternatives up, and the prices down to zero.
But here‚Äôs where the opportunity is: developer tools can be a profitable business, you just have to sell them shovels, not the house.
There are at least three startups right now creating PaaS platforms targeted at developers who don‚Äôt want to run their own backend [3]. They bundle and resell really hot technologies, like GraphQL, Lambda, and microservice architectures, and combine them in ways so developers don‚Äôt have to worry about how they are interconnected and scaled. But the problem is, developers are the same as carpenters who are building homes. They don‚Äôt want someone to build it for them. Developers are builders that want to leverage the best tools to build their own house.
However, by viewing said technologies as channels instead of products, startups can sell tools and services that make serious money.
For historical precedent, here are some companies that come to mind that took this approach:
These are just two companies that leverage the technology space to offer tools that supercharge a developer‚Äôs productivity, without building the house for them.
It will be really interesting to see how companies build on top of GraphQL. There are some really amazing use cases that can be unlocked when developers have a common interchange format, which they can use to simplify the work between the frontend and backend. But I believe the most interesting developer facing companies of the future will be ones that leverage GraphQL (and other new technologies) to break down the data silos between organizations, and who make it easier to work with the tech ‚Äî not build their entire house for them. [4]
[1] ‚Äî I believe one of the reasons we‚Äôre seeing more PaaS out there is because it‚Äôs at least 10x easier to build with AWS. But that doesn‚Äôt mean it‚Äôs the best business to start.
[2] ‚Äî Does anyone else remember SOA and how WSDLs were an early precursor to GraphQL?
[3] ‚Äî Definitely read @BostonVC‚Äôs excellent article on how JBoss rose to the top
[4] ‚Äî http://www.apollodata.com/ looks like the leader so far here, but I‚Äôm sure there are at least 10 other GraphQL related tools that could turn into big businesses.
Co-founder, CTO @webflowapp.
2 
2¬†
2 
Co-founder, CTO @webflowapp.
"
https://medium.com/@auth0/cloud-scale-thinking-from-day-one-for-your-saas-products-190d6f3803c4?source=search_post---------239,"Sign in
There are currently no responses for this story.
Be the first to respond.
Auth0
Jul 26, 2018¬∑7 min read
TL;DR: In this article, we will explore some of the key technical considerations you have to make while building highly-scalable SaaS products. The idea is to show that it‚Äôs better to use reliable PaaS (Platform as a Service) vendors available in the market instead of utilizing your valuable engineering resources on infrastructure requirements. As you will learn, this will make your engineers available to focus on what matters the most, the key features of your project.
‚ÄúRelying on battle-tested solutions allows your engineers to focus on what matters most to your company ‚Äî the unique features of your SaaS products.‚Äù
TWEET THIS
Before going into the details, I need to give you a short background of Document360, which will help you to understand the context of the article better.
Document360 is a self-service knowledge base product that helps you to create public or private product documentation. Take as an example Auth0‚Äôs own documentation. Using Document360, you can easily build such product documentation.
When the idea for Document360 was conceived at the end of 2017, one of the key decisions we have made was to build a solution to scale to unlimited users without any architectural changes. This means that the product has to serve 500 customers today and it shouldn‚Äôt suffer big architectural changes to serve 500,000 customers in a few years down the line.
Architecturally, this requires a different level of thinking and infrastructure requirements when you are designing a system that‚Äôs capable of 500 customers and 500k customers. You need to be careful you are not over-engineering the solution, which will end up being difficult to manage and very expensive.
For example, let‚Äôs say you have the requirement to pick a video file from a storage location to do some processing (like creating a transcript) and to store the result in a third-party storage location. When you are looking at processing 5 video messages per day, the solution is pretty simple, but imagine if you are YouTube or Wistia and need to process 100,000+ videos per day. Then, this single piece of functionality will require significant architecture and infrastructure investment.
If you do not plan correctly and decide to build scalable components yourself, your valuable software engineering time will be spent on creating basic versions of those functionalities. The cloud Platform as a Service (PaaS) market has evolved significantly in the past 5‚Äì8 years and, today, there is a specialized offering for each piece of the puzzle. It might be a smart move to pick the required Lego blocks and assemble it together rather than building everything yourself.
For Document360, there are five core pieces of the product that required cloud-scale thinking:
Before going into identity management, which is the core of this article, let‚Äôs quickly take a brief look at the background about other scalable parts of the architecture.
These web applications are straightforward requirements. Both applications should be scalable, reliable, and fast to provide a great experience to both end customers and technical writers. We decided to use Microsoft Azure Web Apps as the core front-end facing technology with Azure Traffic Manager to route the traffic to the closest location.
For any self-service knowledge base product, a good search engine is the key. These days, people do not navigate through your structure, they will just go and hit that big search box to look out for answers. We need to make sure the search feature is robust and, again, scalable when 1000‚Äôs of customers arrive. There is no point in building this in-house. As such, we decided to go with Algolia as our search provider.
A document management product like Document360 is full of text documents, so we need a reliable storage (database) with fast read and write capabilities and that can also scale as we grow. For this feature, we decided to go with MongoDB cloud as our data storage provider.
Now, let‚Äôs get a bit deeper into the main part of this article: ‚ÄúIdentity Management as Service‚Äù. Document360 got various types of users logging into the system. When you are building a public facing self-service knowledge base, your draft writers and editors need to safely login to the system to produce relevant content. In some scenarios, where the customer decided to keep their self-service knowledge base private to the organization, then the whole organizations need to securely login in.
Out of the five core areas of Document360, getting the initial authentication part in a secure, reliable, and scalable part is the most important aspect. For this, we decided to go with Auth0 to provide the initial login and user authentication for our product.
There are few reasons why we decided to use Auth0 instead of custom building our own identity providers:
‚ÄúBy using Auth0, we save money by simply paying based on our usage. That is, we pay more when we make more money.‚Äù
TWEET THIS
If you are building a SaaS product today, you really shouldn‚Äôt think about building things yourself. The modern way of building stuff is all about assembling the best solutions in the industry together and constructing a solid application. That‚Äôs exactly what we have done in our case. The core parts of the business are running with the help of great products in the market and we act more or less like an orchestrator to assemble and create a beautiful music out of all these talents.
Auth0, a global leader in Identity-as-a-Service (IDaaS), provides thousands of enterprise customers with a Universal Identity Platform for their web, mobile, IoT, and internal applications. Its extensible platform seamlessly authenticates and secures more than 1.5B logins per month, making it loved by developers and trusted by global enterprises. The company‚Äôs U.S. headquarters in Bellevue, WA, and additional offices in Buenos Aires, London, Tokyo, and Sydney, support its customers that are located in 70+ countries.
For more information, visit https://auth0.com or follow @auth0 on Twitter.
Saravana Kumar is the Founder of Document360, a product that helps your team create, collaborate, and publish a self-service knowledge base for your software with ease. Saravana is passionate about technology and he holds the famous Microsoft Most Valuable Professional title for 12 years in a row. He founded and scaled three other successful enterprise products (BizTalk360, Serverless360 and Atomic Scope) in the last 7 years.
Originally published at auth0.com.
Identity Is Complex, Deal With It. Auth0 is The Identity Platform for Application Builders.
See all (400)
6 
6¬†claps
6 
Identity Is Complex, Deal With It. Auth0 is The Identity Platform for Application Builders.
About
Write
Help
Legal
Get the Medium app
"
https://medium.com/@alibaba-cloud/installing-alfresco-community-edition-on-centos-94d9d6af9950?source=search_post---------240,"Sign in
There are currently no responses for this story.
Be the first to respond.
Alibaba Cloud
Sep 14, 2018¬∑7 min read
By Arslan Ud Din Shafiq, Alibaba Cloud Tech Share Author. Tech Share is Alibaba Cloud‚Äôs incentive program to encourage the sharing of technical knowledge and best practices within the cloud community.
Alfresco Community Edition is an open source Enterprise Content Management (ECM) software for managing the contents of an enterprise. Alfresco Community Edition is one of the software products of Alfresco. It is developed for Windows and Unix operating systems. It is written in Java, and PostgreSQL is used for storing its database. Alfresco is used within an enterprise for managing its various systems and digital assets such as videos, documents, images, and records. WebDAV, CIMS, SMB, and FTP can be used for accessing the file repository of hosted Alfresco.
With Alfresco, many enterprise challenges can be addressed, including displaying important information at one place and keeping track of employee performance. For getting the advantages of community-driven development, Alfresco Community Edition could be the best option for your enterprise.
When talking about availability and scalability, Alfresco does have some limitations. For instance, the community edition of Alfresco does not support clustering. The quality assurance and the bug fixes are also limited. However, Alfresco Community Edition provides enterprises of different levels with ease of managing their content and non-critical business process. It is easy to use and the source code of the Community Edition is also publicly available.
As a developer, I prefer the services of Alibaba Cloud to deploy Alfresco. Alibaba Elastic Compute Service (ECS) is highly scalable and flexible. You can upgrade the hardware resources anytime when required. Alibaba Cloud can also provide you technical support and assistance in order to launch any of your system.
Alfresco does not restrict its installation to any specific operating system (OS). You can use any operating system (OS) of your choice; however, the installation steps would vary according to the choice of operating system.
In this tutorial, we will be installing and configuring Alfresco Community Edition on an Alibaba Cloud Elastic Compute Service (ECS) instance with CentOS 7.
The installer package for Alfresco is easily available on their official website. This installer package by Alfresco contains all the programs required to execute Alfresco Community Edition on your Operating System. The LibreOffice plugin require some dependencies that needs to be installed.
Perform the following installations by entering the relevant commands:
Install fontconfig
Install libSM
Install libICE
Install cups-libs
Install libGLU, cairo, mesa-libGL-devel
After completing all the above installations, remove Postfix or MTA from the machine with the command:
Nano editor is used to edit different files. It helps you in editing files easily. We will be using this editor for editing a few files, so downloading it on prior basis makes it easy for us to continue with the configurations and editing processes. Here‚Äôs the command to install the editor.
We are now all set to install Alfresco on our ECS instance.
The next step is to download the latest Alfresco installer via its official page. It is recommended to use the installer that is provided by the official Alfresco website, as it will not get you in trouble due to bugs or other errors during or after installation of Alfresco.
This downloading process may take a while, and after it is saved, it will generate a message of saving the installer package. This installer package requires certain execution permissions. The following command will provide it with the necessary permissions.
We can now install the Alfresco Community Edition easily. Execute the following command to start the installation process.
After running the command, you will be prompted to select an installation language. Select the installation language by entering the respective number for your preferred language. After the language selection, it asks you to select the installation type. For installing the application with default configurations, you should select the ‚ÄúEasy Install‚Äù method.
You will then be prompted to select a folder to install Alfresco community. Select /opt/alfresco-community, which is the default location for installing Alfresco. Continue with the default folder by pressing Enter.
You will need to specify a password for the Alfresco Content Services administrator account. This will be the credential that you will be using for accessing the Alfresco services, after they are installed, by using the administrative ID and password. After setting up a password, select ‚ÄòY‚Äô for installing it as a service.
Right after the Alfresco is installed, it asks ‚ÄòView Readme File?‚Äô. Select ‚ÄòY‚Äô and the server should start immediately with the following output.
You can also launch your application right away, as the installer has already provided the start-up service.
You need to get the Alfresco service enabled for it to start automatically at boot time. You can do this with the following command:
By default, the Tomcat server starts on port 8080. To check the working status of Alfresco server, the port 8080 needs to be allowed through the system firewall. This will be done by the firewall settings mentioned with details at the end of this tutorial.
Go to a browser and log on to http://47.90.214.177:8080/share/ where 47.90.214.177 is my public IP. Remember to replace it with yours. Upon loading this, you will be shown Alfresco‚Äôs landing page.
By default, Tomcat server runs on port 8080. Here we are going to use Nginx as a reverse proxy for the application to be easily accessible through the standard HTTP and HTTPS ports. We will also be configuring Nginx for using an SSL generated with Let‚Äôs Encrypt free SSL.
Now, install Nginx server.
We will be starting the web server along with enabling it to automatically start at the boot time.
Next, you need to configure your reverse proxy. All we need to do is to create a new block file in Alfresco.
Here softpedia.xyz is the public domain name, replace it with yours. The next thing is that we shall be populating this file with the following code.
Save the modified changes and close the file. Now we are done with the necessary changes made for the configuration.
Restart the server to save your configuration and for the changes to take effect.
Now go to http://softpedia.xyz/share/page/ (or your own domain name) and access the various services of Alfresco Community Edition. Use credentials that you provided during the installation process of Alfresco.
Alfresco Community Edition is now accessible through the domain name, easily. You can now use the amazing services provided by this application by giving the authenticated administrative credentials.
If you have activated firewalls, you will have to define a rule in Alibaba Cloud security group for your cloud server to add exception for port 80/TCP and 443/TCP. You can enable these ports while creating ECS instance, but in case if you have forgotten to unblock these ports, you can follow the procedure below.
By default, these ports are blocked by the firewalls. Also, we need to add port 8080 for accessing the Alfresco. To do this, go to your Elastic Compute Service section. Click on More for the ECS you are using for Alfresco and click Security Group Configuration.
Click on Configure Rules and then click on Quickly Create Rules.
Add the configurations as shown in screenshot below and click OK.
Reference:
https://www.alibabacloud.com/blog/installing-alfresco-community-edition-on-centos_593922?spm=a2c41.11954966.0.0
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
52 
52¬†
52 
Follow me to keep abreast with the latest technology news, industry insights, and developer trends.
"
https://medium.com/@aheadcrm/clash-of-titans-microsoft-and-sap-weigh-in-3e67a99867f?source=search_post---------241,"Sign in
There are currently no responses for this story.
Be the first to respond.
Thomas Wieberneit
Aug 28, 2018¬∑6 min read
As it has been some time since I published Clash of Titans ‚Äî Platform Play, the first part of this little series, let me start with a little recap.
The business applications market, especially the CRM market, is evolving fast. CRM has morphed from concentrating on transactions to become an enabler of engagements. Engagements in turn result in experiences. And positive experiences are what companies want to achieve.
In a digital world this is possible only if companies rely on a foundation, a (technical) platform. Becoming the provider of the dominant technical platform therefore has become the main goal of of the big business software vendors.
However, even governing a great technical platform is not enough. Software vendors that want to be successful platform players need to be able to deliver on four areas to succeed:
Only if they deliver on all four aspects are ‚Äòplatform players‚Äô able to provide their customers with what they need to involve themselves in digital engagements that result in sustainably positive experiences.
I will look at how the big four are measuring up in this and the next article of this little series. Microsoft and SAP will be the starters. Then I will look at Oracle and Salesforce.
I might conclude with some surprise additions.
But let the games begin!
Microsoft is the (not so, if you look sharply) hidden champion of this game.
Actually, I think that Microsoft is the 800 pound gorilla in this game.
It is Microsoft‚Äôs objective to become the fabric that connects enterprises of all sizes with their stakeholders, including the customers‚Äô personal lives. And, as I have written earlier, they have all the ingredients they need to achieve this objective.
With Azure there is one of the strongest IaaS and PaaS games in the play. Including Azure Stack, Microsoft is capable of offering hybrid deployments. And in all seriousness, hybrid clouds are here to stay for quite a while. The Power* series of tools and applications helps extending the business applications and the development environments are very powerful.
Microsoft is the clear leader when it comes to productivity applications outside the core business applications, which are also tightly integrated into the business applications for further impact.
On the insight side the company has few equals, being able to leverage the power of both, LinkedIn and Bing, their own search engine, and the wealth of data that comes from a plethora of different devices. This is combined with strong analytics and machine learning capabilities, which can create insight out of all the data.
Last but not least, Microsoft has one of the strongest ecosystems on this planet. What they do not have themselves, someone else is developing. Microsoft then embraces the partnership angle. A very visible example for this is the current strategic partnership with Adobe. Microsoft till recently did not have an enterprise grade multichannel marketing engine. Nor an ecommerce system.
Adobe has both. Microsoft is reselling Adobe as part of their strategic partnership.
Finally, there is something else that needs to be considered. As stated above, the enterprise market is saturated. All big vendors, and many more small ones, are tackling the SMB market. Microsoft Dynamics is not as high end as the competition but very suitable for the higher end of the SMB market. This makes Microsoft interesting for companies that would not look at SAP, Salesforce, or Oracle. Microsoft also runs a very strong partnership with Nimble, which opens up the Microsoft Dynamics world for small, but growing businesses. On the flip side: Microsoft is not (yet) universally perceived as a business applications company.
Still, the company is in a position that none of the other vendors can take (yet): None of them is able to combine the enterprise value chain with a productivity suite as powerful as Microsoft‚Äôs and a reach to the end customer. Add some tremendous data assets and a strong ecosystem to the mix. Exactly this breadth and width of the offering is Microsoft‚Äôs biggest strength, which covers for functional weaknesses in some areas like supply chain, ecommerce or marketing. If Microsoft is able to mitigate these weaknesses while continuing to play to its strengths, the company should be able to gain considerable market share on cost of one or more of the other three.
Using Microsoft‚Äôs objective as a guideline, SAP is currently the business vendor that is closest to being the fabric of enterprises. The reason for this is the access to data in combination with the ability to support the whole value chain of companies across a wide range of industries and sizes.
Looking at the enterprise software market, SAP is the clear leader in ERP software. On top of this, SAP has Ariba. Ariba, or the SAP Business Network is one of the largest, if not the largest, business market places around.
In combination, SAP can say that nearly 80 per cent of all business transactions touch an SAP system, one time or another.
On top of this, with Gigya SAP owns one of the strongest Customer Identity and Access Management platforms around. Via this platform SAP manages more than 1.3 billion identities, along with their consents, across hundreds of sites. The smart progressive profiling methodology that is built into this software also helps with building valuable profiles out of these mere identities.
In combination with SAP‚Äôs strong analytics capabilities, the company is able to generate extremely valuable insight to businesses.
In addition SAP, like Microsoft and Oracle, covers the complete value chain of businesses, just that SAP‚Äôs offering is probably stronger than that of the competition. This, again, gives SAP customers vast amounts of consistent data that can be utilized to offer more value to their customers.
This application strength in what SAP calls the ‚Äòdigital core‚Äô is also a good part of its platform. Add to it an SAP Cloud Platform (SCP) that offers the majority of services that an agile business needs and that gets increasingly stronger we have a very strong (PaaS) platform play. This platform, along with one of the strongest partner ecosystems around can open up the SMB market, and hence strong growth, for SAP.
Talking about its ecosystem, SAP has a wide variety of implementation and consulting partners, that support each other and get support via platforms like the SAP Community Network SCN, or the SAP Partner Edge.
SAP positions itself as an enterprise software player, as opposed to a full stack player like, e.g. Microsoft. Consequently, the company‚Äôs IaaS capabilities are limited. Instead, SAP is pursuing a multi cloud approach by being able to have its software run on all major infrastructures. This is a smart move as it keeps the company‚Äôs independence while offering choice to clients.
One of the company‚Äôs better kept secrets ‚Äî SAP Business by Design ‚Äî is a central element of its strategy to address midmarket companies.
Apart from the prevailing (but increasingly wrong) opinion that SAP is difficult to deal with, SAP‚Äôs weakest spot is productivity in the sense of office products. The company covers this topic via integrations with Microsoft‚Äôs suite of applications, and probably Google apps soon. But, to be sure, efficient, and automated execution of business processes is at the heart of SAP‚Äôs value proposition.
If SAP continues to play on its ERP strength while pursuing the newly established focus on its Customer Experience unit it has a good chance to stay one of the dominant players.
Here we have two companies that are greatly positioned in a platform market. With different starting points and strenghts they share similar visions. And they work hard towards it.
Exciting times.
But let us see how Oracle and Salesforce are playing their cards ‚Äî or should be.
A bientot!
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
3 
3¬†
3 
Helping businesses to improve in Digital Transformation, Customer Engagement, Customer Experience, CRM, Innovation
"
https://medium.com/@cardmagic/5-ugly-devops-lies-a9e521b9dab3?source=search_post---------242,"Sign in
There are currently no responses for this story.
Be the first to respond.
Lucas Carlson
Oct 25, 2016¬∑4 min read
If the snake oil salesman still exists in the 21st Century, it does so in the guise of the DevOps vendor. Like the secondhand car dealer, the solar panels sales guy, or the crooked cop, the DevOps vendor will tell you black is white ‚Äî oh, no actually white is black.
Their lies travel like Japanese Knotweed.
Almost every week, a new technology solution is launched which promises to solve all your problems. One that will boil the ocean. Maybe some hot new trendy DevOps startup that just raised $10 million in seed funding and is ready to save the world. Why trust me? Because I used to run one of those trendy DevOps startups myself.
And if there‚Äôs one thing I learned, it‚Äôs to not believe a word of it. It‚Äôs all just a pack of lies. In fact, I‚Äôve sat in so many presentations, watched so many launch demos from DevOps start-ups that I decided ‚Äî for your delight and pleasure ‚Äî to make a list of the lies I‚Äôve seen spun recently.
‚ÄúI will solve all your problems, all you have to do is just throw out all your old systems and replace them with our shiny new platform.‚Äù
DevOps vendors typically call on vulnerable customers to demolish their existing IT management practices and replace them with their solution. The name of their solution will vary from vendor to vendor. They might call it Platform-as-a-Service, or a Container Orchestration Platform, or a DevOps Management Platform. The names change but the truth doesn‚Äôt: These vendors simply want you to rebuild your systems on their architectures.
The Truth: New platforms that require major changes in IT processes, no matter how popular or trendy, carry major hidden risks around integration, production readiness, security and robustness.
‚ÄúI will solve all your problems, all you have to do is just rebuild all your applications in our shiny new programming language.‚Äù
There‚Äôs a reason your most important code is 30 years old and still written in Cobol: It works. Almost every organization wants new, innovative code. But the insidious part of the lie is when vendors refuse to service your older apps. Refuse to help you add agility and modern tools to old code that still works. Not everything needs to be rewritten in Go or Clojure or Rust before it‚Äôs ready to go into a Continuous Delivery pipeline.
The Truth: Sometimes you can teach an old dog new tricks. There are solutions out there that can add agility to existing IT processes without rebuilding every application from scratch. But you have to look hard for them.
‚ÄúEverything is moving to the cloud. Get on board before it‚Äôs too late.‚Äù
Vendors can‚Äôt stop themselves calling out the benefits of the cloud. Cheaper, more efficient, more reliable. It‚Äôs the future ‚Äî on-premise is over. Soon they‚Äôll argue the cloud will guess next week‚Äôs lottery numbers for you. It‚Äôs hype. Pure and simple. Yes, there are occasions when it makes sense to rent space (cloud), but sometimes it‚Äôs better to own (datacenter). Saying nobody‚Äôs going to own datacenters soon is like saying nobody‚Äôs going to buy a home in the future. The idea that somehow everyone‚Äôs going to magically realize one day that renting a house is better for everyone in all situations: It‚Äôs a lie. Datacenters will never go away. Sorry Amazon.
The Truth: Sometimes the total cost of ownership is lower than the total cost of renting. Sometimes renting is cheaper. There is no one-size-fits-all. Anyone who says otherwise has an agenda that‚Äôs probably not in your best interest.
‚ÄúIt‚Äôs open source, so it‚Äôs better.‚Äù
Open source has come a long way over the years, and the always-active open source communities are one of the primary reasons for its success. And there are many open source projects that are solid and battle-tested. But don‚Äôt let those DevOps vendors sell you snake-oil. Not all open source software works well at scale, and not all software that works well at scale is open source. While there are benefits to open source software, what you should be looking for in a DevOps solution is a long track record of stable and scalable execution.
The Truth: You would be surprised at how many open-source projects, even popular and trendy ones, have never been deployed in a system with more than 50 servers. Buyer beware, you might actually be getting exactly as much as you pay for it.
‚ÄúEverybody‚Äôs talking about X, so you should have an X strategy.‚Äù
Don‚Äôt believe the hype. Especially if your job depends on it. New technology trends might end up becoming battle-tested eventually. But let other people forge those paths for you. The upside potential of new, disruptive technology is only matched by the unforeseen downsides of putting it into production. The reality is that if a system you‚Äôve used has worked for the last 10 years, it‚Äôs likely to keep working for the next 10 years.
The Truth: Everyone wants to lead you in an IT Revolution. Nobody wants an IT Iteration. But what is lost in that discussion is the fact that there were good reasons to build things the way that they were built. For all its shortcomings, it works. Maybe what enterprise IT needs most today is iteration, not revolution.
So watch out. Many DevOps myths could end up murdering your business.
Want to learn more about the topics I cover in my blogs: DevOps, AgileOps, Continuous Delivery, Release Automation, Digital Transformation (and many others!), then feel free to register here to get regular updates from me.
Originally posted on DZone: https://dzone.com/articles/five-big-lies-devops-vendors-love-to-tell
Consultant, Entrepreneur & Novelist | CraftsmanFounder.com
2 
2¬†
2 
Consultant, Entrepreneur & Novelist | CraftsmanFounder.com
"
https://blog.hellotangible.com/help-us-shape-the-future-of-xervo-b1cbbdd3dfab?source=search_post---------243,
https://medium.com/containercamp/meet-the-container-experts-mike-hepburn-45fbbb0f4879?source=search_post---------244,NA
https://medium.com/@renebuest/platform-as-a-service-strategies-technologies-and-providers-a-compendium-for-it-decision-makers-fbb8d1bf924c?source=search_post---------245,NA
https://medium.com/the-techreckoning-dispatch/its-going-to-get-worse-before-it-gets-better-techreckoning-dispatch-v4n1-65b0afda9f77?source=search_post---------246,NA
https://medium.com/@Apiumhub/cloud-computing-trends-to-watch-in-2017-6e0d8696256b?source=search_post---------247,NA
https://medium.com/@engineyard/up-your-devops-game-its-time-for-noops-5722138ab27b?source=search_post---------248,NA
https://medium.com/@alibaba-cloud/cloud-foundry-now-available-on-alibaba-cloud-b19ed33ac0b2?source=search_post---------249,NA
https://airtable.news/the-right-sort-of-api-updates-b3b7c3c1a527?source=search_post---------250,NA
https://medium.com/@ghaff/the-new-distributed-application-development-platform-breaking-down-silos-c63498f93e7a?source=search_post---------251,NA
https://medium.com/@matsuustudio/najlepszy-hosting-node-js-w-2018-roku-6104eec58321?source=search_post---------252,NA
https://medium.com/@renebuest/api-economy-as-a-competitive-factor-ipaas-in-the-age-of-the-internet-of-things-iot-and-multi-b59bea0f5865?source=search_post---------253,NA
https://medium.com/altoros-blog/addressing-complex-software-systems-with-microservices-and-ci-cd-5037f89c5f1b?source=search_post---------254,NA
https://medium.com/@codefinger/the-happiest-platform-on-earth-what-the-cloud-can-learn-from-disney-world-e9aaf88393e?source=search_post---------255,NA
https://medium.com/@engineyard/best-practices-for-application-deployment-in-2021-715dae06e676?source=search_post---------256,NA
https://medium.com/altoros-blog/liberty-mutual-delivers-an-insurance-app-in-6-months-with-cloud-foundry-8feb02ff0a81?source=search_post---------257,NA
https://medium.com/@istrategylabs/how-to-effectively-manage-and-avoid-saas-pollution-1c876134cc27?source=search_post---------258,NA
https://medium.com/@pavanbelagatti/mindset-of-a-software-developer-9f988365fe58?source=search_post---------259,NA
https://medium.com/@giuliano/stamplay-launches-on-pivotal-cloud-foundry-platform-d7d4f562c83f?source=search_post---------260,NA
https://medium.com/@alibaba-cloud/web-alibaba-clouds-web-app-service-part-1-a4d17f73cc74?source=search_post---------261,NA
https://medium.com/@mikethebbop/was-oracles-most-recent-quarterly-earnings-report-a-typical-scorecard-on-enterprise-business-52d92210c44f?source=search_post---------262,NA
https://medium.com/altoros-blog/2016-2017-trends-the-open-source-ecosystem-is-universal-f84f3fcb4fd2?source=search_post---------263,NA
https://medium.com/@chupchap/surviving-the-on-demand-economy-13c8f39449f5?source=search_post---------264,NA
https://medium.com/@alibaba-cloud/web-alibaba-clouds-web-app-service-part-2-c97caf7a8a34?source=search_post---------265,NA
https://medium.com/@PeopleAsService/10-expert-employees-at-a-one-person-company-6955f628897c?source=search_post---------266,NA
https://medium.com/@eFileCabinet_57957/xaas-the-good-the-bad-the-ugly-32-experts-share-their-insights-873440976dd9?source=search_post---------267,NA
https://medium.com/@LawrenceHecht/contrarian-look-at-software-spending-42e692bb0071?source=search_post---------268,NA
https://medium.com/altoros-blog/the-year-2016-in-review-top-10-issues-of-enterprise-it-8e73af61b2fe?source=search_post---------269,NA
https://medium.com/@aheadcrm/clash-of-titans-the-war-cry-oracle-and-salesforce-d48dfbc1dfac?source=search_post---------270,NA
https://zef.me/ruby-creator-joins-heroku-562c6141082b?source=search_post---------271,NA
https://medium.com/@aheadcrm/sap-and-microsoft-bring-their-partnership-to-the-next-level-20c555a4d7d9?source=search_post---------272,NA
https://medium.com/@aheadcrm/another-strong-year-for-sap-2b624bbfb26b?source=search_post---------273,NA
https://medium.com/@stfk1105/iaas-paas-saas-%E4%B8%89%E5%85%84%E5%BC%9F-c745dfa0cfd4?source=search_post---------274,NA
https://medium.com/hackernoon/what-is-micro-paas-and-why-its-the-future-of-app-development-3aa30d086703?source=search_post---------275,NA
https://medium.com/@RemindEng/introducing-empire-a-self-hosted-paas-built-on-docker-amazon-ecs-7f8beb7f6ae4?source=search_post---------276,NA
https://itnext.io/knative-kubernetes-native-paas-with-serverless-a1e0a0612943?source=search_post---------277,NA
https://medium.com/hackernoon/paas-a-blessing-or-a-curse-7398c08506bd?source=search_post---------278,NA
https://medium.com/@lucyzhao_/how-paas-companies-calculate-churn-ltv-examples-from-uber-airbnb-plivo-789c6fca1b41?source=search_post---------279,NA
https://bar8.com.br/sap-paas-saas-iaas-f4b176565e04?source=search_post---------280,NA
https://medium.com/volterra-io/control-plane-for-distributed-kubernetes-paas-e20a82acd6d3?source=search_post---------281,NA
https://medium.com/@scott.weiss/knative-kubernetes-native-paas-with-serverless-d06ddfca05a3?source=search_post---------282,NA
https://medium.com/kenshoos-engineering-blog/microcosm-yes-kenshoo-has-also-built-a-paas-17b0ec4c2680?source=search_post---------283,NA
https://medium.com/@doctor_julz/so-i-hear-youre-planning-to-write-a-paas-2a110ced47f0?source=search_post---------284,NA
https://medium.com/@benwang_2362/the-difference-between-iaas-paas-baas-and-saas-91133d728917?source=search_post---------285,NA
https://medium.com/@eosinfra_io/introducing-eosinfra-io-enterprise-grade-paas-for-eos-7b21d3e7fb75?source=search_post---------286,NA
https://medium.com/@sandipd/designing-a-paas-platform-as-a-service-add1e3519b5?source=search_post---------287,NA
https://blog.tsuru.io/tsuru-paas-on-google-cloud-platform-21640abb4386?source=search_post---------288,NA
https://medium.com/@dibmartins/https-medium-com-dibmartins-nanobox-com-php-parte-1-introducao-ao-micro-paas-2355ddfa4589?source=search_post---------289,NA
https://medium.com/@kumarshivam-66534/a-walk-through-on-iaas-paas-and-saas-7e8a4e4793fb?source=search_post---------290,NA
https://medium.com/highly-available-applications-using-ibms-cloud/highly-available-applications-using-ibms-cloud-foundry-paas-part-1-the-underpinnings-b35a92360114?source=search_post---------291,NA
https://blog.drie.co/paas-false-economics-13f72d87b485?source=search_post---------292,NA
https://medium.com/@mike.dvorkin/service-exchange-evolution-of-service-management-in-disaggregated-paas-world-6ca98b4561c3?source=search_post---------293,NA
https://medium.com/@selvaganesh93/diy-how-to-build-own-paas-by-yourself-self-hosted-heroku-architecture-on-ubuntu-3a4a6f4c4f5?source=search_post---------294,NA
https://medium.com/@sandipd/a-kubernetes-paas-on-digitalocean-for-app-developers-e2c75c316d10?source=search_post---------295,NA
https://medium.com/@marcodesanctis2/consume-cosmos-db-or-other-paas-services-from-azure-kubernetes-service-4ee0e304cfc1?source=search_post---------296,NA
https://medium.com/@robachmann/cloud-native-buildpacks-to-unite-paas-and-caas-cac215f53442?source=search_post---------297,NA
https://medium.com/chenjd-xyz/azure-fundamental-iaas-paas-saas-973e0c406de7?source=search_post---------298,NA
https://contos.io/moving-from-old-school-azure-cloud-services-to-v2-azure-paas-cbf1e93547e5?source=search_post---------299,NA
https://medium.com/@doctor_julz/all-about-ux-how-to-build-a-paas-part-deux-12579799743c?source=search_post---------300,NA
https://medium.com/@AwesomePaaS/imap-rfcs-c92960325d1d?source=search_post---------301,NA
https://medium.com/@ALYSShow/4-reasons-why-your-company-should-consider-a-paas-cloud-now-69b60eca9558?source=search_post---------302,NA
https://faun.pub/managing-microsoft-azure-paas-with-ansible-7ca1ecda5b60?source=search_post---------303,NA
https://itnext.io/platform-as-code-elevating-kubernetes-to-next-generation-paas-9b806b565ffc?source=search_post---------304,NA
https://medium.com/@houdinisparks/serverless-faas-eg-aws-lambda-vs-paas-eg-azure-web-apps-ca0e7146b1c4?source=search_post---------305,NA
https://blog.mutable.io/mutable-the-paas-solution-for-5g-edge-compute-infrastructure-688fb7129b94?source=search_post---------306,NA
https://medium.com/@cgrant/deis-workflow-a-paas-on-kubernetes-3f61faabacbc?source=search_post---------307,NA
https://2017doneright.com/flynn-io-host-your-own-heroku-paas-5eaa1eba59e7?source=search_post---------308,NA
https://medium.com/@AwesomePaaS/linagora-at-mix-it-2015-895f764f1749?source=search_post---------309,NA
https://medium.com/@doctor_julz/a-controversial-mission-statement-for-paas-why-paas-must-be-containerless-3e8c65788427?source=search_post---------310,NA
https://medium.com/oracledevs/using-terraform-with-oracle-paas-service-manager-psm-d21f2ddbae3f?source=search_post---------311,NA
https://blog.devgenius.io/iaas-paas-saas-difference-fbed005dd196?source=search_post---------312,NA
https://medium.com/instinctools/choose-the-right-cloud-model-for-your-business-iaas-paas-and-saas-31ba4f56e845?source=search_post---------313,NA
https://medium.com/devobs/le-iaas-et-le-paas-sont-morts-vive-lipaas-e187c552ec7b?source=search_post---------314,NA
https://medium.com/@sachalabourey/paas-between-a-rock8s-and-a-hard-place-fe93f70e212c?source=search_post---------315,NA
https://medium.com/@victorshinya/ibm-cloud-paas-com-cloud-foundry-o-que-define-uma-regi%C3%A3o-1684fac7bc8f?source=search_post---------316,NA
https://medium.com/@shereef-pt/what-is-saas-iaas-paas-cloud-computing-3efa26a61dcf?source=search_post---------317,NA
https://medium.com/@victorshinya/ibm-cloud-paas-com-cloud-foundry-escalando-a-sua-solu%C3%A7%C3%A3o-vertical-e-horizontalmente-6c445bc66a4a?source=search_post---------318,NA
https://medium.com/signal-sciences-labs/how-to-get-started-with-paas-in-heroku-ibm-bluemix-and-pivotal-cca16610249d?source=search_post---------319,NA
https://medium.com/@alielmali/platform-ve-paas-d%C3%BCnyas%C4%B1nda-geli%C5%9Fmelere-dair-notlar-i-ba9c4cef63bf?source=search_post---------320,NA
https://medium.com/@vincent-lui/sitecore-cloud-migration-from-on-premise-to-microsoft-azure-platform-as-a-service-paas-part-1-7a18d9e8a99a?source=search_post---------321,NA
https://medium.com/connect-platform/write-up-adding-a-web-based-remote-shell-to-a-paas-bd1e5f88d2b2?source=search_post---------322,NA
https://medium.com/@brunosimioni/paas-microservices-smac-and-digital-helps-your-company-to-react-quickly-6682d4927dc1?source=search_post---------323,NA
https://medium.com/highly-available-applications-using-ibms-cloud/highly-available-applications-using-ibms-cloud-foundry-paas-part-2-in-practice-f96ee27a267e?source=search_post---------324,NA
https://medium.com/@shubhaat/define-the-cloud-computing-saas-paas-and-iaas-4322b82cc2e2?source=search_post---------325,NA
https://medium.com/prodio-designworks/tradewizer-v3-0-a-market-paas-14099e23f802?source=search_post---------326,NA
https://medium.com/@deep75/d%C3%A9couverte-de-jelastic-paas-lite-edition-dans-digitalocean-65e5fd3122d7?source=search_post---------327,NA
https://medium.com/lattice-research/iot-considerations-server-side-iaas-paas-saas-1f55afc03185?source=search_post---------328,NA
https://medium.com/@mike.bray.ae/azure-paas-and-disaster-recovery-de18ede42c0e?source=search_post---------329,NA
https://medium.com/cloudready-ch/cest-quoi-iaas-paas-et-saas-le-cloud-c169451d73bc?source=search_post---------330,NA
https://medium.com/@thomas.cenni/deploy-a-django-application-with-caprover-paas-60e30475f392?source=search_post---------331,NA
https://medium.com/@ludovicbonivert/paas-and-furious-containers-kubernetes-red-hat-openshift-1e14c7ebb35d?source=search_post---------332,NA
https://medium.com/better-through-code/headless-cms-self-hosted-or-paas-c559b8f938fc?source=search_post---------333,NA
https://medium.com/@deep75/jelastic-combine-paas-et-caas-en-un-seul-package-pour-les-h%C3%A9bergeurs-les-entreprises-de-fe3b0bd18669?source=search_post---------334,NA
https://medium.com/edurator-at-work-and-life/%E7%A7%91%E6%8A%80%E5%BE%8C%E8%8F%9C%E9%B3%A5%E7%9A%84%E5%AD%97%E8%A9%9E%E5%85%B8-%E9%9B%B2%E7%AB%AF%E5%B7%A5%E5%85%B7%E6%A6%82%E5%BF%B5%E7%AF%87-iaas-paas-saas-9624ac7f657?source=search_post---------335,NA
https://medium.com/@einnovator/the-evolution-of-paas-cloud-manager-a-new-multicloud-platform-built-on-kubernetes-e8fa1c60273f?source=search_post---------336,NA
https://medium.com/@wbfny/hydrogen-more-than-a-paas-provider-a-visionary-within-the-rising-decentralized-economy-a6d13f1f47bc?source=search_post---------337,NA
https://medium.com/@vincent-lui/sitecore-melbourne-meetup-may-23rd-2019-pain-points-from-iaas-to-paas-aaf0172985df?source=search_post---------338,NA
https://aws.plainenglish.io/dont-pass-on-paas-67308e432a96?source=search_post---------339,NA
https://medium.com/hackernoon/how-to-choose-cloud-hosting-for-ecommerce-saas-vs-paas-vs-iaas-f710c6295b8d?source=search_post---------340,NA
https://medium.com/@vincent-lui/sitecore-cloud-migration-from-on-premise-to-microsoft-azure-platform-as-a-service-paas-part-2-9e1cdff2fbd2?source=search_post---------341,NA
https://medium.com/hackernoon/paas-for-dummies-what-is-platform-as-a-service-a8a5df8a197f?source=search_post---------342,NA
https://medium.com/@pishchulin/high-performance-messaging-service-for-paas-and-web-applications-7f588e40fe5a?source=search_post---------343,NA
https://medium.com/zero-equals-false/iaas-vs-paas-infrastructure-as-a-service-vs-platform-as-a-service-ade4fd55b027?source=search_post---------344,NA
https://medium.com/@Zengularity/paas-quand-la-production-dapplications-devient-un-non-%C3%A9v%C3%A8nement-8373f2d55870?source=search_post---------345,NA
https://medium.com/nerd-for-tech/1-cloud-series-the-iaas-paas-saas-8faa46124722?source=search_post---------346,NA
https://medium.com/@lalitadithya/how-to-save-money-by-turning-off-your-azure-paas-resources-7209a5c5fbb4?source=search_post---------347,NA
https://chatbotslife.com/its-time-to-paas-personal-assistant-as-a-service-f342cf1255e0?source=search_post---------348,NA
https://medium.com/ecfmg-engineering/got-legacy-net-b17d1f7602e9?source=search_post---------349,NA
https://medium.com/@AwesomePaaS/openpaas-ux-documentation-for-everyone-a0b8ba91a6b6?source=search_post---------350,NA
https://medium.com/@jacklyu/an-economics-analysis-of-decentralized-saas-and-paas-39c70744eaef?source=search_post---------351,NA
https://medium.com/@jelastic/what-is-paas-platform-as-a-service-types-explained-e6ca128fbff4?source=search_post---------352,NA
https://medium.com/@marirsgo/ai-driven-design-thinking-solution-capabilities-to-consider-for-ai-driven-paas-and-saas-products-6fde8fb6d5cd?source=search_post---------353,NA
https://blog.tsuru.io/tsuru-at-london-paas-user-group-lopug-17cecf0bd98c?source=search_post---------354,NA
https://medium.com/@vbcloudboy/setup-basic-paas-based-web-application-on-azure-using-terraform-private-modules-1713bd616709?source=search_post---------355,NA
https://medium.com/@drpdishant/your-own-self-hosted-paas-platform-as-a-service-server-using-tsuru-2ef9bc90ed5b?source=search_post---------356,NA
https://medium.com/@arjenvanveen_97343/example-of-a-ci-cd-setup-for-sitecore-paas-on-azure-64ec8996724a?source=search_post---------357,NA
https://medium.com/@BreezeTelecom/saas-paas-and-iaas-how-and-when-to-use-a90f526f10ae?source=search_post---------358,NA
https://medium.com/@elie29/deploy-quarkus-application-with-gitlab-ci-to-heroku-paas-72c0e9214669?source=search_post---------359,NA
https://medium.com/pixboost/clouds-cloud-computing-explained-5e1c8dea14a4?source=search_post---------360,NA
https://medium.com/@fabinfo/blockchains-and-paas-business-models-ff9439db797a?source=search_post---------361,NA
https://medium.com/@vincent-lui/sitecore-cloud-migration-from-on-premise-to-microsoft-azure-platform-as-a-service-paas-part-3-789ecb289755?source=search_post---------362,NA
https://medium.com/@imanzia28/meray-paas-tum-ho-bellows-an-unprecedented-look-into-female-driven-infidelity-in-pakistan-a19ddcbd2dc8?source=search_post---------363,NA
https://medium.com/@thallukrish/paas-6ed7ea22d55b?source=search_post---------364,NA
https://medium.com/@pishchulin/what-we-are-missing-in-modern-paas-1bdf40eb2dbe?source=search_post---------365,NA
https://medium.com/strykz/football-stars-a-platform-as-a-service-paas-3bff9fa99112?source=search_post---------366,NA
https://medium.com/@sefidrodi/sad-startup-stories-or-the-real-cost-of-trying-to-establish-an-paas-saas-business-de4556299c0f?source=search_post---------367,NA
https://medium.com/who-what-with/web-directions-respond-2017-9ac0b965ea15?source=search_post---------368,NA
https://medium.com/@pikumar/trends-in-i-ntegration-paas-e04ea6b54476?source=search_post---------369,NA
https://medium.com/@mrrishisingh/iaas-paas-and-saas-57bef8fdf19a?source=search_post---------370,NA
https://medium.com/@joaovagner/a-menor-implementacao-paas-que-voce-ja-viu-a1d0bca6e51c?source=search_post---------371,NA
https://medium.com/@kingofpaas/when-i-knew-i-was-in-the-wrong-company-part-i-9f66a9db7f9f?source=search_post---------372,NA
https://medium.com/@aytanvahidova/saas-paas-and-iaas-in-oracle-cloud-computing-7e5592266e69?source=search_post---------373,NA
https://medium.com/@bluenimbleinc/mystifying-paas-a6a0f2e2026e?source=search_post---------374,NA
https://medium.com/@rahulsethuram/theres-another-option-that-isn-t-quite-mentioned-which-is-the-paas-approach-85d1e7efc480?source=search_post---------375,NA
https://medium.com/@focaloidtechnologies/saas-vs-paas-vs-iaas-fee5e382a397?source=search_post---------376,NA
https://medium.com/techstack-ltd/what-type-of-a-cloud-service-do-you-need-saas-paas-or-iaas-32538fcfc064?source=search_post---------377,NA
https://medium.com/@exclusiveplatform/exclusive-platform-introduces-platform-as-a-service-paas-a-blockchain-project-implementation-9abc2a44eef1?source=search_post---------378,NA
https://medium.com/@unipaygateway/the-word-of-cloud-computting-saas-paas-iaas-and-more-d49a7e05a9db?source=search_post---------379,NA
https://medium.com/@Cycligent/what-paas-is-doing-wrong-abca5ceaedae?source=search_post---------380,NA
https://medium.com/@victor.oliveira.comp/production-ready-kubernetes-paas-in-a-couple-of-easy-steps-iaas-included-174fe64be881?source=search_post---------381,NA
https://medium.com/@salmansaleem920/iaas-vs-paas-infrastructure-as-a-service-vs-platform-as-a-service-e23b51d9868a?source=search_post---------382,NA
https://medium.com/cloudready-ch/azure-paas-gratuit-886f9e792181?source=search_post---------383,NA
https://blog.containership.io/iaas-vs-paas-vs-caas-which-cloud-architecture-is-right-for-you-part-1-c7bf3c48c70c?source=search_post---------384,NA
https://blog.containership.io/iaas-vs-paas-vs-caas-which-cloud-architecture-is-right-for-you-part-2-a72623d7d001?source=search_post---------385,NA
https://medium.com/mess-up/saas-paas-iaas%E6%AF%94%E8%BC%83-7d98cf52b194?source=search_post---------386,NA
https://saasholic.com/saas-iaas-paas-haas-as-diferentes-faces-do-as-a-service-infogr%C3%A1fico-c3cd842c5b34?source=search_post---------387,NA
https://medium.com/itmagination/building-a-scalable-data-warehouse-in-the-cloud-with-paas-sion-3421b211bc21?source=search_post---------388,NA
https://medium.com/nttlabs/ois-denver-2019-d8ae8aaa1f1b?source=search_post---------389,NA
https://medium.com/radixweb/choosing-the-right-cloud-computing-service-model-for-your-business-saas-iaas-paas-or-daas-15d72d7ec98c?source=search_post---------390,NA
https://thinking.philosophie.is/create-your-own-paas-with-dokku-22cf92d28444?source=search_post---------391,NA
https://medium.com/analytics-vidhya/implement-ptc-thingworx-in-azure-paas-4ec7270f5c7e?source=search_post---------392,NA
https://medium.com/@woodystonian/from-self-driving-car-to-paas-of-transportation-87bd8a5a6827?source=search_post---------393,NA
https://medium.com/@rahulrandive09/how-to-create-user-and-logins-in-azure-sql-paas-db-726a2850d72d?source=search_post---------394,NA
https://medium.com/@rstarmer/understanding-the-business-value-of-cloud-services-saas-paas-and-iaas-6b2d5579f52f?source=search_post---------397,NA
